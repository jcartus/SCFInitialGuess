{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jcartus/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from os.path import join\n",
    "\n",
    "plt.style.use([\"seaborn\", \"thesis\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SCFInitialGuess.utilities.dataset import extract_triu_batch, AbstractDataset\n",
    "\n",
    "data_path = \"../../dataset/TSmall_sto3g\"\n",
    "postfix = \"TSmall_sto3g\"\n",
    "dim = 26\n",
    "\n",
    "S = np.load(join(data_path, \"S\" + postfix + \".npy\"))\n",
    "P = np.load(join(data_path, \"P\" + postfix + \".npy\"))\n",
    "F = np.load(join(data_path, \"F\" + postfix + \".npy\"))\n",
    "\n",
    "index = np.load(join(data_path, \"index\" + postfix + \".npy\"))\n",
    "\n",
    "molecules = np.load(join(data_path, \"molecules\" + postfix + \".npy\"))\n",
    "\n",
    "def split(x, y, ind):\n",
    "    return x[:ind], y[:ind], x[ind:], y[ind:]\n",
    "\n",
    "S = np.load(join(data_path, \"S\" + postfix + \".npy\"))\n",
    "P = np.load(join(data_path, \"P\" + postfix + \".npy\"))\n",
    "F = np.load(join(data_path, \"F\" + postfix + \".npy\"))\n",
    "\n",
    "index = np.load(join(data_path, \"index\" + postfix + \".npy\"))\n",
    "\n",
    "molecules = np.load(join(data_path, \"molecules\" + postfix + \".npy\"))\n",
    "\n",
    "\n",
    "\n",
    "ind = int(0.8 * len(index))\n",
    "\n",
    "s_triu = extract_triu_batch(S, dim)\n",
    "p_triu = extract_triu_batch(P, dim)\n",
    "\n",
    "s_triu_norm, mu, std = AbstractDataset.normalize(s_triu)\n",
    "\n",
    "\n",
    "s_train, p_train, s_test, p_test = split(s_triu_norm, p_triu, ind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Utilities "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model generation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_triu = dim * (dim + 1) // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "intializer = keras.initializers.TruncatedNormal(mean=0.0, stddev=0.01)\n",
    "\n",
    "def build_model(activation, structure, learning_rate):\n",
    "\n",
    "\n",
    "\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    # input layer\n",
    "    model.add(keras.layers.Dense(dim_triu, activation=activation, input_dim=dim_triu, kernel_initializer=intializer, bias_initializer='zeros'))\n",
    "\n",
    "    # hidden\n",
    "    for layer in structure:\n",
    "\n",
    "        model.add(keras.layers.Dense(\n",
    "                layer, \n",
    "                activation=activation, \n",
    "                kernel_initializer=intializer, \n",
    "                #bias_initializer='zeros',\n",
    "                #kernel_regularizer=keras.regularizers.l2(1e-8)\n",
    "        ))\n",
    "\n",
    "\n",
    "    #output\n",
    "    model.add(keras.layers.Dense(dim_triu))\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate), loss='MSE', metrics=['mae', 'mse'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_mean_squared_error\", \n",
    "    min_delta=1e-7, \n",
    "    patience=50, \n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss', \n",
    "    factor=0.5, \n",
    "    patience=10, \n",
    "    verbose=1, \n",
    "    mode='auto', \n",
    "    min_delta=1e-5, \n",
    "    cooldown=10, \n",
    "    min_lr=1e-10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tests = 5\n",
    "n_resets = 3\n",
    "epochs = 10000\n",
    "\n",
    "\n",
    "def test_model(structure, activation, learning_rate=1e-4):\n",
    "    error = []\n",
    "    \n",
    "    for i in range(n_tests):\n",
    "        \n",
    "        keras.backend.clear_session()\n",
    "        model = build_model(activation, structure, learning_rate)\n",
    "        \n",
    "        for j in range(n_resets):\n",
    "            keras.backend.set_value(model.optimizer.lr, learning_rate)\n",
    "            \n",
    "            history = model.fit(\n",
    "                x = s_train,\n",
    "                y = p_train,\n",
    "                epochs=epochs,\n",
    "                shuffle=True,\n",
    "                validation_data=(s_test, p_test), \n",
    "                verbose=0, \n",
    "                callbacks=[\n",
    "                    early_stopping, \n",
    "                    reduce_lr\n",
    "                ]\n",
    "            )\n",
    "        \n",
    "        error.append(np.min(history.history[\"val_mean_absolute_error\"]))\n",
    "        \n",
    "        print(\" - Test \" + str(i+1) + \": \" + str(error[-1]))\n",
    "    \n",
    "    return error\n",
    "\n",
    "def run_layer_test_series(activation, structures, learning_rate):\n",
    "    error = []\n",
    "    for structure in structures:\n",
    "        print(\"Layers: \" + str(structure))\n",
    "        error.append(test_model(structure, activation, learning_rate=learning_rate))\n",
    "    return error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "structures = [\n",
    "        [dim_triu, dim_triu],\n",
    "        [dim_triu, dim_triu, dim_triu],\n",
    "        [dim_triu + 100, dim_triu + 100],\n",
    "        [dim_triu + 250, dim_triu + 150, dim_triu + 50],\n",
    "        #[dim_triu + 100, dim_triu + 200, dim_triu + 100],\n",
    "        #[dim_triu * 2]\n",
    "    ]\n",
    "        \n",
    "learning_rates = [1e-3, 1e-4, 1e-5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# lr0.001\n",
      "Layers: [351, 351]\n",
      "\n",
      "Epoch 00067: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00091: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00110: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00129: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00148: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00167: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00186: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00205: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00224: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00243: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00262: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00281: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00300: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "Epoch 00306: early stopping\n",
      "\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00070: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00089: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00108: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00127: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00146: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00165: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00184: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00203: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00222: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00241: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00260: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "Epoch 00273: early stopping\n",
      "\n",
      "Epoch 00061: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00080: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00099: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00118: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00137: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00156: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00175: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00194: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00213: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00232: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00251: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00270: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "Epoch 00284: early stopping\n",
      " - Test 1: 0.004371648934665159\n",
      "\n",
      "Epoch 00082: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00110: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00129: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00148: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00167: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00193: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00212: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00231: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00250: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00269: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00288: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00307: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "Epoch 00320: early stopping\n",
      "\n",
      "Epoch 00071: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00100: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00119: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00138: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00157: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00176: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00195: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00214: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00233: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00252: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00271: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00290: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00309: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 00328: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "Epoch 00342: early stopping\n",
      "\n",
      "Epoch 00070: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00097: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00116: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00135: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00154: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00173: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00192: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00211: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00230: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00249: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00268: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00287: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00306: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "Epoch 00315: early stopping\n",
      " - Test 2: 0.005041269372351727\n",
      "\n",
      "Epoch 00072: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00091: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00110: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00129: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00148: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00167: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00186: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00205: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00224: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00243: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00262: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00281: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00300: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "Epoch 00315: early stopping\n",
      "\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00083: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00102: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00121: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00140: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00159: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00178: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00197: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00216: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00235: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00254: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00273: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "Epoch 00291: early stopping\n",
      "\n",
      "Epoch 00056: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00075: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00094: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00113: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00132: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00151: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00170: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00189: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00208: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00227: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00246: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00265: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00284: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 00303: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 00322: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "Epoch 00322: early stopping\n",
      " - Test 3: 0.0045623869069884365\n",
      "\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00093: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00112: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00131: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00150: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00169: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00188: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00207: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00226: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00245: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00264: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00283: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00302: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "Epoch 00304: early stopping\n",
      "\n",
      "Epoch 00069: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00088: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00107: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00126: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00145: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00164: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00183: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00202: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00221: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00240: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00259: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00278: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "Epoch 00291: early stopping\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00069: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00088: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00107: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00126: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00145: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00164: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00183: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00202: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00221: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00240: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00259: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00278: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "Epoch 00290: early stopping\n",
      " - Test 4: 0.004443981005944571\n",
      "\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00084: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00103: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00122: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00141: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00160: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00179: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00198: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00217: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00236: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00255: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00274: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00293: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 00312: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "Epoch 00330: early stopping\n",
      "\n",
      "Epoch 00061: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00080: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00099: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00118: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00137: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00156: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00175: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00194: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00213: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00232: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00251: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00270: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "Epoch 00283: early stopping\n",
      "\n",
      "Epoch 00061: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00080: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00099: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00118: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00137: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00156: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00175: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00194: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00213: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00232: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00251: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00270: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "Epoch 00283: early stopping\n",
      " - Test 5: 0.004331552117729365\n",
      "Layers: [351, 351, 351]\n",
      "\n",
      "Epoch 00083: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00109: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00128: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00147: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00166: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00185: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00210: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00229: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00248: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00267: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00286: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00305: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00324: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "Epoch 00333: early stopping\n",
      "\n",
      "Epoch 00087: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00116: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00141: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00160: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00179: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00198: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00217: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00236: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00255: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00274: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00293: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00312: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00331: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "Epoch 00334: early stopping\n",
      "\n",
      "Epoch 00069: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00088: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00107: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00126: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00145: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00164: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00183: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00202: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00221: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00240: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00259: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00278: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00297: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "Epoch 00310: early stopping\n",
      " - Test 1: 0.004900958511830118\n",
      "\n",
      "Epoch 00074: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00097: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00124: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00145: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00164: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00183: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00202: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00230: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00249: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00268: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00287: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00306: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00325: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 00344: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "Epoch 00361: early stopping\n",
      "\n",
      "Epoch 00127: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00146: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00165: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00184: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00203: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00222: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00241: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00260: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00279: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00298: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00317: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00336: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00355: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 00374: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 00393: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "\n",
      "Epoch 00412: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "Epoch 00412: early stopping\n",
      "\n",
      "Epoch 00107: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00126: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00154: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00173: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00192: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00211: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00230: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00249: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00268: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00287: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00306: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00325: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00344: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 00363: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 00382: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "Epoch 00386: early stopping\n",
      " - Test 2: 0.006969674881918365\n",
      "\n",
      "Epoch 00102: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00122: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00141: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00163: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00182: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00201: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00220: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00239: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00258: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00277: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00296: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00315: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00334: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "Epoch 00352: early stopping\n",
      "\n",
      "Epoch 00071: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00092: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00113: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00132: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00151: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00170: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00189: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00208: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00227: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00246: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00265: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00284: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00303: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 00322: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 00341: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "Epoch 00349: early stopping\n",
      "\n",
      "Epoch 00057: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00083: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00102: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00121: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00140: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00159: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00178: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00199: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00218: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00237: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00256: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00275: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00294: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 00313: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "Epoch 00315: early stopping\n",
      " - Test 3: 0.006097742101520448\n",
      "\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00122: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00148: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00167: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00186: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00205: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00224: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00243: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00262: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00281: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00300: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00319: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00338: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 00357: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "Epoch 00358: early stopping\n",
      "\n",
      "Epoch 00072: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00091: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00110: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00129: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00148: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00167: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00186: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00205: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00224: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00243: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00262: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00281: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00300: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 00319: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 00338: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "Epoch 00349: early stopping\n",
      "\n",
      "Epoch 00091: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00123: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00142: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00161: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00180: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00199: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00218: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00237: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00256: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00275: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00294: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00313: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00332: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 00351: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 00370: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "Epoch 00377: early stopping\n",
      " - Test 4: 0.007107340126062062\n",
      "\n",
      "Epoch 00095: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00114: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00133: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00152: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00171: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00190: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00209: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00228: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00247: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00266: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00285: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00304: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00323: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 00342: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "Epoch 00351: early stopping\n",
      "\n",
      "Epoch 00086: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00105: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00124: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00143: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00162: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00181: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00200: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00219: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00238: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00257: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00276: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00295: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00314: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "Epoch 00331: early stopping\n",
      "\n",
      "Epoch 00172: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00223: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00249: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00268: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00287: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00306: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00325: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00344: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00363: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00382: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00401: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00420: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00439: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 00458: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 00477: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "Epoch 00483: early stopping\n",
      " - Test 5: 0.0073554520981747714\n",
      "Layers: [451, 451]\n",
      "\n",
      "Epoch 00069: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00088: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00107: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00127: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00146: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00165: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00184: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00203: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00222: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00241: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00260: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00279: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00298: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "Epoch 00298: early stopping\n",
      "\n",
      "Epoch 00070: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00095: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00121: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00140: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00159: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00178: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00197: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00216: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00235: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00254: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00273: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00292: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "Epoch 00306: early stopping\n",
      "\n",
      "Epoch 00065: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00084: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00103: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00122: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00141: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00160: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00179: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00198: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00217: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00236: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00255: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00274: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00293: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "Epoch 00301: early stopping\n",
      " - Test 1: 0.004863027242285696\n",
      "\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00074: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00093: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00112: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00131: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00160: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00179: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00198: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00217: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00236: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00255: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00274: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00293: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 00312: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "Epoch 00317: early stopping\n",
      "\n",
      "Epoch 00076: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00095: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00114: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00139: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00158: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00177: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00196: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00215: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00234: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00253: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00272: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00291: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00310: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 00329: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "Epoch 00343: early stopping\n",
      "\n",
      "Epoch 00082: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00109: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00128: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00147: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00166: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00194: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00213: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00232: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00251: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00270: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00289: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00308: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00327: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "Epoch 00341: early stopping\n",
      " - Test 2: 0.004882841822760764\n",
      "\n",
      "Epoch 00062: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00088: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00107: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00126: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00145: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00164: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00183: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00202: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00221: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00240: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00259: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00278: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00297: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "Epoch 00298: early stopping\n",
      "\n",
      "Epoch 00085: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00109: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00128: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00147: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00166: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00185: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00204: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00223: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00242: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00261: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00280: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00299: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00318: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 00337: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "Epoch 00342: early stopping\n",
      "\n",
      "Epoch 00079: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00099: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00118: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00137: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00156: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00175: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00194: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00213: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00232: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00251: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00270: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00289: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00308: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 00327: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "Epoch 00330: early stopping\n",
      " - Test 3: 0.00683164033362299\n",
      "\n",
      "Epoch 00070: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00089: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00108: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00134: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00153: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00172: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00191: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00210: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00229: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00248: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00267: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00286: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00305: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 00324: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "Epoch 00331: early stopping\n",
      "\n",
      "Epoch 00089: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00115: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00134: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00153: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00172: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00191: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00210: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00229: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00248: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00267: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00286: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00305: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00324: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 00343: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "Epoch 00351: early stopping\n",
      "\n",
      "Epoch 00095: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00120: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00141: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00160: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00182: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00201: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00220: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00239: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00258: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00277: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00296: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00315: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00334: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 00353: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "Epoch 00363: early stopping\n",
      " - Test 4: 0.007101774252765807\n",
      "\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00089: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00108: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00127: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00146: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00165: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00184: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00203: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00222: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00241: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00260: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00279: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00298: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "Epoch 00298: early stopping\n",
      "\n",
      "Epoch 00068: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00087: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00106: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00125: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00144: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00163: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00182: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00201: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00220: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00239: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00258: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00277: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00296: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 00315: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "Epoch 00332: early stopping\n",
      "\n",
      "Epoch 00079: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00101: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00120: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00139: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00158: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00177: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00196: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00215: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00234: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00253: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00272: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00291: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00310: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 00329: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 00348: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "Epoch 00354: early stopping\n",
      " - Test 5: 0.005966048696963348\n",
      "Layers: [601, 501, 401]\n",
      "\n",
      "Epoch 00075: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00105: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00134: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00158: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00177: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00196: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00215: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00234: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00253: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00272: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00291: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00310: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00329: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "Epoch 00336: early stopping\n",
      "\n",
      "Epoch 00219: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00286: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00305: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00324: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00343: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00362: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00384: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00403: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00422: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00441: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00460: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00479: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00498: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 00517: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 00536: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "Epoch 00542: early stopping\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00077: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00096: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00115: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00134: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00153: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00172: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00191: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "Epoch 00199: early stopping\n",
      " - Test 1: 0.060594590742196607\n",
      "\n",
      "Epoch 00072: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00102: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00131: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00153: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00172: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00191: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00210: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00229: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00248: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00267: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00286: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00305: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00324: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 00343: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "Epoch 00349: early stopping\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00068: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00270: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00928: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00947: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00972: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00991: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 01010: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 01029: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 01048: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 01067: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 01088: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 01107: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 01126: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "\n",
      "Epoch 01145: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "\n",
      "Epoch 01164: ReduceLROnPlateau reducing learning rate to 7.629394893626795e-09.\n",
      "Epoch 01175: early stopping\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00056: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00075: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00094: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00113: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00132: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00151: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00170: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00189: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "Epoch 00192: early stopping\n",
      " - Test 2: 0.06064464111084962\n",
      "\n",
      "Epoch 00077: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00102: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00131: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00156: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00175: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00194: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00213: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00232: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00251: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00270: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00289: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00308: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00327: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 00346: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 00365: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "Epoch 00370: early stopping\n",
      "\n",
      "Epoch 00307: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00346: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00365: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00384: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00403: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00422: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00441: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00460: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00479: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00498: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00517: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00536: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00555: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 00574: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 00593: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "Epoch 00602: early stopping\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00054: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00073: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00092: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00111: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00130: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00149: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00168: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00187: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "Epoch 00189: early stopping\n",
      " - Test 3: 0.06062390788722394\n",
      "\n",
      "Epoch 00079: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00101: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00120: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00139: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00158: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00185: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00204: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00223: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00242: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00261: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00280: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00299: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00318: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "Epoch 00336: early stopping\n",
      "\n",
      "Epoch 00193: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00221: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00242: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00261: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00280: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00299: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00318: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00337: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00356: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00375: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00394: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00413: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00432: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 00451: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 00470: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "Epoch 00483: early stopping\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00062: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00081: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00100: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00119: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00138: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00157: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00176: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00195: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00214: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "Epoch 00221: early stopping\n",
      " - Test 4: 0.06064339365754554\n",
      "\n",
      "Epoch 00070: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00103: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00130: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00149: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00168: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00187: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00206: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00229: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00248: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00267: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00286: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00305: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00324: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 00343: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 00362: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "Epoch 00362: early stopping\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00176: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00202: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00223: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00251: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00273: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00301: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00320: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00339: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00365: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00384: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00403: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 00422: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 00441: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "Epoch 00452: early stopping\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00072: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00094: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00121: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00144: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00167: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00186: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00205: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00224: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "Epoch 00237: early stopping\n",
      " - Test 5: 0.060594414819532365\n",
      "# lr0.0001\n",
      "Layers: [351, 351]\n",
      "\n",
      "Epoch 00179: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00203: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00222: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00243: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00262: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00281: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00300: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00319: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00338: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00357: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00376: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00395: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "\n",
      "Epoch 00414: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-08.\n",
      "Epoch 00430: early stopping\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00071: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00090: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00109: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00128: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00147: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00166: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00185: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00204: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00223: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "Epoch 00235: early stopping\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00088: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00107: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00126: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00145: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00164: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00183: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00202: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00221: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00240: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "\n",
      "Epoch 00259: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-08.\n",
      "Epoch 00264: early stopping\n",
      " - Test 1: 0.005429708391928406\n",
      "\n",
      "Epoch 00119: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00197: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00220: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00239: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00267: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00286: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00305: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00324: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00343: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00362: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00381: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00400: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "\n",
      "Epoch 00419: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-08.\n",
      "Epoch 00426: early stopping\n",
      "\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00071: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00090: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00109: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00128: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00147: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00166: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00185: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00204: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00223: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00242: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "Epoch 00260: early stopping\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00063: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00082: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00101: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00120: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00139: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00158: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00177: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00196: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00215: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "Epoch 00232: early stopping\n",
      " - Test 2: 0.0056002076566960685\n",
      "\n",
      "Epoch 00152: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00204: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00233: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00252: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00271: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00290: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00309: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00328: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00347: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00366: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00385: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00411: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "\n",
      "Epoch 00430: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-08.\n",
      "\n",
      "Epoch 00449: ReduceLROnPlateau reducing learning rate to 6.103515470812226e-09.\n",
      "Epoch 00463: early stopping\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00071: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00090: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00109: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00128: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00147: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00166: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00185: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00204: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00223: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00242: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "Epoch 00253: early stopping\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00063: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00082: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00101: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00120: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00139: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00158: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00177: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00196: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00215: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "Epoch 00217: early stopping\n",
      " - Test 3: 0.0058055867357596535\n",
      "\n",
      "Epoch 00153: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00214: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00233: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00252: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00271: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00290: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00312: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00331: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00350: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00369: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00388: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00407: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "\n",
      "Epoch 00426: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-08.\n",
      "Epoch 00429: early stopping\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00083: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00102: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00121: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00140: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00159: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00178: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00197: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00216: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00235: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "Epoch 00242: early stopping\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00071: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00090: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00109: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00128: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00147: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00166: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00185: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00204: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00223: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "Epoch 00226: early stopping\n",
      " - Test 4: 0.005601137718973468\n",
      "\n",
      "Epoch 00129: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00207: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00233: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00252: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00271: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00292: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00311: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00330: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00349: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00368: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00387: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00406: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "\n",
      "Epoch 00425: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-08.\n",
      "Epoch 00429: early stopping\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00062: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00081: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00100: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00119: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00138: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00157: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00176: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00195: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00214: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00233: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "Epoch 00247: early stopping\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00066: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00085: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00104: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00123: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00142: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00161: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00180: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00199: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00218: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "Epoch 00221: early stopping\n",
      " - Test 5: 0.0057823209865806415\n",
      "Layers: [351, 351, 351]\n",
      "\n",
      "Epoch 00218: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00284: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00303: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00322: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00341: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00369: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00388: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00407: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00426: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00445: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00464: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00483: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "\n",
      "Epoch 00502: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-08.\n",
      "Epoch 00516: early stopping\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00062: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00081: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00110: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00129: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00148: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00167: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00186: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00205: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00224: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00243: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "\n",
      "Epoch 00262: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-08.\n",
      "Epoch 00277: early stopping\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00080: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00099: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00118: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00137: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00156: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00175: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00194: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00213: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "Epoch 00224: early stopping\n",
      " - Test 1: 0.005654134604598011\n",
      "\n",
      "Epoch 00252: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00271: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00290: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00309: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00328: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00347: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00366: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00385: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00404: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00423: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00442: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00461: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "\n",
      "Epoch 00480: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-08.\n",
      "\n",
      "Epoch 00499: ReduceLROnPlateau reducing learning rate to 6.103515470812226e-09.\n",
      "Epoch 00499: early stopping\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00072: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00091: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00116: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00135: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00154: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00173: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00192: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00211: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00230: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00249: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "Epoch 00257: early stopping\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00054: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00073: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00092: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00111: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00130: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00149: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00168: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00187: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00206: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "Epoch 00208: early stopping\n",
      " - Test 2: 0.006005877561737501\n",
      "\n",
      "Epoch 00185: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00276: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00297: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00316: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00335: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00354: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00373: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00392: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00411: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00430: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00449: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00468: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "\n",
      "Epoch 00487: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-08.\n",
      "\n",
      "Epoch 00506: ReduceLROnPlateau reducing learning rate to 6.103515470812226e-09.\n",
      "Epoch 00515: early stopping\n",
      "\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00066: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00085: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00104: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00123: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00147: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00166: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00185: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00204: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00223: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00242: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00261: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "Epoch 00272: early stopping\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00074: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00093: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00112: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00131: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00150: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00169: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00188: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00207: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00226: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00245: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "Epoch 00250: early stopping\n",
      " - Test 3: 0.0057738983924894485\n",
      "\n",
      "Epoch 00247: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00269: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00288: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00307: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00326: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00345: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00364: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00383: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00402: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00421: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00440: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00459: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "\n",
      "Epoch 00478: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-08.\n",
      "Epoch 00494: early stopping\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00060: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00079: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00098: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00127: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00146: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00165: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00184: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00203: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00222: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00241: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00260: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "Epoch 00271: early stopping\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00057: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00076: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00095: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00114: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00133: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00152: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00171: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00190: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00209: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00228: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "Epoch 00240: early stopping\n",
      " - Test 4: 0.006204206172135932\n",
      "\n",
      "Epoch 00262: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00281: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00300: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00319: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00338: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00357: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00376: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00395: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00414: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00433: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00452: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00471: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "\n",
      "Epoch 00490: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-08.\n",
      "Epoch 00491: early stopping\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00069: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00088: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00107: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00126: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00152: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00171: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00190: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00209: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00228: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00247: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "Epoch 00257: early stopping\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00083: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00102: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00121: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00140: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00159: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00178: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00197: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00216: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "Epoch 00226: early stopping\n",
      " - Test 5: 0.006162674444268888\n",
      "Layers: [451, 451]\n",
      "\n",
      "Epoch 00163: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00190: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00209: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00238: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00257: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00276: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00295: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00314: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00333: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00352: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00371: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00390: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "\n",
      "Epoch 00409: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-08.\n",
      "Epoch 00411: early stopping\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00059: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00078: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00097: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00116: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00135: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00154: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00173: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00192: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00211: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00230: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "Epoch 00236: early stopping\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00077: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00096: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00115: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00134: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00153: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00172: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00191: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00210: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "Epoch 00222: early stopping\n",
      " - Test 1: 0.00543447475491175\n",
      "\n",
      "Epoch 00172: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00191: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00210: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00233: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00252: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00271: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00290: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00309: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00328: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00347: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00366: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00385: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "\n",
      "Epoch 00404: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-08.\n",
      "Epoch 00419: early stopping\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00060: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00079: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00098: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00117: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00136: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00155: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00174: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00193: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00212: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "Epoch 00219: early stopping\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00062: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00081: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00100: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00119: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00138: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00157: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00176: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00195: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00214: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "Epoch 00220: early stopping\n",
      " - Test 2: 0.005242081599967989\n",
      "\n",
      "Epoch 00140: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00174: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00203: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00227: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00246: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00265: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00284: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00313: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00332: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00351: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00370: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00389: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "\n",
      "Epoch 00408: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-08.\n",
      "\n",
      "Epoch 00427: ReduceLROnPlateau reducing learning rate to 6.103515470812226e-09.\n",
      "Epoch 00445: early stopping\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00068: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00087: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00106: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00128: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00147: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00166: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00185: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00204: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00223: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00242: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "Epoch 00242: early stopping\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00057: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00076: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00095: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00114: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00133: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00152: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00171: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00190: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00209: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "Epoch 00217: early stopping\n",
      " - Test 3: 0.005401377137565049\n",
      "\n",
      "Epoch 00172: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00200: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00219: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00238: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00257: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00276: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00295: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00314: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00333: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00352: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00371: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00390: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "Epoch 00398: early stopping\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00065: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00084: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00103: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00122: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00141: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00160: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00179: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00198: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00217: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00236: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "\n",
      "Epoch 00255: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-08.\n",
      "Epoch 00267: early stopping\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00066: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00085: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00104: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00123: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00142: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00161: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00180: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00199: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00218: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "Epoch 00231: early stopping\n",
      " - Test 4: 0.0051222567895974095\n",
      "\n",
      "Epoch 00119: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00175: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00200: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00219: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00238: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00257: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00276: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00295: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00314: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00333: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00352: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00371: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "\n",
      "Epoch 00390: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-08.\n",
      "Epoch 00403: early stopping\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00062: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00081: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00100: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00119: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00147: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00166: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00185: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00204: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00223: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00242: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00261: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "Epoch 00274: early stopping\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00059: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00078: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00097: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00116: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00135: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00154: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00173: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00192: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "Epoch 00206: early stopping\n",
      " - Test 5: 0.005412953847843171\n",
      "Layers: [601, 501, 401]\n",
      "\n",
      "Epoch 00167: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00251: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00277: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00298: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00317: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00336: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00355: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00374: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00393: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00412: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00431: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00450: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "Epoch 00466: early stopping\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00074: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00093: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00112: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00131: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00150: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00169: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00188: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00207: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00226: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00245: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "Epoch 00246: early stopping\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00067: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00086: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00105: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00124: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00143: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00162: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00181: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00200: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "Epoch 00215: early stopping\n",
      " - Test 1: 0.0054523425561315685\n",
      "\n",
      "Epoch 00188: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00215: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00234: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00253: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00272: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00294: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00313: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00332: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00351: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00370: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00389: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00408: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "\n",
      "Epoch 00427: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-08.\n",
      "Epoch 00439: early stopping\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00074: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00093: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00112: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00131: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00150: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00169: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00188: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00207: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00226: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00245: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "\n",
      "Epoch 00264: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-08.\n",
      "Epoch 00271: early stopping\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00083: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00102: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00121: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00140: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00159: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00178: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00197: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00216: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "Epoch 00219: early stopping\n",
      " - Test 2: 0.005364604342951259\n",
      "\n",
      "Epoch 00173: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00238: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00263: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00283: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00302: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00321: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00340: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00359: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00378: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00397: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00416: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00442: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "\n",
      "Epoch 00461: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-08.\n",
      "Epoch 00472: early stopping\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00074: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00093: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00112: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00133: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00152: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00171: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00190: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00209: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00228: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "Epoch 00240: early stopping\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00061: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00080: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00099: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00118: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00137: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00156: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00175: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00194: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00213: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00232: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "Epoch 00239: early stopping\n",
      " - Test 3: 0.00564509382313905\n",
      "\n",
      "Epoch 00226: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00245: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00264: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00283: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00302: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00321: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00340: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00359: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00378: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00397: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00416: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00435: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00445: early stopping\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00060: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00079: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00098: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00117: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00136: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00164: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00183: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00202: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00221: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "Epoch 00235: early stopping\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00063: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00082: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00101: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00120: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00139: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00158: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00177: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00196: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "Epoch 00213: early stopping\n",
      " - Test 4: 0.0052300319816935715\n",
      "\n",
      "Epoch 00200: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00226: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00245: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00264: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00283: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00302: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00329: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00348: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00367: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00386: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00405: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00424: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "Epoch 00439: early stopping\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00077: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00096: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00115: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00134: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00153: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00172: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00191: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00210: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00229: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00248: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "\n",
      "Epoch 00267: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-08.\n",
      "Epoch 00271: early stopping\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00073: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00092: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00111: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00130: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00149: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00168: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00187: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00206: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00225: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "Epoch 00233: early stopping\n",
      " - Test 5: 0.005411775947191674\n",
      "# lr1e-05\n",
      "Layers: [351, 351]\n",
      "\n",
      "Epoch 00615: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00634: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00653: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00672: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00691: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00710: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00729: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00748: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00767: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00786: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00805: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "Epoch 00811: early stopping\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00070: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00089: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00108: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00127: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00146: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00165: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00184: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00203: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "Epoch 00214: early stopping\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00068: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00087: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00106: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00125: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00144: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00163: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00182: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "Epoch 00199: early stopping\n",
      " - Test 1: 0.010856962785940266\n",
      "\n",
      "Epoch 00602: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00621: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00640: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00659: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00678: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00697: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00716: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00735: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00754: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00773: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00792: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "\n",
      "Epoch 00811: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-09.\n",
      "Epoch 00823: early stopping\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00068: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00087: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00106: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00125: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00144: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00163: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00182: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00201: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "\n",
      "Epoch 00220: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-09.\n",
      "\n",
      "Epoch 00239: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-09.\n",
      "Epoch 00245: early stopping\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00077: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00096: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00115: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00134: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00153: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00172: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00191: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00210: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "\n",
      "Epoch 00229: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-09.\n",
      "\n",
      "Epoch 00248: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-09.\n",
      "Epoch 00249: early stopping\n",
      " - Test 2: 0.01111233265912948\n",
      "\n",
      "Epoch 00599: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00618: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00637: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00656: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00675: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00694: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00713: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00732: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00751: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00770: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00789: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "\n",
      "Epoch 00808: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-09.\n",
      "Epoch 00808: early stopping\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00077: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00096: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00115: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00134: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00153: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00172: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00191: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00210: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "\n",
      "Epoch 00229: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-09.\n",
      "Epoch 00233: early stopping\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00056: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00075: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00094: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00113: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00132: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00151: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00170: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00189: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00208: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "Epoch 00226: early stopping\n",
      " - Test 3: 0.010966261010153673\n",
      "\n",
      "Epoch 00587: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00616: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00643: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00662: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00681: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00700: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00719: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00738: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00757: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00776: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00795: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "Epoch 00807: early stopping\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00077: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00096: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00115: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00134: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00153: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00172: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00191: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00210: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "Epoch 00222: early stopping\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00054: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00073: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00092: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00111: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00130: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00149: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00168: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00187: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00206: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00214: early stopping\n",
      " - Test 4: 0.010989936300326342\n",
      "\n",
      "Epoch 00580: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00599: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00618: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00637: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00656: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00675: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00703: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00722: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00741: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00760: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00779: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "\n",
      "Epoch 00798: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-09.\n",
      "Epoch 00815: early stopping\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00069: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00088: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00107: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00126: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00145: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00164: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00183: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00202: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00221: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "Epoch 00223: early stopping\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00072: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00091: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00110: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00129: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00148: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00167: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00186: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00205: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "Epoch 00212: early stopping\n",
      " - Test 5: 0.011124982883162167\n",
      "Layers: [351, 351, 351]\n",
      "\n",
      "Epoch 00788: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00815: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00838: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00857: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00876: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00895: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00914: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00933: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00952: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00971: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00990: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "\n",
      "Epoch 01009: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-09.\n",
      "\n",
      "Epoch 01028: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-09.\n",
      "Epoch 01034: early stopping\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00062: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00081: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00100: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00119: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00138: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00157: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00176: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00195: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00214: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "\n",
      "Epoch 00233: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-09.\n",
      "Epoch 00243: early stopping\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00063: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00082: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00101: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00120: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00139: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00158: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00177: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00196: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00215: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "\n",
      "Epoch 00234: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-09.\n",
      "\n",
      "Epoch 00253: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-09.\n",
      "Epoch 00253: early stopping\n",
      " - Test 1: 0.012677996447170848\n",
      "\n",
      "Epoch 00816: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00835: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00854: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00873: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00892: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00911: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00939: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00958: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00977: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00996: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 01015: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "\n",
      "Epoch 01034: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-09.\n",
      "Epoch 01034: early stopping\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00077: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00096: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00115: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00134: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00153: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00172: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00191: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00210: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "Epoch 00222: early stopping\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00070: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00089: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00108: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00127: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00146: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00165: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00184: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00203: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00222: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "Epoch 00234: early stopping\n",
      " - Test 2: 0.012078599346366094\n",
      "\n",
      "Epoch 00792: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00820: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00842: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00861: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00880: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00899: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00918: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00937: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00956: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00975: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00994: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "\n",
      "Epoch 01013: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-09.\n",
      "\n",
      "Epoch 01032: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-09.\n",
      "Epoch 01039: early stopping\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00057: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00076: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00095: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00114: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00133: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00152: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00171: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00190: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00209: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "\n",
      "Epoch 00228: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-09.\n",
      "Epoch 00243: early stopping\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00057: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00076: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00095: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00114: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00133: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00152: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00171: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00190: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00209: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "\n",
      "Epoch 00228: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-09.\n",
      "Epoch 00230: early stopping\n",
      " - Test 3: 0.012924924752308954\n",
      "\n",
      "Epoch 00798: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00827: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00850: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00869: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00888: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00907: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00926: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00945: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00964: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00983: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 01002: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "\n",
      "Epoch 01021: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-09.\n",
      "Epoch 01036: early stopping\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00056: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00075: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00094: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00113: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00132: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00151: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00170: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00189: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00208: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00227: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "Epoch 00237: early stopping\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00083: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00102: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00121: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00140: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00159: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00178: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00197: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00216: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "Epoch 00217: early stopping\n",
      " - Test 4: 0.012041382148713614\n",
      "\n",
      "Epoch 00827: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00856: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00875: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00894: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00913: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00932: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00951: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00970: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00989: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 01008: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 01027: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "Epoch 01043: early stopping\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00077: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00096: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00115: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00134: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00153: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00172: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00191: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00210: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "\n",
      "Epoch 00229: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-09.\n",
      "Epoch 00229: early stopping\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00074: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00093: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00112: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00131: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00150: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00169: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00188: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00207: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "Epoch 00207: early stopping\n",
      " - Test 5: 0.012415400525527214\n",
      "Layers: [451, 451]\n",
      "\n",
      "Epoch 00527: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00546: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00565: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00584: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00603: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00622: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00641: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00660: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00679: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00698: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00717: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "\n",
      "Epoch 00736: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-09.\n",
      "Epoch 00736: early stopping\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00065: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00084: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00103: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00122: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00141: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00160: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00179: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00198: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00217: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "\n",
      "Epoch 00236: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-09.\n",
      "Epoch 00246: early stopping\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00077: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00096: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00115: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00134: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00153: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00172: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00191: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00210: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "Epoch 00215: early stopping\n",
      " - Test 1: 0.010320408737741003\n",
      "\n",
      "Epoch 00546: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00565: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00584: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00603: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00622: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00641: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00660: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00679: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00698: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00717: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00736: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "Epoch 00741: early stopping\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00061: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00080: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00099: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00118: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00137: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00156: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00175: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00194: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00213: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "\n",
      "Epoch 00232: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-09.\n",
      "Epoch 00247: early stopping\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00068: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00087: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00106: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00125: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00144: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00163: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00182: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00201: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "\n",
      "Epoch 00220: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-09.\n",
      "\n",
      "Epoch 00239: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-09.\n",
      "Epoch 00245: early stopping\n",
      " - Test 2: 0.010207146137433858\n",
      "\n",
      "Epoch 00544: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00563: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00582: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00601: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00620: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00639: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00658: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00677: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00696: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00715: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00734: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00747: early stopping\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00061: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00080: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00099: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00118: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00137: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00156: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00175: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00194: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00213: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "Epoch 00213: early stopping\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00056: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00075: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00094: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00113: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00132: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00151: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00170: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00189: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00208: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "\n",
      "Epoch 00227: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-09.\n",
      "Epoch 00233: early stopping\n",
      " - Test 3: 0.010117259478910052\n",
      "\n",
      "Epoch 00524: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00543: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00562: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00581: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00600: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00619: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00638: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00658: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00677: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00696: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00715: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "\n",
      "Epoch 00734: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-09.\n",
      "\n",
      "Epoch 00753: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-09.\n",
      "Epoch 00767: early stopping\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00077: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00096: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00115: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00134: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00153: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00172: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00191: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00210: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "Epoch 00212: early stopping\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00072: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00091: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00110: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00129: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00148: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00167: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00186: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00205: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "\n",
      "Epoch 00224: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-09.\n",
      "Epoch 00235: early stopping\n",
      " - Test 4: 0.010618870637717829\n",
      "\n",
      "Epoch 00552: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00571: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00590: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00609: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00628: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00647: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00666: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00685: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00704: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00723: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00742: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "Epoch 00757: early stopping\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00068: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00087: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00106: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00125: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00144: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00163: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00182: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00201: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "Epoch 00211: early stopping\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00077: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00096: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00115: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00134: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00153: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00172: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00191: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "Epoch 00206: early stopping\n",
      " - Test 5: 0.010328564454629943\n",
      "Layers: [601, 501, 401]\n",
      "\n",
      "Epoch 00648: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00677: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00699: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00718: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00737: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00756: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00775: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00794: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00813: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00832: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00851: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "\n",
      "Epoch 00870: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-09.\n",
      "\n",
      "Epoch 00889: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-09.\n",
      "\n",
      "Epoch 00908: ReduceLROnPlateau reducing learning rate to 6.103515470812226e-10.\n",
      "Epoch 00910: early stopping\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00059: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00078: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00097: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00116: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00135: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00154: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00173: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00192: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00211: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "\n",
      "Epoch 00230: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-09.\n",
      "\n",
      "Epoch 00249: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-09.\n",
      "Epoch 00265: early stopping\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00083: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00102: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00121: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00140: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00159: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00178: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00197: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00216: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "Epoch 00229: early stopping\n",
      " - Test 1: 0.01166086928891157\n",
      "\n",
      "Epoch 00695: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00714: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00733: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00752: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00771: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00790: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00809: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00828: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00847: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00866: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00886: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "\n",
      "Epoch 00905: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-09.\n",
      "Epoch 00907: early stopping\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00059: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00078: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00097: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00116: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00135: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00154: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00173: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00192: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00211: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "\n",
      "Epoch 00230: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-09.\n",
      "\n",
      "Epoch 00249: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-09.\n",
      "Epoch 00264: early stopping\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00065: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00084: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00103: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00122: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00141: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00160: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00179: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00198: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00217: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "\n",
      "Epoch 00236: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-09.\n",
      "Epoch 00245: early stopping\n",
      " - Test 2: 0.01147216857313665\n",
      "\n",
      "Epoch 00694: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00713: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00732: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00751: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00770: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00791: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00810: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00829: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00848: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00867: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00886: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "\n",
      "Epoch 00905: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-09.\n",
      "Epoch 00916: early stopping\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00062: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00081: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00100: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00119: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00138: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00157: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00176: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00195: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00214: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "\n",
      "Epoch 00233: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-09.\n",
      "\n",
      "Epoch 00252: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-09.\n",
      "Epoch 00255: early stopping\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00077: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00096: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00115: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00134: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00153: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00172: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00191: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00210: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "Epoch 00218: early stopping\n",
      " - Test 3: 0.011466393071175808\n",
      "\n",
      "Epoch 00685: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00714: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00742: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00761: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00780: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00799: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00818: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00837: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00856: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00875: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00894: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "\n",
      "Epoch 00913: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-09.\n",
      "Epoch 00922: early stopping\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00057: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00076: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00095: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00114: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00133: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00152: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00171: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00190: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00209: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "Epoch 00221: early stopping\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00083: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00102: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00121: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00140: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00159: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00178: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00197: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00216: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "\n",
      "Epoch 00235: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-09.\n",
      "Epoch 00248: early stopping\n",
      " - Test 4: 0.011215749891725049\n",
      "\n",
      "Epoch 00647: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00674: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00696: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00715: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00734: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00753: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00772: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00791: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00810: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00829: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00848: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "\n",
      "Epoch 00867: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-09.\n",
      "Epoch 00876: early stopping\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00057: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00076: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00095: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00114: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00133: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00152: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00171: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00190: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00209: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "\n",
      "Epoch 00228: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-09.\n",
      "Epoch 00242: early stopping\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00066: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00085: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00104: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00123: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00142: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00161: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00180: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00199: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00218: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "\n",
      "Epoch 00237: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-09.\n",
      "Epoch 00241: early stopping\n",
      " - Test 5: 0.011965827905197643\n"
     ]
    }
   ],
   "source": [
    "res = []\n",
    "for lr in learning_rates:\n",
    "    print(\"# lr\" + str(lr))\n",
    "    res.append(run_layer_test_series('elu', structures, lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [ \n",
    "    s for s in range(len(structures)) for i in range(n_tests)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'351_351'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def structure_string(structure):\n",
    "    return \"_\".join(list(map(str,list(structure))))\n",
    "structure_string(structures[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd6cf16dbe0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for r, lr in zip(res, learning_rates):\n",
    "    plt.scatter(x, np.array(r).flatten(), marker=\"x\", label=\"$\\eta$ = \" + str(lr) )\n",
    "\n",
    "#plt.xlabel(\"Number of Hidden Layers / 1\")\n",
    "plt.ylabel(\"Mean Absolute Error / 1\")\n",
    "\n",
    "plt.xticks(\n",
    "    np.arange(len(structures)),\n",
    "    [structure_string(structure) for structure in structures],\n",
    "    rotation=-60\n",
    ")\n",
    "\n",
    "plt.ylim(0.0025, 0.015)\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"/home/jcartus/Repos/MastersThesis/SMatrixDescriptor/figures/HyperparameterStudy.pdf\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5e-05"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(5e-3)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
