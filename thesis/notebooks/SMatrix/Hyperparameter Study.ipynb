{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jo/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from os.path import join\n",
    "\n",
    "plt.style.use([\"seaborn\", \"thesis\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc(\"figure\", figsize=(8,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SCFInitialGuess.utilities.dataset import extract_triu_batch, AbstractDataset\n",
    "\n",
    "data_path = \"../../dataset/TSmall_sto3g\"\n",
    "postfix = \"TSmall_sto3g\"\n",
    "dim = 26\n",
    "\n",
    "S = np.load(join(data_path, \"S\" + postfix + \".npy\"))\n",
    "P = np.load(join(data_path, \"P\" + postfix + \".npy\"))\n",
    "F = np.load(join(data_path, \"F\" + postfix + \".npy\"))\n",
    "\n",
    "index = np.load(join(data_path, \"index\" + postfix + \".npy\"))\n",
    "\n",
    "molecules = np.load(join(data_path, \"molecules\" + postfix + \".npy\"))\n",
    "\n",
    "def split(x, y, ind):\n",
    "    return x[:ind], y[:ind], x[ind:], y[ind:]\n",
    "\n",
    "S = np.load(join(data_path, \"S\" + postfix + \".npy\"))\n",
    "P = np.load(join(data_path, \"P\" + postfix + \".npy\"))\n",
    "F = np.load(join(data_path, \"F\" + postfix + \".npy\"))\n",
    "\n",
    "index = np.load(join(data_path, \"index\" + postfix + \".npy\"))\n",
    "\n",
    "molecules = np.load(join(data_path, \"molecules\" + postfix + \".npy\"))\n",
    "\n",
    "\n",
    "\n",
    "ind = int(0.8 * len(index))\n",
    "ind_val = int(0.8 * ind)\n",
    "\n",
    "s_triu = extract_triu_batch(S, dim)\n",
    "p_triu = extract_triu_batch(P, dim)\n",
    "\n",
    "s_triu_norm, mu, std = AbstractDataset.normalize(s_triu)\n",
    "\n",
    "\n",
    "s_train, p_train, s_test, p_test = split(s_triu_norm, p_triu, ind)\n",
    "s_train, p_train, s_val, p_val = split(s_train, p_train, ind_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((640, 351), (160, 351), (201, 351))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_train.shape, s_val.shape, s_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Utilities "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model generation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_triu = dim * (dim + 1) // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "intializer = keras.initializers.TruncatedNormal(mean=0.0, stddev=0.01)\n",
    "\n",
    "def build_model(activation, structure, learning_rate):\n",
    "\n",
    "\n",
    "\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    # input layer\n",
    "    model.add(keras.layers.Dense(dim_triu, activation=activation, input_dim=dim_triu, kernel_initializer=intializer, bias_initializer='zeros'))\n",
    "\n",
    "    # hidden\n",
    "    for layer in structure:\n",
    "\n",
    "        model.add(keras.layers.Dense(\n",
    "                layer, \n",
    "                activation=activation, \n",
    "                kernel_initializer=intializer, \n",
    "                #bias_initializer='zeros',\n",
    "                #kernel_regularizer=keras.regularizers.l2(1e-8)\n",
    "        ))\n",
    "\n",
    "\n",
    "    #output\n",
    "    model.add(keras.layers.Dense(dim_triu))\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate), loss='MSE', metrics=['mae', 'mse'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_mean_squared_error\", \n",
    "    min_delta=1e-7, \n",
    "    patience=50, \n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss', \n",
    "    factor=0.5, \n",
    "    patience=10, \n",
    "    verbose=1, \n",
    "    mode='auto', \n",
    "    min_delta=1e-5, \n",
    "    cooldown=10, \n",
    "    min_lr=1e-10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tests = 5\n",
    "n_resets = 3\n",
    "epochs = 10000\n",
    "\n",
    "\n",
    "def test_model(structure, activation, learning_rate=1e-4):\n",
    "    error = []\n",
    "    \n",
    "    for i in range(n_tests):\n",
    "        \n",
    "        keras.backend.clear_session()\n",
    "        model = build_model(activation, structure, learning_rate)\n",
    "        \n",
    "        for j in range(n_resets):\n",
    "            keras.backend.set_value(model.optimizer.lr, learning_rate)\n",
    "            \n",
    "            history = model.fit(\n",
    "                x = s_train,\n",
    "                y = p_train,\n",
    "                epochs=epochs,\n",
    "                shuffle=True,\n",
    "                validation_data=(s_val, p_val), \n",
    "                verbose=0, \n",
    "                callbacks=[\n",
    "                    early_stopping, \n",
    "                    reduce_lr\n",
    "                ]\n",
    "            )\n",
    "        \n",
    "        error.append(model.evaluate(s_test, p_test, verbose=0)[1])\n",
    "        \n",
    "        print(\" - Test \" + str(i+1) + \": \" + str(error[-1]))\n",
    "    \n",
    "    return error\n",
    "\n",
    "def run_layer_test_series(activation, structures, learning_rate):\n",
    "    error = []\n",
    "    for structure in structures:\n",
    "        print(\"Layers: \" + str(structure))\n",
    "        error.append(test_model(structure, activation, learning_rate=learning_rate))\n",
    "    return error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "structures = [\n",
    "        [dim_triu, dim_triu],\n",
    "        [dim_triu, dim_triu, dim_triu],\n",
    "        [dim_triu + 100, dim_triu + 100],\n",
    "        [dim_triu + 250, dim_triu + 150, dim_triu + 50],\n",
    "        [dim_triu + 100, dim_triu + 200, dim_triu + 100],\n",
    "        [dim_triu, dim_triu, dim_triu, dim_triu, dim_triu]\n",
    "    ]\n",
    "        \n",
    "learning_rates = [1e-3, 1e-4, 1e-5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# lr0.001\n",
      "Layers: [351, 351]\n",
      "\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00106: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00134: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00162: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00181: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00200: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00219: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00238: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00257: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00276: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00295: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00314: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00333: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 00352: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "Epoch 00358: early stopping\n",
      "\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00080: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00099: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00118: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00137: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00156: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00175: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00194: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00213: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00232: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00251: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00270: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00289: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 00308: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "Epoch 00320: early stopping\n",
      "\n",
      "Epoch 00093: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00112: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00131: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00150: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00169: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00190: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00209: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00228: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00247: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00266: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00285: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00304: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "Epoch 00318: early stopping\n",
      " - Test 1: 0.005914154840142128\n",
      "\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00102: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00127: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00147: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00166: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00185: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00204: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00223: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00242: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00261: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00280: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00299: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00318: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "Epoch 00320: early stopping\n",
      "\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00083: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00102: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00121: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00140: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00159: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00178: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00197: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00216: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00235: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00254: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00273: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "Epoch 00279: early stopping\n",
      "\n",
      "Epoch 00062: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00081: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00100: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00119: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00138: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00157: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00176: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00195: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00214: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00233: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00252: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00271: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "Epoch 00276: early stopping\n",
      " - Test 2: 0.004364290151893351\n",
      "\n",
      "Epoch 00079: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00099: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00118: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00137: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00156: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00175: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00194: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00213: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00232: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00251: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00270: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00289: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00308: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 00327: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "Epoch 00334: early stopping\n",
      "\n",
      "Epoch 00069: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00093: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00112: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00131: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00150: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00169: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00188: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00207: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00226: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00245: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00264: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00283: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00302: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "Epoch 00310: early stopping\n",
      "\n",
      "Epoch 00056: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00085: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00110: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00129: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00148: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00167: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00186: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00205: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00224: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00243: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00262: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00281: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00300: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "Epoch 00313: early stopping\n",
      " - Test 3: 0.005227424278484648\n",
      "\n",
      "Epoch 00086: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00113: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00132: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00151: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00170: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00189: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00208: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00227: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00246: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00265: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00284: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00303: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00322: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 00341: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "Epoch 00352: early stopping\n",
      "\n",
      "Epoch 00071: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00090: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00112: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00131: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00150: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00169: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00188: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00207: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00226: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00245: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00264: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "Epoch 00276: early stopping\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00062: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00081: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00100: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00119: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00138: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00157: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00176: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00195: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00214: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00233: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00252: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00271: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "Epoch 00272: early stopping\n",
      " - Test 4: 0.00410173434662211\n",
      "\n",
      "Epoch 00081: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00105: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00124: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00143: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00162: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00181: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00200: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00219: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00238: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00257: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00276: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00295: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "Epoch 00310: early stopping\n",
      "\n",
      "Epoch 00071: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00098: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00117: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00136: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00155: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00174: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00193: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00212: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00231: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00250: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00269: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00288: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00307: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "Epoch 00313: early stopping\n",
      "\n",
      "Epoch 00072: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00101: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00128: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00147: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00166: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00185: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00204: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00223: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00242: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00261: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00280: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00299: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "Epoch 00313: early stopping\n",
      " - Test 5: 0.005037153000707057\n",
      "Layers: [351, 351, 351]\n",
      "\n",
      "Epoch 00080: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00148: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00176: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00201: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00220: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00239: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00258: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00277: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00296: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00315: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00334: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00353: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00372: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 00391: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "Epoch 00395: early stopping\n",
      "\n",
      "Epoch 00113: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00141: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00160: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00179: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00198: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00217: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00236: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00255: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00274: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00293: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00312: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00331: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00350: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 00369: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 00388: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "Epoch 00388: early stopping\n",
      "\n",
      "Epoch 00075: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00094: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00113: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00134: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00153: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00172: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00191: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00210: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00229: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00248: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00267: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00286: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00305: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "Epoch 00322: early stopping\n",
      " - Test 1: 0.007059892769254262\n",
      "\n",
      "Epoch 00080: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00133: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00159: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00178: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00197: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00216: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00235: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00254: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00273: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00292: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00311: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00330: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00349: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "Epoch 00358: early stopping\n",
      "\n",
      "Epoch 00108: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00130: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00149: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00174: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00193: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00212: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00231: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00250: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00269: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00288: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00307: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00326: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00345: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 00364: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "Epoch 00366: early stopping\n",
      "\n",
      "Epoch 00086: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00112: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00131: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00150: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00169: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00188: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00207: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00226: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00245: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00264: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00283: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00302: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00321: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "Epoch 00332: early stopping\n",
      " - Test 2: 0.007299676764552569\n",
      "\n",
      "Epoch 00113: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00141: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00160: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00179: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00198: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00217: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00236: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00255: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00274: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00293: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00312: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00331: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "Epoch 00342: early stopping\n",
      "\n",
      "Epoch 00108: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00134: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00153: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00176: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00195: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00214: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00233: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00252: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00271: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00290: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00309: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00328: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00347: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 00366: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 00385: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "Epoch 00391: early stopping\n",
      "\n",
      "Epoch 00087: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00115: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00134: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00153: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00172: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00191: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00210: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00229: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00248: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00267: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00286: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00305: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00324: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 00343: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 00362: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "Epoch 00369: early stopping\n",
      " - Test 3: 0.006829421960317821\n",
      "\n",
      "Epoch 00108: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00134: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00153: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00172: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00191: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00210: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00239: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00258: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00277: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00296: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00315: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00334: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00353: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "Epoch 00363: early stopping\n",
      "\n",
      "Epoch 00129: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00150: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00169: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00188: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00215: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00234: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00253: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00272: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00291: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00310: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00329: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00348: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00367: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "Epoch 00377: early stopping\n",
      "\n",
      "Epoch 00071: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00096: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00115: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00134: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00153: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00172: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00191: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00210: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00229: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00248: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00267: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00286: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00305: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "Epoch 00316: early stopping\n",
      " - Test 4: 0.005936083543712079\n",
      "\n",
      "Epoch 00092: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00133: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00152: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00171: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00190: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00209: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00228: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00247: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00266: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00285: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00304: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00323: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00342: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 00361: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 00380: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "Epoch 00392: early stopping\n",
      "\n",
      "Epoch 00102: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00122: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00141: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00160: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00179: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00198: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00217: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00236: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00255: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00274: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00293: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00312: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00331: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "Epoch 00339: early stopping\n",
      "\n",
      "Epoch 00106: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00146: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00175: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00194: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00213: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00232: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00251: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00270: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00289: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00308: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00327: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00346: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00365: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 00384: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "Epoch 00401: early stopping\n",
      " - Test 5: 0.008045101306628232\n",
      "Layers: [451, 451]\n",
      "\n",
      "Epoch 00084: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00103: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00122: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00141: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00160: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00179: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00198: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00217: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00236: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00255: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00274: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00293: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00312: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "Epoch 00330: early stopping\n",
      "\n",
      "Epoch 00088: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00107: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00126: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00145: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00164: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00183: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00202: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00221: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00243: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00262: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00281: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00300: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00319: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "Epoch 00325: early stopping\n",
      "\n",
      "Epoch 00075: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00099: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00118: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00137: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00156: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00182: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00201: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00220: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00239: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00258: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00277: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00296: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00315: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 00334: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "Epoch 00337: early stopping\n",
      " - Test 1: 0.006095747905899191\n",
      "\n",
      "Epoch 00054: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00099: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00123: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00142: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00161: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00180: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00199: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00218: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00237: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00263: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00282: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00301: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00320: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "Epoch 00327: early stopping\n",
      "\n",
      "Epoch 00072: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00100: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00129: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00148: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00167: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00186: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00205: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00224: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00243: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00262: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00281: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00300: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00319: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "Epoch 00330: early stopping\n",
      "\n",
      "Epoch 00072: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00095: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00114: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00133: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00155: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00174: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00193: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00212: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00231: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00250: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00269: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00288: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00307: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 00326: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "Epoch 00331: early stopping\n",
      " - Test 2: 0.005986563027349871\n",
      "\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00101: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00127: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00150: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00169: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00188: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00207: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00226: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00245: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00264: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00283: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00302: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00321: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "Epoch 00331: early stopping\n",
      "\n",
      "Epoch 00096: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00115: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00134: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00153: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00172: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00191: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00210: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00229: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00248: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00267: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00286: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00305: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00324: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "Epoch 00333: early stopping\n",
      "\n",
      "Epoch 00095: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00120: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00139: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00158: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00177: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00196: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00215: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00234: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00253: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00272: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00291: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00310: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00329: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 00348: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "Epoch 00354: early stopping\n",
      " - Test 3: 0.00702826649098847\n",
      "\n",
      "Epoch 00074: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00098: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00117: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00136: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00155: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00174: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00201: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00220: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00239: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00258: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00277: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00296: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00315: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "Epoch 00324: early stopping\n",
      "\n",
      "Epoch 00097: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00137: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00156: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00175: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00194: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00213: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00232: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00251: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00270: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00289: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00308: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00327: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00346: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 00365: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "Epoch 00382: early stopping\n",
      "\n",
      "Epoch 00092: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00115: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00134: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00153: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00172: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00191: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00210: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00229: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00248: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00267: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00286: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00305: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00324: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 00343: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 00362: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "Epoch 00362: early stopping\n",
      " - Test 4: 0.008371521084018015\n",
      "\n",
      "Epoch 00101: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00120: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00139: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00158: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00177: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00196: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00215: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00234: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00253: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00272: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00291: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00310: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00329: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "Epoch 00331: early stopping\n",
      "\n",
      "Epoch 00120: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00142: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00162: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00181: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00200: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00219: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00246: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00265: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00284: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00303: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00322: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00341: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00360: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 00379: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 00398: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00408: early stopping\n",
      "\n",
      "Epoch 00136: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00155: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00179: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00198: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00217: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00236: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00265: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00284: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00303: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00322: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00341: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00360: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00379: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 00398: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "Epoch 00414: early stopping\n",
      " - Test 5: 0.009696317743973353\n",
      "Layers: [601, 501, 401]\n",
      "\n",
      "Epoch 00071: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00113: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00135: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00154: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00173: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00192: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00211: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00230: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00249: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00268: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00287: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00306: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00325: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 00344: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 00363: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "Epoch 00369: early stopping\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00123: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00311: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00354: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00384: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00403: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00422: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00441: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00460: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00481: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00500: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00519: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00538: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 00557: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 00576: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "Epoch 00584: early stopping\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00071: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00100: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00119: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00138: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00157: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00176: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00195: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "Epoch 00210: early stopping\n",
      " - Test 1: 0.060843300407947\n",
      "\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00108: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00127: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00146: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00167: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00186: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00205: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00224: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00243: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00262: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00281: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00300: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00319: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 00338: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "Epoch 00345: early stopping\n",
      "\n",
      "Epoch 00140: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00201: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00220: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00239: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00258: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00277: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00296: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00315: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00334: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00353: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00372: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00391: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00410: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 00429: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 00448: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "\n",
      "Epoch 00467: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "Epoch 00475: early stopping\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00074: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00093: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00114: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00139: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00158: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00177: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00196: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00215: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "Epoch 00226: early stopping\n",
      " - Test 2: 0.060814132404268084\n",
      "\n",
      "Epoch 00107: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00129: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00148: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00167: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00186: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00205: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00224: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00243: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00262: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00281: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00300: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00319: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00338: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 00357: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "Epoch 00358: early stopping\n",
      "\n",
      "Epoch 00126: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00178: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00205: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00224: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00243: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00268: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00287: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00306: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00325: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00344: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00363: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00382: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00401: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 00420: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 00439: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "\n",
      "Epoch 00458: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "Epoch 00462: early stopping\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00060: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00079: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00098: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00117: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 00118: early stopping\n",
      " - Test 3: 0.060740377531567614\n",
      "\n",
      "Epoch 00066: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00117: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00137: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00156: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00175: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00194: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00213: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00232: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00251: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00270: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00289: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00308: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00327: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 00346: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "Epoch 00348: early stopping\n",
      "\n",
      "Epoch 00153: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00174: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00193: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00212: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00236: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00255: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00274: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00293: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00312: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00331: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00350: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00369: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00388: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 00407: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "Epoch 00416: early stopping\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00066: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00324: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00371: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00390: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00410: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00429: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00455: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00474: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00493: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00512: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00531: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 00550: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "Epoch 00567: early stopping\n",
      " - Test 4: 0.038067756507971985\n",
      "\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00102: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00128: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00147: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00166: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00185: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00204: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00223: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00247: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00266: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00285: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00304: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00323: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 00342: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "Epoch 00350: early stopping\n",
      "\n",
      "Epoch 00114: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00156: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00182: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00201: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00225: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00244: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00263: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00282: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00301: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00320: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00339: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00358: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00377: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 00396: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "Epoch 00401: early stopping\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00056: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00075: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00094: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00356: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00894: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00913: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00932: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00951: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00970: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00989: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 01008: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 01027: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 01046: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "\n",
      "Epoch 01065: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "\n",
      "Epoch 01084: ReduceLROnPlateau reducing learning rate to 7.629394893626795e-09.\n",
      "\n",
      "Epoch 01103: ReduceLROnPlateau reducing learning rate to 3.814697446813398e-09.\n",
      "Epoch 01114: early stopping\n",
      " - Test 5: 0.039666140090618564\n",
      "Layers: [451, 551, 451]\n",
      "\n",
      "Epoch 00088: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00123: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00142: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00161: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00180: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00199: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00222: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00241: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00260: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00279: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00298: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00317: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00336: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 00355: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "Epoch 00361: early stopping\n",
      "\n",
      "Epoch 00179: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00235: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00256: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00283: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00302: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00321: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00340: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00359: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00378: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00397: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00416: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00435: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00454: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 00473: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "Epoch 00485: early stopping\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00141: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00161: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00192: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00211: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00231: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00267: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00286: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00307: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00326: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00345: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00364: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00383: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 00402: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 00421: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "Epoch 00431: early stopping\n",
      " - Test 1: 0.04490776549079525\n",
      "\n",
      "Epoch 00083: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00125: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00151: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00170: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00189: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00208: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00227: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00246: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00265: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00284: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00303: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00322: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00341: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 00360: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "Epoch 00365: early stopping\n",
      "\n",
      "Epoch 00145: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00255: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00573: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00609: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00631: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00653: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00672: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00691: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00710: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00729: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00748: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00767: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00786: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 00805: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 00824: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "Epoch 00828: early stopping\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00057: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00076: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00095: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00114: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00133: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00152: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00171: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00190: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "Epoch 00191: early stopping\n",
      " - Test 2: 0.060808691497317595\n",
      "\n",
      "Epoch 00076: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00123: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00143: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00162: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00181: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00210: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00229: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00248: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00267: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00286: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00305: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00324: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00343: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 00362: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "Epoch 00375: early stopping\n",
      "\n",
      "Epoch 00160: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00217: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00242: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00261: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00280: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00299: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00318: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00337: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00356: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00375: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00394: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00413: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00432: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 00451: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 00470: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "Epoch 00475: early stopping\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00195: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00221: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00240: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00267: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00286: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00305: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00324: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00343: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00362: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00381: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00400: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00419: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "Epoch 00419: early stopping\n",
      " - Test 3: 0.037360849183293715\n",
      "\n",
      "Epoch 00065: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00125: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00149: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00168: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00187: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00206: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00225: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00244: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00263: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00282: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00301: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00320: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00339: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "Epoch 00348: early stopping\n",
      "\n",
      "Epoch 00083: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00119: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00138: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00157: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00176: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00195: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00214: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00233: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00252: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00271: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00290: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00309: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00328: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 00347: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "Epoch 00351: early stopping\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00157: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00179: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00198: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00217: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00236: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00255: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00283: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00302: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00321: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "Epoch 00323: early stopping\n",
      " - Test 4: 0.038890358357138895\n",
      "\n",
      "Epoch 00101: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00130: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00149: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00168: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00187: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00206: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00225: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00244: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00263: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00282: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00301: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00320: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00339: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "Epoch 00343: early stopping\n",
      "\n",
      "Epoch 00153: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00177: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00198: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00217: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00236: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00255: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00274: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00298: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00317: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00336: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00355: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00374: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00393: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 00412: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 00431: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "Epoch 00445: early stopping\n",
      "\n",
      "Epoch 00191: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00235: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00255: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00274: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00293: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00312: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00331: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00350: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00369: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00388: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00407: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00426: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00445: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 00464: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "Epoch 00470: early stopping\n",
      " - Test 5: 0.008572001663495355\n",
      "Layers: [351, 351, 351, 351, 351]\n",
      "\n",
      "Epoch 00148: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00217: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00244: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00263: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00282: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00301: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00320: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00339: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00358: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00377: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00397: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00416: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00435: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 00454: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 00473: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "Epoch 00483: early stopping\n",
      "\n",
      "Epoch 00213: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00262: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00287: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00316: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00345: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00364: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00383: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00402: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00421: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00440: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00459: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00478: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00497: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 00516: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 00535: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "\n",
      "Epoch 00554: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "\n",
      "Epoch 00573: ReduceLROnPlateau reducing learning rate to 7.629394893626795e-09.\n",
      "Epoch 00576: early stopping\n",
      "\n",
      "Epoch 00308: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00348: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00367: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00386: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00411: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00430: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00451: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00470: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00489: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00508: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00527: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00546: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00565: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 00584: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 00603: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "Epoch 00614: early stopping\n",
      " - Test 1: 0.017396599610350026\n",
      "\n",
      "Epoch 00143: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00222: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00249: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00268: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00287: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00306: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00325: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00354: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00373: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00392: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00411: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00430: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00449: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "Epoch 00459: early stopping\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00057: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00076: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00212: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00231: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00250: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00269: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 00286: early stopping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00057: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00076: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00095: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00122: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00141: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00160: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00179: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "Epoch 00188: early stopping\n",
      " - Test 2: 0.06080653514731583\n",
      "\n",
      "Epoch 00195: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00225: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00250: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00269: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00288: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00307: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00326: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00345: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00364: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00383: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00402: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00421: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00440: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "Epoch 00450: early stopping\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00704: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00747: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00775: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00794: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00813: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00832: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00851: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00870: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00889: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00908: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00927: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 00946: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 00965: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "\n",
      "Epoch 00984: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "Epoch 00989: early stopping\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00065: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00084: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00103: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00130: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00149: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00168: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 00170: early stopping\n",
      " - Test 3: 0.0608155471620275\n",
      "\n",
      "Epoch 00194: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00237: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00261: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00280: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00300: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00319: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00338: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00357: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00376: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00395: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00414: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00433: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00452: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 00471: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "Epoch 00483: early stopping\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00088: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00247: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00302: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00322: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00347: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00366: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00385: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00404: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00423: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00442: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00461: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00480: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 00499: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "Epoch 00505: early stopping\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00060: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00089: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00108: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00127: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00146: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00165: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 00165: early stopping\n",
      " - Test 4: 0.060820868933823574\n",
      "\n",
      "Epoch 00202: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00236: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00264: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00283: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00302: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00328: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00347: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00366: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00385: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00404: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00423: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00442: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00461: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 00480: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "Epoch 00488: early stopping\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00076: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00095: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00120: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00139: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00158: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 00160: early stopping\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00095: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00186: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00208: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00237: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00261: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00280: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00299: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00318: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00337: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00356: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00375: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00394: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 00413: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 00432: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "\n",
      "Epoch 00451: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "\n",
      "Epoch 00470: ReduceLROnPlateau reducing learning rate to 7.629394893626795e-09.\n",
      "Epoch 00481: early stopping\n",
      " - Test 5: 0.04486110452469902\n",
      "# lr0.0001\n",
      "Layers: [351, 351]\n",
      "\n",
      "Epoch 00200: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00227: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00246: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00265: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00284: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00303: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00322: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00341: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00360: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00379: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00398: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00417: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "\n",
      "Epoch 00436: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-08.\n",
      "Epoch 00439: early stopping\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00056: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00080: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00099: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00118: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00137: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00156: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00175: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00194: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00213: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00232: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00251: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "\n",
      "Epoch 00270: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-08.\n",
      "Epoch 00275: early stopping\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00056: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00075: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00094: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00113: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00132: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00151: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00170: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00189: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00208: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "Epoch 00216: early stopping\n",
      " - Test 1: 0.00688078498643874\n",
      "\n",
      "Epoch 00157: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00266: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00285: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00304: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00323: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00342: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00361: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00380: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00399: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00418: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00437: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00456: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "\n",
      "Epoch 00475: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-08.\n",
      "\n",
      "Epoch 00494: ReduceLROnPlateau reducing learning rate to 6.103515470812226e-09.\n",
      "Epoch 00497: early stopping\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00054: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00073: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00092: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00111: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00130: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00149: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00168: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00187: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00206: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00225: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00244: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "Epoch 00248: early stopping\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00057: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00076: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00095: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00114: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00133: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00152: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00171: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00190: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00209: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "Epoch 00220: early stopping\n",
      " - Test 2: 0.006599110229153983\n",
      "\n",
      "Epoch 00184: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00208: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00227: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00246: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00265: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00284: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00303: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00328: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00347: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00366: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00385: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00404: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "\n",
      "Epoch 00423: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-08.\n",
      "Epoch 00424: early stopping\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00083: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00102: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00121: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00140: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00159: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00178: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00197: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00216: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00235: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00254: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "Epoch 00259: early stopping\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00083: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00102: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00121: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00140: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00159: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00178: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00197: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00216: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00235: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "Epoch 00241: early stopping\n",
      " - Test 3: 0.0065260007259301585\n",
      "\n",
      "Epoch 00197: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00216: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00235: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00254: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00273: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00292: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00311: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00330: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00349: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00368: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00387: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00406: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "\n",
      "Epoch 00425: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-08.\n",
      "Epoch 00426: early stopping\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00081: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00100: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00119: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00138: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00157: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00176: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00195: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00214: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00233: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00252: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "Epoch 00254: early stopping\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00057: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00076: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00095: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00114: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00133: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00152: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00171: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00190: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00209: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00228: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "Epoch 00232: early stopping\n",
      " - Test 4: 0.006694306318291384\n",
      "\n",
      "Epoch 00190: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00217: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00236: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00255: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00274: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00293: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00312: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00337: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00356: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00375: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00394: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00413: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "\n",
      "Epoch 00432: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-08.\n",
      "\n",
      "Epoch 00451: ReduceLROnPlateau reducing learning rate to 6.103515470812226e-09.\n",
      "Epoch 00461: early stopping\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00062: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00081: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00100: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00119: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00144: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00163: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00182: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00201: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00220: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00239: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00258: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00277: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-08.\n",
      "Epoch 00283: early stopping\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00069: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00088: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00107: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00126: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00145: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00164: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00183: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00202: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00221: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00240: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "Epoch 00241: early stopping\n",
      " - Test 5: 0.006438147781685514\n",
      "Layers: [351, 351, 351]\n",
      "\n",
      "Epoch 00252: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00318: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00345: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00366: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00385: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00404: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00423: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00442: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00461: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00480: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00499: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00518: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "\n",
      "Epoch 00537: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-08.\n",
      "Epoch 00537: early stopping\n",
      "\n",
      "Epoch 00056: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00075: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00094: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00113: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00132: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00151: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00170: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00189: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00208: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00227: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00246: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00265: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "Epoch 00275: early stopping\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00061: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00080: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00099: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00118: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00137: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00156: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00175: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00194: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00213: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00232: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "Epoch 00249: early stopping\n",
      " - Test 1: 0.007034059634793605\n",
      "\n",
      "Epoch 00209: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00306: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00331: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00350: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00369: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00395: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00414: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00433: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00452: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00471: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00490: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00509: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "\n",
      "Epoch 00528: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-08.\n",
      "Epoch 00536: early stopping\n",
      "\n",
      "Epoch 00072: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00091: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00110: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00129: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00158: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00177: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00196: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00215: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00234: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00253: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00272: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00291: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "Epoch 00304: early stopping\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00059: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00078: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00097: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00116: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00135: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00154: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00173: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00192: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00211: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "Epoch 00223: early stopping\n",
      " - Test 2: 0.007093786185523912\n",
      "\n",
      "Epoch 00243: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00285: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00314: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00334: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00353: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00372: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00391: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00410: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00429: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00448: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00467: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00486: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00505: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-08.\n",
      "Epoch 00506: early stopping\n",
      "\n",
      "Epoch 00062: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00091: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00110: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00129: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00148: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00167: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00186: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00205: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00224: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00243: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00262: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00281: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "Epoch 00290: early stopping\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00061: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00080: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00099: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00118: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00137: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00156: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00175: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00194: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00213: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "Epoch 00228: early stopping\n",
      " - Test 3: 0.006743243946438998\n",
      "\n",
      "Epoch 00273: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00300: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00319: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00338: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00357: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00376: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00395: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00414: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00433: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00452: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00471: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00490: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "\n",
      "Epoch 00509: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-08.\n",
      "Epoch 00515: early stopping\n",
      "\n",
      "Epoch 00054: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00073: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00092: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00111: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00132: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00151: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00170: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00189: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00208: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00227: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00246: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00265: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "Epoch 00271: early stopping\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00059: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00078: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00097: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00116: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00135: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00154: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00173: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00192: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00211: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "Epoch 00225: early stopping\n",
      " - Test 4: 0.006716733891053579\n",
      "\n",
      "Epoch 00243: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00273: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00298: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00320: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00339: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00358: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00377: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00396: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00415: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00434: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00453: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00472: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "\n",
      "Epoch 00491: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-08.\n",
      "Epoch 00501: early stopping\n",
      "\n",
      "Epoch 00065: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00094: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00114: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00133: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00152: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00171: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00190: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00209: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00228: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00247: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00266: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00285: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "Epoch 00293: early stopping\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00061: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00080: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00099: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00118: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00137: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00156: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00175: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00194: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00213: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00232: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "Epoch 00233: early stopping\n",
      " - Test 5: 0.0067727760601770225\n",
      "Layers: [451, 451]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00149: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00204: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00223: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00242: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00261: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00282: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00301: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00320: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00339: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00358: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00377: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00396: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "\n",
      "Epoch 00415: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-08.\n",
      "Epoch 00423: early stopping\n",
      "\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00071: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00090: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00109: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00128: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00147: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00166: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00185: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00204: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00223: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00242: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00261: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "Epoch 00261: early stopping\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00070: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00089: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00108: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00127: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00146: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00165: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00184: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00203: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00222: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "Epoch 00237: early stopping\n",
      " - Test 1: 0.00606105983748439\n",
      "\n",
      "Epoch 00183: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00203: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00222: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00242: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00261: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00280: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00299: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00318: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00337: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00356: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00375: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00394: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "Epoch 00409: early stopping\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00054: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00073: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00092: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00111: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00130: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00149: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00168: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00187: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00206: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00225: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "Epoch 00234: early stopping\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00062: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00081: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00100: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00119: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00138: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00157: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00176: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00195: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00214: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "Epoch 00223: early stopping\n",
      " - Test 2: 0.006237618372641245\n",
      "\n",
      "Epoch 00225: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00244: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00263: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00282: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00301: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00320: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00339: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00358: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00377: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00396: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00415: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00434: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "\n",
      "Epoch 00453: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-08.\n",
      "Epoch 00465: early stopping\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00062: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00081: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00100: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00119: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00138: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00157: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00176: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00195: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00214: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "Epoch 00221: early stopping\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00066: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00085: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00104: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00123: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00142: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00161: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00180: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00199: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00218: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00237: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "\n",
      "Epoch 00256: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-08.\n",
      "Epoch 00262: early stopping\n",
      " - Test 3: 0.005880931042486904\n",
      "\n",
      "Epoch 00166: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00185: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00204: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00223: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00242: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00261: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00287: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00306: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00325: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00344: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00363: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00382: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "Epoch 00396: early stopping\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00065: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00085: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00104: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00123: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00142: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00169: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00188: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00207: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00226: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00245: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00264: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "\n",
      "Epoch 00283: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-08.\n",
      "Epoch 00292: early stopping\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00059: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00078: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00097: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00116: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00135: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00154: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00173: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00192: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00211: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "Epoch 00222: early stopping\n",
      " - Test 4: 0.006404044139036788\n",
      "\n",
      "Epoch 00149: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00172: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00201: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00221: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00240: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00259: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00278: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00297: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00316: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00335: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00354: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00373: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "\n",
      "Epoch 00392: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-08.\n",
      "\n",
      "Epoch 00411: ReduceLROnPlateau reducing learning rate to 6.103515470812226e-09.\n",
      "Epoch 00418: early stopping\n",
      "\n",
      "Epoch 00067: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00086: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00105: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00124: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00143: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00162: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00181: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00200: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00219: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00238: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00257: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "Epoch 00268: early stopping\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00077: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00096: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00115: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00134: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00153: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00172: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00191: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00210: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00229: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "Epoch 00239: early stopping\n",
      " - Test 5: 0.006230488461233787\n",
      "Layers: [601, 501, 401]\n",
      "\n",
      "Epoch 00177: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00263: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00288: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00307: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00326: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00348: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00367: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00386: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00405: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00424: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00443: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00462: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "\n",
      "Epoch 00481: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-08.\n",
      "Epoch 00489: early stopping\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00075: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00096: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00115: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00134: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00153: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00172: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00191: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00210: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00229: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00248: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00267: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "\n",
      "Epoch 00286: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-08.\n",
      "Epoch 00298: early stopping\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00063: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00082: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00101: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00120: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00139: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00158: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00177: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00196: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00215: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "Epoch 00220: early stopping\n",
      " - Test 1: 0.006672953744303083\n",
      "\n",
      "Epoch 00207: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00254: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00282: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00302: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00321: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00340: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00359: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00378: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00397: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00416: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00435: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00454: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "\n",
      "Epoch 00473: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-08.\n",
      "\n",
      "Epoch 00492: ReduceLROnPlateau reducing learning rate to 6.103515470812226e-09.\n",
      "\n",
      "Epoch 00511: ReduceLROnPlateau reducing learning rate to 3.051757735406113e-09.\n",
      "Epoch 00516: early stopping\n",
      "\n",
      "Epoch 00067: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00086: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00105: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00124: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00143: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00162: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00181: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00200: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00219: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00238: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00257: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00276: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "Epoch 00282: early stopping\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00075: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00094: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00113: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00132: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00151: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00170: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00189: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00208: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00227: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00246: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "Epoch 00256: early stopping\n",
      " - Test 2: 0.005966978518301575\n",
      "\n",
      "Epoch 00181: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00252: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00278: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00300: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00319: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00338: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00357: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00379: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00398: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00417: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00436: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00455: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "\n",
      "Epoch 00474: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-08.\n",
      "Epoch 00488: early stopping\n",
      "\n",
      "Epoch 00057: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00076: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00095: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00114: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00133: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00157: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00176: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00195: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00214: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00233: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00252: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00271: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "Epoch 00289: early stopping\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00067: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00086: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00105: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00124: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00143: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00162: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00181: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00200: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00219: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00238: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "Epoch 00246: early stopping\n",
      " - Test 3: 0.006283325726972587\n",
      "\n",
      "Epoch 00217: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00242: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00261: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00280: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00299: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00320: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00339: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00358: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00377: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00396: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00415: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00434: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "\n",
      "Epoch 00453: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-08.\n",
      "Epoch 00455: early stopping\n",
      "\n",
      "Epoch 00057: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00076: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00095: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00114: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00133: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00152: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00171: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00190: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00209: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00228: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00247: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "Epoch 00255: early stopping\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00059: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00078: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00097: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00116: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00135: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00154: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00173: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00192: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00211: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "Epoch 00222: early stopping\n",
      " - Test 4: 0.006641225981994054\n",
      "\n",
      "Epoch 00158: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00266: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00286: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00305: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00324: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00343: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00362: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00381: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00400: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00419: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00438: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00457: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "\n",
      "Epoch 00476: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-08.\n",
      "Epoch 00480: early stopping\n",
      "\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00077: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00096: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00115: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00139: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00158: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00177: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00196: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00215: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00234: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00253: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "Epoch 00265: early stopping\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00061: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00080: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00099: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00118: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00137: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00156: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00175: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00194: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00213: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "Epoch 00226: early stopping\n",
      " - Test 5: 0.006877959942194953\n",
      "Layers: [451, 551, 451]\n",
      "\n",
      "Epoch 00199: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00295: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00320: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00342: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00361: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00380: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00399: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00418: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00437: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00456: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00475: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00494: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "Epoch 00504: early stopping\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00083: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00102: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00121: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00140: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00159: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00178: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00197: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00216: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00235: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00254: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "\n",
      "Epoch 00273: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-08.\n",
      "Epoch 00278: early stopping\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00054: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00073: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00092: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00111: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00130: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00149: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00168: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00187: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00206: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00225: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00244: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "Epoch 00251: early stopping\n",
      " - Test 1: 0.0063351367516860145\n",
      "\n",
      "Epoch 00225: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00258: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00277: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00296: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00315: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00336: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00355: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00374: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00393: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00412: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00431: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00450: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "\n",
      "Epoch 00469: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-08.\n",
      "Epoch 00472: early stopping\n",
      "\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00076: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00096: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00115: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00134: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00153: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00172: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00191: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00210: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00229: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00248: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "Epoch 00266: early stopping\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00066: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00085: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00104: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00123: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00142: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00161: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00180: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00199: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00218: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00237: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "Epoch 00243: early stopping\n",
      " - Test 2: 0.006489996650066245\n",
      "\n",
      "Epoch 00228: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00257: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00284: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00303: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00322: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00341: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00360: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00379: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00398: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00417: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00436: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00455: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "\n",
      "Epoch 00474: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-08.\n",
      "Epoch 00478: early stopping\n",
      "\n",
      "Epoch 00062: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00091: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00113: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00132: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00151: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00170: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00189: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00208: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00227: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00246: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00265: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00284: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "Epoch 00297: early stopping\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00061: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00080: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00099: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00118: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00137: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00156: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00175: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00194: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00213: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00232: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "Epoch 00243: early stopping\n",
      " - Test 3: 0.0067759234995687775\n",
      "\n",
      "Epoch 00195: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00279: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00306: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00326: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00345: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00364: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00383: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00407: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00426: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00445: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00464: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00483: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "Epoch 00494: early stopping\n",
      "\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00075: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00099: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00118: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00137: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00156: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00175: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00194: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00213: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00232: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00251: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00270: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "Epoch 00277: early stopping\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00063: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00082: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00101: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00120: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00139: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00158: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00177: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00196: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00215: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00234: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "Epoch 00234: early stopping\n",
      " - Test 4: 0.006727790221368051\n",
      "\n",
      "Epoch 00232: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00261: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00280: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00299: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00318: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00337: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00356: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00375: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00394: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00413: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00432: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00451: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "\n",
      "Epoch 00470: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-08.\n",
      "Epoch 00481: early stopping\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00073: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00092: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00111: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00130: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00149: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00168: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00187: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00206: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00225: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00244: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "\n",
      "Epoch 00263: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-08.\n",
      "Epoch 00272: early stopping\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00056: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00075: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00094: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00113: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00132: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00151: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00170: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00189: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00213: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00232: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00251: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "\n",
      "Epoch 00270: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-08.\n",
      "Epoch 00272: early stopping\n",
      " - Test 5: 0.006798237564496289\n",
      "Layers: [351, 351, 351, 351, 351]\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00461: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00483: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00509: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00528: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00547: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00566: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00585: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00604: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00623: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00642: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "\n",
      "Epoch 00661: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-08.\n",
      "\n",
      "Epoch 00680: ReduceLROnPlateau reducing learning rate to 6.103515470812226e-09.\n",
      "\n",
      "Epoch 00699: ReduceLROnPlateau reducing learning rate to 3.051757735406113e-09.\n",
      "Epoch 00710: early stopping\n",
      "\n",
      "Epoch 00506: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00532: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00551: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00570: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00589: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00608: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00627: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00646: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00665: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00684: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00703: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00722: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "\n",
      "Epoch 00741: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-08.\n",
      "Epoch 00744: early stopping\n",
      "\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00067: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00086: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00105: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00124: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00143: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00162: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00181: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00200: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00219: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00238: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00257: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00268: early stopping\n",
      " - Test 1: 0.008097169253585943\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00913: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00943: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00971: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00990: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 01009: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 01028: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 01047: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 01066: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 01085: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 01104: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "\n",
      "Epoch 01123: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-08.\n",
      "\n",
      "Epoch 01142: ReduceLROnPlateau reducing learning rate to 6.103515470812226e-09.\n",
      "\n",
      "Epoch 01161: ReduceLROnPlateau reducing learning rate to 3.051757735406113e-09.\n",
      "Epoch 01171: early stopping\n",
      "\n",
      "Epoch 00131: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00174: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00193: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00218: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00237: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00261: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00280: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00299: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00318: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00337: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00356: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00375: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "\n",
      "Epoch 00394: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-08.\n",
      "Epoch 00406: early stopping\n",
      "\n",
      "Epoch 00148: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00240: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00262: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00281: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00300: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00319: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00338: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00357: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00376: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00395: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00414: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00433: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "\n",
      "Epoch 00452: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-08.\n",
      "Epoch 00461: early stopping\n",
      " - Test 2: 0.013026442758701927\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00063: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00705: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00733: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00752: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00771: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00790: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00809: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00828: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00847: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00866: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "\n",
      "Epoch 00885: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-08.\n",
      "\n",
      "Epoch 00904: ReduceLROnPlateau reducing learning rate to 6.103515470812226e-09.\n",
      "\n",
      "Epoch 00923: ReduceLROnPlateau reducing learning rate to 3.051757735406113e-09.\n",
      "\n",
      "Epoch 00942: ReduceLROnPlateau reducing learning rate to 1.5258788677030566e-09.\n",
      "\n",
      "Epoch 00961: ReduceLROnPlateau reducing learning rate to 7.629394338515283e-10.\n",
      "Epoch 00964: early stopping\n",
      "\n",
      "Epoch 00113: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00143: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00174: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00193: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00212: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00231: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00250: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00269: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00289: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00308: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00327: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00346: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "\n",
      "Epoch 00365: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-08.\n",
      "\n",
      "Epoch 00384: ReduceLROnPlateau reducing learning rate to 6.103515470812226e-09.\n",
      "\n",
      "Epoch 00403: ReduceLROnPlateau reducing learning rate to 3.051757735406113e-09.\n",
      "Epoch 00407: early stopping\n",
      "\n",
      "Epoch 00259: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00341: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00368: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00387: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00406: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00425: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00444: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00463: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00482: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00501: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00520: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00539: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "\n",
      "Epoch 00558: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-08.\n",
      "\n",
      "Epoch 00577: ReduceLROnPlateau reducing learning rate to 6.103515470812226e-09.\n",
      "\n",
      "Epoch 00596: ReduceLROnPlateau reducing learning rate to 3.051757735406113e-09.\n",
      "Epoch 00599: early stopping\n",
      " - Test 3: 0.010236682217401354\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00455: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00477: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00497: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00519: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00538: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00557: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00576: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00595: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00614: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00633: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "\n",
      "Epoch 00652: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-08.\n",
      "\n",
      "Epoch 00671: ReduceLROnPlateau reducing learning rate to 6.103515470812226e-09.\n",
      "\n",
      "Epoch 00690: ReduceLROnPlateau reducing learning rate to 3.051757735406113e-09.\n",
      "Epoch 00695: early stopping\n",
      "\n",
      "Epoch 00483: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00502: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00521: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00540: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00559: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00578: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00597: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00616: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00635: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00654: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00673: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00692: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "\n",
      "Epoch 00711: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-08.\n",
      "Epoch 00723: early stopping\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00070: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00089: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00108: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00127: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00146: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00165: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00184: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00203: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00222: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "Epoch 00232: early stopping\n",
      " - Test 4: 0.008684401840564623\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00473: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00887: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00908: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00927: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00946: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00965: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00984: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 01003: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 01022: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 01041: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 01060: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "\n",
      "Epoch 01079: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-08.\n",
      "Epoch 01094: early stopping\n",
      "\n",
      "Epoch 00142: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00162: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00186: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00207: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00226: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00245: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00264: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00283: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00302: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00322: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00341: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00360: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "\n",
      "Epoch 00379: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-08.\n",
      "\n",
      "Epoch 00398: ReduceLROnPlateau reducing learning rate to 6.103515470812226e-09.\n",
      "\n",
      "Epoch 00417: ReduceLROnPlateau reducing learning rate to 3.051757735406113e-09.\n",
      "Epoch 00422: early stopping\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00062: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00081: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00100: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00119: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00138: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00157: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00176: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00195: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\n",
      "Epoch 00214: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "\n",
      "Epoch 00233: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "\n",
      "Epoch 00252: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "Epoch 00260: early stopping\n",
      " - Test 5: 0.009801272590139612\n",
      "# lr1e-05\n",
      "Layers: [351, 351]\n",
      "\n",
      "Epoch 00682: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00701: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00720: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00739: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00758: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00777: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00796: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00815: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00834: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00853: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00872: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "\n",
      "Epoch 00891: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-09.\n",
      "Epoch 00909: early stopping\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00074: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00093: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00112: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00131: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00150: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00169: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00188: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00207: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "Epoch 00225: early stopping\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00059: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00078: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00097: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00116: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00135: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00154: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00173: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00192: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "Epoch 00206: early stopping\n",
      " - Test 1: 0.012087767443327761\n",
      "\n",
      "Epoch 00702: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00721: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00740: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00759: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00778: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00797: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00816: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00835: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00854: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00873: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00892: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "Epoch 00898: early stopping\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00066: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00085: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00104: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00123: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00142: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00161: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00180: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00199: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00218: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "Epoch 00221: early stopping\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00068: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00087: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00106: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00125: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00144: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00163: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00182: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00201: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "Epoch 00207: early stopping\n",
      " - Test 2: 0.012282230571579577\n",
      "\n",
      "Epoch 00692: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00711: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00730: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00749: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00768: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00787: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00806: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00825: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00844: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00863: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00882: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "\n",
      "Epoch 00901: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-09.\n",
      "\n",
      "Epoch 00920: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-09.\n",
      "Epoch 00935: early stopping\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00062: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00081: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00100: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00119: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00138: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00157: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00176: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00195: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00214: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "Epoch 00226: early stopping\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00068: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00087: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00106: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00125: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00144: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00163: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00182: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00201: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "Epoch 00205: early stopping\n",
      " - Test 3: 0.012223671903991285\n",
      "\n",
      "Epoch 00667: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00696: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00722: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00741: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00760: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00779: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00798: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00817: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00836: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00855: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00874: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "\n",
      "Epoch 00893: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-09.\n",
      "\n",
      "Epoch 00912: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-09.\n",
      "Epoch 00914: early stopping\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00059: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00078: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00097: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00116: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00135: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00154: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00173: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00192: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00211: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "Epoch 00215: early stopping\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00068: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00087: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00106: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00125: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00144: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00163: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00182: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00201: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "\n",
      "Epoch 00220: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-09.\n",
      "Epoch 00229: early stopping\n",
      " - Test 4: 0.012545794684124824\n",
      "\n",
      "Epoch 00705: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00724: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00743: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00762: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00781: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00800: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00819: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00838: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00857: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00876: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00895: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "Epoch 00900: early stopping\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00059: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00078: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00097: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00116: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00135: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00154: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00173: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00192: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00211: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "Epoch 00211: early stopping\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00068: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00087: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00106: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00125: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00144: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00163: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00182: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00201: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "\n",
      "Epoch 00220: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-09.\n",
      "Epoch 00230: early stopping\n",
      " - Test 5: 0.012125390771757904\n",
      "Layers: [351, 351, 351]\n",
      "\n",
      "Epoch 00940: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00959: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00978: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00997: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 01016: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 01035: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 01054: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 01073: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 01092: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 01111: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 01130: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "Epoch 01139: early stopping\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00071: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00090: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00109: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00128: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00147: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00166: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00185: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00204: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00223: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "Epoch 00225: early stopping\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00083: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00102: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00121: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00140: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00159: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00178: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00197: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00216: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "\n",
      "Epoch 00235: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-09.\n",
      "Epoch 00242: early stopping\n",
      " - Test 1: 0.013487841827396433\n",
      "\n",
      "Epoch 00970: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00998: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 01027: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 01046: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 01065: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 01084: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 01103: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 01122: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 01141: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 01160: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 01179: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "\n",
      "Epoch 01198: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-09.\n",
      "Epoch 01214: early stopping\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00074: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00093: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00112: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00131: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00150: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00169: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00188: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00207: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "\n",
      "Epoch 00226: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-09.\n",
      "Epoch 00244: early stopping\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00068: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00087: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00106: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00125: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00144: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00163: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00182: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00201: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00220: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "\n",
      "Epoch 00239: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-09.\n",
      "Epoch 00240: early stopping\n",
      " - Test 2: 0.013673583620149105\n",
      "\n",
      "Epoch 00893: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00921: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00947: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00966: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00985: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 01004: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 01023: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 01042: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 01061: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 01080: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 01099: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "Epoch 01117: early stopping\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00056: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00075: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00094: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00113: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00132: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00151: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00170: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00189: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00208: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "Epoch 00216: early stopping\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00059: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00078: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00097: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00116: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00135: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00154: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00173: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00192: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00211: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "Epoch 00214: early stopping\n",
      " - Test 3: 0.014145136704269926\n",
      "\n",
      "Epoch 00937: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00956: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00975: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00994: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 01013: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 01032: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 01051: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 01070: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 01097: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 01116: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 01135: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "\n",
      "Epoch 01154: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-09.\n",
      "Epoch 01163: early stopping\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00067: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00086: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00105: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00124: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00143: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00162: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00181: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00200: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00219: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "Epoch 00229: early stopping\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00077: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00096: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00115: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00134: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00153: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00172: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00191: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00210: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "Epoch 00217: early stopping\n",
      " - Test 4: 0.013642435365203601\n",
      "\n",
      "Epoch 00966: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00985: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 01004: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 01023: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 01042: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 01061: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 01080: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 01099: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 01118: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 01137: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 01156: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "Epoch 01166: early stopping\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00067: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00086: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00105: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00124: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00143: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00162: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00181: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00200: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00219: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "Epoch 00226: early stopping\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00077: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00096: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00115: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00134: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00153: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00172: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00191: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00210: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "Epoch 00221: early stopping\n",
      " - Test 5: 0.013436958272547568\n",
      "Layers: [451, 451]\n",
      "\n",
      "Epoch 00609: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00628: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00647: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00666: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00685: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00704: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00723: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00742: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00761: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00780: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00799: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "\n",
      "Epoch 00818: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-09.\n",
      "Epoch 00826: early stopping\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00061: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00080: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00099: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00118: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00137: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00156: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00175: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00194: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00213: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "\n",
      "Epoch 00232: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-09.\n",
      "Epoch 00232: early stopping\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00056: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00075: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00094: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00113: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00132: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00151: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00170: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00189: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00208: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "Epoch 00217: early stopping\n",
      " - Test 1: 0.011547851964683081\n",
      "\n",
      "Epoch 00608: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00627: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00646: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00665: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00684: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00703: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00722: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00741: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00760: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00779: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00798: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "\n",
      "Epoch 00817: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-09.\n",
      "Epoch 00822: early stopping\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00062: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00081: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00100: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00119: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00138: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00157: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00176: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00195: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00214: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "Epoch 00226: early stopping\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00070: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00089: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00108: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00127: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00146: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00165: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00184: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "Epoch 00199: early stopping\n",
      " - Test 2: 0.011518826152184117\n",
      "\n",
      "Epoch 00600: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00629: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00648: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00667: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00686: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00705: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00724: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00743: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00762: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00781: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00800: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "\n",
      "Epoch 00819: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-09.\n",
      "Epoch 00820: early stopping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00068: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00087: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00106: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00125: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00144: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00163: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00182: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00201: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "Epoch 00210: early stopping\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00056: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00075: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00094: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00113: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00132: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00151: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00170: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00189: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00208: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "\n",
      "Epoch 00227: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-09.\n",
      "Epoch 00237: early stopping\n",
      " - Test 3: 0.01175533884682169\n",
      "\n",
      "Epoch 00606: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00625: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00644: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00663: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00682: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00701: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00720: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00739: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00758: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00777: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00796: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "Epoch 00803: early stopping\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00068: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00087: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00106: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00125: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00144: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00163: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00182: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00201: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "\n",
      "Epoch 00220: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-09.\n",
      "\n",
      "Epoch 00239: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-09.\n",
      "Epoch 00241: early stopping\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00054: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00073: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00092: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00111: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00130: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00149: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00168: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00187: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00206: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "Epoch 00218: early stopping\n",
      " - Test 4: 0.011686406014904158\n",
      "\n",
      "Epoch 00620: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00639: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00658: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00677: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00696: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00715: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00734: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00753: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00772: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00791: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00810: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "Epoch 00815: early stopping\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00068: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00087: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00106: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00125: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00144: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00163: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00182: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00201: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "Epoch 00210: early stopping\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00077: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00096: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00115: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00134: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00153: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00172: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00191: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00210: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "Epoch 00227: early stopping\n",
      " - Test 5: 0.011645039895651353\n",
      "Layers: [601, 501, 401]\n",
      "\n",
      "Epoch 00807: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00826: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00845: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00864: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00883: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00902: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00921: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00940: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00959: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00978: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00997: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "\n",
      "Epoch 01016: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-09.\n",
      "\n",
      "Epoch 01035: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-09.\n",
      "Epoch 01042: early stopping\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00056: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00075: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00094: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00113: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00132: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00151: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00170: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00189: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00208: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "Epoch 00217: early stopping\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00057: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00076: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00095: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00114: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00133: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00152: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00171: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00190: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00209: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "\n",
      "Epoch 00228: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-09.\n",
      "Epoch 00234: early stopping\n",
      " - Test 1: 0.012839959813884241\n",
      "\n",
      "Epoch 00710: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00735: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00757: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00776: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00795: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00814: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00833: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00852: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00871: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00890: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00909: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "\n",
      "Epoch 00928: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-09.\n",
      "\n",
      "Epoch 00947: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-09.\n",
      "Epoch 00955: early stopping\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00063: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00091: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00110: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00129: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00148: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00167: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00186: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00205: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00224: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00243: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "\n",
      "Epoch 00262: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-09.\n",
      "Epoch 00271: early stopping\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00063: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00082: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00101: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00120: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00139: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00158: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00177: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00196: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00215: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "Epoch 00218: early stopping\n",
      " - Test 2: 0.013696911707705824\n",
      "\n",
      "Epoch 00783: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00811: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00830: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00849: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00868: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00887: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00906: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00925: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00944: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00963: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00982: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "Epoch 00994: early stopping\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00068: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00087: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00106: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00125: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00144: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00163: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00182: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00201: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "Epoch 00212: early stopping\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00059: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00078: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00100: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00119: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00138: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00157: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00176: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00195: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00214: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00233: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-09.\n",
      "\n",
      "Epoch 00252: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-09.\n",
      "Epoch 00254: early stopping\n",
      " - Test 3: 0.012934252110064326\n",
      "\n",
      "Epoch 00690: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00715: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00736: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00755: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00774: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00793: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00812: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00831: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00850: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00869: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00888: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "Epoch 00900: early stopping\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00063: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00082: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00101: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00120: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00141: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00160: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00179: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00198: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00217: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00236: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "Epoch 00253: early stopping\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00062: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00081: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00100: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00119: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00138: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00157: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00176: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00195: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00214: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "Epoch 00230: early stopping\n",
      " - Test 4: 0.013927074149250984\n",
      "\n",
      "Epoch 00756: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00784: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00810: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00829: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00848: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00867: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00886: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00905: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00924: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00943: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00962: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "\n",
      "Epoch 00981: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-09.\n",
      "Epoch 00989: early stopping\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00083: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00102: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00121: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00140: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00159: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00178: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00197: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00216: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "\n",
      "Epoch 00235: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-09.\n",
      "Epoch 00238: early stopping\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00072: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00091: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00110: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00129: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00148: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00167: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00186: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00205: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00224: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "Epoch 00234: early stopping\n",
      " - Test 5: 0.012631520930103106\n",
      "Layers: [451, 551, 451]\n",
      "\n",
      "Epoch 00775: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00803: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00830: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00849: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00868: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00887: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00906: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00925: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00944: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00963: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00982: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "\n",
      "Epoch 01001: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-09.\n",
      "Epoch 01009: early stopping\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00062: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00081: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00100: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00119: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00138: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00157: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00176: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00195: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00214: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "Epoch 00222: early stopping\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00066: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00085: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00104: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00123: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00142: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00161: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00180: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00199: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00218: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "Epoch 00225: early stopping\n",
      " - Test 1: 0.01335357086946122\n",
      "\n",
      "Epoch 00798: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00826: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00845: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00864: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00883: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00902: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00921: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00940: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00959: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00978: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00997: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "\n",
      "Epoch 01016: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-09.\n",
      "Epoch 01017: early stopping\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00059: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00078: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00097: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00116: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00135: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00154: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00173: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00192: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00211: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "\n",
      "Epoch 00230: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-09.\n",
      "Epoch 00241: early stopping\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00059: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00078: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00097: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00116: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00135: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00154: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00173: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00192: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00211: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "Epoch 00222: early stopping\n",
      " - Test 2: 0.01316806609135362\n",
      "\n",
      "Epoch 00766: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00793: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00819: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00838: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00857: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00876: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00895: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00914: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00933: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00952: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00971: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "Epoch 00983: early stopping\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00057: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00076: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00095: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00114: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00133: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00152: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00171: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00190: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00209: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "Epoch 00219: early stopping\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00070: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00089: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00108: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00127: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00146: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00165: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00184: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00203: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00222: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "Epoch 00226: early stopping\n",
      " - Test 3: 0.013582339667858769\n",
      "\n",
      "Epoch 00791: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00820: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00847: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00866: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00885: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00904: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00923: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00942: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00961: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00980: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00999: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "\n",
      "Epoch 01018: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-09.\n",
      "Epoch 01019: early stopping\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00066: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00085: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00104: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00123: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00142: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00161: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00180: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00199: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00218: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00237: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-09.\n",
      "\n",
      "Epoch 00256: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-09.\n",
      "Epoch 00261: early stopping\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00059: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00078: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00097: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00116: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00135: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00154: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00173: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00192: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00211: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "\n",
      "Epoch 00230: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-09.\n",
      "Epoch 00247: early stopping\n",
      " - Test 4: 0.013194530349762286\n",
      "\n",
      "Epoch 00782: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00811: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00838: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00857: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00876: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00895: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00914: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00933: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00952: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00971: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00990: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "\n",
      "Epoch 01009: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-09.\n",
      "Epoch 01015: early stopping\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00074: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00093: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00112: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00131: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00150: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00169: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00188: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00207: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00226: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "Epoch 00242: early stopping\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00060: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00079: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\n",
      "Epoch 00098: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\n",
      "Epoch 00117: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "\n",
      "Epoch 00136: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "\n",
      "Epoch 00155: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "\n",
      "Epoch 00174: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "\n",
      "Epoch 00193: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "\n",
      "Epoch 00212: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "Epoch 00219: early stopping\n",
      " - Test 5: 0.013465736107669067\n",
      "Layers: [351, 351, 351, 351, 351]\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00063: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00082: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00101: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "Epoch 00113: early stopping\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "Epoch 00055: early stopping\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "Epoch 00060: early stopping\n",
      " - Test 1: 0.06092623932592904\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00060: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00079: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00098: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "Epoch 00105: early stopping\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "Epoch 00055: early stopping\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00068: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "Epoch 00080: early stopping\n",
      " - Test 2: 0.0608976604370632\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00065: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00084: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "Epoch 00095: early stopping\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "Epoch 00057: early stopping\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00056: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "Epoch 00058: early stopping\n",
      " - Test 3: 0.06091343503982866\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00077: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00096: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "Epoch 00105: early stopping\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00059: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "Epoch 00067: early stopping\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "Epoch 00059: early stopping\n",
      " - Test 4: 0.060903294095352514\n",
      "\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00066: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00085: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00104: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "Epoch 00113: early stopping\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\n",
      "Epoch 00068: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "Epoch 00080: early stopping\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "Epoch 00056: early stopping\n",
      " - Test 5: 0.06092216841765304\n"
     ]
    }
   ],
   "source": [
    "res = []\n",
    "for lr in learning_rates:\n",
    "    print(\"# lr\" + str(lr))\n",
    "    res.append(run_layer_test_series('elu', structures, lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [ \n",
    "    s for s in range(len(structures)) for i in range(n_tests)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"data/hyperpar_res.npy\", res)\n",
    "np.save(\"data/hyperpar_x.npy\", x)\n",
    "np.save(\"data/hyperpar_structures.npy\", structures)\n",
    "np.save(\"data/hyperpar_lr.npy\", learning_rates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'351_351'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def structure_string(structure):\n",
    "    return \"_\".join(list(map(str,list(structure))))\n",
    "structure_string(structures[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc(\"figure\", figsize=(8,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.001     , 0.00177828, 0.00316228, 0.00562341, 0.01      ,\n",
       "       0.01778279, 0.03162278, 0.05623413, 0.1       ])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f36b40d3e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.ticker as mtick\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.gca()\n",
    "\n",
    "for r, lr in zip(res, learning_rates):\n",
    "    ax.scatter(x, np.array(r).flatten(), marker=\"x\", label=\"$\\eta$ = {:1.0e}\".format(lr) )\n",
    "\n",
    "ax.set_yscale('log')\n",
    "#yticks = [2.5e-3, 5e-3, 7.5e-3, 1e-2, 2.5e-2, 5e-2, 7.5e-2, 1e-1]\n",
    "yticks = [5e-3, 1e-2, 5e-2, 1e-1]\n",
    "plt.yticks(yticks, yticks)\n",
    "\n",
    "ax.yaxis.set_major_formatter(mtick.FormatStrFormatter('%.0e'))\n",
    "\n",
    "#plt.xlabel(\"Number of Hidden Layers / 1\")\n",
    "plt.ylabel(\"Mean Absolute Error / 1\")\n",
    "\n",
    "plt.xticks(\n",
    "    np.arange(len(structures)),\n",
    "    [structure_string(structure) for structure in structures],\n",
    "    rotation=-60\n",
    ")\n",
    "#yticks = [2e-3, 5e-3, 1e-2, 5e-2, 1e-1]\n",
    "#plt.yticks(yticks, yticks)\n",
    "\n",
    "#plt.ylim(0.0025, 0.015)\n",
    "plt.legend()\n",
    "#plt.legend(loc='upper right',bbox_to_anchor=(1.15, 1.))\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"/home/jo/Repos/MastersThesis/SMatrixDescriptor/figures/HyperparameterStudy.pdf\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(5e-3)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
