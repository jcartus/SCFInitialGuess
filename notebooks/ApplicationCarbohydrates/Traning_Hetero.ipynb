{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jo/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import seaborn as sns\n",
    "\n",
    "from os.path import join\n",
    "\n",
    "plt.style.use([\"seaborn\", \"thesis\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc(\"figure\", figsize=(8,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Molecules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SCFInitialGuess.utilities.dataset import ScreenedData\n",
    "\n",
    "target = \"P\"\n",
    "basis = \"6-311++g**\"\n",
    "\n",
    "data = ScreenedData(r_max=10)\n",
    "\n",
    "data.include(data_path = \"../../thesis/dataset/MethanT/\", postfix = \"MethanT\", target=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = Data()\n",
    "\n",
    "#data.include(data_path = \"../../dataset/MethanT/\", postfix = \"MethanT\", target=target)\n",
    "data.include(data_path = \"../../thesis/dataset/MethanT2/\", postfix = \"MethanT2\", target=target)\n",
    "data.include(data_path = \"../../thesis/dataset/MethanT3/\", postfix = \"MethanT3\", target=target)\n",
    "data.include(data_path = \"../../thesis/dataset/MethanT4/\", postfix = \"MethanT4\", target=target)\n",
    "\n",
    "data.include(data_path = \"../../thesis/dataset/EthanT/\",  postfix = \"EthanT\", target=target)\n",
    "data.include(data_path = \"../../thesis/dataset/EthanT2/\", postfix = \"EthanT2\", target=target)\n",
    "data.include(data_path = \"../../thesis/dataset/EthanT3/\", postfix = \"EthanT3\", target=target)\n",
    "\n",
    "data.include(data_path = \"../../thesis/dataset/EthenT/\",  postfix = \"EthenT\", target=target)\n",
    "data.include(data_path = \"../../thesis/dataset/EthenT2/\", postfix = \"EthenT2\", target=target)\n",
    "data.include(data_path = \"../../thesis/dataset/EthenT3/\", postfix = \"EthenT3\", target=target)\n",
    "\n",
    "data.include(data_path = \"../../thesis/dataset/EthinT/\",  postfix = \"EthinT\", target=target)\n",
    "data.include(data_path = \"../../thesis/dataset/EthinT2/\", postfix = \"EthinT2\", target=target)\n",
    "data.include(data_path = \"../../thesis/dataset/EthinT3/\", postfix = \"EthinT3\", target=target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descriptor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 50, 75)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from SCFInitialGuess.descriptors.high_level import AtomicNumberWeighted\n",
    "from SCFInitialGuess.descriptors.cutoffs import BehlerCutoff1\n",
    "from SCFInitialGuess.descriptors.models import RADIAL_GAUSSIAN_MODELS, make_uniform\n",
    "from SCFInitialGuess.descriptors.coordinate_descriptors import \\\n",
    "    Gaussians, SPHAngularDescriptor\n",
    "import pickle\n",
    "\n",
    "model = make_uniform(25, 5, eta_max=60, eta_min=20)\n",
    "\n",
    "descriptor_C = AtomicNumberWeighted(\n",
    "    Gaussians(*model),\n",
    "    SPHAngularDescriptor(4),\n",
    "    BehlerCutoff1(5)\n",
    ")\n",
    "\n",
    "\n",
    "#pickle.dump(descriptor, open(model_path + \"descriptor.dump\", \"wb\"))\n",
    "    \n",
    "descriptor_C.radial_descriptor.number_of_descriptors, descriptor_C.angular_descriptor.number_of_descriptors, descriptor_C.number_of_descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptor_H = descriptor_C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Package Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SCFInitialGuess.utilities.dataset import make_block_dataset, extract_HETERO_block_dataset_pairs\n",
    "\n",
    "dataset = make_block_dataset(\n",
    "    [descriptor_C, descriptor_H],\n",
    "    data.molecules,\n",
    "    data.T,\n",
    "    [\"C\", \"H\"],\n",
    "    extract_HETERO_block_dataset_pairs\n",
    ")\n",
    "\n",
    "#np.save(model_path + \"normalisation.npy\", (dataset.x_mean, dataset.x_std))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35440, 8880, 11140)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.training[0]), len(dataset.validation[0]), len(dataset.testing[0]), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SCFInitialGuess.utilities.constants import number_of_basis_functions as N_BASIS\n",
    "\n",
    "\n",
    "dim_C = N_BASIS[basis][\"C\"]\n",
    "dim_H = N_BASIS[basis][\"H\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN Utils "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keras.backend.clear_session()\n",
    "\n",
    "#activation = \"elu\"\n",
    "#learning_rate = 1e-5\n",
    "\n",
    "intializer = keras.initializers.TruncatedNormal(mean=0.0, stddev=0.01)\n",
    "\n",
    "def make_model(\n",
    "        structure, \n",
    "        input_dim, \n",
    "        output_dim,\n",
    "        activation=\"elu\", \n",
    "        learning_rate=1e-3\n",
    "    ):\n",
    "\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    # input layer\n",
    "    model.add(keras.layers.Dense(\n",
    "        structure[0], \n",
    "        activation=activation, \n",
    "        input_dim=input_dim, \n",
    "        kernel_initializer=intializer\n",
    "    ))\n",
    "\n",
    "    for layer in structure[1:]:\n",
    "        model.add(keras.layers.Dense(\n",
    "            layer, \n",
    "            activation=activation, \n",
    "            kernel_initializer=intializer, \n",
    "            #bias_initializer='zeros',\n",
    "            kernel_regularizer=keras.regularizers.l2(5e-3)\n",
    "        ))\n",
    "\n",
    "    #output\n",
    "    model.add(keras.layers.Dense(output_dim))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate), \n",
    "        loss='MSE', \n",
    "        metrics=['mse']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_mean_squared_error\", \n",
    "    min_delta=1e-8, \n",
    "    patience=20, \n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_mean_squared_error', \n",
    "    factor=0.1, \n",
    "    patience=3, \n",
    "    verbose=1, \n",
    "    mode='auto', \n",
    "    min_delta=1e-6, \n",
    "    cooldown=2, \n",
    "    min_lr=1e-10\n",
    ")\n",
    "\n",
    "\n",
    "epochs = 1000\n",
    "\n",
    "\n",
    "def train_model(model, dataset, filepath=None, learning_rate=1e-4, log_dir=None):\n",
    "\n",
    "    if not log_dir is None:\n",
    "        tensorboard = keras.callbacks.TensorBoard(\n",
    "            log_dir=log_dir, \n",
    "            histogram_freq=0, \n",
    "            batch_size=32, \n",
    "            #update_freq='epoch'\n",
    "        )\n",
    "    \n",
    "    if not filepath is None:\n",
    "        checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "            filepath, \n",
    "            monitor='val_mean_squared_error', \n",
    "            verbose=1, \n",
    "            save_best_only=True, \n",
    "            save_weights_only=False, \n",
    "            mode='auto', \n",
    "            period=1\n",
    "        )\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    \n",
    "    train, validation = [], []\n",
    "    while True:\n",
    "        keras.backend.set_value(model.optimizer.lr, learning_rate)\n",
    "            \n",
    "        history = model.fit(\n",
    "            x = dataset.training[0],\n",
    "            y = dataset.training[1],\n",
    "            epochs=epochs,\n",
    "            shuffle=True,\n",
    "            validation_data=dataset.validation, \n",
    "            verbose=1, \n",
    "            callbacks=[\n",
    "                early_stopping, \n",
    "                reduce_lr,\n",
    "                #checkpoint,\n",
    "                #tensorboard\n",
    "            ]\n",
    "        )\n",
    "            \n",
    "        \n",
    "        #error.append(model.evaluate(\n",
    "        #    dataset.testing[0], \n",
    "        #    dataset.testing[1], \n",
    "        #    verbose=1\n",
    "        #)[1])\n",
    "    \n",
    "    return error\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35440, 150), (35440, 154))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.training[0].shape, dataset.training[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75, 75, 154)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descriptor_C.number_of_descriptors, descriptor_H.number_of_descriptors, dim_C * dim_H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "structure = [200, 200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 200)               30200     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 154)               30954     \n",
      "=================================================================\n",
      "Total params: 101,354\n",
      "Trainable params: 101,354\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = make_model(\n",
    "    structure=structure,\n",
    "    input_dim=descriptor_C.number_of_descriptors + descriptor_H.number_of_descriptors,\n",
    "    output_dim=dim_C * dim_H,\n",
    "    \n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path=\"models/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 35440 samples, validate on 8880 samples\n",
      "Epoch 1/1000\n",
      "35440/35440 [==============================] - 3s 79us/step - loss: 5.1395e-04 - mean_squared_error: 3.5811e-04 - val_loss: 3.6483e-04 - val_mean_squared_error: 2.9660e-04\n",
      "Epoch 2/1000\n",
      "35440/35440 [==============================] - 3s 73us/step - loss: 3.2587e-04 - mean_squared_error: 2.6846e-04 - val_loss: 3.0919e-04 - val_mean_squared_error: 2.5642e-04\n",
      "Epoch 3/1000\n",
      "35440/35440 [==============================] - 3s 95us/step - loss: 2.6655e-04 - mean_squared_error: 2.1864e-04 - val_loss: 2.9375e-04 - val_mean_squared_error: 2.3882e-04\n",
      "Epoch 4/1000\n",
      "35440/35440 [==============================] - 4s 111us/step - loss: 2.3471e-04 - mean_squared_error: 1.9242e-04 - val_loss: 3.2881e-04 - val_mean_squared_error: 2.5017e-04\n",
      "Epoch 5/1000\n",
      "35440/35440 [==============================] - 3s 93us/step - loss: 2.5128e-04 - mean_squared_error: 1.9124e-04 - val_loss: 2.6459e-04 - val_mean_squared_error: 2.2889e-04\n",
      "Epoch 6/1000\n",
      "35440/35440 [==============================] - 4s 108us/step - loss: 2.0678e-04 - mean_squared_error: 1.7239e-04 - val_loss: 2.6114e-04 - val_mean_squared_error: 2.3040e-04\n",
      "Epoch 7/1000\n",
      "35440/35440 [==============================] - 3s 98us/step - loss: 2.0856e-04 - mean_squared_error: 1.7171e-04 - val_loss: 2.6434e-04 - val_mean_squared_error: 2.2788e-04\n",
      "Epoch 8/1000\n",
      "35440/35440 [==============================] - 3s 86us/step - loss: 2.3788e-04 - mean_squared_error: 1.8203e-04 - val_loss: 2.6491e-04 - val_mean_squared_error: 2.2888e-04\n",
      "Epoch 9/1000\n",
      "35440/35440 [==============================] - 3s 80us/step - loss: 1.9390e-04 - mean_squared_error: 1.6332e-04 - val_loss: 2.5211e-04 - val_mean_squared_error: 2.2497e-04\n",
      "Epoch 10/1000\n",
      "35440/35440 [==============================] - 3s 91us/step - loss: 1.9236e-04 - mean_squared_error: 1.6134e-04 - val_loss: 2.5295e-04 - val_mean_squared_error: 2.2191e-04\n",
      "Epoch 11/1000\n",
      "35440/35440 [==============================] - 4s 114us/step - loss: 1.9196e-04 - mean_squared_error: 1.6057e-04 - val_loss: 2.5167e-04 - val_mean_squared_error: 2.2126e-04\n",
      "Epoch 12/1000\n",
      "35440/35440 [==============================] - 3s 96us/step - loss: 1.9227e-04 - mean_squared_error: 1.5968e-04 - val_loss: 2.6211e-04 - val_mean_squared_error: 2.2595e-04\n",
      "Epoch 13/1000\n",
      "35440/35440 [==============================] - 4s 110us/step - loss: 1.9332e-04 - mean_squared_error: 1.5948e-04 - val_loss: 2.5230e-04 - val_mean_squared_error: 2.2190e-04\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 14/1000\n",
      "35440/35440 [==============================] - 4s 99us/step - loss: 1.5718e-04 - mean_squared_error: 1.3974e-04 - val_loss: 2.2461e-04 - val_mean_squared_error: 2.0796e-04\n",
      "Epoch 15/1000\n",
      "35440/35440 [==============================] - 4s 106us/step - loss: 1.5477e-04 - mean_squared_error: 1.3848e-04 - val_loss: 2.2131e-04 - val_mean_squared_error: 2.0582e-04\n",
      "Epoch 16/1000\n",
      "35440/35440 [==============================] - 4s 119us/step - loss: 1.5346e-04 - mean_squared_error: 1.3797e-04 - val_loss: 2.2270e-04 - val_mean_squared_error: 2.0745e-04\n",
      "Epoch 17/1000\n",
      "35440/35440 [==============================] - 4s 104us/step - loss: 1.5208e-04 - mean_squared_error: 1.3729e-04 - val_loss: 2.2151e-04 - val_mean_squared_error: 2.0682e-04\n",
      "Epoch 18/1000\n",
      "35440/35440 [==============================] - 4s 106us/step - loss: 1.5088e-04 - mean_squared_error: 1.3676e-04 - val_loss: 2.2051e-04 - val_mean_squared_error: 2.0668e-04\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 19/1000\n",
      "35440/35440 [==============================] - 4s 120us/step - loss: 1.4668e-04 - mean_squared_error: 1.3397e-04 - val_loss: 2.1703e-04 - val_mean_squared_error: 2.0423e-04\n",
      "Epoch 20/1000\n",
      "35440/35440 [==============================] - 4s 124us/step - loss: 1.4628e-04 - mean_squared_error: 1.3359e-04 - val_loss: 2.1686e-04 - val_mean_squared_error: 2.0429e-04\n",
      "Epoch 21/1000\n",
      "35440/35440 [==============================] - 4s 117us/step - loss: 1.4610e-04 - mean_squared_error: 1.3351e-04 - val_loss: 2.1664e-04 - val_mean_squared_error: 2.0402e-04\n",
      "Epoch 22/1000\n",
      "35440/35440 [==============================] - 4s 123us/step - loss: 1.4597e-04 - mean_squared_error: 1.3343e-04 - val_loss: 2.1665e-04 - val_mean_squared_error: 2.0414e-04\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 23/1000\n",
      "35440/35440 [==============================] - 6s 176us/step - loss: 1.4550e-04 - mean_squared_error: 1.3307e-04 - val_loss: 2.1619e-04 - val_mean_squared_error: 2.0377e-04\n",
      "Epoch 24/1000\n",
      "35440/35440 [==============================] - 5s 141us/step - loss: 1.4541e-04 - mean_squared_error: 1.3302e-04 - val_loss: 2.1607e-04 - val_mean_squared_error: 2.0368e-04\n",
      "Epoch 25/1000\n",
      "35440/35440 [==============================] - 4s 120us/step - loss: 1.4538e-04 - mean_squared_error: 1.3300e-04 - val_loss: 2.1608e-04 - val_mean_squared_error: 2.0370e-04\n",
      "Epoch 26/1000\n",
      "35440/35440 [==============================] - 5s 129us/step - loss: 1.4536e-04 - mean_squared_error: 1.3299e-04 - val_loss: 2.1602e-04 - val_mean_squared_error: 2.0365e-04\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 27/1000\n",
      "35440/35440 [==============================] - 6s 182us/step - loss: 1.4529e-04 - mean_squared_error: 1.3292e-04 - val_loss: 2.1602e-04 - val_mean_squared_error: 2.0365e-04\n",
      "Epoch 28/1000\n",
      "35440/35440 [==============================] - 5s 137us/step - loss: 1.4529e-04 - mean_squared_error: 1.3292e-04 - val_loss: 2.1602e-04 - val_mean_squared_error: 2.0365e-04\n",
      "Epoch 29/1000\n",
      "35440/35440 [==============================] - 5s 146us/step - loss: 1.4529e-04 - mean_squared_error: 1.3292e-04 - val_loss: 2.1602e-04 - val_mean_squared_error: 2.0365e-04\n",
      "Epoch 30/1000\n",
      "35440/35440 [==============================] - 5s 129us/step - loss: 1.4529e-04 - mean_squared_error: 1.3292e-04 - val_loss: 2.1602e-04 - val_mean_squared_error: 2.0365e-04\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "Epoch 31/1000\n",
      "35440/35440 [==============================] - 5s 145us/step - loss: 1.4528e-04 - mean_squared_error: 1.3291e-04 - val_loss: 2.1602e-04 - val_mean_squared_error: 2.0365e-04\n",
      "Epoch 32/1000\n",
      "35440/35440 [==============================] - 5s 137us/step - loss: 1.4528e-04 - mean_squared_error: 1.3291e-04 - val_loss: 2.1602e-04 - val_mean_squared_error: 2.0365e-04\n",
      "Epoch 33/1000\n",
      "35440/35440 [==============================] - 5s 133us/step - loss: 1.4528e-04 - mean_squared_error: 1.3291e-04 - val_loss: 2.1602e-04 - val_mean_squared_error: 2.0365e-04\n",
      "Epoch 34/1000\n",
      "35440/35440 [==============================] - 5s 148us/step - loss: 1.4528e-04 - mean_squared_error: 1.3291e-04 - val_loss: 2.1602e-04 - val_mean_squared_error: 2.0365e-04\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "Epoch 35/1000\n",
      "35440/35440 [==============================] - 8s 230us/step - loss: 1.4528e-04 - mean_squared_error: 1.3291e-04 - val_loss: 2.1602e-04 - val_mean_squared_error: 2.0365e-04\n",
      "Epoch 36/1000\n",
      "35440/35440 [==============================] - 5s 152us/step - loss: 1.4528e-04 - mean_squared_error: 1.3291e-04 - val_loss: 2.1602e-04 - val_mean_squared_error: 2.0365e-04\n",
      "Epoch 37/1000\n",
      "35440/35440 [==============================] - 5s 140us/step - loss: 1.4528e-04 - mean_squared_error: 1.3291e-04 - val_loss: 2.1602e-04 - val_mean_squared_error: 2.0365e-04\n",
      "Epoch 38/1000\n",
      "35440/35440 [==============================] - 5s 134us/step - loss: 1.4528e-04 - mean_squared_error: 1.3291e-04 - val_loss: 2.1602e-04 - val_mean_squared_error: 2.0365e-04\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "Epoch 39/1000\n",
      "35440/35440 [==============================] - 5s 148us/step - loss: 1.4528e-04 - mean_squared_error: 1.3291e-04 - val_loss: 2.1602e-04 - val_mean_squared_error: 2.0365e-04\n",
      "Epoch 40/1000\n",
      "35440/35440 [==============================] - 5s 134us/step - loss: 1.4528e-04 - mean_squared_error: 1.3291e-04 - val_loss: 2.1602e-04 - val_mean_squared_error: 2.0365e-04\n",
      "Epoch 41/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35440/35440 [==============================] - 7s 202us/step - loss: 1.4528e-04 - mean_squared_error: 1.3291e-04 - val_loss: 2.1602e-04 - val_mean_squared_error: 2.0365e-04\n",
      "Epoch 42/1000\n",
      "35440/35440 [==============================] - 6s 176us/step - loss: 1.4528e-04 - mean_squared_error: 1.3291e-04 - val_loss: 2.1602e-04 - val_mean_squared_error: 2.0365e-04\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
      "Epoch 43/1000\n",
      "35440/35440 [==============================] - 6s 180us/step - loss: 1.4528e-04 - mean_squared_error: 1.3291e-04 - val_loss: 2.1602e-04 - val_mean_squared_error: 2.0365e-04\n",
      "Epoch 44/1000\n",
      "35440/35440 [==============================] - 5s 142us/step - loss: 1.4528e-04 - mean_squared_error: 1.3291e-04 - val_loss: 2.1602e-04 - val_mean_squared_error: 2.0365e-04\n",
      "Epoch 45/1000\n",
      "35440/35440 [==============================] - 5s 141us/step - loss: 1.4528e-04 - mean_squared_error: 1.3291e-04 - val_loss: 2.1602e-04 - val_mean_squared_error: 2.0365e-04\n",
      "Epoch 46/1000\n",
      "35440/35440 [==============================] - 4s 125us/step - loss: 1.4528e-04 - mean_squared_error: 1.3291e-04 - val_loss: 2.1602e-04 - val_mean_squared_error: 2.0365e-04\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
      "Epoch 00046: early stopping\n",
      "Train on 35440 samples, validate on 8880 samples\n",
      "Epoch 1/1000\n",
      "35440/35440 [==============================] - 5s 145us/step - loss: 2.2087e-04 - mean_squared_error: 1.6899e-04 - val_loss: 2.5132e-04 - val_mean_squared_error: 2.2342e-04\n",
      "Epoch 2/1000\n",
      "35440/35440 [==============================] - 5s 131us/step - loss: 1.8325e-04 - mean_squared_error: 1.5339e-04 - val_loss: 2.4710e-04 - val_mean_squared_error: 2.1950e-04\n",
      "Epoch 3/1000\n",
      "35440/35440 [==============================] - 5s 139us/step - loss: 2.0960e-04 - mean_squared_error: 1.6291e-04 - val_loss: 2.7531e-04 - val_mean_squared_error: 2.3591e-04\n",
      "Epoch 4/1000\n",
      "35440/35440 [==============================] - 5s 142us/step - loss: 1.8273e-04 - mean_squared_error: 1.5228e-04 - val_loss: 2.4310e-04 - val_mean_squared_error: 2.1497e-04\n",
      "Epoch 5/1000\n",
      "35440/35440 [==============================] - 8s 222us/step - loss: 1.8089e-04 - mean_squared_error: 1.5144e-04 - val_loss: 2.5577e-04 - val_mean_squared_error: 2.2437e-04\n",
      "Epoch 6/1000\n",
      "35440/35440 [==============================] - 6s 173us/step - loss: 1.8405e-04 - mean_squared_error: 1.5236e-04 - val_loss: 2.6083e-04 - val_mean_squared_error: 2.3038e-04\n",
      "Epoch 7/1000\n",
      "35440/35440 [==============================] - 6s 174us/step - loss: 1.8295e-04 - mean_squared_error: 1.5148e-04 - val_loss: 2.6050e-04 - val_mean_squared_error: 2.2819e-04\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 8/1000\n",
      "35440/35440 [==============================] - 5s 128us/step - loss: 1.5042e-04 - mean_squared_error: 1.3370e-04 - val_loss: 2.2265e-04 - val_mean_squared_error: 2.0681e-04\n",
      "Epoch 9/1000\n",
      "35440/35440 [==============================] - 6s 183us/step - loss: 1.4826e-04 - mean_squared_error: 1.3267e-04 - val_loss: 2.2312e-04 - val_mean_squared_error: 2.0809e-04\n",
      "Epoch 10/1000\n",
      "35440/35440 [==============================] - 7s 204us/step - loss: 1.4701e-04 - mean_squared_error: 1.3219e-04 - val_loss: 2.2105e-04 - val_mean_squared_error: 2.0668e-04\n",
      "Epoch 11/1000\n",
      "35440/35440 [==============================] - 5s 139us/step - loss: 1.4564e-04 - mean_squared_error: 1.3152e-04 - val_loss: 2.2109e-04 - val_mean_squared_error: 2.0703e-04\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 12/1000\n",
      "35440/35440 [==============================] - 5s 144us/step - loss: 1.4170e-04 - mean_squared_error: 1.2885e-04 - val_loss: 2.1806e-04 - val_mean_squared_error: 2.0532e-04\n",
      "Epoch 13/1000\n",
      "35440/35440 [==============================] - 5s 128us/step - loss: 1.4132e-04 - mean_squared_error: 1.2863e-04 - val_loss: 2.1735e-04 - val_mean_squared_error: 2.0472e-04\n",
      "Epoch 14/1000\n",
      "35440/35440 [==============================] - 7s 190us/step - loss: 1.4114e-04 - mean_squared_error: 1.2855e-04 - val_loss: 2.1769e-04 - val_mean_squared_error: 2.0510e-04\n",
      "Epoch 15/1000\n",
      "35440/35440 [==============================] - 7s 194us/step - loss: 1.4097e-04 - mean_squared_error: 1.2843e-04 - val_loss: 2.1757e-04 - val_mean_squared_error: 2.0514e-04\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 16/1000\n",
      "35440/35440 [==============================] - 7s 185us/step - loss: 1.4055e-04 - mean_squared_error: 1.2819e-04 - val_loss: 2.1718e-04 - val_mean_squared_error: 2.0481e-04\n",
      "Epoch 17/1000\n",
      "35440/35440 [==============================] - 6s 180us/step - loss: 1.4046e-04 - mean_squared_error: 1.2810e-04 - val_loss: 2.1701e-04 - val_mean_squared_error: 2.0466e-04\n",
      "Epoch 18/1000\n",
      "35440/35440 [==============================] - 6s 170us/step - loss: 1.4043e-04 - mean_squared_error: 1.2808e-04 - val_loss: 2.1704e-04 - val_mean_squared_error: 2.0468e-04\n",
      "Epoch 19/1000\n",
      "35440/35440 [==============================] - 6s 181us/step - loss: 1.4041e-04 - mean_squared_error: 1.2806e-04 - val_loss: 2.1714e-04 - val_mean_squared_error: 2.0478e-04\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 20/1000\n",
      "35440/35440 [==============================] - 7s 188us/step - loss: 1.4034e-04 - mean_squared_error: 1.2799e-04 - val_loss: 2.1710e-04 - val_mean_squared_error: 2.0475e-04\n",
      "Epoch 21/1000\n",
      "35440/35440 [==============================] - 7s 184us/step - loss: 1.4034e-04 - mean_squared_error: 1.2799e-04 - val_loss: 2.1708e-04 - val_mean_squared_error: 2.0473e-04\n",
      "Epoch 22/1000\n",
      "35440/35440 [==============================] - 6s 179us/step - loss: 1.4034e-04 - mean_squared_error: 1.2799e-04 - val_loss: 2.1706e-04 - val_mean_squared_error: 2.0471e-04\n",
      "Epoch 23/1000\n",
      "35440/35440 [==============================] - 6s 169us/step - loss: 1.4033e-04 - mean_squared_error: 1.2799e-04 - val_loss: 2.1705e-04 - val_mean_squared_error: 2.0470e-04\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "Epoch 24/1000\n",
      "35440/35440 [==============================] - 7s 191us/step - loss: 1.4033e-04 - mean_squared_error: 1.2798e-04 - val_loss: 2.1704e-04 - val_mean_squared_error: 2.0470e-04\n",
      "Epoch 25/1000\n",
      "35440/35440 [==============================] - 7s 191us/step - loss: 1.4033e-04 - mean_squared_error: 1.2798e-04 - val_loss: 2.1704e-04 - val_mean_squared_error: 2.0470e-04\n",
      "Epoch 26/1000\n",
      "35440/35440 [==============================] - 7s 189us/step - loss: 1.4033e-04 - mean_squared_error: 1.2798e-04 - val_loss: 2.1704e-04 - val_mean_squared_error: 2.0470e-04\n",
      "Epoch 27/1000\n",
      "35440/35440 [==============================] - 6s 178us/step - loss: 1.4033e-04 - mean_squared_error: 1.2798e-04 - val_loss: 2.1704e-04 - val_mean_squared_error: 2.0469e-04\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "Epoch 28/1000\n",
      "35440/35440 [==============================] - 7s 196us/step - loss: 1.4032e-04 - mean_squared_error: 1.2798e-04 - val_loss: 2.1704e-04 - val_mean_squared_error: 2.0469e-04\n",
      "Epoch 29/1000\n",
      "35440/35440 [==============================] - 6s 170us/step - loss: 1.4032e-04 - mean_squared_error: 1.2798e-04 - val_loss: 2.1704e-04 - val_mean_squared_error: 2.0469e-04\n",
      "Epoch 30/1000\n",
      "35440/35440 [==============================] - 6s 182us/step - loss: 1.4032e-04 - mean_squared_error: 1.2798e-04 - val_loss: 2.1704e-04 - val_mean_squared_error: 2.0469e-04\n",
      "Epoch 31/1000\n",
      "35440/35440 [==============================] - 7s 207us/step - loss: 1.4032e-04 - mean_squared_error: 1.2798e-04 - val_loss: 2.1704e-04 - val_mean_squared_error: 2.0469e-04\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "Epoch 32/1000\n",
      "35440/35440 [==============================] - 9s 242us/step - loss: 1.4032e-04 - mean_squared_error: 1.2798e-04 - val_loss: 2.1704e-04 - val_mean_squared_error: 2.0469e-04\n",
      "Epoch 33/1000\n",
      "35440/35440 [==============================] - 6s 177us/step - loss: 1.4032e-04 - mean_squared_error: 1.2798e-04 - val_loss: 2.1704e-04 - val_mean_squared_error: 2.0469e-04\n",
      "Epoch 34/1000\n",
      "35440/35440 [==============================] - 7s 198us/step - loss: 1.4032e-04 - mean_squared_error: 1.2798e-04 - val_loss: 2.1704e-04 - val_mean_squared_error: 2.0469e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/1000\n",
      "35440/35440 [==============================] - 6s 180us/step - loss: 1.4032e-04 - mean_squared_error: 1.2798e-04 - val_loss: 2.1704e-04 - val_mean_squared_error: 2.0469e-04\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
      "Epoch 36/1000\n",
      "35440/35440 [==============================] - 6s 183us/step - loss: 1.4032e-04 - mean_squared_error: 1.2798e-04 - val_loss: 2.1704e-04 - val_mean_squared_error: 2.0469e-04\n",
      "Epoch 37/1000\n",
      "35440/35440 [==============================] - 6s 171us/step - loss: 1.4032e-04 - mean_squared_error: 1.2798e-04 - val_loss: 2.1704e-04 - val_mean_squared_error: 2.0469e-04\n",
      "Epoch 00037: early stopping\n",
      "Train on 35440 samples, validate on 8880 samples\n",
      "Epoch 1/1000\n",
      "35440/35440 [==============================] - 6s 167us/step - loss: 2.1039e-04 - mean_squared_error: 1.6014e-04 - val_loss: 3.0009e-04 - val_mean_squared_error: 2.5350e-04\n",
      "Epoch 2/1000\n",
      "35440/35440 [==============================] - 6s 175us/step - loss: 2.0403e-04 - mean_squared_error: 1.5882e-04 - val_loss: 2.4658e-04 - val_mean_squared_error: 2.1835e-04\n",
      "Epoch 3/1000\n",
      "35440/35440 [==============================] - 6s 182us/step - loss: 1.8525e-04 - mean_squared_error: 1.5095e-04 - val_loss: 2.5184e-04 - val_mean_squared_error: 2.2418e-04\n",
      "Epoch 4/1000\n",
      "35440/35440 [==============================] - 6s 181us/step - loss: 1.7903e-04 - mean_squared_error: 1.4847e-04 - val_loss: 2.3898e-04 - val_mean_squared_error: 2.0985e-04\n",
      "Epoch 5/1000\n",
      "35440/35440 [==============================] - 6s 172us/step - loss: 1.7853e-04 - mean_squared_error: 1.4787e-04 - val_loss: 2.4800e-04 - val_mean_squared_error: 2.2152e-04\n",
      "Epoch 6/1000\n",
      "35440/35440 [==============================] - 9s 245us/step - loss: 1.7874e-04 - mean_squared_error: 1.4772e-04 - val_loss: 2.6059e-04 - val_mean_squared_error: 2.2997e-04\n",
      "Epoch 7/1000\n",
      "35440/35440 [==============================] - 7s 198us/step - loss: 1.8025e-04 - mean_squared_error: 1.4822e-04 - val_loss: 2.6508e-04 - val_mean_squared_error: 2.2874e-04\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 8/1000\n",
      "35440/35440 [==============================] - 7s 185us/step - loss: 1.4723e-04 - mean_squared_error: 1.3015e-04 - val_loss: 2.2517e-04 - val_mean_squared_error: 2.0867e-04\n",
      "Epoch 9/1000\n",
      "35440/35440 [==============================] - 9s 254us/step - loss: 1.4484e-04 - mean_squared_error: 1.2905e-04 - val_loss: 2.2349e-04 - val_mean_squared_error: 2.0828e-04\n",
      "Epoch 10/1000\n",
      "35440/35440 [==============================] - 6s 175us/step - loss: 1.4352e-04 - mean_squared_error: 1.2860e-04 - val_loss: 2.2141e-04 - val_mean_squared_error: 2.0689e-04\n",
      "Epoch 11/1000\n",
      "35440/35440 [==============================] - 4s 127us/step - loss: 1.4233e-04 - mean_squared_error: 1.2822e-04 - val_loss: 2.2232e-04 - val_mean_squared_error: 2.0829e-04\n",
      "Epoch 12/1000\n",
      "35440/35440 [==============================] - 6s 180us/step - loss: 1.4124e-04 - mean_squared_error: 1.2778e-04 - val_loss: 2.2241e-04 - val_mean_squared_error: 2.0944e-04\n",
      "Epoch 13/1000\n",
      "35440/35440 [==============================] - 7s 204us/step - loss: 1.4034e-04 - mean_squared_error: 1.2748e-04 - val_loss: 2.2065e-04 - val_mean_squared_error: 2.0777e-04\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 14/1000\n",
      "35440/35440 [==============================] - 6s 183us/step - loss: 1.3651e-04 - mean_squared_error: 1.2475e-04 - val_loss: 2.1710e-04 - val_mean_squared_error: 2.0554e-04\n",
      "Epoch 15/1000\n",
      "35440/35440 [==============================] - 6s 169us/step - loss: 1.3610e-04 - mean_squared_error: 1.2454e-04 - val_loss: 2.1664e-04 - val_mean_squared_error: 2.0508e-04\n",
      "Epoch 16/1000\n",
      "35440/35440 [==============================] - 6s 169us/step - loss: 1.3599e-04 - mean_squared_error: 1.2448e-04 - val_loss: 2.1781e-04 - val_mean_squared_error: 2.0626e-04\n",
      "Epoch 17/1000\n",
      "35440/35440 [==============================] - 7s 184us/step - loss: 1.3588e-04 - mean_squared_error: 1.2444e-04 - val_loss: 2.1660e-04 - val_mean_squared_error: 2.0518e-04\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 18/1000\n",
      "35440/35440 [==============================] - 7s 188us/step - loss: 1.3546e-04 - mean_squared_error: 1.2409e-04 - val_loss: 2.1663e-04 - val_mean_squared_error: 2.0527e-04\n",
      "Epoch 19/1000\n",
      "35440/35440 [==============================] - 6s 178us/step - loss: 1.3537e-04 - mean_squared_error: 1.2402e-04 - val_loss: 2.1668e-04 - val_mean_squared_error: 2.0535e-04\n",
      "Epoch 20/1000\n",
      "35440/35440 [==============================] - 9s 252us/step - loss: 1.3535e-04 - mean_squared_error: 1.2402e-04 - val_loss: 2.1651e-04 - val_mean_squared_error: 2.0518e-04\n",
      "Epoch 21/1000\n",
      "35440/35440 [==============================] - 7s 186us/step - loss: 1.3533e-04 - mean_squared_error: 1.2400e-04 - val_loss: 2.1642e-04 - val_mean_squared_error: 2.0511e-04\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 22/1000\n",
      "35440/35440 [==============================] - 7s 194us/step - loss: 1.3526e-04 - mean_squared_error: 1.2396e-04 - val_loss: 2.1642e-04 - val_mean_squared_error: 2.0511e-04\n",
      "Epoch 23/1000\n",
      "35440/35440 [==============================] - 7s 190us/step - loss: 1.3526e-04 - mean_squared_error: 1.2395e-04 - val_loss: 2.1642e-04 - val_mean_squared_error: 2.0511e-04\n",
      "Epoch 24/1000\n",
      "35440/35440 [==============================] - 9s 251us/step - loss: 1.3526e-04 - mean_squared_error: 1.2395e-04 - val_loss: 2.1641e-04 - val_mean_squared_error: 2.0510e-04\n",
      "Epoch 25/1000\n",
      "35440/35440 [==============================] - 8s 231us/step - loss: 1.3526e-04 - mean_squared_error: 1.2395e-04 - val_loss: 2.1641e-04 - val_mean_squared_error: 2.0510e-04\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "Epoch 26/1000\n",
      "35440/35440 [==============================] - 6s 176us/step - loss: 1.3525e-04 - mean_squared_error: 1.2394e-04 - val_loss: 2.1641e-04 - val_mean_squared_error: 2.0510e-04\n",
      "Epoch 27/1000\n",
      "35440/35440 [==============================] - 8s 230us/step - loss: 1.3525e-04 - mean_squared_error: 1.2394e-04 - val_loss: 2.1641e-04 - val_mean_squared_error: 2.0510e-04\n",
      "Epoch 28/1000\n",
      "35440/35440 [==============================] - 8s 229us/step - loss: 1.3525e-04 - mean_squared_error: 1.2394e-04 - val_loss: 2.1640e-04 - val_mean_squared_error: 2.0510e-04\n",
      "Epoch 29/1000\n",
      "35440/35440 [==============================] - 7s 194us/step - loss: 1.3525e-04 - mean_squared_error: 1.2394e-04 - val_loss: 2.1640e-04 - val_mean_squared_error: 2.0510e-04\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "Epoch 30/1000\n",
      "35440/35440 [==============================] - 6s 172us/step - loss: 1.3525e-04 - mean_squared_error: 1.2394e-04 - val_loss: 2.1640e-04 - val_mean_squared_error: 2.0510e-04\n",
      "Epoch 31/1000\n",
      "35440/35440 [==============================] - 7s 191us/step - loss: 1.3525e-04 - mean_squared_error: 1.2394e-04 - val_loss: 2.1640e-04 - val_mean_squared_error: 2.0510e-04\n",
      "Epoch 32/1000\n",
      "35440/35440 [==============================] - 7s 185us/step - loss: 1.3525e-04 - mean_squared_error: 1.2394e-04 - val_loss: 2.1640e-04 - val_mean_squared_error: 2.0510e-04\n",
      "Epoch 33/1000\n",
      "35440/35440 [==============================] - 7s 198us/step - loss: 1.3525e-04 - mean_squared_error: 1.2394e-04 - val_loss: 2.1640e-04 - val_mean_squared_error: 2.0510e-04\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "Epoch 34/1000\n",
      "35440/35440 [==============================] - 9s 245us/step - loss: 1.3525e-04 - mean_squared_error: 1.2394e-04 - val_loss: 2.1640e-04 - val_mean_squared_error: 2.0510e-04\n",
      "Epoch 35/1000\n",
      "35440/35440 [==============================] - 7s 207us/step - loss: 1.3525e-04 - mean_squared_error: 1.2394e-04 - val_loss: 2.1640e-04 - val_mean_squared_error: 2.0510e-04\n",
      "Epoch 00035: early stopping\n",
      "Train on 35440 samples, validate on 8880 samples\n",
      "Epoch 1/1000\n",
      "35440/35440 [==============================] - 7s 186us/step - loss: 2.0248e-04 - mean_squared_error: 1.5652e-04 - val_loss: 2.4928e-04 - val_mean_squared_error: 2.2031e-04\n",
      "Epoch 2/1000\n",
      "35440/35440 [==============================] - 8s 233us/step - loss: 1.7547e-04 - mean_squared_error: 1.4494e-04 - val_loss: 2.5958e-04 - val_mean_squared_error: 2.2671e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/1000\n",
      "35440/35440 [==============================] - 8s 223us/step - loss: 1.7614e-04 - mean_squared_error: 1.4505e-04 - val_loss: 2.5866e-04 - val_mean_squared_error: 2.2712e-04\n",
      "Epoch 4/1000\n",
      "35440/35440 [==============================] - 6s 165us/step - loss: 1.7633e-04 - mean_squared_error: 1.4521e-04 - val_loss: 2.5683e-04 - val_mean_squared_error: 2.2501e-04\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 5/1000\n",
      "35440/35440 [==============================] - 6s 165us/step - loss: 1.4440e-04 - mean_squared_error: 1.2797e-04 - val_loss: 2.2442e-04 - val_mean_squared_error: 2.0849e-04\n",
      "Epoch 6/1000\n",
      "35440/35440 [==============================] - 6s 181us/step - loss: 1.4233e-04 - mean_squared_error: 1.2707e-04 - val_loss: 2.2267e-04 - val_mean_squared_error: 2.0783e-04\n",
      "Epoch 7/1000\n",
      "35440/35440 [==============================] - 6s 182us/step - loss: 1.4105e-04 - mean_squared_error: 1.2658e-04 - val_loss: 2.1851e-04 - val_mean_squared_error: 2.0462e-04\n",
      "Epoch 8/1000\n",
      "35440/35440 [==============================] - 6s 172us/step - loss: 1.4011e-04 - mean_squared_error: 1.2630e-04 - val_loss: 2.2162e-04 - val_mean_squared_error: 2.0799e-04\n",
      "Epoch 9/1000\n",
      "35440/35440 [==============================] - 9s 249us/step - loss: 1.3917e-04 - mean_squared_error: 1.2594e-04 - val_loss: 2.2063e-04 - val_mean_squared_error: 2.0763e-04\n",
      "Epoch 10/1000\n",
      "35440/35440 [==============================] - 7s 186us/step - loss: 1.3838e-04 - mean_squared_error: 1.2571e-04 - val_loss: 2.2164e-04 - val_mean_squared_error: 2.0912e-04\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 11/1000\n",
      "35440/35440 [==============================] - 6s 183us/step - loss: 1.3445e-04 - mean_squared_error: 1.2293e-04 - val_loss: 2.1686e-04 - val_mean_squared_error: 2.0544e-04\n",
      "Epoch 12/1000\n",
      "35440/35440 [==============================] - 6s 173us/step - loss: 1.3407e-04 - mean_squared_error: 1.2272e-04 - val_loss: 2.1781e-04 - val_mean_squared_error: 2.0642e-04\n",
      "Epoch 13/1000\n",
      "35440/35440 [==============================] - 6s 166us/step - loss: 1.3396e-04 - mean_squared_error: 1.2266e-04 - val_loss: 2.1707e-04 - val_mean_squared_error: 2.0571e-04\n",
      "Epoch 14/1000\n",
      "35440/35440 [==============================] - 9s 241us/step - loss: 1.3385e-04 - mean_squared_error: 1.2259e-04 - val_loss: 2.1568e-04 - val_mean_squared_error: 2.0446e-04\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 15/1000\n",
      "35440/35440 [==============================] - 8s 227us/step - loss: 1.3348e-04 - mean_squared_error: 1.2233e-04 - val_loss: 2.1607e-04 - val_mean_squared_error: 2.0493e-04\n",
      "Epoch 16/1000\n",
      "35440/35440 [==============================] - 8s 233us/step - loss: 1.3336e-04 - mean_squared_error: 1.2222e-04 - val_loss: 2.1602e-04 - val_mean_squared_error: 2.0490e-04\n",
      "Epoch 17/1000\n",
      "35440/35440 [==============================] - 7s 209us/step - loss: 1.3333e-04 - mean_squared_error: 1.2221e-04 - val_loss: 2.1601e-04 - val_mean_squared_error: 2.0490e-04\n",
      "Epoch 18/1000\n",
      "35440/35440 [==============================] - 6s 178us/step - loss: 1.3331e-04 - mean_squared_error: 1.2220e-04 - val_loss: 2.1593e-04 - val_mean_squared_error: 2.0483e-04\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 19/1000\n",
      "35440/35440 [==============================] - 6s 168us/step - loss: 1.3325e-04 - mean_squared_error: 1.2215e-04 - val_loss: 2.1596e-04 - val_mean_squared_error: 2.0487e-04\n",
      "Epoch 20/1000\n",
      "35440/35440 [==============================] - 6s 174us/step - loss: 1.3324e-04 - mean_squared_error: 1.2215e-04 - val_loss: 2.1597e-04 - val_mean_squared_error: 2.0487e-04\n",
      "Epoch 21/1000\n",
      "35440/35440 [==============================] - 8s 221us/step - loss: 1.3324e-04 - mean_squared_error: 1.2215e-04 - val_loss: 2.1598e-04 - val_mean_squared_error: 2.0489e-04\n",
      "Epoch 22/1000\n",
      "35440/35440 [==============================] - 8s 233us/step - loss: 1.3324e-04 - mean_squared_error: 1.2214e-04 - val_loss: 2.1599e-04 - val_mean_squared_error: 2.0489e-04\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "Epoch 23/1000\n",
      "35440/35440 [==============================] - 9s 260us/step - loss: 1.3323e-04 - mean_squared_error: 1.2214e-04 - val_loss: 2.1599e-04 - val_mean_squared_error: 2.0490e-04\n",
      "Epoch 24/1000\n",
      "35440/35440 [==============================] - 9s 248us/step - loss: 1.3323e-04 - mean_squared_error: 1.2214e-04 - val_loss: 2.1599e-04 - val_mean_squared_error: 2.0490e-04\n",
      "Epoch 25/1000\n",
      "35440/35440 [==============================] - 6s 175us/step - loss: 1.3323e-04 - mean_squared_error: 1.2214e-04 - val_loss: 2.1599e-04 - val_mean_squared_error: 2.0490e-04\n",
      "Epoch 26/1000\n",
      "35440/35440 [==============================] - 8s 227us/step - loss: 1.3323e-04 - mean_squared_error: 1.2214e-04 - val_loss: 2.1599e-04 - val_mean_squared_error: 2.0490e-04\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "Epoch 27/1000\n",
      "35440/35440 [==============================] - 8s 232us/step - loss: 1.3323e-04 - mean_squared_error: 1.2213e-04 - val_loss: 2.1599e-04 - val_mean_squared_error: 2.0490e-04\n",
      "Epoch 28/1000\n",
      "35440/35440 [==============================] - 6s 181us/step - loss: 1.3323e-04 - mean_squared_error: 1.2213e-04 - val_loss: 2.1599e-04 - val_mean_squared_error: 2.0490e-04\n",
      "Epoch 29/1000\n",
      "35440/35440 [==============================] - 9s 254us/step - loss: 1.3323e-04 - mean_squared_error: 1.2213e-04 - val_loss: 2.1599e-04 - val_mean_squared_error: 2.0490e-04\n",
      "Epoch 30/1000\n",
      "35440/35440 [==============================] - 7s 189us/step - loss: 1.3323e-04 - mean_squared_error: 1.2213e-04 - val_loss: 2.1599e-04 - val_mean_squared_error: 2.0490e-04\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "Epoch 31/1000\n",
      "35440/35440 [==============================] - 7s 193us/step - loss: 1.3323e-04 - mean_squared_error: 1.2213e-04 - val_loss: 2.1599e-04 - val_mean_squared_error: 2.0490e-04\n",
      "Epoch 32/1000\n",
      "35440/35440 [==============================] - 9s 260us/step - loss: 1.3323e-04 - mean_squared_error: 1.2213e-04 - val_loss: 2.1599e-04 - val_mean_squared_error: 2.0490e-04\n",
      "Epoch 33/1000\n",
      "35440/35440 [==============================] - 9s 242us/step - loss: 1.3323e-04 - mean_squared_error: 1.2213e-04 - val_loss: 2.1599e-04 - val_mean_squared_error: 2.0490e-04\n",
      "Epoch 34/1000\n",
      "35440/35440 [==============================] - 7s 193us/step - loss: 1.3323e-04 - mean_squared_error: 1.2213e-04 - val_loss: 2.1599e-04 - val_mean_squared_error: 2.0490e-04\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
      "Epoch 00034: early stopping\n",
      "Train on 35440 samples, validate on 8880 samples\n",
      "Epoch 1/1000\n",
      "35440/35440 [==============================] - 9s 245us/step - loss: 2.1773e-04 - mean_squared_error: 1.5948e-04 - val_loss: 2.5504e-04 - val_mean_squared_error: 2.2451e-04\n",
      "Epoch 2/1000\n",
      "35440/35440 [==============================] - 9s 260us/step - loss: 1.7197e-04 - mean_squared_error: 1.4278e-04 - val_loss: 2.5728e-04 - val_mean_squared_error: 2.2828e-04\n",
      "Epoch 3/1000\n",
      "35440/35440 [==============================] - 8s 234us/step - loss: 1.7272e-04 - mean_squared_error: 1.4285e-04 - val_loss: 2.5582e-04 - val_mean_squared_error: 2.2665e-04\n",
      "Epoch 4/1000\n",
      "35440/35440 [==============================] - 7s 209us/step - loss: 1.7374e-04 - mean_squared_error: 1.4341e-04 - val_loss: 2.5098e-04 - val_mean_squared_error: 2.2240e-04\n",
      "Epoch 5/1000\n",
      "35440/35440 [==============================] - 8s 218us/step - loss: 1.7511e-04 - mean_squared_error: 1.4377e-04 - val_loss: 2.6211e-04 - val_mean_squared_error: 2.3138e-04\n",
      "Epoch 6/1000\n",
      "35440/35440 [==============================] - 8s 238us/step - loss: 1.8496e-04 - mean_squared_error: 1.4726e-04 - val_loss: 2.6279e-04 - val_mean_squared_error: 2.3004e-04\n",
      "Epoch 7/1000\n",
      "35440/35440 [==============================] - 8s 233us/step - loss: 1.7722e-04 - mean_squared_error: 1.4437e-04 - val_loss: 2.5106e-04 - val_mean_squared_error: 2.2280e-04\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 8/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35440/35440 [==============================] - 6s 165us/step - loss: 1.4291e-04 - mean_squared_error: 1.2647e-04 - val_loss: 2.2413e-04 - val_mean_squared_error: 2.0813e-04\n",
      "Epoch 9/1000\n",
      "35440/35440 [==============================] - 6s 171us/step - loss: 1.4103e-04 - mean_squared_error: 1.2559e-04 - val_loss: 2.2165e-04 - val_mean_squared_error: 2.0677e-04\n",
      "Epoch 10/1000\n",
      "35440/35440 [==============================] - 8s 217us/step - loss: 1.3971e-04 - mean_squared_error: 1.2511e-04 - val_loss: 2.2234e-04 - val_mean_squared_error: 2.0813e-04\n",
      "Epoch 11/1000\n",
      "35440/35440 [==============================] - 8s 233us/step - loss: 1.3864e-04 - mean_squared_error: 1.2478e-04 - val_loss: 2.2445e-04 - val_mean_squared_error: 2.1069e-04\n",
      "Epoch 12/1000\n",
      "35440/35440 [==============================] - 6s 168us/step - loss: 1.3777e-04 - mean_squared_error: 1.2448e-04 - val_loss: 2.1838e-04 - val_mean_squared_error: 2.0572e-04\n",
      "Epoch 13/1000\n",
      "35440/35440 [==============================] - 8s 236us/step - loss: 1.3695e-04 - mean_squared_error: 1.2422e-04 - val_loss: 2.1714e-04 - val_mean_squared_error: 2.0470e-04\n",
      "Epoch 14/1000\n",
      "35440/35440 [==============================] - 8s 230us/step - loss: 1.3624e-04 - mean_squared_error: 1.2395e-04 - val_loss: 2.1936e-04 - val_mean_squared_error: 2.0740e-04\n",
      "Epoch 15/1000\n",
      "35440/35440 [==============================] - 8s 229us/step - loss: 1.3557e-04 - mean_squared_error: 1.2366e-04 - val_loss: 2.2183e-04 - val_mean_squared_error: 2.1029e-04\n",
      "Epoch 16/1000\n",
      "35440/35440 [==============================] - 7s 206us/step - loss: 1.3504e-04 - mean_squared_error: 1.2352e-04 - val_loss: 2.1707e-04 - val_mean_squared_error: 2.0591e-04\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 17/1000\n",
      "35440/35440 [==============================] - 6s 183us/step - loss: 1.3108e-04 - mean_squared_error: 1.2068e-04 - val_loss: 2.1687e-04 - val_mean_squared_error: 2.0647e-04\n",
      "Epoch 18/1000\n",
      "35440/35440 [==============================] - 9s 253us/step - loss: 1.3071e-04 - mean_squared_error: 1.2040e-04 - val_loss: 2.1600e-04 - val_mean_squared_error: 2.0567e-04\n",
      "Epoch 19/1000\n",
      "35440/35440 [==============================] - 6s 178us/step - loss: 1.3065e-04 - mean_squared_error: 1.2035e-04 - val_loss: 2.1589e-04 - val_mean_squared_error: 2.0571e-04\n",
      "Epoch 20/1000\n",
      "35440/35440 [==============================] - 7s 211us/step - loss: 1.3052e-04 - mean_squared_error: 1.2031e-04 - val_loss: 2.1651e-04 - val_mean_squared_error: 2.0627e-04\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 21/1000\n",
      "35440/35440 [==============================] - 8s 239us/step - loss: 1.3014e-04 - mean_squared_error: 1.1996e-04 - val_loss: 2.1584e-04 - val_mean_squared_error: 2.0570e-04\n",
      "Epoch 22/1000\n",
      "35440/35440 [==============================] - 8s 229us/step - loss: 1.3004e-04 - mean_squared_error: 1.1990e-04 - val_loss: 2.1589e-04 - val_mean_squared_error: 2.0576e-04\n",
      "Epoch 23/1000\n",
      "35440/35440 [==============================] - 8s 227us/step - loss: 1.3001e-04 - mean_squared_error: 1.1988e-04 - val_loss: 2.1574e-04 - val_mean_squared_error: 2.0562e-04\n",
      "Epoch 24/1000\n",
      "35440/35440 [==============================] - 6s 170us/step - loss: 1.2999e-04 - mean_squared_error: 1.1987e-04 - val_loss: 2.1574e-04 - val_mean_squared_error: 2.0563e-04\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 25/1000\n",
      "35440/35440 [==============================] - 6s 176us/step - loss: 1.2993e-04 - mean_squared_error: 1.1982e-04 - val_loss: 2.1574e-04 - val_mean_squared_error: 2.0563e-04\n",
      "Epoch 26/1000\n",
      "35440/35440 [==============================] - 8s 216us/step - loss: 1.2992e-04 - mean_squared_error: 1.1982e-04 - val_loss: 2.1575e-04 - val_mean_squared_error: 2.0564e-04\n",
      "Epoch 27/1000\n",
      "35440/35440 [==============================] - 8s 234us/step - loss: 1.2992e-04 - mean_squared_error: 1.1981e-04 - val_loss: 2.1575e-04 - val_mean_squared_error: 2.0564e-04\n",
      "Epoch 28/1000\n",
      "35440/35440 [==============================] - 8s 229us/step - loss: 1.2992e-04 - mean_squared_error: 1.1981e-04 - val_loss: 2.1575e-04 - val_mean_squared_error: 2.0564e-04\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "Epoch 29/1000\n",
      "35440/35440 [==============================] - 6s 169us/step - loss: 1.2991e-04 - mean_squared_error: 1.1980e-04 - val_loss: 2.1575e-04 - val_mean_squared_error: 2.0564e-04\n",
      "Epoch 30/1000\n",
      "35440/35440 [==============================] - 6s 177us/step - loss: 1.2991e-04 - mean_squared_error: 1.1980e-04 - val_loss: 2.1575e-04 - val_mean_squared_error: 2.0564e-04\n",
      "Epoch 31/1000\n",
      "35440/35440 [==============================] - 7s 185us/step - loss: 1.2991e-04 - mean_squared_error: 1.1980e-04 - val_loss: 2.1575e-04 - val_mean_squared_error: 2.0564e-04\n",
      "Epoch 32/1000\n",
      "35440/35440 [==============================] - 7s 194us/step - loss: 1.2991e-04 - mean_squared_error: 1.1980e-04 - val_loss: 2.1575e-04 - val_mean_squared_error: 2.0564e-04\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "Epoch 33/1000\n",
      "35440/35440 [==============================] - 9s 263us/step - loss: 1.2991e-04 - mean_squared_error: 1.1980e-04 - val_loss: 2.1575e-04 - val_mean_squared_error: 2.0564e-04\n",
      "Epoch 00033: early stopping\n",
      "Train on 35440 samples, validate on 8880 samples\n",
      "Epoch 1/1000\n",
      "35440/35440 [==============================] - 8s 240us/step - loss: 2.0007e-04 - mean_squared_error: 1.5338e-04 - val_loss: 2.4809e-04 - val_mean_squared_error: 2.1957e-04\n",
      "Epoch 2/1000\n",
      "35440/35440 [==============================] - 8s 234us/step - loss: 1.7122e-04 - mean_squared_error: 1.4121e-04 - val_loss: 2.4821e-04 - val_mean_squared_error: 2.2226e-04\n",
      "Epoch 3/1000\n",
      "35440/35440 [==============================] - 8s 231us/step - loss: 1.7452e-04 - mean_squared_error: 1.4279e-04 - val_loss: 4.0966e-04 - val_mean_squared_error: 2.9263e-04\n",
      "Epoch 4/1000\n",
      "35440/35440 [==============================] - 8s 229us/step - loss: 1.7532e-04 - mean_squared_error: 1.4232e-04 - val_loss: 2.5579e-04 - val_mean_squared_error: 2.2616e-04\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 5/1000\n",
      "35440/35440 [==============================] - 6s 174us/step - loss: 1.4134e-04 - mean_squared_error: 1.2518e-04 - val_loss: 2.2521e-04 - val_mean_squared_error: 2.0969e-04\n",
      "Epoch 6/1000\n",
      "35440/35440 [==============================] - 9s 244us/step - loss: 1.3949e-04 - mean_squared_error: 1.2442e-04 - val_loss: 2.2608e-04 - val_mean_squared_error: 2.1124e-04\n",
      "Epoch 7/1000\n",
      "35440/35440 [==============================] - 8s 230us/step - loss: 1.3825e-04 - mean_squared_error: 1.2394e-04 - val_loss: 2.2521e-04 - val_mean_squared_error: 2.1123e-04\n",
      "Epoch 8/1000\n",
      "35440/35440 [==============================] - 8s 233us/step - loss: 1.3715e-04 - mean_squared_error: 1.2352e-04 - val_loss: 2.2120e-04 - val_mean_squared_error: 2.0803e-04\n",
      "Epoch 9/1000\n",
      "35440/35440 [==============================] - 8s 231us/step - loss: 1.3634e-04 - mean_squared_error: 1.2330e-04 - val_loss: 2.2104e-04 - val_mean_squared_error: 2.0831e-04\n",
      "Epoch 10/1000\n",
      "35440/35440 [==============================] - 8s 231us/step - loss: 1.3552e-04 - mean_squared_error: 1.2296e-04 - val_loss: 2.2315e-04 - val_mean_squared_error: 2.1070e-04\n",
      "Epoch 11/1000\n",
      "35440/35440 [==============================] - 8s 232us/step - loss: 1.3490e-04 - mean_squared_error: 1.2275e-04 - val_loss: 2.2232e-04 - val_mean_squared_error: 2.1031e-04\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 12/1000\n",
      "35440/35440 [==============================] - 8s 231us/step - loss: 1.3092e-04 - mean_squared_error: 1.2003e-04 - val_loss: 2.1770e-04 - val_mean_squared_error: 2.0688e-04\n",
      "Epoch 13/1000\n",
      "35440/35440 [==============================] - 8s 231us/step - loss: 1.3055e-04 - mean_squared_error: 1.1974e-04 - val_loss: 2.1745e-04 - val_mean_squared_error: 2.0672e-04\n",
      "Epoch 14/1000\n",
      "35440/35440 [==============================] - 8s 233us/step - loss: 1.3045e-04 - mean_squared_error: 1.1969e-04 - val_loss: 2.1730e-04 - val_mean_squared_error: 2.0661e-04\n",
      "Epoch 15/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35440/35440 [==============================] - 8s 228us/step - loss: 1.3033e-04 - mean_squared_error: 1.1961e-04 - val_loss: 2.1818e-04 - val_mean_squared_error: 2.0752e-04\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 16/1000\n",
      "35440/35440 [==============================] - 6s 178us/step - loss: 1.2993e-04 - mean_squared_error: 1.1933e-04 - val_loss: 2.1786e-04 - val_mean_squared_error: 2.0727e-04\n",
      "Epoch 17/1000\n",
      "35440/35440 [==============================] - 6s 179us/step - loss: 1.2984e-04 - mean_squared_error: 1.1924e-04 - val_loss: 2.1768e-04 - val_mean_squared_error: 2.0711e-04\n",
      "Epoch 18/1000\n",
      "35440/35440 [==============================] - 6s 173us/step - loss: 1.2981e-04 - mean_squared_error: 1.1923e-04 - val_loss: 2.1780e-04 - val_mean_squared_error: 2.0722e-04\n",
      "Epoch 19/1000\n",
      "35440/35440 [==============================] - 6s 166us/step - loss: 1.2980e-04 - mean_squared_error: 1.1923e-04 - val_loss: 2.1761e-04 - val_mean_squared_error: 2.0704e-04\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 20/1000\n",
      "35440/35440 [==============================] - 8s 232us/step - loss: 1.2973e-04 - mean_squared_error: 1.1916e-04 - val_loss: 2.1764e-04 - val_mean_squared_error: 2.0706e-04\n",
      "Epoch 21/1000\n",
      "35440/35440 [==============================] - 9s 263us/step - loss: 1.2973e-04 - mean_squared_error: 1.1915e-04 - val_loss: 2.1765e-04 - val_mean_squared_error: 2.0708e-04\n",
      "Epoch 22/1000\n",
      "35440/35440 [==============================] - 9s 262us/step - loss: 1.2972e-04 - mean_squared_error: 1.1915e-04 - val_loss: 2.1766e-04 - val_mean_squared_error: 2.0709e-04\n",
      "Epoch 23/1000\n",
      "35440/35440 [==============================] - 7s 189us/step - loss: 1.2972e-04 - mean_squared_error: 1.1915e-04 - val_loss: 2.1767e-04 - val_mean_squared_error: 2.0710e-04\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "Epoch 24/1000\n",
      "35440/35440 [==============================] - 7s 196us/step - loss: 1.2972e-04 - mean_squared_error: 1.1914e-04 - val_loss: 2.1767e-04 - val_mean_squared_error: 2.0710e-04\n",
      "Epoch 25/1000\n",
      "35440/35440 [==============================] - 9s 246us/step - loss: 1.2972e-04 - mean_squared_error: 1.1914e-04 - val_loss: 2.1767e-04 - val_mean_squared_error: 2.0710e-04\n",
      "Epoch 26/1000\n",
      "35440/35440 [==============================] - 6s 170us/step - loss: 1.2971e-04 - mean_squared_error: 1.1914e-04 - val_loss: 2.1767e-04 - val_mean_squared_error: 2.0710e-04\n",
      "Epoch 27/1000\n",
      "35440/35440 [==============================] - 6s 182us/step - loss: 1.2971e-04 - mean_squared_error: 1.1914e-04 - val_loss: 2.1767e-04 - val_mean_squared_error: 2.0710e-04\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "Epoch 28/1000\n",
      "35440/35440 [==============================] - 6s 182us/step - loss: 1.2971e-04 - mean_squared_error: 1.1914e-04 - val_loss: 2.1767e-04 - val_mean_squared_error: 2.0710e-04\n",
      "Epoch 29/1000\n",
      "35440/35440 [==============================] - 6s 175us/step - loss: 1.2971e-04 - mean_squared_error: 1.1914e-04 - val_loss: 2.1767e-04 - val_mean_squared_error: 2.0710e-04\n",
      "Epoch 30/1000\n",
      "35440/35440 [==============================] - 9s 254us/step - loss: 1.2971e-04 - mean_squared_error: 1.1914e-04 - val_loss: 2.1767e-04 - val_mean_squared_error: 2.0710e-04\n",
      "Epoch 31/1000\n",
      "35440/35440 [==============================] - 6s 183us/step - loss: 1.2971e-04 - mean_squared_error: 1.1914e-04 - val_loss: 2.1767e-04 - val_mean_squared_error: 2.0710e-04\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "Epoch 32/1000\n",
      "35440/35440 [==============================] - 7s 205us/step - loss: 1.2971e-04 - mean_squared_error: 1.1914e-04 - val_loss: 2.1767e-04 - val_mean_squared_error: 2.0710e-04\n",
      "Epoch 33/1000\n",
      "35440/35440 [==============================] - 9s 244us/step - loss: 1.2971e-04 - mean_squared_error: 1.1914e-04 - val_loss: 2.1767e-04 - val_mean_squared_error: 2.0710e-04\n",
      "Epoch 34/1000\n",
      "35440/35440 [==============================] - 8s 226us/step - loss: 1.2971e-04 - mean_squared_error: 1.1914e-04 - val_loss: 2.1767e-04 - val_mean_squared_error: 2.0710e-04\n",
      "Epoch 00034: early stopping\n",
      "Train on 35440 samples, validate on 8880 samples\n",
      "Epoch 1/1000\n",
      "35440/35440 [==============================] - 8s 233us/step - loss: 1.9600e-04 - mean_squared_error: 1.5108e-04 - val_loss: 2.5912e-04 - val_mean_squared_error: 2.2810e-04\n",
      "Epoch 2/1000\n",
      "35440/35440 [==============================] - 8s 228us/step - loss: 1.6967e-04 - mean_squared_error: 1.3999e-04 - val_loss: 2.4723e-04 - val_mean_squared_error: 2.2219e-04\n",
      "Epoch 3/1000\n",
      "35440/35440 [==============================] - 8s 228us/step - loss: 1.7164e-04 - mean_squared_error: 1.4097e-04 - val_loss: 2.5935e-04 - val_mean_squared_error: 2.2820e-04\n",
      "Epoch 4/1000\n",
      "35440/35440 [==============================] - 6s 178us/step - loss: 1.7188e-04 - mean_squared_error: 1.4101e-04 - val_loss: 2.5235e-04 - val_mean_squared_error: 2.2310e-04\n",
      "Epoch 5/1000\n",
      "35440/35440 [==============================] - 9s 242us/step - loss: 1.7152e-04 - mean_squared_error: 1.4078e-04 - val_loss: 2.5425e-04 - val_mean_squared_error: 2.2381e-04\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 6/1000\n",
      "35440/35440 [==============================] - 9s 260us/step - loss: 1.4015e-04 - mean_squared_error: 1.2400e-04 - val_loss: 2.2390e-04 - val_mean_squared_error: 2.0857e-04\n",
      "Epoch 7/1000\n",
      "35440/35440 [==============================] - 7s 200us/step - loss: 1.3816e-04 - mean_squared_error: 1.2310e-04 - val_loss: 2.2536e-04 - val_mean_squared_error: 2.1041e-04\n",
      "Epoch 8/1000\n",
      "35440/35440 [==============================] - 7s 196us/step - loss: 1.3706e-04 - mean_squared_error: 1.2277e-04 - val_loss: 2.2503e-04 - val_mean_squared_error: 2.1095e-04\n",
      "Epoch 9/1000\n",
      "35440/35440 [==============================] - 9s 248us/step - loss: 1.3588e-04 - mean_squared_error: 1.2231e-04 - val_loss: 2.2378e-04 - val_mean_squared_error: 2.1024e-04\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 10/1000\n",
      "35440/35440 [==============================] - 9s 246us/step - loss: 1.3205e-04 - mean_squared_error: 1.1976e-04 - val_loss: 2.1912e-04 - val_mean_squared_error: 2.0705e-04\n",
      "Epoch 11/1000\n",
      "35440/35440 [==============================] - 9s 265us/step - loss: 1.3166e-04 - mean_squared_error: 1.1957e-04 - val_loss: 2.1961e-04 - val_mean_squared_error: 2.0755e-04\n",
      "Epoch 12/1000\n",
      "35440/35440 [==============================] - 7s 189us/step - loss: 1.3152e-04 - mean_squared_error: 1.1947e-04 - val_loss: 2.2018e-04 - val_mean_squared_error: 2.0822e-04\n",
      "Epoch 13/1000\n",
      "35440/35440 [==============================] - 7s 207us/step - loss: 1.3137e-04 - mean_squared_error: 1.1940e-04 - val_loss: 2.1984e-04 - val_mean_squared_error: 2.0795e-04\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 14/1000\n",
      "35440/35440 [==============================] - 9s 242us/step - loss: 1.3097e-04 - mean_squared_error: 1.1913e-04 - val_loss: 2.1952e-04 - val_mean_squared_error: 2.0769e-04\n",
      "Epoch 15/1000\n",
      "35440/35440 [==============================] - 7s 199us/step - loss: 1.3088e-04 - mean_squared_error: 1.1906e-04 - val_loss: 2.1930e-04 - val_mean_squared_error: 2.0749e-04\n",
      "Epoch 16/1000\n",
      "35440/35440 [==============================] - 9s 244us/step - loss: 1.3085e-04 - mean_squared_error: 1.1903e-04 - val_loss: 2.1930e-04 - val_mean_squared_error: 2.0751e-04\n",
      "Epoch 17/1000\n",
      "35440/35440 [==============================] - 9s 263us/step - loss: 1.3083e-04 - mean_squared_error: 1.1903e-04 - val_loss: 2.1938e-04 - val_mean_squared_error: 2.0757e-04\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 18/1000\n",
      "35440/35440 [==============================] - 11s 316us/step - loss: 1.3077e-04 - mean_squared_error: 1.1897e-04 - val_loss: 2.1934e-04 - val_mean_squared_error: 2.0754e-04\n",
      "Epoch 19/1000\n",
      "35440/35440 [==============================] - 10s 281us/step - loss: 1.3076e-04 - mean_squared_error: 1.1896e-04 - val_loss: 2.1931e-04 - val_mean_squared_error: 2.0752e-04\n",
      "Epoch 20/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35440/35440 [==============================] - 9s 246us/step - loss: 1.3076e-04 - mean_squared_error: 1.1896e-04 - val_loss: 2.1930e-04 - val_mean_squared_error: 2.0751e-04\n",
      "Epoch 21/1000\n",
      "35440/35440 [==============================] - 8s 228us/step - loss: 1.3076e-04 - mean_squared_error: 1.1896e-04 - val_loss: 2.1929e-04 - val_mean_squared_error: 2.0749e-04\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "Epoch 22/1000\n",
      "35440/35440 [==============================] - 8s 225us/step - loss: 1.3075e-04 - mean_squared_error: 1.1896e-04 - val_loss: 2.1929e-04 - val_mean_squared_error: 2.0749e-04\n",
      "Epoch 23/1000\n",
      "35440/35440 [==============================] - 8s 229us/step - loss: 1.3075e-04 - mean_squared_error: 1.1896e-04 - val_loss: 2.1928e-04 - val_mean_squared_error: 2.0749e-04\n",
      "Epoch 24/1000\n",
      "35440/35440 [==============================] - 8s 227us/step - loss: 1.3075e-04 - mean_squared_error: 1.1896e-04 - val_loss: 2.1928e-04 - val_mean_squared_error: 2.0749e-04\n",
      "Epoch 25/1000\n",
      "35440/35440 [==============================] - 8s 228us/step - loss: 1.3075e-04 - mean_squared_error: 1.1896e-04 - val_loss: 2.1928e-04 - val_mean_squared_error: 2.0749e-04\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "Epoch 26/1000\n",
      "35440/35440 [==============================] - 8s 230us/step - loss: 1.3075e-04 - mean_squared_error: 1.1896e-04 - val_loss: 2.1928e-04 - val_mean_squared_error: 2.0749e-04\n",
      "Epoch 27/1000\n",
      "35440/35440 [==============================] - 8s 226us/step - loss: 1.3075e-04 - mean_squared_error: 1.1896e-04 - val_loss: 2.1928e-04 - val_mean_squared_error: 2.0749e-04\n",
      "Epoch 28/1000\n",
      "35440/35440 [==============================] - 8s 230us/step - loss: 1.3075e-04 - mean_squared_error: 1.1896e-04 - val_loss: 2.1928e-04 - val_mean_squared_error: 2.0749e-04\n",
      "Epoch 29/1000\n",
      "35440/35440 [==============================] - 9s 242us/step - loss: 1.3075e-04 - mean_squared_error: 1.1896e-04 - val_loss: 2.1928e-04 - val_mean_squared_error: 2.0749e-04\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "Epoch 30/1000\n",
      "35440/35440 [==============================] - 9s 262us/step - loss: 1.3075e-04 - mean_squared_error: 1.1896e-04 - val_loss: 2.1928e-04 - val_mean_squared_error: 2.0749e-04\n",
      "Epoch 00030: early stopping\n",
      "Train on 35440 samples, validate on 8880 samples\n",
      "Epoch 1/1000\n",
      "35440/35440 [==============================] - 8s 228us/step - loss: 1.8615e-04 - mean_squared_error: 1.4598e-04 - val_loss: 2.5938e-04 - val_mean_squared_error: 2.2913e-04\n",
      "Epoch 2/1000\n",
      "35440/35440 [==============================] - 6s 182us/step - loss: 1.7150e-04 - mean_squared_error: 1.4042e-04 - val_loss: 2.6314e-04 - val_mean_squared_error: 2.3223e-04\n",
      "Epoch 3/1000\n",
      "35440/35440 [==============================] - 7s 197us/step - loss: 1.7173e-04 - mean_squared_error: 1.4018e-04 - val_loss: 2.5614e-04 - val_mean_squared_error: 2.2587e-04\n",
      "Epoch 4/1000\n",
      "35440/35440 [==============================] - 9s 245us/step - loss: 1.7041e-04 - mean_squared_error: 1.3970e-04 - val_loss: 2.5812e-04 - val_mean_squared_error: 2.2768e-04\n",
      "Epoch 5/1000\n",
      "35440/35440 [==============================] - 9s 246us/step - loss: 1.7379e-04 - mean_squared_error: 1.4104e-04 - val_loss: 2.5590e-04 - val_mean_squared_error: 2.2481e-04\n",
      "Epoch 6/1000\n",
      "35440/35440 [==============================] - 9s 261us/step - loss: 1.7098e-04 - mean_squared_error: 1.3989e-04 - val_loss: 2.5741e-04 - val_mean_squared_error: 2.2454e-04\n",
      "Epoch 7/1000\n",
      "35440/35440 [==============================] - 9s 255us/step - loss: 1.6977e-04 - mean_squared_error: 1.3933e-04 - val_loss: 2.5502e-04 - val_mean_squared_error: 2.2668e-04\n",
      "Epoch 8/1000\n",
      "35440/35440 [==============================] - 9s 241us/step - loss: 1.7059e-04 - mean_squared_error: 1.3973e-04 - val_loss: 2.6244e-04 - val_mean_squared_error: 2.3035e-04\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 9/1000\n",
      "35440/35440 [==============================] - 9s 267us/step - loss: 1.3884e-04 - mean_squared_error: 1.2275e-04 - val_loss: 2.2612e-04 - val_mean_squared_error: 2.1057e-04\n",
      "Epoch 10/1000\n",
      "35440/35440 [==============================] - 7s 196us/step - loss: 1.3698e-04 - mean_squared_error: 1.2201e-04 - val_loss: 2.2463e-04 - val_mean_squared_error: 2.1026e-04\n",
      "Epoch 11/1000\n",
      "35440/35440 [==============================] - 7s 188us/step - loss: 1.3576e-04 - mean_squared_error: 1.2157e-04 - val_loss: 2.2508e-04 - val_mean_squared_error: 2.1121e-04\n",
      "Epoch 12/1000\n",
      "35440/35440 [==============================] - 9s 253us/step - loss: 1.3474e-04 - mean_squared_error: 1.2129e-04 - val_loss: 2.2541e-04 - val_mean_squared_error: 2.1198e-04\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 13/1000\n",
      "35440/35440 [==============================] - 6s 172us/step - loss: 1.3081e-04 - mean_squared_error: 1.1860e-04 - val_loss: 2.2077e-04 - val_mean_squared_error: 2.0874e-04\n",
      "Epoch 14/1000\n",
      "35440/35440 [==============================] - 8s 222us/step - loss: 1.3048e-04 - mean_squared_error: 1.1846e-04 - val_loss: 2.2097e-04 - val_mean_squared_error: 2.0908e-04\n",
      "Epoch 15/1000\n",
      "35440/35440 [==============================] - 9s 266us/step - loss: 1.3033e-04 - mean_squared_error: 1.1839e-04 - val_loss: 2.2021e-04 - val_mean_squared_error: 2.0841e-04\n",
      "Epoch 16/1000\n",
      "35440/35440 [==============================] - 9s 261us/step - loss: 1.3020e-04 - mean_squared_error: 1.1839e-04 - val_loss: 2.2123e-04 - val_mean_squared_error: 2.0936e-04\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 17/1000\n",
      "35440/35440 [==============================] - 8s 214us/step - loss: 1.2981e-04 - mean_squared_error: 1.1802e-04 - val_loss: 2.2039e-04 - val_mean_squared_error: 2.0862e-04\n",
      "Epoch 18/1000\n",
      "35440/35440 [==============================] - 7s 200us/step - loss: 1.2970e-04 - mean_squared_error: 1.1795e-04 - val_loss: 2.2028e-04 - val_mean_squared_error: 2.0854e-04\n",
      "Epoch 19/1000\n",
      "35440/35440 [==============================] - 9s 249us/step - loss: 1.2967e-04 - mean_squared_error: 1.1794e-04 - val_loss: 2.2027e-04 - val_mean_squared_error: 2.0855e-04\n",
      "Epoch 20/1000\n",
      "35440/35440 [==============================] - 8s 231us/step - loss: 1.2965e-04 - mean_squared_error: 1.1793e-04 - val_loss: 2.2029e-04 - val_mean_squared_error: 2.0858e-04\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 21/1000\n",
      "35440/35440 [==============================] - 6s 172us/step - loss: 1.2959e-04 - mean_squared_error: 1.1788e-04 - val_loss: 2.2030e-04 - val_mean_squared_error: 2.0859e-04\n",
      "Epoch 22/1000\n",
      "35440/35440 [==============================] - 8s 233us/step - loss: 1.2958e-04 - mean_squared_error: 1.1788e-04 - val_loss: 2.2031e-04 - val_mean_squared_error: 2.0860e-04\n",
      "Epoch 23/1000\n",
      "35440/35440 [==============================] - 8s 234us/step - loss: 1.2958e-04 - mean_squared_error: 1.1788e-04 - val_loss: 2.2031e-04 - val_mean_squared_error: 2.0861e-04\n",
      "Epoch 24/1000\n",
      "35440/35440 [==============================] - 9s 261us/step - loss: 1.2958e-04 - mean_squared_error: 1.1787e-04 - val_loss: 2.2032e-04 - val_mean_squared_error: 2.0861e-04\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "Epoch 25/1000\n",
      "35440/35440 [==============================] - 9s 250us/step - loss: 1.2957e-04 - mean_squared_error: 1.1787e-04 - val_loss: 2.2032e-04 - val_mean_squared_error: 2.0862e-04\n",
      "Epoch 26/1000\n",
      "35440/35440 [==============================] - 8s 231us/step - loss: 1.2957e-04 - mean_squared_error: 1.1787e-04 - val_loss: 2.2032e-04 - val_mean_squared_error: 2.0862e-04\n",
      "Epoch 27/1000\n",
      "35440/35440 [==============================] - 8s 232us/step - loss: 1.2957e-04 - mean_squared_error: 1.1787e-04 - val_loss: 2.2032e-04 - val_mean_squared_error: 2.0862e-04\n",
      "Epoch 28/1000\n",
      "35440/35440 [==============================] - 6s 177us/step - loss: 1.2957e-04 - mean_squared_error: 1.1787e-04 - val_loss: 2.2032e-04 - val_mean_squared_error: 2.0862e-04\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "Epoch 29/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35440/35440 [==============================] - 8s 237us/step - loss: 1.2957e-04 - mean_squared_error: 1.1787e-04 - val_loss: 2.2032e-04 - val_mean_squared_error: 2.0862e-04\n",
      "Epoch 30/1000\n",
      "35440/35440 [==============================] - 8s 229us/step - loss: 1.2957e-04 - mean_squared_error: 1.1787e-04 - val_loss: 2.2032e-04 - val_mean_squared_error: 2.0862e-04\n",
      "Epoch 31/1000\n",
      "35440/35440 [==============================] - 8s 227us/step - loss: 1.2957e-04 - mean_squared_error: 1.1787e-04 - val_loss: 2.2032e-04 - val_mean_squared_error: 2.0862e-04\n",
      "Epoch 32/1000\n",
      "35440/35440 [==============================] - 7s 204us/step - loss: 1.2957e-04 - mean_squared_error: 1.1787e-04 - val_loss: 2.2032e-04 - val_mean_squared_error: 2.0862e-04\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "Epoch 33/1000\n",
      "35440/35440 [==============================] - 6s 176us/step - loss: 1.2957e-04 - mean_squared_error: 1.1787e-04 - val_loss: 2.2032e-04 - val_mean_squared_error: 2.0862e-04\n",
      "Epoch 34/1000\n",
      "35440/35440 [==============================] - 9s 252us/step - loss: 1.2957e-04 - mean_squared_error: 1.1787e-04 - val_loss: 2.2032e-04 - val_mean_squared_error: 2.0862e-04\n",
      "Epoch 35/1000\n",
      "35440/35440 [==============================] - 6s 180us/step - loss: 1.2957e-04 - mean_squared_error: 1.1787e-04 - val_loss: 2.2032e-04 - val_mean_squared_error: 2.0862e-04\n",
      "Epoch 00035: early stopping\n",
      "Train on 35440 samples, validate on 8880 samples\n",
      "Epoch 1/1000\n",
      "35440/35440 [==============================] - 7s 205us/step - loss: 1.8533e-04 - mean_squared_error: 1.4487e-04 - val_loss: 2.5573e-04 - val_mean_squared_error: 2.2641e-04\n",
      "Epoch 2/1000\n",
      "35440/35440 [==============================] - 8s 240us/step - loss: 1.7132e-04 - mean_squared_error: 1.3942e-04 - val_loss: 2.6045e-04 - val_mean_squared_error: 2.2976e-04\n",
      "Epoch 3/1000\n",
      "35440/35440 [==============================] - 8s 229us/step - loss: 1.7080e-04 - mean_squared_error: 1.3936e-04 - val_loss: 2.5889e-04 - val_mean_squared_error: 2.2715e-04\n",
      "Epoch 4/1000\n",
      "35440/35440 [==============================] - 6s 169us/step - loss: 1.6946e-04 - mean_squared_error: 1.3900e-04 - val_loss: 2.5602e-04 - val_mean_squared_error: 2.2392e-04\n",
      "Epoch 5/1000\n",
      "35440/35440 [==============================] - 8s 239us/step - loss: 1.6960e-04 - mean_squared_error: 1.3887e-04 - val_loss: 2.5847e-04 - val_mean_squared_error: 2.2887e-04\n",
      "Epoch 6/1000\n",
      "35440/35440 [==============================] - 9s 261us/step - loss: 1.7054e-04 - mean_squared_error: 1.3943e-04 - val_loss: 2.6136e-04 - val_mean_squared_error: 2.3199e-04\n",
      "Epoch 7/1000\n",
      "35440/35440 [==============================] - 8s 229us/step - loss: 1.7064e-04 - mean_squared_error: 1.3914e-04 - val_loss: 2.5774e-04 - val_mean_squared_error: 2.2786e-04\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 8/1000\n",
      "35440/35440 [==============================] - 8s 230us/step - loss: 1.3836e-04 - mean_squared_error: 1.2225e-04 - val_loss: 2.2933e-04 - val_mean_squared_error: 2.1385e-04\n",
      "Epoch 9/1000\n",
      "35440/35440 [==============================] - 8s 229us/step - loss: 1.3643e-04 - mean_squared_error: 1.2144e-04 - val_loss: 2.2823e-04 - val_mean_squared_error: 2.1378e-04\n",
      "Epoch 10/1000\n",
      "35440/35440 [==============================] - 8s 232us/step - loss: 1.3513e-04 - mean_squared_error: 1.2096e-04 - val_loss: 2.2890e-04 - val_mean_squared_error: 2.1537e-04\n",
      "Epoch 11/1000\n",
      "35440/35440 [==============================] - 9s 259us/step - loss: 1.3414e-04 - mean_squared_error: 1.2063e-04 - val_loss: 2.2417e-04 - val_mean_squared_error: 2.1092e-04\n",
      "Epoch 12/1000\n",
      "35440/35440 [==============================] - 8s 229us/step - loss: 1.3326e-04 - mean_squared_error: 1.2032e-04 - val_loss: 2.2826e-04 - val_mean_squared_error: 2.1576e-04\n",
      "Epoch 13/1000\n",
      "35440/35440 [==============================] - 8s 237us/step - loss: 1.3246e-04 - mean_squared_error: 1.2010e-04 - val_loss: 2.2586e-04 - val_mean_squared_error: 2.1399e-04\n",
      "Epoch 14/1000\n",
      "35440/35440 [==============================] - 8s 233us/step - loss: 1.3188e-04 - mean_squared_error: 1.1994e-04 - val_loss: 2.2752e-04 - val_mean_squared_error: 2.1549e-04\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 15/1000\n",
      "35440/35440 [==============================] - 8s 228us/step - loss: 1.2794e-04 - mean_squared_error: 1.1721e-04 - val_loss: 2.2198e-04 - val_mean_squared_error: 2.1128e-04\n",
      "Epoch 16/1000\n",
      "35440/35440 [==============================] - 9s 263us/step - loss: 1.2754e-04 - mean_squared_error: 1.1693e-04 - val_loss: 2.2332e-04 - val_mean_squared_error: 2.1265e-04\n",
      "Epoch 17/1000\n",
      "35440/35440 [==============================] - 9s 240us/step - loss: 1.2743e-04 - mean_squared_error: 1.1686e-04 - val_loss: 2.2216e-04 - val_mean_squared_error: 2.1159e-04\n",
      "Epoch 18/1000\n",
      "35440/35440 [==============================] - 6s 177us/step - loss: 1.2730e-04 - mean_squared_error: 1.1676e-04 - val_loss: 2.2239e-04 - val_mean_squared_error: 2.1189e-04\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 19/1000\n",
      "35440/35440 [==============================] - 9s 241us/step - loss: 1.2693e-04 - mean_squared_error: 1.1652e-04 - val_loss: 2.2207e-04 - val_mean_squared_error: 2.1169e-04\n",
      "Epoch 20/1000\n",
      "35440/35440 [==============================] - 9s 261us/step - loss: 1.2683e-04 - mean_squared_error: 1.1643e-04 - val_loss: 2.2183e-04 - val_mean_squared_error: 2.1145e-04\n",
      "Epoch 21/1000\n",
      "35440/35440 [==============================] - 9s 265us/step - loss: 1.2680e-04 - mean_squared_error: 1.1641e-04 - val_loss: 2.2187e-04 - val_mean_squared_error: 2.1149e-04\n",
      "Epoch 22/1000\n",
      "35440/35440 [==============================] - 10s 273us/step - loss: 1.2678e-04 - mean_squared_error: 1.1639e-04 - val_loss: 2.2194e-04 - val_mean_squared_error: 2.1156e-04\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 23/1000\n",
      "35440/35440 [==============================] - 9s 264us/step - loss: 1.2671e-04 - mean_squared_error: 1.1634e-04 - val_loss: 2.2194e-04 - val_mean_squared_error: 2.1156e-04\n",
      "Epoch 24/1000\n",
      "35440/35440 [==============================] - 9s 241us/step - loss: 1.2671e-04 - mean_squared_error: 1.1634e-04 - val_loss: 2.2194e-04 - val_mean_squared_error: 2.1156e-04\n",
      "Epoch 25/1000\n",
      "35440/35440 [==============================] - 8s 231us/step - loss: 1.2671e-04 - mean_squared_error: 1.1633e-04 - val_loss: 2.2194e-04 - val_mean_squared_error: 2.1156e-04\n",
      "Epoch 26/1000\n",
      "35440/35440 [==============================] - 8s 238us/step - loss: 1.2671e-04 - mean_squared_error: 1.1633e-04 - val_loss: 2.2194e-04 - val_mean_squared_error: 2.1157e-04\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "Epoch 27/1000\n",
      "35440/35440 [==============================] - 8s 226us/step - loss: 1.2670e-04 - mean_squared_error: 1.1632e-04 - val_loss: 2.2194e-04 - val_mean_squared_error: 2.1157e-04\n",
      "Epoch 28/1000\n",
      "35440/35440 [==============================] - 6s 174us/step - loss: 1.2670e-04 - mean_squared_error: 1.1632e-04 - val_loss: 2.2194e-04 - val_mean_squared_error: 2.1157e-04\n",
      "Epoch 29/1000\n",
      "35440/35440 [==============================] - 9s 253us/step - loss: 1.2670e-04 - mean_squared_error: 1.1632e-04 - val_loss: 2.2194e-04 - val_mean_squared_error: 2.1157e-04\n",
      "Epoch 30/1000\n",
      "35440/35440 [==============================] - 9s 265us/step - loss: 1.2670e-04 - mean_squared_error: 1.1632e-04 - val_loss: 2.2194e-04 - val_mean_squared_error: 2.1156e-04\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "Epoch 31/1000\n",
      "35440/35440 [==============================] - 10s 269us/step - loss: 1.2670e-04 - mean_squared_error: 1.1632e-04 - val_loss: 2.2194e-04 - val_mean_squared_error: 2.1156e-04\n",
      "Epoch 00031: early stopping\n",
      "Train on 35440 samples, validate on 8880 samples\n",
      "Epoch 1/1000\n",
      "35440/35440 [==============================] - 10s 290us/step - loss: 1.8439e-04 - mean_squared_error: 1.4473e-04 - val_loss: 2.7145e-04 - val_mean_squared_error: 2.3768e-04\n",
      "Epoch 2/1000\n",
      "35440/35440 [==============================] - 11s 320us/step - loss: 1.6706e-04 - mean_squared_error: 1.3752e-04 - val_loss: 2.6320e-04 - val_mean_squared_error: 2.3681e-04\n",
      "Epoch 3/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35440/35440 [==============================] - 9s 259us/step - loss: 1.7022e-04 - mean_squared_error: 1.3866e-04 - val_loss: 2.6038e-04 - val_mean_squared_error: 2.3118e-04\n",
      "Epoch 4/1000\n",
      "35440/35440 [==============================] - 8s 227us/step - loss: 1.6862e-04 - mean_squared_error: 1.3802e-04 - val_loss: 2.5929e-04 - val_mean_squared_error: 2.3148e-04\n",
      "Epoch 5/1000\n",
      "35440/35440 [==============================] - 9s 255us/step - loss: 1.7008e-04 - mean_squared_error: 1.3856e-04 - val_loss: 2.5934e-04 - val_mean_squared_error: 2.2812e-04\n",
      "Epoch 6/1000\n",
      "35440/35440 [==============================] - 8s 238us/step - loss: 1.6945e-04 - mean_squared_error: 1.3832e-04 - val_loss: 2.7882e-04 - val_mean_squared_error: 2.3990e-04\n",
      "Epoch 7/1000\n",
      "35440/35440 [==============================] - 6s 166us/step - loss: 1.8004e-04 - mean_squared_error: 1.4293e-04 - val_loss: 2.6278e-04 - val_mean_squared_error: 2.3121e-04\n",
      "Epoch 8/1000\n",
      "35440/35440 [==============================] - 8s 234us/step - loss: 1.7028e-04 - mean_squared_error: 1.3853e-04 - val_loss: 3.2828e-04 - val_mean_squared_error: 2.4436e-04\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 9/1000\n",
      "35440/35440 [==============================] - 8s 230us/step - loss: 1.3944e-04 - mean_squared_error: 1.2208e-04 - val_loss: 2.2889e-04 - val_mean_squared_error: 2.1357e-04\n",
      "Epoch 10/1000\n",
      "35440/35440 [==============================] - 8s 231us/step - loss: 1.3636e-04 - mean_squared_error: 1.2109e-04 - val_loss: 2.3092e-04 - val_mean_squared_error: 2.1605e-04\n",
      "Epoch 11/1000\n",
      "35440/35440 [==============================] - 8s 229us/step - loss: 1.3514e-04 - mean_squared_error: 1.2072e-04 - val_loss: 2.2635e-04 - val_mean_squared_error: 2.1216e-04\n",
      "Epoch 12/1000\n",
      "35440/35440 [==============================] - 8s 228us/step - loss: 1.3403e-04 - mean_squared_error: 1.2032e-04 - val_loss: 2.2780e-04 - val_mean_squared_error: 2.1472e-04\n",
      "Epoch 13/1000\n",
      "35440/35440 [==============================] - 8s 230us/step - loss: 1.3306e-04 - mean_squared_error: 1.2003e-04 - val_loss: 2.2770e-04 - val_mean_squared_error: 2.1499e-04\n",
      "Epoch 14/1000\n",
      "35440/35440 [==============================] - 8s 212us/step - loss: 1.3216e-04 - mean_squared_error: 1.1969e-04 - val_loss: 2.2876e-04 - val_mean_squared_error: 2.1604e-04\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 15/1000\n",
      "35440/35440 [==============================] - 6s 177us/step - loss: 1.2830e-04 - mean_squared_error: 1.1698e-04 - val_loss: 2.2498e-04 - val_mean_squared_error: 2.1384e-04\n",
      "Epoch 16/1000\n",
      "35440/35440 [==============================] - 9s 255us/step - loss: 1.2784e-04 - mean_squared_error: 1.1675e-04 - val_loss: 2.2465e-04 - val_mean_squared_error: 2.1363e-04\n",
      "Epoch 17/1000\n",
      "35440/35440 [==============================] - 9s 260us/step - loss: 1.2773e-04 - mean_squared_error: 1.1673e-04 - val_loss: 2.2464e-04 - val_mean_squared_error: 2.1363e-04\n",
      "Epoch 18/1000\n",
      "35440/35440 [==============================] - 9s 245us/step - loss: 1.2761e-04 - mean_squared_error: 1.1667e-04 - val_loss: 2.2489e-04 - val_mean_squared_error: 2.1387e-04\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 19/1000\n",
      "35440/35440 [==============================] - 8s 228us/step - loss: 1.2720e-04 - mean_squared_error: 1.1629e-04 - val_loss: 2.2468e-04 - val_mean_squared_error: 2.1382e-04\n",
      "Epoch 20/1000\n",
      "35440/35440 [==============================] - 6s 171us/step - loss: 1.2711e-04 - mean_squared_error: 1.1625e-04 - val_loss: 2.2424e-04 - val_mean_squared_error: 2.1342e-04\n",
      "Epoch 21/1000\n",
      "35440/35440 [==============================] - 7s 184us/step - loss: 1.2708e-04 - mean_squared_error: 1.1626e-04 - val_loss: 2.2424e-04 - val_mean_squared_error: 2.1342e-04\n",
      "Epoch 22/1000\n",
      "35440/35440 [==============================] - 7s 205us/step - loss: 1.2706e-04 - mean_squared_error: 1.1624e-04 - val_loss: 2.2424e-04 - val_mean_squared_error: 2.1343e-04\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 23/1000\n",
      "35440/35440 [==============================] - 9s 241us/step - loss: 1.2700e-04 - mean_squared_error: 1.1618e-04 - val_loss: 2.2423e-04 - val_mean_squared_error: 2.1342e-04\n",
      "Epoch 24/1000\n",
      "35440/35440 [==============================] - 9s 251us/step - loss: 1.2700e-04 - mean_squared_error: 1.1618e-04 - val_loss: 2.2422e-04 - val_mean_squared_error: 2.1341e-04\n",
      "Epoch 25/1000\n",
      "35440/35440 [==============================] - 11s 308us/step - loss: 1.2699e-04 - mean_squared_error: 1.1618e-04 - val_loss: 2.2423e-04 - val_mean_squared_error: 2.1343e-04\n",
      "Epoch 26/1000\n",
      "35440/35440 [==============================] - 11s 305us/step - loss: 1.2699e-04 - mean_squared_error: 1.1618e-04 - val_loss: 2.2424e-04 - val_mean_squared_error: 2.1343e-04\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "Epoch 27/1000\n",
      "35440/35440 [==============================] - 11s 301us/step - loss: 1.2698e-04 - mean_squared_error: 1.1618e-04 - val_loss: 2.2424e-04 - val_mean_squared_error: 2.1343e-04\n",
      "Epoch 28/1000\n",
      "35440/35440 [==============================] - 10s 268us/step - loss: 1.2698e-04 - mean_squared_error: 1.1618e-04 - val_loss: 2.2423e-04 - val_mean_squared_error: 2.1343e-04\n",
      "Epoch 29/1000\n",
      "35440/35440 [==============================] - 8s 229us/step - loss: 1.2698e-04 - mean_squared_error: 1.1618e-04 - val_loss: 2.2423e-04 - val_mean_squared_error: 2.1343e-04\n",
      "Epoch 30/1000\n",
      "35440/35440 [==============================] - 9s 268us/step - loss: 1.2698e-04 - mean_squared_error: 1.1618e-04 - val_loss: 2.2423e-04 - val_mean_squared_error: 2.1343e-04\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "Epoch 31/1000\n",
      "35440/35440 [==============================] - 9s 266us/step - loss: 1.2698e-04 - mean_squared_error: 1.1617e-04 - val_loss: 2.2423e-04 - val_mean_squared_error: 2.1343e-04\n",
      "Epoch 00031: early stopping\n",
      "Train on 35440 samples, validate on 8880 samples\n",
      "Epoch 1/1000\n",
      "35440/35440 [==============================] - 8s 233us/step - loss: 2.0179e-04 - mean_squared_error: 1.5060e-04 - val_loss: 2.6181e-04 - val_mean_squared_error: 2.3200e-04\n",
      "Epoch 2/1000\n",
      "35440/35440 [==============================] - 8s 230us/step - loss: 1.6698e-04 - mean_squared_error: 1.3716e-04 - val_loss: 2.5806e-04 - val_mean_squared_error: 2.2774e-04\n",
      "Epoch 3/1000\n",
      "35440/35440 [==============================] - 9s 266us/step - loss: 1.6903e-04 - mean_squared_error: 1.3790e-04 - val_loss: 2.5431e-04 - val_mean_squared_error: 2.2312e-04\n",
      "Epoch 4/1000\n",
      "35440/35440 [==============================] - 10s 272us/step - loss: 1.6749e-04 - mean_squared_error: 1.3726e-04 - val_loss: 2.6470e-04 - val_mean_squared_error: 2.3360e-04\n",
      "Epoch 5/1000\n",
      "35440/35440 [==============================] - 8s 232us/step - loss: 1.6890e-04 - mean_squared_error: 1.3806e-04 - val_loss: 2.5979e-04 - val_mean_squared_error: 2.2854e-04\n",
      "Epoch 6/1000\n",
      "35440/35440 [==============================] - 8s 232us/step - loss: 1.6981e-04 - mean_squared_error: 1.3811e-04 - val_loss: 2.6863e-04 - val_mean_squared_error: 2.3685e-04\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 7/1000\n",
      "35440/35440 [==============================] - 8s 237us/step - loss: 1.3717e-04 - mean_squared_error: 1.2115e-04 - val_loss: 2.3196e-04 - val_mean_squared_error: 2.1678e-04\n",
      "Epoch 8/1000\n",
      "35440/35440 [==============================] - 8s 233us/step - loss: 1.3522e-04 - mean_squared_error: 1.2037e-04 - val_loss: 2.2830e-04 - val_mean_squared_error: 2.1368e-04\n",
      "Epoch 9/1000\n",
      "35440/35440 [==============================] - 8s 230us/step - loss: 1.3405e-04 - mean_squared_error: 1.1997e-04 - val_loss: 2.2942e-04 - val_mean_squared_error: 2.1591e-04\n",
      "Epoch 10/1000\n",
      "35440/35440 [==============================] - 8s 234us/step - loss: 1.3288e-04 - mean_squared_error: 1.1959e-04 - val_loss: 2.3098e-04 - val_mean_squared_error: 2.1816e-04\n",
      "Epoch 11/1000\n",
      "35440/35440 [==============================] - 9s 265us/step - loss: 1.3201e-04 - mean_squared_error: 1.1928e-04 - val_loss: 2.2949e-04 - val_mean_squared_error: 2.1716e-04\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 12/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35440/35440 [==============================] - 8s 234us/step - loss: 1.2815e-04 - mean_squared_error: 1.1677e-04 - val_loss: 2.2674e-04 - val_mean_squared_error: 2.1547e-04\n",
      "Epoch 13/1000\n",
      "35440/35440 [==============================] - 6s 165us/step - loss: 1.2776e-04 - mean_squared_error: 1.1651e-04 - val_loss: 2.2662e-04 - val_mean_squared_error: 2.1537e-04\n",
      "Epoch 14/1000\n",
      "35440/35440 [==============================] - 8s 233us/step - loss: 1.2762e-04 - mean_squared_error: 1.1642e-04 - val_loss: 2.2631e-04 - val_mean_squared_error: 2.1514e-04\n",
      "Epoch 15/1000\n",
      "35440/35440 [==============================] - 10s 271us/step - loss: 1.2750e-04 - mean_squared_error: 1.1636e-04 - val_loss: 2.2607e-04 - val_mean_squared_error: 2.1498e-04\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 16/1000\n",
      "35440/35440 [==============================] - 9s 265us/step - loss: 1.2710e-04 - mean_squared_error: 1.1609e-04 - val_loss: 2.2564e-04 - val_mean_squared_error: 2.1465e-04\n",
      "Epoch 17/1000\n",
      "35440/35440 [==============================] - 9s 253us/step - loss: 1.2700e-04 - mean_squared_error: 1.1601e-04 - val_loss: 2.2566e-04 - val_mean_squared_error: 2.1468e-04\n",
      "Epoch 18/1000\n",
      "35440/35440 [==============================] - 6s 176us/step - loss: 1.2697e-04 - mean_squared_error: 1.1600e-04 - val_loss: 2.2565e-04 - val_mean_squared_error: 2.1467e-04\n",
      "Epoch 19/1000\n",
      "35440/35440 [==============================] - 8s 214us/step - loss: 1.2695e-04 - mean_squared_error: 1.1598e-04 - val_loss: 2.2569e-04 - val_mean_squared_error: 2.1472e-04\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 20/1000\n",
      "35440/35440 [==============================] - 9s 261us/step - loss: 1.2689e-04 - mean_squared_error: 1.1592e-04 - val_loss: 2.2568e-04 - val_mean_squared_error: 2.1471e-04\n",
      "Epoch 21/1000\n",
      "35440/35440 [==============================] - 9s 261us/step - loss: 1.2689e-04 - mean_squared_error: 1.1592e-04 - val_loss: 2.2568e-04 - val_mean_squared_error: 2.1471e-04\n",
      "Epoch 22/1000\n",
      "35440/35440 [==============================] - 8s 231us/step - loss: 1.2688e-04 - mean_squared_error: 1.1592e-04 - val_loss: 2.2567e-04 - val_mean_squared_error: 2.1471e-04\n",
      "Epoch 23/1000\n",
      "35440/35440 [==============================] - 8s 229us/step - loss: 1.2688e-04 - mean_squared_error: 1.1591e-04 - val_loss: 2.2567e-04 - val_mean_squared_error: 2.1470e-04\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "Epoch 24/1000\n",
      "35440/35440 [==============================] - 8s 231us/step - loss: 1.2687e-04 - mean_squared_error: 1.1591e-04 - val_loss: 2.2566e-04 - val_mean_squared_error: 2.1470e-04\n",
      "Epoch 25/1000\n",
      "35440/35440 [==============================] - 8s 229us/step - loss: 1.2687e-04 - mean_squared_error: 1.1591e-04 - val_loss: 2.2566e-04 - val_mean_squared_error: 2.1470e-04\n",
      "Epoch 26/1000\n",
      "35440/35440 [==============================] - 8s 230us/step - loss: 1.2687e-04 - mean_squared_error: 1.1591e-04 - val_loss: 2.2566e-04 - val_mean_squared_error: 2.1470e-04\n",
      "Epoch 27/1000\n",
      "35440/35440 [==============================] - 8s 230us/step - loss: 1.2687e-04 - mean_squared_error: 1.1591e-04 - val_loss: 2.2566e-04 - val_mean_squared_error: 2.1470e-04\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "Epoch 28/1000\n",
      "35440/35440 [==============================] - 8s 232us/step - loss: 1.2687e-04 - mean_squared_error: 1.1591e-04 - val_loss: 2.2566e-04 - val_mean_squared_error: 2.1470e-04\n",
      "Epoch 00028: early stopping\n",
      "Train on 35440 samples, validate on 8880 samples\n",
      "Epoch 1/1000\n",
      "35440/35440 [==============================] - 8s 229us/step - loss: 1.8496e-04 - mean_squared_error: 1.4393e-04 - val_loss: 2.6925e-04 - val_mean_squared_error: 2.3921e-04\n",
      "Epoch 2/1000\n",
      "35440/35440 [==============================] - 8s 230us/step - loss: 1.6712e-04 - mean_squared_error: 1.3690e-04 - val_loss: 2.8789e-04 - val_mean_squared_error: 2.4014e-04\n",
      "Epoch 3/1000\n",
      "35440/35440 [==============================] - 9s 265us/step - loss: 1.7009e-04 - mean_squared_error: 1.3773e-04 - val_loss: 2.7199e-04 - val_mean_squared_error: 2.3959e-04\n",
      "Epoch 4/1000\n",
      "35440/35440 [==============================] - 8s 228us/step - loss: 1.6737e-04 - mean_squared_error: 1.3720e-04 - val_loss: 2.6724e-04 - val_mean_squared_error: 2.3396e-04\n",
      "Epoch 5/1000\n",
      "35440/35440 [==============================] - 6s 170us/step - loss: 1.6886e-04 - mean_squared_error: 1.3771e-04 - val_loss: 2.6617e-04 - val_mean_squared_error: 2.3208e-04\n",
      "Epoch 6/1000\n",
      "35440/35440 [==============================] - 9s 244us/step - loss: 1.6867e-04 - mean_squared_error: 1.3725e-04 - val_loss: 2.6892e-04 - val_mean_squared_error: 2.4079e-04\n",
      "Epoch 7/1000\n",
      "35440/35440 [==============================] - 7s 199us/step - loss: 1.7322e-04 - mean_squared_error: 1.3917e-04 - val_loss: 2.4770e-04 - val_mean_squared_error: 2.1921e-04\n",
      "Epoch 8/1000\n",
      "35440/35440 [==============================] - 7s 193us/step - loss: 1.6747e-04 - mean_squared_error: 1.3704e-04 - val_loss: 2.6307e-04 - val_mean_squared_error: 2.3309e-04\n",
      "Epoch 9/1000\n",
      "35440/35440 [==============================] - 9s 254us/step - loss: 1.6742e-04 - mean_squared_error: 1.3690e-04 - val_loss: 2.7093e-04 - val_mean_squared_error: 2.3502e-04\n",
      "Epoch 10/1000\n",
      "35440/35440 [==============================] - 8s 230us/step - loss: 1.6825e-04 - mean_squared_error: 1.3711e-04 - val_loss: 2.5356e-04 - val_mean_squared_error: 2.2531e-04\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 11/1000\n",
      "35440/35440 [==============================] - 9s 243us/step - loss: 1.3630e-04 - mean_squared_error: 1.2041e-04 - val_loss: 2.3138e-04 - val_mean_squared_error: 2.1655e-04\n",
      "Epoch 12/1000\n",
      "35440/35440 [==============================] - 9s 261us/step - loss: 1.3431e-04 - mean_squared_error: 1.1955e-04 - val_loss: 2.3463e-04 - val_mean_squared_error: 2.2027e-04\n",
      "Epoch 13/1000\n",
      "35440/35440 [==============================] - 8s 233us/step - loss: 1.3313e-04 - mean_squared_error: 1.1920e-04 - val_loss: 2.3349e-04 - val_mean_squared_error: 2.1975e-04\n",
      "Epoch 14/1000\n",
      "35440/35440 [==============================] - 8s 233us/step - loss: 1.3203e-04 - mean_squared_error: 1.1883e-04 - val_loss: 2.3198e-04 - val_mean_squared_error: 2.1914e-04\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 15/1000\n",
      "35440/35440 [==============================] - 8s 230us/step - loss: 1.2820e-04 - mean_squared_error: 1.1641e-04 - val_loss: 2.2873e-04 - val_mean_squared_error: 2.1697e-04\n",
      "Epoch 16/1000\n",
      "35440/35440 [==============================] - 8s 234us/step - loss: 1.2779e-04 - mean_squared_error: 1.1612e-04 - val_loss: 2.2732e-04 - val_mean_squared_error: 2.1557e-04\n",
      "Epoch 17/1000\n",
      "35440/35440 [==============================] - 8s 230us/step - loss: 1.2767e-04 - mean_squared_error: 1.1604e-04 - val_loss: 2.2768e-04 - val_mean_squared_error: 2.1605e-04\n",
      "Epoch 18/1000\n",
      "35440/35440 [==============================] - 8s 239us/step - loss: 1.2752e-04 - mean_squared_error: 1.1596e-04 - val_loss: 2.2775e-04 - val_mean_squared_error: 2.1622e-04\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 19/1000\n",
      "35440/35440 [==============================] - 10s 270us/step - loss: 1.2710e-04 - mean_squared_error: 1.1563e-04 - val_loss: 2.2743e-04 - val_mean_squared_error: 2.1599e-04\n",
      "Epoch 20/1000\n",
      "35440/35440 [==============================] - 9s 264us/step - loss: 1.2701e-04 - mean_squared_error: 1.1558e-04 - val_loss: 2.2733e-04 - val_mean_squared_error: 2.1591e-04\n",
      "Epoch 21/1000\n",
      "35440/35440 [==============================] - 8s 232us/step - loss: 1.2698e-04 - mean_squared_error: 1.1556e-04 - val_loss: 2.2727e-04 - val_mean_squared_error: 2.1587e-04\n",
      "Epoch 22/1000\n",
      "35440/35440 [==============================] - 9s 262us/step - loss: 1.2697e-04 - mean_squared_error: 1.1557e-04 - val_loss: 2.2728e-04 - val_mean_squared_error: 2.1589e-04\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 23/1000\n",
      "35440/35440 [==============================] - 11s 297us/step - loss: 1.2690e-04 - mean_squared_error: 1.1551e-04 - val_loss: 2.2729e-04 - val_mean_squared_error: 2.1590e-04\n",
      "Epoch 24/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13024/35440 [==========>...................] - ETA: 5s - loss: 1.2687e-04 - mean_squared_error: 1.1548e-04"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-f9526a0e83e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#model_path + name_folder,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;31m#log_dir=None#\"./logs/H/\" + name + \"_\" + \"x\".join(list(map(str, structure))) + \"_\" + str(i)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m )\n",
      "\u001b[0;32m<ipython-input-11-1a05f5499106>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, dataset, filepath, learning_rate, log_dir)\u001b[0m\n\u001b[1;32m     59\u001b[0m             callbacks=[\n\u001b[1;32m     60\u001b[0m                 \u001b[0mearly_stopping\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                 \u001b[0mreduce_lr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m                 \u001b[0;31m#checkpoint,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m                 \u001b[0;31m#tensorboard\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1361\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1362\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1363\u001b[0;31m           validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1365\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    262\u001b[0m           \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m           \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2912\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_arrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_symbols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2914\u001b[0;31m     \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2915\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2916\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f510f70e2e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#i+=1\n",
    "train_model(\n",
    "    model, \n",
    "    dataset, \n",
    "    #model_path + name_folder,\n",
    "    learning_rate=1e-3,\n",
    "    #log_dir=None#\"./logs/H/\" + name + \"_\" + \"x\".join(list(map(str, structure))) + \"_\" + str(i)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
