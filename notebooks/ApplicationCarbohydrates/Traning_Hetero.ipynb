{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jo/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import seaborn as sns\n",
    "\n",
    "from os.path import join\n",
    "\n",
    "plt.style.use([\"seaborn\", \"thesis\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc(\"figure\", figsize=(8,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"../../thesis/models/DescriptorHetero/CH/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Molecules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SCFInitialGuess.utilities.dataset import ScreenedData\n",
    "\n",
    "target = \"P\"\n",
    "basis = \"6-311++g**\"\n",
    "\n",
    "data = ScreenedData(r_max=10)\n",
    "\n",
    "data.include(data_path = \"../../thesis/dataset/MethanT/\", postfix = \"MethanT\", target=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SCFInitialGuess.utilities.dataset import ScreenedData\n",
    "\n",
    "target = \"P\"\n",
    "\n",
    "data = ScreenedData(r_max=10)\n",
    "\n",
    "data.include(data_path = \"../../thesis/dataset/MethanT/\", postfix = \"MethanT\", target=target)\n",
    "data.include(data_path = \"../../thesis/dataset/MethanT2/\", postfix = \"MethanT2\", target=target)\n",
    "data.include(data_path = \"../../thesis/dataset/MethanT3/\", postfix = \"MethanT3\", target=target)\n",
    "data.include(data_path = \"../../thesis/dataset/MethanT4/\", postfix = \"MethanT4\", target=target)\n",
    "\n",
    "data.include(data_path = \"../../thesis/dataset/EthanT/\",  postfix = \"EthanT\", target=target)\n",
    "data.include(data_path = \"../../thesis/dataset/EthanT2/\", postfix = \"EthanT2\", target=target)\n",
    "data.include(data_path = \"../../thesis/dataset/EthanT3/\", postfix = \"EthanT3\", target=target)\n",
    "data.include(data_path = \"../../thesis/dataset/EthanT4/\",  postfix = \"EthanT4\", target=target)\n",
    "data.include(data_path = \"../../thesis/dataset/EthanT5/\",  postfix = \"EthanT5\", target=target)\n",
    "data.include(data_path = \"../../thesis/dataset/EthanT6/\",  postfix = \"EthanT6\", target=target)\n",
    "\n",
    "data.include(data_path = \"../../thesis/dataset/EthenT/\",  postfix = \"EthenT\", target=target)\n",
    "data.include(data_path = \"../../thesis/dataset/EthenT2/\", postfix = \"EthenT2\", target=target)\n",
    "data.include(data_path = \"../../thesis/dataset/EthenT3/\", postfix = \"EthenT3\", target=target)\n",
    "data.include(data_path = \"../../thesis/dataset/EthenT4/\",  postfix = \"EthenT4\", target=target)\n",
    "data.include(data_path = \"../../thesis/dataset/EthenT5/\",  postfix = \"EthenT5\", target=target)\n",
    "data.include(data_path = \"../../thesis/dataset/EthenT6/\",  postfix = \"EthenT6\", target=target)\n",
    "\n",
    "\n",
    "data.include(data_path = \"../../thesis/dataset/EthinT/\",  postfix = \"EthinT\", target=target)\n",
    "data.include(data_path = \"../../thesis/dataset/EthinT2/\", postfix = \"EthinT2\", target=target)\n",
    "data.include(data_path = \"../../thesis/dataset/EthinT3/\", postfix = \"EthinT3\", target=target)\n",
    "\n",
    "#data.include(data_path = \"../../dataset/QM9/\", postfix = \"QM9-300\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descriptor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 50, 75)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from SCFInitialGuess.descriptors.high_level import AtomicNumberWeighted\n",
    "from SCFInitialGuess.descriptors.cutoffs import BehlerCutoff1\n",
    "from SCFInitialGuess.descriptors.models import RADIAL_GAUSSIAN_MODELS, make_uniform\n",
    "from SCFInitialGuess.descriptors.coordinate_descriptors import \\\n",
    "    Gaussians, SPHAngularDescriptor\n",
    "import pickle\n",
    "\n",
    "model = make_uniform(25, 5, eta_max=60, eta_min=20)\n",
    "\n",
    "descriptor_C = AtomicNumberWeighted(\n",
    "    Gaussians(*model),\n",
    "    SPHAngularDescriptor(4),\n",
    "    BehlerCutoff1(5)\n",
    ")\n",
    "\n",
    "\n",
    "pickle.dump(descriptor_C, open(model_path + \"descriptor_C.dump\", \"wb\"))\n",
    "    \n",
    "descriptor_C.radial_descriptor.number_of_descriptors, descriptor_C.angular_descriptor.number_of_descriptors, descriptor_C.number_of_descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 32, 57)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from SCFInitialGuess.descriptors.high_level import AtomicNumberWeighted\n",
    "from SCFInitialGuess.descriptors.cutoffs import BehlerCutoff1\n",
    "from SCFInitialGuess.descriptors.models import RADIAL_GAUSSIAN_MODELS, make_uniform\n",
    "from SCFInitialGuess.descriptors.coordinate_descriptors import \\\n",
    "    Gaussians, SPHAngularDescriptor\n",
    "import pickle\n",
    "\n",
    "model = make_uniform(25, 5, eta_max=60, eta_min=20)\n",
    "\n",
    "descriptor_H = AtomicNumberWeighted(\n",
    "    Gaussians(*model),\n",
    "    SPHAngularDescriptor(3),\n",
    "    BehlerCutoff1(5)\n",
    ")\n",
    "\n",
    "\n",
    "pickle.dump(descriptor_H, open(model_path + \"descriptor_H.dump\", \"wb\"))\n",
    "    \n",
    "descriptor_H.radial_descriptor.number_of_descriptors, descriptor_H.angular_descriptor.number_of_descriptors, descriptor_H.number_of_descriptors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Package Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SCFInitialGuess.utilities.dataset import make_block_dataset, extract_HETERO_block_dataset_pairs\n",
    "\n",
    "dataset = make_block_dataset(\n",
    "    [descriptor_C, descriptor_H],\n",
    "    data.molecules,\n",
    "    data.T,\n",
    "    [\"C\", \"H\"],\n",
    "    extract_HETERO_block_dataset_pairs\n",
    ")\n",
    "\n",
    "np.save(model_path + \"normalisation.npy\", (dataset.x_mean, dataset.x_std))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49416, 12408, 15560)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.training[0]), len(dataset.validation[0]), len(dataset.testing[0]), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SCFInitialGuess.utilities.constants import number_of_basis_functions as N_BASIS\n",
    "\n",
    "\n",
    "dim_C = N_BASIS[basis][\"C\"]\n",
    "dim_H = N_BASIS[basis][\"H\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN Utils "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keras.backend.clear_session()\n",
    "\n",
    "#activation = \"elu\"\n",
    "#learning_rate = 1e-5\n",
    "\n",
    "intializer = keras.initializers.TruncatedNormal(mean=0.0, stddev=0.01)\n",
    "\n",
    "def make_model(\n",
    "        structure, \n",
    "        input_dim, \n",
    "        output_dim,\n",
    "        activation=\"elu\", \n",
    "        learning_rate=1e-3\n",
    "    ):\n",
    "\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    # input layer\n",
    "    model.add(keras.layers.Dense(\n",
    "        structure[0], \n",
    "        activation=activation, \n",
    "        input_dim=input_dim, \n",
    "        kernel_initializer=intializer\n",
    "    ))\n",
    "\n",
    "    for layer in structure[1:]:\n",
    "        model.add(keras.layers.Dense(\n",
    "            layer, \n",
    "            activation=activation, \n",
    "            kernel_initializer=intializer, \n",
    "            #bias_initializer='zeros',\n",
    "            kernel_regularizer=keras.regularizers.l2(5e-3)\n",
    "        ))\n",
    "\n",
    "    #output\n",
    "    model.add(keras.layers.Dense(output_dim))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate), \n",
    "        loss='MSE', \n",
    "        metrics=['mse']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_mean_squared_error\", \n",
    "    min_delta=1e-8, \n",
    "    patience=20, \n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_mean_squared_error', \n",
    "    factor=0.1, \n",
    "    patience=3, \n",
    "    verbose=1, \n",
    "    mode='auto', \n",
    "    min_delta=1e-6, \n",
    "    cooldown=2, \n",
    "    min_lr=1e-10\n",
    ")\n",
    "\n",
    "\n",
    "epochs = 1000\n",
    "\n",
    "\n",
    "def train_model(model, dataset, filepath=None, learning_rate=1e-4, log_dir=None):\n",
    "\n",
    "    if not log_dir is None:\n",
    "        tensorboard = keras.callbacks.TensorBoard(\n",
    "            log_dir=log_dir, \n",
    "            histogram_freq=0, \n",
    "            batch_size=32, \n",
    "            #update_freq='epoch'\n",
    "        )\n",
    "    \n",
    "    if not filepath is None:\n",
    "        checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "            filepath, \n",
    "            monitor='val_mean_squared_error', \n",
    "            verbose=1, \n",
    "            save_best_only=True, \n",
    "            save_weights_only=False, \n",
    "            mode='auto', \n",
    "            period=1\n",
    "        )\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    \n",
    "    train, validation = [], []\n",
    "    while True:\n",
    "        keras.backend.set_value(model.optimizer.lr, learning_rate)\n",
    "            \n",
    "        history = model.fit(\n",
    "            x = dataset.training[0],\n",
    "            y = dataset.training[1],\n",
    "            epochs=epochs,\n",
    "            shuffle=True,\n",
    "            validation_data=dataset.validation, \n",
    "            verbose=1, \n",
    "            callbacks=[\n",
    "                early_stopping, \n",
    "                reduce_lr,\n",
    "                checkpoint,\n",
    "                #tensorboard\n",
    "            ]\n",
    "        )\n",
    "            \n",
    "        \n",
    "        #error.append(model.evaluate(\n",
    "        #    dataset.testing[0], \n",
    "        #    dataset.testing[1], \n",
    "        #    verbose=1\n",
    "        #)[1])\n",
    "    \n",
    "    return error\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((49416, 132), (49416, 154))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.training[0].shape, dataset.training[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75, 57, 154)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descriptor_C.number_of_descriptors, descriptor_H.number_of_descriptors, dim_C * dim_H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "structure = [200, 200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 200)               26600     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 154)               30954     \n",
      "=================================================================\n",
      "Total params: 97,754\n",
      "Trainable params: 97,754\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = make_model(\n",
    "    structure=structure,\n",
    "    input_dim=descriptor_C.number_of_descriptors + descriptor_H.number_of_descriptors,\n",
    "    output_dim=dim_C * dim_H,\n",
    "    \n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 49416 samples, validate on 12408 samples\n",
      "Epoch 1/1000\n",
      "49416/49416 [==============================] - 4s 85us/step - loss: 4.8210e-04 - mean_squared_error: 3.5001e-04 - val_loss: 4.4461e-04 - val_mean_squared_error: 3.1651e-04\n",
      "\n",
      "Epoch 00001: val_mean_squared_error improved from inf to 0.00032, saving model to ../../thesis/models/DescriptorHetero/CH/model.h5\n",
      "Epoch 2/1000\n",
      "49416/49416 [==============================] - 3s 69us/step - loss: 3.0434e-04 - mean_squared_error: 2.5791e-04 - val_loss: 3.1714e-04 - val_mean_squared_error: 2.7634e-04\n",
      "\n",
      "Epoch 00002: val_mean_squared_error improved from 0.00032 to 0.00028, saving model to ../../thesis/models/DescriptorHetero/CH/model.h5\n",
      "Epoch 3/1000\n",
      "49416/49416 [==============================] - 3s 70us/step - loss: 2.7576e-04 - mean_squared_error: 2.2424e-04 - val_loss: 3.1802e-04 - val_mean_squared_error: 2.6742e-04\n",
      "\n",
      "Epoch 00003: val_mean_squared_error improved from 0.00028 to 0.00027, saving model to ../../thesis/models/DescriptorHetero/CH/model.h5\n",
      "Epoch 4/1000\n",
      "49416/49416 [==============================] - 3s 70us/step - loss: 2.3699e-04 - mean_squared_error: 1.9980e-04 - val_loss: 3.1614e-04 - val_mean_squared_error: 2.7405e-04\n",
      "\n",
      "Epoch 00004: val_mean_squared_error did not improve from 0.00027\n",
      "Epoch 5/1000\n",
      "49416/49416 [==============================] - 3s 71us/step - loss: 2.3814e-04 - mean_squared_error: 1.9528e-04 - val_loss: 2.8721e-04 - val_mean_squared_error: 2.5041e-04\n",
      "\n",
      "Epoch 00005: val_mean_squared_error improved from 0.00027 to 0.00025, saving model to ../../thesis/models/DescriptorHetero/CH/model.h5\n",
      "Epoch 6/1000\n",
      "49416/49416 [==============================] - 4s 72us/step - loss: 2.1700e-04 - mean_squared_error: 1.8360e-04 - val_loss: 2.9061e-04 - val_mean_squared_error: 2.5543e-04\n",
      "\n",
      "Epoch 00006: val_mean_squared_error did not improve from 0.00025\n",
      "Epoch 7/1000\n",
      "49416/49416 [==============================] - 4s 71us/step - loss: 2.1496e-04 - mean_squared_error: 1.8094e-04 - val_loss: 2.8132e-04 - val_mean_squared_error: 2.5070e-04\n",
      "\n",
      "Epoch 00007: val_mean_squared_error did not improve from 0.00025\n",
      "Epoch 8/1000\n",
      "49416/49416 [==============================] - 4s 71us/step - loss: 2.1287e-04 - mean_squared_error: 1.7833e-04 - val_loss: 2.7471e-04 - val_mean_squared_error: 2.4285e-04\n",
      "\n",
      "Epoch 00008: val_mean_squared_error improved from 0.00025 to 0.00024, saving model to ../../thesis/models/DescriptorHetero/CH/model.h5\n",
      "Epoch 9/1000\n",
      "49416/49416 [==============================] - 4s 71us/step - loss: 2.0943e-04 - mean_squared_error: 1.7599e-04 - val_loss: 2.8105e-04 - val_mean_squared_error: 2.4689e-04\n",
      "\n",
      "Epoch 00009: val_mean_squared_error did not improve from 0.00024\n",
      "Epoch 10/1000\n",
      "49416/49416 [==============================] - 4s 73us/step - loss: 2.1990e-04 - mean_squared_error: 1.7960e-04 - val_loss: 2.7648e-04 - val_mean_squared_error: 2.4547e-04\n",
      "\n",
      "Epoch 00010: val_mean_squared_error did not improve from 0.00024\n",
      "Epoch 11/1000\n",
      "49416/49416 [==============================] - 4s 74us/step - loss: 2.2364e-04 - mean_squared_error: 1.7976e-04 - val_loss: 2.7288e-04 - val_mean_squared_error: 2.4448e-04\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 00011: val_mean_squared_error did not improve from 0.00024\n",
      "Epoch 12/1000\n",
      "49416/49416 [==============================] - 4s 74us/step - loss: 1.7316e-04 - mean_squared_error: 1.5547e-04 - val_loss: 2.4521e-04 - val_mean_squared_error: 2.2772e-04\n",
      "\n",
      "Epoch 00012: val_mean_squared_error improved from 0.00024 to 0.00023, saving model to ../../thesis/models/DescriptorHetero/CH/model.h5\n",
      "Epoch 13/1000\n",
      "49416/49416 [==============================] - 4s 80us/step - loss: 1.7086e-04 - mean_squared_error: 1.5422e-04 - val_loss: 2.4404e-04 - val_mean_squared_error: 2.2796e-04\n",
      "\n",
      "Epoch 00013: val_mean_squared_error did not improve from 0.00023\n",
      "Epoch 14/1000\n",
      "49416/49416 [==============================] - 4s 73us/step - loss: 1.6892e-04 - mean_squared_error: 1.5334e-04 - val_loss: 2.4392e-04 - val_mean_squared_error: 2.2871e-04\n",
      "\n",
      "Epoch 00014: val_mean_squared_error did not improve from 0.00023\n",
      "Epoch 15/1000\n",
      "49416/49416 [==============================] - 4s 73us/step - loss: 1.6732e-04 - mean_squared_error: 1.5263e-04 - val_loss: 2.4267e-04 - val_mean_squared_error: 2.2860e-04\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 00015: val_mean_squared_error did not improve from 0.00023\n",
      "Epoch 16/1000\n",
      "49416/49416 [==============================] - 4s 75us/step - loss: 1.6256e-04 - mean_squared_error: 1.4956e-04 - val_loss: 2.3890e-04 - val_mean_squared_error: 2.2594e-04\n",
      "\n",
      "Epoch 00016: val_mean_squared_error improved from 0.00023 to 0.00023, saving model to ../../thesis/models/DescriptorHetero/CH/model.h5\n",
      "Epoch 17/1000\n",
      "49416/49416 [==============================] - 4s 73us/step - loss: 1.6214e-04 - mean_squared_error: 1.4925e-04 - val_loss: 2.3819e-04 - val_mean_squared_error: 2.2527e-04\n",
      "\n",
      "Epoch 00017: val_mean_squared_error improved from 0.00023 to 0.00023, saving model to ../../thesis/models/DescriptorHetero/CH/model.h5\n",
      "Epoch 18/1000\n",
      "49416/49416 [==============================] - 4s 74us/step - loss: 1.6190e-04 - mean_squared_error: 1.4910e-04 - val_loss: 2.3891e-04 - val_mean_squared_error: 2.2610e-04\n",
      "\n",
      "Epoch 00018: val_mean_squared_error did not improve from 0.00023\n",
      "Epoch 19/1000\n",
      "49416/49416 [==============================] - 4s 74us/step - loss: 1.6169e-04 - mean_squared_error: 1.4899e-04 - val_loss: 2.3824e-04 - val_mean_squared_error: 2.2552e-04\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "\n",
      "Epoch 00019: val_mean_squared_error did not improve from 0.00023\n",
      "Epoch 20/1000\n",
      "49416/49416 [==============================] - 4s 75us/step - loss: 1.6118e-04 - mean_squared_error: 1.4855e-04 - val_loss: 2.3811e-04 - val_mean_squared_error: 2.2553e-04\n",
      "\n",
      "Epoch 00020: val_mean_squared_error did not improve from 0.00023\n",
      "Epoch 21/1000\n",
      "49416/49416 [==============================] - 4s 74us/step - loss: 1.6107e-04 - mean_squared_error: 1.4850e-04 - val_loss: 2.3802e-04 - val_mean_squared_error: 2.2546e-04\n",
      "\n",
      "Epoch 00021: val_mean_squared_error did not improve from 0.00023\n",
      "Epoch 22/1000\n",
      "49416/49416 [==============================] - 4s 74us/step - loss: 1.6103e-04 - mean_squared_error: 1.4849e-04 - val_loss: 2.3788e-04 - val_mean_squared_error: 2.2534e-04\n",
      "\n",
      "Epoch 00022: val_mean_squared_error did not improve from 0.00023\n",
      "Epoch 23/1000\n",
      "49416/49416 [==============================] - 4s 75us/step - loss: 1.6100e-04 - mean_squared_error: 1.4847e-04 - val_loss: 2.3786e-04 - val_mean_squared_error: 2.2534e-04\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "\n",
      "Epoch 00023: val_mean_squared_error did not improve from 0.00023\n",
      "Epoch 24/1000\n",
      "49416/49416 [==============================] - 4s 75us/step - loss: 1.6093e-04 - mean_squared_error: 1.4842e-04 - val_loss: 2.3786e-04 - val_mean_squared_error: 2.2535e-04\n",
      "\n",
      "Epoch 00024: val_mean_squared_error did not improve from 0.00023\n",
      "Epoch 25/1000\n",
      "49416/49416 [==============================] - 4s 76us/step - loss: 1.6093e-04 - mean_squared_error: 1.4841e-04 - val_loss: 2.3787e-04 - val_mean_squared_error: 2.2535e-04\n",
      "\n",
      "Epoch 00025: val_mean_squared_error did not improve from 0.00023\n",
      "Epoch 26/1000\n",
      "49416/49416 [==============================] - 4s 74us/step - loss: 1.6092e-04 - mean_squared_error: 1.4841e-04 - val_loss: 2.3787e-04 - val_mean_squared_error: 2.2536e-04\n",
      "\n",
      "Epoch 00026: val_mean_squared_error did not improve from 0.00023\n",
      "Epoch 27/1000\n",
      "49416/49416 [==============================] - 4s 74us/step - loss: 1.6092e-04 - mean_squared_error: 1.4841e-04 - val_loss: 2.3788e-04 - val_mean_squared_error: 2.2537e-04\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "\n",
      "Epoch 00027: val_mean_squared_error did not improve from 0.00023\n",
      "Epoch 28/1000\n",
      "49416/49416 [==============================] - 4s 75us/step - loss: 1.6091e-04 - mean_squared_error: 1.4840e-04 - val_loss: 2.3788e-04 - val_mean_squared_error: 2.2537e-04\n",
      "\n",
      "Epoch 00028: val_mean_squared_error did not improve from 0.00023\n",
      "Epoch 29/1000\n",
      "49416/49416 [==============================] - 5s 92us/step - loss: 1.6091e-04 - mean_squared_error: 1.4840e-04 - val_loss: 2.3788e-04 - val_mean_squared_error: 2.2537e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00029: val_mean_squared_error did not improve from 0.00023\n",
      "Epoch 30/1000\n",
      "49416/49416 [==============================] - 5s 110us/step - loss: 1.6091e-04 - mean_squared_error: 1.4840e-04 - val_loss: 2.3788e-04 - val_mean_squared_error: 2.2537e-04\n",
      "\n",
      "Epoch 00030: val_mean_squared_error did not improve from 0.00023\n",
      "Epoch 31/1000\n",
      "49416/49416 [==============================] - 5s 93us/step - loss: 1.6091e-04 - mean_squared_error: 1.4840e-04 - val_loss: 2.3788e-04 - val_mean_squared_error: 2.2537e-04\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "\n",
      "Epoch 00031: val_mean_squared_error did not improve from 0.00023\n",
      "Epoch 32/1000\n",
      "49416/49416 [==============================] - 4s 84us/step - loss: 1.6091e-04 - mean_squared_error: 1.4840e-04 - val_loss: 2.3788e-04 - val_mean_squared_error: 2.2537e-04\n",
      "\n",
      "Epoch 00032: val_mean_squared_error did not improve from 0.00023\n",
      "Epoch 33/1000\n",
      "49416/49416 [==============================] - 5s 99us/step - loss: 1.6091e-04 - mean_squared_error: 1.4840e-04 - val_loss: 2.3788e-04 - val_mean_squared_error: 2.2537e-04\n",
      "\n",
      "Epoch 00033: val_mean_squared_error did not improve from 0.00023\n",
      "Epoch 34/1000\n",
      "49416/49416 [==============================] - 5s 93us/step - loss: 1.6091e-04 - mean_squared_error: 1.4840e-04 - val_loss: 2.3788e-04 - val_mean_squared_error: 2.2537e-04\n",
      "\n",
      "Epoch 00034: val_mean_squared_error did not improve from 0.00023\n",
      "Epoch 35/1000\n",
      "49416/49416 [==============================] - 5s 95us/step - loss: 1.6091e-04 - mean_squared_error: 1.4840e-04 - val_loss: 2.3788e-04 - val_mean_squared_error: 2.2537e-04\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "\n",
      "Epoch 00035: val_mean_squared_error did not improve from 0.00023\n",
      "Epoch 36/1000\n",
      "43744/49416 [=========================>....] - ETA: 0s - loss: 1.6142e-04 - mean_squared_error: 1.4892e-04"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-d07d8919daff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmodel_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"model.h5\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;31m#log_dir=None#\"./logs/H/\" + name + \"_\" + \"x\".join(list(map(str, structure))) + \"_\" + str(i)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m )\n",
      "\u001b[0;32m<ipython-input-14-563aadfd480d>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, dataset, filepath, learning_rate, log_dir)\u001b[0m\n\u001b[1;32m     60\u001b[0m                 \u001b[0mearly_stopping\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m                 \u001b[0mreduce_lr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m                 \u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m                 \u001b[0;31m#tensorboard\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             ]\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1361\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1362\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1363\u001b[0;31m           validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1365\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    262\u001b[0m           \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m           \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2912\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_arrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_symbols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2914\u001b[0;31m     \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2915\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2916\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8f38877a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_model(\n",
    "    model, \n",
    "    dataset, \n",
    "    model_path + \"model.h5\",\n",
    "    learning_rate=1e-3,\n",
    "    #log_dir=None#\"./logs/H/\" + name + \"_\" + \"x\".join(list(map(str, structure))) + \"_\" + str(i)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
