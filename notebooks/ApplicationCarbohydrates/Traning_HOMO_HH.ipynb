{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jo/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import seaborn as sns\n",
    "\n",
    "from os.path import join\n",
    "\n",
    "plt.style.use([\"seaborn\", \"thesis\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc(\"figure\", figsize=(8,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"../../thesis/models/DescriptorHomo/HH/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Molecules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SCFInitialGuess.utilities.dataset import ScreenedData\n",
    "\n",
    "target = \"P\"\n",
    "basis = \"6-311++g**\"\n",
    "\n",
    "data = ScreenedData(r_max=10)\n",
    "\n",
    "data.include(data_path = \"../../thesis/dataset/MethanT/\", postfix = \"MethanT\", target=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SCFInitialGuess.utilities.dataset import ScreenedData\n",
    "\n",
    "target = \"P\"\n",
    "\n",
    "data = ScreenedData(r_max=10)\n",
    "\n",
    "data.include(data_path = \"../../thesis/dataset/MethanT/\", postfix = \"MethanT\", target=target)\n",
    "data.include(data_path = \"../../thesis/dataset/MethanT2/\", postfix = \"MethanT2\", target=target)\n",
    "data.include(data_path = \"../../thesis/dataset/MethanT3/\", postfix = \"MethanT3\", target=target)\n",
    "data.include(data_path = \"../../thesis/dataset/MethanT4/\", postfix = \"MethanT4\", target=target)\n",
    "\n",
    "data.include(data_path = \"../../thesis/dataset/EthanT/\",  postfix = \"EthanT\", target=target)\n",
    "data.include(data_path = \"../../thesis/dataset/EthanT2/\", postfix = \"EthanT2\", target=target)\n",
    "data.include(data_path = \"../../thesis/dataset/EthanT3/\", postfix = \"EthanT3\", target=target)\n",
    "data.include(data_path = \"../../thesis/dataset/EthanT4/\",  postfix = \"EthanT4\", target=target)\n",
    "data.include(data_path = \"../../thesis/dataset/EthanT5/\",  postfix = \"EthanT5\", target=target)\n",
    "data.include(data_path = \"../../thesis/dataset/EthanT6/\",  postfix = \"EthanT6\", target=target)\n",
    "\n",
    "data.include(data_path = \"../../thesis/dataset/EthenT/\",  postfix = \"EthenT\", target=target)\n",
    "data.include(data_path = \"../../thesis/dataset/EthenT2/\", postfix = \"EthenT2\", target=target)\n",
    "data.include(data_path = \"../../thesis/dataset/EthenT3/\", postfix = \"EthenT3\", target=target)\n",
    "data.include(data_path = \"../../thesis/dataset/EthenT4/\",  postfix = \"EthenT4\", target=target)\n",
    "data.include(data_path = \"../../thesis/dataset/EthenT5/\",  postfix = \"EthenT5\", target=target)\n",
    "data.include(data_path = \"../../thesis/dataset/EthenT6/\",  postfix = \"EthenT6\", target=target)\n",
    "\n",
    "\n",
    "data.include(data_path = \"../../thesis/dataset/EthinT/\",  postfix = \"EthinT\", target=target)\n",
    "data.include(data_path = \"../../thesis/dataset/EthinT2/\", postfix = \"EthinT2\", target=target)\n",
    "data.include(data_path = \"../../thesis/dataset/EthinT3/\", postfix = \"EthinT3\", target=target)\n",
    "\n",
    "#data.include(data_path = \"../../dataset/QM9/\", postfix = \"QM9-300\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descriptor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 32, 57)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from SCFInitialGuess.descriptors.high_level import AtomicNumberWeighted\n",
    "from SCFInitialGuess.descriptors.cutoffs import BehlerCutoff1\n",
    "from SCFInitialGuess.descriptors.models import RADIAL_GAUSSIAN_MODELS, make_uniform\n",
    "from SCFInitialGuess.descriptors.coordinate_descriptors import \\\n",
    "    Gaussians, SPHAngularDescriptor\n",
    "import pickle\n",
    "\n",
    "model = make_uniform(25, 5, eta_max=60, eta_min=20)\n",
    "\n",
    "descriptor = AtomicNumberWeighted(\n",
    "    Gaussians(*model),\n",
    "    SPHAngularDescriptor(3),\n",
    "    BehlerCutoff1(5)\n",
    ")\n",
    "\n",
    "pickle.dump(descriptor, open(model_path + \"descriptor.dump\", \"wb\"))\n",
    "    \n",
    "descriptor.radial_descriptor.number_of_descriptors, descriptor.angular_descriptor.number_of_descriptors, descriptor.number_of_descriptors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Package Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SCFInitialGuess.utilities.dataset import make_block_dataset, extract_HOMO_block_dataset_pairs\n",
    "\n",
    "dataset = make_block_dataset(\n",
    "    descriptor,\n",
    "    data.molecules,\n",
    "    data.T,\n",
    "    \"H\",\n",
    "    extract_HOMO_block_dataset_pairs\n",
    ")\n",
    "\n",
    "np.save(model_path + \"normalisation.npy\", (dataset.x_mean, dataset.x_std))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47442, 11918, 14945)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.training[0]), len(dataset.validation[0]), len(dataset.testing[0]), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SCFInitialGuess.utilities.constants import number_of_basis_functions as N_BASIS\n",
    "\n",
    "species = \"H\"\n",
    "dim = N_BASIS[basis][species]\n",
    "dim_triu = dim * (dim + 1) // 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN Utils "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keras.backend.clear_session()\n",
    "\n",
    "#activation = \"elu\"\n",
    "#learning_rate = 1e-5\n",
    "\n",
    "intializer = keras.initializers.TruncatedNormal(mean=0.0, stddev=0.01)\n",
    "\n",
    "def make_model(\n",
    "        structure, \n",
    "        input_dim, \n",
    "        output_dim,\n",
    "        activation=\"elu\", \n",
    "        learning_rate=1e-3\n",
    "    ):\n",
    "\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    # input layer\n",
    "    model.add(keras.layers.Dense(\n",
    "        structure[0], \n",
    "        activation=activation, \n",
    "        input_dim=input_dim, \n",
    "        kernel_initializer=intializer\n",
    "    ))\n",
    "\n",
    "    for layer in structure[1:]:\n",
    "        model.add(keras.layers.Dense(\n",
    "            layer, \n",
    "            activation=activation, \n",
    "            kernel_initializer=intializer, \n",
    "            #bias_initializer='zeros',\n",
    "            kernel_regularizer=keras.regularizers.l2(5e-3)\n",
    "        ))\n",
    "\n",
    "    #output\n",
    "    model.add(keras.layers.Dense(output_dim))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate), \n",
    "        loss='MSE', \n",
    "        metrics=['mse']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_mean_squared_error\", \n",
    "    min_delta=1e-8, \n",
    "    patience=20, \n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_mean_squared_error', \n",
    "    factor=0.1, \n",
    "    patience=3, \n",
    "    verbose=1, \n",
    "    mode='auto', \n",
    "    min_delta=1e-6, \n",
    "    cooldown=2, \n",
    "    min_lr=1e-10\n",
    ")\n",
    "\n",
    "\n",
    "epochs = 1000\n",
    "\n",
    "\n",
    "def train_model(model, dataset, filepath=None, learning_rate=1e-4, log_dir=None):\n",
    "\n",
    "    if not log_dir is None:\n",
    "        tensorboard = keras.callbacks.TensorBoard(\n",
    "            log_dir=log_dir, \n",
    "            histogram_freq=0, \n",
    "            batch_size=32, \n",
    "            #update_freq='epoch'\n",
    "        )\n",
    "    \n",
    "    if not filepath is None:\n",
    "        checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "            filepath, \n",
    "            monitor='val_mean_squared_error', \n",
    "            verbose=1, \n",
    "            save_best_only=True, \n",
    "            save_weights_only=False, \n",
    "            mode='auto', \n",
    "            period=1\n",
    "        )\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    \n",
    "    train, validation = [], []\n",
    "    while True:\n",
    "        keras.backend.set_value(model.optimizer.lr, learning_rate)\n",
    "            \n",
    "        history = model.fit(\n",
    "            x = dataset.training[0],\n",
    "            y = dataset.training[1],\n",
    "            epochs=epochs,\n",
    "            shuffle=True,\n",
    "            validation_data=dataset.validation, \n",
    "            verbose=1, \n",
    "            callbacks=[\n",
    "                early_stopping, \n",
    "                reduce_lr,\n",
    "                checkpoint,\n",
    "                #tensorboard\n",
    "            ]\n",
    "        )\n",
    "            \n",
    "        \n",
    "        #error.append(model.evaluate(\n",
    "        #    dataset.testing[0], \n",
    "        #    dataset.testing[1], \n",
    "        #    verbose=1\n",
    "        #)[1])\n",
    "    \n",
    "    return error\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((47442, 114), (47442, 49))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.training[0].shape, dataset.training[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57, 49)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descriptor.number_of_descriptors, dim**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "structure = [100, 70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 100)               11500     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 70)                7070      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 49)                3479      \n",
      "=================================================================\n",
      "Total params: 22,049\n",
      "Trainable params: 22,049\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = make_model(\n",
    "    structure=structure,\n",
    "    input_dim=descriptor.number_of_descriptors * 2,\n",
    "    output_dim=dim**2,\n",
    "    \n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 47442 samples, validate on 11918 samples\n",
      "Epoch 1/1000\n",
      "47442/47442 [==============================] - 5s 103us/step - loss: 1.0268e-04 - mean_squared_error: 8.4960e-05 - val_loss: 9.7681e-05 - val_mean_squared_error: 8.8935e-05\n",
      "\n",
      "Epoch 00001: val_mean_squared_error improved from inf to 0.00009, saving model to ../../thesis/models/DescriptorHomo/HH/model.h5\n",
      "Epoch 2/1000\n",
      "47442/47442 [==============================] - 4s 86us/step - loss: 8.8698e-05 - mean_squared_error: 8.1220e-05 - val_loss: 9.2096e-05 - val_mean_squared_error: 8.4988e-05\n",
      "\n",
      "Epoch 00002: val_mean_squared_error improved from 0.00009 to 0.00008, saving model to ../../thesis/models/DescriptorHomo/HH/model.h5\n",
      "Epoch 3/1000\n",
      "47442/47442 [==============================] - 4s 87us/step - loss: 8.0020e-05 - mean_squared_error: 7.2119e-05 - val_loss: 8.8748e-05 - val_mean_squared_error: 8.0103e-05\n",
      "\n",
      "Epoch 00003: val_mean_squared_error improved from 0.00008 to 0.00008, saving model to ../../thesis/models/DescriptorHomo/HH/model.h5\n",
      "Epoch 4/1000\n",
      "47442/47442 [==============================] - 4s 88us/step - loss: 7.0263e-05 - mean_squared_error: 6.3072e-05 - val_loss: 8.2252e-05 - val_mean_squared_error: 7.5635e-05\n",
      "\n",
      "Epoch 00004: val_mean_squared_error improved from 0.00008 to 0.00008, saving model to ../../thesis/models/DescriptorHomo/HH/model.h5\n",
      "Epoch 5/1000\n",
      "47442/47442 [==============================] - 4s 88us/step - loss: 6.5723e-05 - mean_squared_error: 5.9270e-05 - val_loss: 8.3859e-05 - val_mean_squared_error: 7.8203e-05\n",
      "\n",
      "Epoch 00005: val_mean_squared_error did not improve from 0.00008\n",
      "Epoch 6/1000\n",
      "47442/47442 [==============================] - 4s 89us/step - loss: 6.2675e-05 - mean_squared_error: 5.6972e-05 - val_loss: 7.4934e-05 - val_mean_squared_error: 7.0029e-05\n",
      "\n",
      "Epoch 00006: val_mean_squared_error improved from 0.00008 to 0.00007, saving model to ../../thesis/models/DescriptorHomo/HH/model.h5\n",
      "Epoch 7/1000\n",
      "47442/47442 [==============================] - 4s 90us/step - loss: 6.0334e-05 - mean_squared_error: 5.4415e-05 - val_loss: 7.6247e-05 - val_mean_squared_error: 7.0101e-05\n",
      "\n",
      "Epoch 00007: val_mean_squared_error did not improve from 0.00007\n",
      "Epoch 8/1000\n",
      "47442/47442 [==============================] - 4s 87us/step - loss: 5.7686e-05 - mean_squared_error: 5.1694e-05 - val_loss: 7.7043e-05 - val_mean_squared_error: 7.0718e-05\n",
      "\n",
      "Epoch 00008: val_mean_squared_error did not improve from 0.00007\n",
      "Epoch 9/1000\n",
      "47442/47442 [==============================] - 4s 92us/step - loss: 5.6775e-05 - mean_squared_error: 5.0655e-05 - val_loss: 7.6498e-05 - val_mean_squared_error: 7.0358e-05\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 00009: val_mean_squared_error did not improve from 0.00007\n",
      "Epoch 10/1000\n",
      "47442/47442 [==============================] - 4s 91us/step - loss: 4.9267e-05 - mean_squared_error: 4.5747e-05 - val_loss: 6.7971e-05 - val_mean_squared_error: 6.4549e-05\n",
      "\n",
      "Epoch 00010: val_mean_squared_error improved from 0.00007 to 0.00006, saving model to ../../thesis/models/DescriptorHomo/HH/model.h5\n",
      "Epoch 11/1000\n",
      "47442/47442 [==============================] - 4s 90us/step - loss: 4.8617e-05 - mean_squared_error: 4.5395e-05 - val_loss: 6.6804e-05 - val_mean_squared_error: 6.3811e-05\n",
      "\n",
      "Epoch 00011: val_mean_squared_error improved from 0.00006 to 0.00006, saving model to ../../thesis/models/DescriptorHomo/HH/model.h5\n",
      "Epoch 12/1000\n",
      "47442/47442 [==============================] - 4s 89us/step - loss: 4.8206e-05 - mean_squared_error: 4.5185e-05 - val_loss: 6.5892e-05 - val_mean_squared_error: 6.2786e-05\n",
      "\n",
      "Epoch 00012: val_mean_squared_error improved from 0.00006 to 0.00006, saving model to ../../thesis/models/DescriptorHomo/HH/model.h5\n",
      "Epoch 13/1000\n",
      "47442/47442 [==============================] - 4s 91us/step - loss: 4.7881e-05 - mean_squared_error: 4.5008e-05 - val_loss: 6.6934e-05 - val_mean_squared_error: 6.4181e-05\n",
      "\n",
      "Epoch 00013: val_mean_squared_error did not improve from 0.00006\n",
      "Epoch 14/1000\n",
      "47442/47442 [==============================] - 4s 91us/step - loss: 4.7578e-05 - mean_squared_error: 4.4836e-05 - val_loss: 6.6784e-05 - val_mean_squared_error: 6.4092e-05\n",
      "\n",
      "Epoch 00014: val_mean_squared_error did not improve from 0.00006\n",
      "Epoch 15/1000\n",
      "47442/47442 [==============================] - 5s 109us/step - loss: 4.7317e-05 - mean_squared_error: 4.4639e-05 - val_loss: 6.5529e-05 - val_mean_squared_error: 6.3125e-05\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 00015: val_mean_squared_error did not improve from 0.00006\n",
      "Epoch 16/1000\n",
      "47442/47442 [==============================] - 5s 108us/step - loss: 4.6439e-05 - mean_squared_error: 4.4065e-05 - val_loss: 6.5324e-05 - val_mean_squared_error: 6.2922e-05\n",
      "\n",
      "Epoch 00016: val_mean_squared_error did not improve from 0.00006\n",
      "Epoch 17/1000\n",
      "47442/47442 [==============================] - 5s 102us/step - loss: 4.6332e-05 - mean_squared_error: 4.3896e-05 - val_loss: 6.5362e-05 - val_mean_squared_error: 6.2948e-05\n",
      "\n",
      "Epoch 00017: val_mean_squared_error did not improve from 0.00006\n",
      "Epoch 18/1000\n",
      "34912/47442 [=====================>........] - ETA: 1s - loss: 4.5764e-05 - mean_squared_error: 4.3324e-05"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-87ba1c7f8906>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmodel_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"model.h5\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;31m#log_dir=None#\"./logs/H/\" + name + \"_\" + \"x\".join(list(map(str, structure))) + \"_\" + str(i)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m )\n",
      "\u001b[0;32m<ipython-input-11-563aadfd480d>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, dataset, filepath, learning_rate, log_dir)\u001b[0m\n\u001b[1;32m     60\u001b[0m                 \u001b[0mearly_stopping\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m                 \u001b[0mreduce_lr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m                 \u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m                 \u001b[0;31m#tensorboard\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             ]\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1361\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1362\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1363\u001b[0;31m           validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1365\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    262\u001b[0m           \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m           \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2912\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_arrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_symbols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2914\u001b[0;31m     \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2915\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2916\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f113c363208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#i+=1\n",
    "train_model(\n",
    "    model, \n",
    "    dataset, \n",
    "    model_path + \"model.h5\",\n",
    "    learning_rate=1e-3,\n",
    "    #log_dir=None#\"./logs/H/\" + name + \"_\" + \"x\".join(list(map(str, structure))) + \"_\" + str(i)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
