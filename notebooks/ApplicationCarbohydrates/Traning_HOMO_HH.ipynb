{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jo/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import seaborn as sns\n",
    "\n",
    "from os.path import join\n",
    "\n",
    "plt.style.use([\"seaborn\", \"thesis\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc(\"figure\", figsize=(8,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Molecules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SCFInitialGuess.utilities.dataset import ScreenedData\n",
    "\n",
    "target = \"P\"\n",
    "basis = \"6-311++g**\"\n",
    "\n",
    "data = ScreenedData(r_max=10)\n",
    "\n",
    "data.include(data_path = \"../../thesis/dataset/MethanT/\", postfix = \"MethanT\", target=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = Data()\n",
    "\n",
    "#data.include(data_path = \"../../dataset/MethanT/\", postfix = \"MethanT\", target=target)\n",
    "data.include(data_path = \"../../thesis/dataset/MethanT2/\", postfix = \"MethanT2\", target=target)\n",
    "data.include(data_path = \"../../thesis/dataset/MethanT3/\", postfix = \"MethanT3\", target=target)\n",
    "data.include(data_path = \"../../thesis/dataset/MethanT4/\", postfix = \"MethanT4\", target=target)\n",
    "\n",
    "data.include(data_path = \"../../thesis/dataset/EthanT/\",  postfix = \"EthanT\", target=target)\n",
    "data.include(data_path = \"../../thesis/dataset/EthanT2/\", postfix = \"EthanT2\", target=target)\n",
    "data.include(data_path = \"../../thesis/dataset/EthanT3/\", postfix = \"EthanT3\", target=target)\n",
    "\n",
    "data.include(data_path = \"../../thesis/dataset/EthenT/\",  postfix = \"EthenT\", target=target)\n",
    "data.include(data_path = \"../../thesis/dataset/EthenT2/\", postfix = \"EthenT2\", target=target)\n",
    "data.include(data_path = \"../../thesis/dataset/EthenT3/\", postfix = \"EthenT3\", target=target)\n",
    "\n",
    "data.include(data_path = \"../../thesis/dataset/EthinT/\",  postfix = \"EthinT\", target=target)\n",
    "data.include(data_path = \"../../thesis/dataset/EthinT2/\", postfix = \"EthinT2\", target=target)\n",
    "data.include(data_path = \"../../thesis/dataset/EthinT3/\", postfix = \"EthinT3\", target=target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descriptor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 50, 75)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from SCFInitialGuess.descriptors.high_level import AtomicNumberWeighted\n",
    "from SCFInitialGuess.descriptors.cutoffs import BehlerCutoff1\n",
    "from SCFInitialGuess.descriptors.models import RADIAL_GAUSSIAN_MODELS, make_uniform\n",
    "from SCFInitialGuess.descriptors.coordinate_descriptors import \\\n",
    "    Gaussians, SPHAngularDescriptor\n",
    "import pickle\n",
    "\n",
    "model = make_uniform(25, 5, eta_max=60, eta_min=20)\n",
    "\n",
    "descriptor = AtomicNumberWeighted(\n",
    "    Gaussians(*model),\n",
    "    SPHAngularDescriptor(4),\n",
    "    BehlerCutoff1(5)\n",
    ")\n",
    "\n",
    "#pickle.dump(descriptor, open(model_path + \"descriptor.dump\", \"wb\"))\n",
    "    \n",
    "descriptor.radial_descriptor.number_of_descriptors, descriptor.angular_descriptor.number_of_descriptors, descriptor.number_of_descriptors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Package Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SCFInitialGuess.utilities.dataset import make_block_dataset, extract_HOMO_block_dataset_pairs\n",
    "\n",
    "dataset = make_block_dataset(\n",
    "    descriptor,\n",
    "    data.molecules,\n",
    "    data.T,\n",
    "    \"H\",\n",
    "    extract_HOMO_block_dataset_pairs\n",
    ")\n",
    "\n",
    "#np.save(model_path + \"normalisation.npy\", (dataset.x_mean, dataset.x_std))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3840, 960, 1206)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.training[0]), len(dataset.validation[0]), len(dataset.testing[0]), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SCFInitialGuess.utilities.constants import number_of_basis_functions as N_BASIS\n",
    "\n",
    "species = \"H\"\n",
    "dim = N_BASIS[basis][species]\n",
    "dim_triu = dim * (dim + 1) // 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN Utils "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keras.backend.clear_session()\n",
    "\n",
    "#activation = \"elu\"\n",
    "#learning_rate = 1e-5\n",
    "\n",
    "intializer = keras.initializers.TruncatedNormal(mean=0.0, stddev=0.01)\n",
    "\n",
    "def make_model(\n",
    "        structure, \n",
    "        input_dim, \n",
    "        output_dim,\n",
    "        activation=\"elu\", \n",
    "        learning_rate=1e-3\n",
    "    ):\n",
    "\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    # input layer\n",
    "    model.add(keras.layers.Dense(\n",
    "        structure[0], \n",
    "        activation=activation, \n",
    "        input_dim=input_dim, \n",
    "        kernel_initializer=intializer\n",
    "    ))\n",
    "\n",
    "    for layer in structure[1:]:\n",
    "        model.add(keras.layers.Dense(\n",
    "            layer, \n",
    "            activation=activation, \n",
    "            kernel_initializer=intializer, \n",
    "            #bias_initializer='zeros',\n",
    "            kernel_regularizer=keras.regularizers.l2(5e-3)\n",
    "        ))\n",
    "\n",
    "    #output\n",
    "    model.add(keras.layers.Dense(output_dim))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate), \n",
    "        loss='MSE', \n",
    "        metrics=['mse']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_mean_squared_error\", \n",
    "    min_delta=1e-8, \n",
    "    patience=20, \n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_mean_squared_error', \n",
    "    factor=0.1, \n",
    "    patience=3, \n",
    "    verbose=1, \n",
    "    mode='auto', \n",
    "    min_delta=1e-6, \n",
    "    cooldown=2, \n",
    "    min_lr=1e-10\n",
    ")\n",
    "\n",
    "\n",
    "epochs = 1000\n",
    "\n",
    "\n",
    "def train_model(model, dataset, filepath=None, learning_rate=1e-4, log_dir=None):\n",
    "\n",
    "    if not log_dir is None:\n",
    "        tensorboard = keras.callbacks.TensorBoard(\n",
    "            log_dir=log_dir, \n",
    "            histogram_freq=0, \n",
    "            batch_size=32, \n",
    "            #update_freq='epoch'\n",
    "        )\n",
    "    \n",
    "    if not filepath is None:\n",
    "        checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "            filepath, \n",
    "            monitor='val_mean_squared_error', \n",
    "            verbose=1, \n",
    "            save_best_only=True, \n",
    "            save_weights_only=False, \n",
    "            mode='auto', \n",
    "            period=1\n",
    "        )\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    \n",
    "    train, validation = [], []\n",
    "    while True:\n",
    "        keras.backend.set_value(model.optimizer.lr, learning_rate)\n",
    "            \n",
    "        history = model.fit(\n",
    "            x = dataset.training[0],\n",
    "            y = dataset.training[1],\n",
    "            epochs=epochs,\n",
    "            shuffle=True,\n",
    "            validation_data=dataset.validation, \n",
    "            verbose=1, \n",
    "            callbacks=[\n",
    "                early_stopping, \n",
    "                reduce_lr,\n",
    "                #checkpoint,\n",
    "                #tensorboard\n",
    "            ]\n",
    "        )\n",
    "            \n",
    "        \n",
    "        #error.append(model.evaluate(\n",
    "        #    dataset.testing[0], \n",
    "        #    dataset.testing[1], \n",
    "        #    verbose=1\n",
    "        #)[1])\n",
    "    \n",
    "    return error\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3840, 150), (3840, 49))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.training[0].shape, dataset.training[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75, 49)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descriptor.number_of_descriptors, dim**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "structure = [100, 70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 100)               15100     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 70)                7070      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 49)                3479      \n",
      "=================================================================\n",
      "Total params: 25,649\n",
      "Trainable params: 25,649\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = make_model(\n",
    "    structure=structure,\n",
    "    input_dim=descriptor.number_of_descriptors * 2,\n",
    "    output_dim=dim**2,\n",
    "    \n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path=\"models/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 34452 samples, validate on 8636 samples\n",
      "Epoch 1/1000\n",
      "34452/34452 [==============================] - 3s 82us/step - loss: 9.8828e-05 - mean_squared_error: 7.5530e-05 - val_loss: 8.4463e-05 - val_mean_squared_error: 7.5253e-05\n",
      "Epoch 2/1000\n",
      "34452/34452 [==============================] - 2s 72us/step - loss: 7.7401e-05 - mean_squared_error: 7.0636e-05 - val_loss: 8.1669e-05 - val_mean_squared_error: 7.1496e-05\n",
      "Epoch 3/1000\n",
      "34452/34452 [==============================] - 3s 74us/step - loss: 6.8792e-05 - mean_squared_error: 6.1838e-05 - val_loss: 7.4394e-05 - val_mean_squared_error: 6.7062e-05\n",
      "Epoch 4/1000\n",
      "34452/34452 [==============================] - 2s 72us/step - loss: 5.9804e-05 - mean_squared_error: 5.3238e-05 - val_loss: 7.4991e-05 - val_mean_squared_error: 6.7165e-05\n",
      "Epoch 5/1000\n",
      "34452/34452 [==============================] - 3s 73us/step - loss: 5.4024e-05 - mean_squared_error: 4.7568e-05 - val_loss: 7.0260e-05 - val_mean_squared_error: 6.2846e-05\n",
      "Epoch 6/1000\n",
      "34452/34452 [==============================] - 3s 74us/step - loss: 5.0858e-05 - mean_squared_error: 4.4395e-05 - val_loss: 7.1433e-05 - val_mean_squared_error: 6.3691e-05\n",
      "Epoch 7/1000\n",
      "34452/34452 [==============================] - 3s 76us/step - loss: 4.8821e-05 - mean_squared_error: 4.2435e-05 - val_loss: 7.0718e-05 - val_mean_squared_error: 6.4949e-05\n",
      "Epoch 8/1000\n",
      "34452/34452 [==============================] - 3s 74us/step - loss: 4.6809e-05 - mean_squared_error: 4.0888e-05 - val_loss: 6.7601e-05 - val_mean_squared_error: 6.0312e-05\n",
      "Epoch 9/1000\n",
      "34452/34452 [==============================] - 3s 75us/step - loss: 4.5818e-05 - mean_squared_error: 3.9849e-05 - val_loss: 6.7854e-05 - val_mean_squared_error: 6.1742e-05\n",
      "Epoch 10/1000\n",
      "34452/34452 [==============================] - 3s 75us/step - loss: 4.5965e-05 - mean_squared_error: 3.9645e-05 - val_loss: 6.3329e-05 - val_mean_squared_error: 5.7173e-05\n",
      "Epoch 11/1000\n",
      "34452/34452 [==============================] - 3s 75us/step - loss: 4.3687e-05 - mean_squared_error: 3.8059e-05 - val_loss: 6.5839e-05 - val_mean_squared_error: 6.0854e-05\n",
      "Epoch 12/1000\n",
      "34452/34452 [==============================] - 3s 74us/step - loss: 4.3510e-05 - mean_squared_error: 3.7912e-05 - val_loss: 6.7130e-05 - val_mean_squared_error: 6.0822e-05\n",
      "Epoch 13/1000\n",
      "34452/34452 [==============================] - 3s 75us/step - loss: 4.3880e-05 - mean_squared_error: 3.8049e-05 - val_loss: 6.7292e-05 - val_mean_squared_error: 6.1600e-05\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 14/1000\n",
      "34452/34452 [==============================] - 3s 75us/step - loss: 3.7146e-05 - mean_squared_error: 3.3765e-05 - val_loss: 5.8818e-05 - val_mean_squared_error: 5.5403e-05\n",
      "Epoch 15/1000\n",
      "34452/34452 [==============================] - 3s 75us/step - loss: 3.6648e-05 - mean_squared_error: 3.3462e-05 - val_loss: 5.9338e-05 - val_mean_squared_error: 5.6215e-05\n",
      "Epoch 16/1000\n",
      "34452/34452 [==============================] - 3s 75us/step - loss: 3.6396e-05 - mean_squared_error: 3.3334e-05 - val_loss: 5.8351e-05 - val_mean_squared_error: 5.5476e-05\n",
      "Epoch 17/1000\n",
      "34452/34452 [==============================] - 3s 75us/step - loss: 3.6151e-05 - mean_squared_error: 3.3231e-05 - val_loss: 5.8825e-05 - val_mean_squared_error: 5.5938e-05\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 18/1000\n",
      "34452/34452 [==============================] - 3s 77us/step - loss: 3.5347e-05 - mean_squared_error: 3.2630e-05 - val_loss: 5.8414e-05 - val_mean_squared_error: 5.5718e-05\n",
      "Epoch 19/1000\n",
      "34452/34452 [==============================] - 3s 76us/step - loss: 3.5266e-05 - mean_squared_error: 3.2583e-05 - val_loss: 5.8326e-05 - val_mean_squared_error: 5.5605e-05\n",
      "Epoch 20/1000\n",
      "34452/34452 [==============================] - 3s 76us/step - loss: 3.5231e-05 - mean_squared_error: 3.2536e-05 - val_loss: 5.8096e-05 - val_mean_squared_error: 5.5434e-05\n",
      "Epoch 21/1000\n",
      "34452/34452 [==============================] - 3s 76us/step - loss: 3.5202e-05 - mean_squared_error: 3.2545e-05 - val_loss: 5.8213e-05 - val_mean_squared_error: 5.5560e-05\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 22/1000\n",
      "34452/34452 [==============================] - 3s 86us/step - loss: 3.5101e-05 - mean_squared_error: 3.2455e-05 - val_loss: 5.8228e-05 - val_mean_squared_error: 5.5586e-05\n",
      "Epoch 23/1000\n",
      "34452/34452 [==============================] - 4s 128us/step - loss: 3.5088e-05 - mean_squared_error: 3.2444e-05 - val_loss: 5.8207e-05 - val_mean_squared_error: 5.5565e-05\n",
      "Epoch 24/1000\n",
      "34452/34452 [==============================] - 4s 118us/step - loss: 3.5082e-05 - mean_squared_error: 3.2440e-05 - val_loss: 5.8201e-05 - val_mean_squared_error: 5.5561e-05\n",
      "Epoch 25/1000\n",
      "34452/34452 [==============================] - 3s 94us/step - loss: 3.5077e-05 - mean_squared_error: 3.2434e-05 - val_loss: 5.8205e-05 - val_mean_squared_error: 5.5567e-05\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 26/1000\n",
      "34452/34452 [==============================] - 3s 87us/step - loss: 3.5064e-05 - mean_squared_error: 3.2425e-05 - val_loss: 5.8204e-05 - val_mean_squared_error: 5.5565e-05\n",
      "Epoch 27/1000\n",
      "34452/34452 [==============================] - 4s 102us/step - loss: 3.5063e-05 - mean_squared_error: 3.2425e-05 - val_loss: 5.8204e-05 - val_mean_squared_error: 5.5565e-05\n",
      "Epoch 28/1000\n",
      "34452/34452 [==============================] - 3s 89us/step - loss: 3.5063e-05 - mean_squared_error: 3.2425e-05 - val_loss: 5.8202e-05 - val_mean_squared_error: 5.5564e-05\n",
      "Epoch 29/1000\n",
      "34452/34452 [==============================] - 3s 95us/step - loss: 3.5062e-05 - mean_squared_error: 3.2424e-05 - val_loss: 5.8201e-05 - val_mean_squared_error: 5.5563e-05\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "Epoch 30/1000\n",
      "34452/34452 [==============================] - 3s 97us/step - loss: 3.5061e-05 - mean_squared_error: 3.2422e-05 - val_loss: 5.8201e-05 - val_mean_squared_error: 5.5563e-05\n",
      "Epoch 31/1000\n",
      "34452/34452 [==============================] - 3s 89us/step - loss: 3.5061e-05 - mean_squared_error: 3.2422e-05 - val_loss: 5.8201e-05 - val_mean_squared_error: 5.5563e-05\n",
      "Epoch 32/1000\n",
      "34452/34452 [==============================] - 4s 109us/step - loss: 3.5061e-05 - mean_squared_error: 3.2422e-05 - val_loss: 5.8201e-05 - val_mean_squared_error: 5.5563e-05\n",
      "Epoch 33/1000\n",
      "34452/34452 [==============================] - 5s 135us/step - loss: 3.5061e-05 - mean_squared_error: 3.2422e-05 - val_loss: 5.8201e-05 - val_mean_squared_error: 5.5563e-05\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "Epoch 34/1000\n",
      "34452/34452 [==============================] - 4s 107us/step - loss: 3.5060e-05 - mean_squared_error: 3.2422e-05 - val_loss: 5.8201e-05 - val_mean_squared_error: 5.5563e-05\n",
      "Epoch 00034: early stopping\n",
      "Train on 34452 samples, validate on 8636 samples\n",
      "Epoch 1/1000\n",
      "34452/34452 [==============================] - 3s 95us/step - loss: 4.6876e-05 - mean_squared_error: 3.9223e-05 - val_loss: 6.3075e-05 - val_mean_squared_error: 5.8572e-05\n",
      "Epoch 2/1000\n",
      "34452/34452 [==============================] - 4s 110us/step - loss: 4.2579e-05 - mean_squared_error: 3.7059e-05 - val_loss: 6.6162e-05 - val_mean_squared_error: 6.0464e-05\n",
      "Epoch 3/1000\n",
      "34452/34452 [==============================] - 3s 96us/step - loss: 4.2267e-05 - mean_squared_error: 3.6770e-05 - val_loss: 6.7766e-05 - val_mean_squared_error: 6.2391e-05\n",
      "Epoch 4/1000\n",
      "34452/34452 [==============================] - 4s 102us/step - loss: 4.2170e-05 - mean_squared_error: 3.6584e-05 - val_loss: 6.7293e-05 - val_mean_squared_error: 5.9954e-05\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 5/1000\n",
      "34452/34452 [==============================] - 5s 131us/step - loss: 3.6040e-05 - mean_squared_error: 3.2811e-05 - val_loss: 5.9387e-05 - val_mean_squared_error: 5.6261e-05\n",
      "Epoch 6/1000\n",
      "34452/34452 [==============================] - 4s 117us/step - loss: 3.5607e-05 - mean_squared_error: 3.2594e-05 - val_loss: 5.9119e-05 - val_mean_squared_error: 5.6037e-05\n",
      "Epoch 7/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34452/34452 [==============================] - 4s 106us/step - loss: 3.5433e-05 - mean_squared_error: 3.2533e-05 - val_loss: 5.8882e-05 - val_mean_squared_error: 5.6133e-05\n",
      "Epoch 8/1000\n",
      "34452/34452 [==============================] - 3s 100us/step - loss: 3.5224e-05 - mean_squared_error: 3.2429e-05 - val_loss: 5.8582e-05 - val_mean_squared_error: 5.5995e-05\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 9/1000\n",
      "34452/34452 [==============================] - 3s 90us/step - loss: 3.4459e-05 - mean_squared_error: 3.1922e-05 - val_loss: 5.8356e-05 - val_mean_squared_error: 5.5811e-05\n",
      "Epoch 10/1000\n",
      "34452/34452 [==============================] - 3s 79us/step - loss: 3.4369e-05 - mean_squared_error: 3.1809e-05 - val_loss: 5.8388e-05 - val_mean_squared_error: 5.5841e-05\n",
      "Epoch 11/1000\n",
      "34452/34452 [==============================] - 3s 92us/step - loss: 3.4350e-05 - mean_squared_error: 3.1810e-05 - val_loss: 5.8624e-05 - val_mean_squared_error: 5.6046e-05\n",
      "Epoch 12/1000\n",
      "34452/34452 [==============================] - 4s 108us/step - loss: 3.4307e-05 - mean_squared_error: 3.1746e-05 - val_loss: 5.8609e-05 - val_mean_squared_error: 5.6064e-05\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 13/1000\n",
      "34452/34452 [==============================] - 3s 99us/step - loss: 3.4238e-05 - mean_squared_error: 3.1707e-05 - val_loss: 5.8384e-05 - val_mean_squared_error: 5.5850e-05\n",
      "Epoch 14/1000\n",
      "34452/34452 [==============================] - 4s 104us/step - loss: 3.4216e-05 - mean_squared_error: 3.1682e-05 - val_loss: 5.8375e-05 - val_mean_squared_error: 5.5847e-05\n",
      "Epoch 15/1000\n",
      "34452/34452 [==============================] - 4s 106us/step - loss: 3.4209e-05 - mean_squared_error: 3.1682e-05 - val_loss: 5.8386e-05 - val_mean_squared_error: 5.5856e-05\n",
      "Epoch 16/1000\n",
      "34452/34452 [==============================] - 3s 97us/step - loss: 3.4206e-05 - mean_squared_error: 3.1675e-05 - val_loss: 5.8390e-05 - val_mean_squared_error: 5.5863e-05\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 17/1000\n",
      "34452/34452 [==============================] - 4s 111us/step - loss: 3.4192e-05 - mean_squared_error: 3.1666e-05 - val_loss: 5.8390e-05 - val_mean_squared_error: 5.5864e-05\n",
      "Epoch 18/1000\n",
      "34452/34452 [==============================] - 3s 93us/step - loss: 3.4192e-05 - mean_squared_error: 3.1666e-05 - val_loss: 5.8390e-05 - val_mean_squared_error: 5.5864e-05\n",
      "Epoch 19/1000\n",
      "34452/34452 [==============================] - 4s 115us/step - loss: 3.4191e-05 - mean_squared_error: 3.1665e-05 - val_loss: 5.8391e-05 - val_mean_squared_error: 5.5865e-05\n",
      "Epoch 20/1000\n",
      "34452/34452 [==============================] - 3s 96us/step - loss: 3.4191e-05 - mean_squared_error: 3.1665e-05 - val_loss: 5.8390e-05 - val_mean_squared_error: 5.5864e-05\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "Epoch 21/1000\n",
      "34452/34452 [==============================] - 3s 86us/step - loss: 3.4189e-05 - mean_squared_error: 3.1664e-05 - val_loss: 5.8390e-05 - val_mean_squared_error: 5.5864e-05\n",
      "Epoch 22/1000\n",
      "34452/34452 [==============================] - 3s 83us/step - loss: 3.4189e-05 - mean_squared_error: 3.1664e-05 - val_loss: 5.8390e-05 - val_mean_squared_error: 5.5864e-05\n",
      "Epoch 23/1000\n",
      "34452/34452 [==============================] - 3s 93us/step - loss: 3.4189e-05 - mean_squared_error: 3.1664e-05 - val_loss: 5.8390e-05 - val_mean_squared_error: 5.5864e-05\n",
      "Epoch 24/1000\n",
      "34452/34452 [==============================] - 4s 116us/step - loss: 3.4189e-05 - mean_squared_error: 3.1664e-05 - val_loss: 5.8390e-05 - val_mean_squared_error: 5.5864e-05\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "Epoch 25/1000\n",
      "34452/34452 [==============================] - 3s 95us/step - loss: 3.4189e-05 - mean_squared_error: 3.1663e-05 - val_loss: 5.8390e-05 - val_mean_squared_error: 5.5864e-05\n",
      "Epoch 26/1000\n",
      "34452/34452 [==============================] - 4s 111us/step - loss: 3.4189e-05 - mean_squared_error: 3.1663e-05 - val_loss: 5.8390e-05 - val_mean_squared_error: 5.5864e-05\n",
      "Epoch 27/1000\n",
      "34452/34452 [==============================] - 3s 100us/step - loss: 3.4189e-05 - mean_squared_error: 3.1663e-05 - val_loss: 5.8390e-05 - val_mean_squared_error: 5.5864e-05\n",
      "Epoch 28/1000\n",
      "34452/34452 [==============================] - 4s 109us/step - loss: 3.4189e-05 - mean_squared_error: 3.1663e-05 - val_loss: 5.8390e-05 - val_mean_squared_error: 5.5864e-05\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "Epoch 29/1000\n",
      "34452/34452 [==============================] - 4s 108us/step - loss: 3.4189e-05 - mean_squared_error: 3.1663e-05 - val_loss: 5.8390e-05 - val_mean_squared_error: 5.5864e-05\n",
      "Epoch 00029: early stopping\n",
      "Train on 34452 samples, validate on 8636 samples\n",
      "Epoch 1/1000\n",
      "34452/34452 [==============================] - 4s 103us/step - loss: 4.4589e-05 - mean_squared_error: 3.7608e-05 - val_loss: 7.0085e-05 - val_mean_squared_error: 6.1886e-05\n",
      "Epoch 2/1000\n",
      "34452/34452 [==============================] - 4s 109us/step - loss: 4.2096e-05 - mean_squared_error: 3.6224e-05 - val_loss: 6.2646e-05 - val_mean_squared_error: 5.7764e-05\n",
      "Epoch 3/1000\n",
      "34452/34452 [==============================] - 4s 102us/step - loss: 4.1330e-05 - mean_squared_error: 3.5957e-05 - val_loss: 6.4796e-05 - val_mean_squared_error: 5.9562e-05\n",
      "Epoch 4/1000\n",
      "34452/34452 [==============================] - 4s 113us/step - loss: 4.1348e-05 - mean_squared_error: 3.5925e-05 - val_loss: 6.3648e-05 - val_mean_squared_error: 5.8373e-05\n",
      "Epoch 5/1000\n",
      "34452/34452 [==============================] - 3s 99us/step - loss: 4.1263e-05 - mean_squared_error: 3.5788e-05 - val_loss: 6.6114e-05 - val_mean_squared_error: 5.9706e-05\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 6/1000\n",
      "34452/34452 [==============================] - 4s 119us/step - loss: 3.5300e-05 - mean_squared_error: 3.2149e-05 - val_loss: 5.8476e-05 - val_mean_squared_error: 5.5749e-05\n",
      "Epoch 7/1000\n",
      "34452/34452 [==============================] - 3s 97us/step - loss: 3.4885e-05 - mean_squared_error: 3.1963e-05 - val_loss: 5.8725e-05 - val_mean_squared_error: 5.5900e-05\n",
      "Epoch 8/1000\n",
      "34452/34452 [==============================] - 4s 118us/step - loss: 3.4694e-05 - mean_squared_error: 3.1879e-05 - val_loss: 6.0056e-05 - val_mean_squared_error: 5.7164e-05\n",
      "Epoch 9/1000\n",
      "34452/34452 [==============================] - 3s 97us/step - loss: 3.4548e-05 - mean_squared_error: 3.1826e-05 - val_loss: 5.9275e-05 - val_mean_squared_error: 5.6343e-05\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 10/1000\n",
      "34452/34452 [==============================] - 4s 113us/step - loss: 3.3854e-05 - mean_squared_error: 3.1283e-05 - val_loss: 5.8542e-05 - val_mean_squared_error: 5.6047e-05\n",
      "Epoch 11/1000\n",
      "34452/34452 [==============================] - 4s 103us/step - loss: 3.3754e-05 - mean_squared_error: 3.1257e-05 - val_loss: 5.8639e-05 - val_mean_squared_error: 5.6148e-05\n",
      "Epoch 12/1000\n",
      "34452/34452 [==============================] - 4s 111us/step - loss: 3.3736e-05 - mean_squared_error: 3.1252e-05 - val_loss: 5.8649e-05 - val_mean_squared_error: 5.6173e-05\n",
      "Epoch 13/1000\n",
      "34452/34452 [==============================] - 4s 107us/step - loss: 3.3703e-05 - mean_squared_error: 3.1216e-05 - val_loss: 5.8562e-05 - val_mean_squared_error: 5.6101e-05\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 14/1000\n",
      "34452/34452 [==============================] - 4s 107us/step - loss: 3.3620e-05 - mean_squared_error: 3.1168e-05 - val_loss: 5.8567e-05 - val_mean_squared_error: 5.6118e-05\n",
      "Epoch 15/1000\n",
      "34452/34452 [==============================] - 4s 116us/step - loss: 3.3607e-05 - mean_squared_error: 3.1156e-05 - val_loss: 5.8558e-05 - val_mean_squared_error: 5.6107e-05\n",
      "Epoch 16/1000\n",
      "34452/34452 [==============================] - 4s 105us/step - loss: 3.3602e-05 - mean_squared_error: 3.1151e-05 - val_loss: 5.8544e-05 - val_mean_squared_error: 5.6096e-05\n",
      "Epoch 17/1000\n",
      "34452/34452 [==============================] - 4s 113us/step - loss: 3.3598e-05 - mean_squared_error: 3.1151e-05 - val_loss: 5.8515e-05 - val_mean_squared_error: 5.6063e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 18/1000\n",
      "34452/34452 [==============================] - 3s 93us/step - loss: 3.3585e-05 - mean_squared_error: 3.1133e-05 - val_loss: 5.8516e-05 - val_mean_squared_error: 5.6064e-05\n",
      "Epoch 19/1000\n",
      "34452/34452 [==============================] - 4s 113us/step - loss: 3.3584e-05 - mean_squared_error: 3.1133e-05 - val_loss: 5.8518e-05 - val_mean_squared_error: 5.6067e-05\n",
      "Epoch 20/1000\n",
      "34452/34452 [==============================] - 3s 93us/step - loss: 3.3584e-05 - mean_squared_error: 3.1133e-05 - val_loss: 5.8519e-05 - val_mean_squared_error: 5.6068e-05\n",
      "Epoch 21/1000\n",
      "34452/34452 [==============================] - 4s 110us/step - loss: 3.3584e-05 - mean_squared_error: 3.1132e-05 - val_loss: 5.8521e-05 - val_mean_squared_error: 5.6070e-05\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "Epoch 22/1000\n",
      "34452/34452 [==============================] - 3s 97us/step - loss: 3.3582e-05 - mean_squared_error: 3.1131e-05 - val_loss: 5.8521e-05 - val_mean_squared_error: 5.6070e-05\n",
      "Epoch 23/1000\n",
      "34452/34452 [==============================] - 4s 104us/step - loss: 3.3582e-05 - mean_squared_error: 3.1131e-05 - val_loss: 5.8521e-05 - val_mean_squared_error: 5.6070e-05\n",
      "Epoch 24/1000\n",
      "34452/34452 [==============================] - 4s 118us/step - loss: 3.3582e-05 - mean_squared_error: 3.1131e-05 - val_loss: 5.8521e-05 - val_mean_squared_error: 5.6070e-05\n",
      "Epoch 25/1000\n",
      "34452/34452 [==============================] - 4s 117us/step - loss: 3.3582e-05 - mean_squared_error: 3.1131e-05 - val_loss: 5.8521e-05 - val_mean_squared_error: 5.6070e-05\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "Epoch 26/1000\n",
      "34452/34452 [==============================] - 4s 104us/step - loss: 3.3582e-05 - mean_squared_error: 3.1131e-05 - val_loss: 5.8521e-05 - val_mean_squared_error: 5.6070e-05\n",
      "Epoch 00026: early stopping\n",
      "Train on 34452 samples, validate on 8636 samples\n",
      "Epoch 1/1000\n",
      "34452/34452 [==============================] - 3s 100us/step - loss: 4.4070e-05 - mean_squared_error: 3.7012e-05 - val_loss: 6.7464e-05 - val_mean_squared_error: 6.2537e-05\n",
      "Epoch 2/1000\n",
      "34452/34452 [==============================] - 4s 110us/step - loss: 4.0747e-05 - mean_squared_error: 3.5475e-05 - val_loss: 6.4186e-05 - val_mean_squared_error: 5.9304e-05\n",
      "Epoch 3/1000\n",
      "34452/34452 [==============================] - 3s 95us/step - loss: 4.0858e-05 - mean_squared_error: 3.5438e-05 - val_loss: 6.3687e-05 - val_mean_squared_error: 5.8609e-05\n",
      "Epoch 4/1000\n",
      "34452/34452 [==============================] - 4s 119us/step - loss: 4.0910e-05 - mean_squared_error: 3.5398e-05 - val_loss: 6.4100e-05 - val_mean_squared_error: 5.8640e-05\n",
      "Epoch 5/1000\n",
      "34452/34452 [==============================] - 4s 114us/step - loss: 4.0649e-05 - mean_squared_error: 3.5259e-05 - val_loss: 6.6263e-05 - val_mean_squared_error: 5.9938e-05\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 6/1000\n",
      "34452/34452 [==============================] - 3s 94us/step - loss: 3.4834e-05 - mean_squared_error: 3.1767e-05 - val_loss: 6.0039e-05 - val_mean_squared_error: 5.6942e-05\n",
      "Epoch 7/1000\n",
      "34452/34452 [==============================] - 4s 117us/step - loss: 3.4468e-05 - mean_squared_error: 3.1541e-05 - val_loss: 5.9579e-05 - val_mean_squared_error: 5.6748e-05\n",
      "Epoch 8/1000\n",
      "34452/34452 [==============================] - 3s 97us/step - loss: 3.4264e-05 - mean_squared_error: 3.1454e-05 - val_loss: 5.9643e-05 - val_mean_squared_error: 5.6904e-05\n",
      "Epoch 9/1000\n",
      "34452/34452 [==============================] - 4s 113us/step - loss: 3.4139e-05 - mean_squared_error: 3.1414e-05 - val_loss: 5.9269e-05 - val_mean_squared_error: 5.6604e-05\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 10/1000\n",
      "34452/34452 [==============================] - 4s 119us/step - loss: 3.3371e-05 - mean_squared_error: 3.0848e-05 - val_loss: 5.9006e-05 - val_mean_squared_error: 5.6509e-05\n",
      "Epoch 11/1000\n",
      "34452/34452 [==============================] - 4s 119us/step - loss: 3.3316e-05 - mean_squared_error: 3.0825e-05 - val_loss: 5.8868e-05 - val_mean_squared_error: 5.6357e-05\n",
      "Epoch 12/1000\n",
      "34452/34452 [==============================] - 4s 124us/step - loss: 3.3286e-05 - mean_squared_error: 3.0785e-05 - val_loss: 5.8813e-05 - val_mean_squared_error: 5.6333e-05\n",
      "Epoch 13/1000\n",
      "34452/34452 [==============================] - 4s 116us/step - loss: 3.3256e-05 - mean_squared_error: 3.0773e-05 - val_loss: 5.8804e-05 - val_mean_squared_error: 5.6330e-05\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 14/1000\n",
      "34452/34452 [==============================] - 4s 120us/step - loss: 3.3184e-05 - mean_squared_error: 3.0722e-05 - val_loss: 5.8776e-05 - val_mean_squared_error: 5.6318e-05\n",
      "Epoch 15/1000\n",
      "34452/34452 [==============================] - 4s 121us/step - loss: 3.3166e-05 - mean_squared_error: 3.0705e-05 - val_loss: 5.8799e-05 - val_mean_squared_error: 5.6342e-05\n",
      "Epoch 16/1000\n",
      "34452/34452 [==============================] - 4s 121us/step - loss: 3.3160e-05 - mean_squared_error: 3.0701e-05 - val_loss: 5.8816e-05 - val_mean_squared_error: 5.6362e-05\n",
      "Epoch 17/1000\n",
      "34452/34452 [==============================] - 4s 120us/step - loss: 3.3156e-05 - mean_squared_error: 3.0699e-05 - val_loss: 5.8777e-05 - val_mean_squared_error: 5.6321e-05\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 18/1000\n",
      "34452/34452 [==============================] - 3s 96us/step - loss: 3.3143e-05 - mean_squared_error: 3.0687e-05 - val_loss: 5.8781e-05 - val_mean_squared_error: 5.6325e-05\n",
      "Epoch 19/1000\n",
      "34452/34452 [==============================] - 4s 116us/step - loss: 3.3143e-05 - mean_squared_error: 3.0687e-05 - val_loss: 5.8782e-05 - val_mean_squared_error: 5.6327e-05\n",
      "Epoch 20/1000\n",
      "34452/34452 [==============================] - 3s 101us/step - loss: 3.3142e-05 - mean_squared_error: 3.0687e-05 - val_loss: 5.8786e-05 - val_mean_squared_error: 5.6330e-05\n",
      "Epoch 21/1000\n",
      "34452/34452 [==============================] - 4s 113us/step - loss: 3.3142e-05 - mean_squared_error: 3.0687e-05 - val_loss: 5.8786e-05 - val_mean_squared_error: 5.6331e-05\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "Epoch 22/1000\n",
      "34452/34452 [==============================] - 4s 107us/step - loss: 3.3140e-05 - mean_squared_error: 3.0685e-05 - val_loss: 5.8787e-05 - val_mean_squared_error: 5.6331e-05\n",
      "Epoch 23/1000\n",
      "34452/34452 [==============================] - 4s 109us/step - loss: 3.3140e-05 - mean_squared_error: 3.0685e-05 - val_loss: 5.8787e-05 - val_mean_squared_error: 5.6331e-05\n",
      "Epoch 24/1000\n",
      "34452/34452 [==============================] - 4s 121us/step - loss: 3.3140e-05 - mean_squared_error: 3.0685e-05 - val_loss: 5.8787e-05 - val_mean_squared_error: 5.6331e-05\n",
      "Epoch 25/1000\n",
      "34452/34452 [==============================] - 4s 125us/step - loss: 3.3140e-05 - mean_squared_error: 3.0685e-05 - val_loss: 5.8787e-05 - val_mean_squared_error: 5.6331e-05\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "Epoch 26/1000\n",
      "34452/34452 [==============================] - 4s 122us/step - loss: 3.3140e-05 - mean_squared_error: 3.0685e-05 - val_loss: 5.8787e-05 - val_mean_squared_error: 5.6331e-05\n",
      "Epoch 27/1000\n",
      "34452/34452 [==============================] - 4s 125us/step - loss: 3.3140e-05 - mean_squared_error: 3.0685e-05 - val_loss: 5.8787e-05 - val_mean_squared_error: 5.6331e-05\n",
      "Epoch 28/1000\n",
      "34452/34452 [==============================] - 4s 122us/step - loss: 3.3140e-05 - mean_squared_error: 3.0685e-05 - val_loss: 5.8787e-05 - val_mean_squared_error: 5.6331e-05\n",
      "Epoch 29/1000\n",
      "34452/34452 [==============================] - 4s 127us/step - loss: 3.3140e-05 - mean_squared_error: 3.0685e-05 - val_loss: 5.8787e-05 - val_mean_squared_error: 5.6331e-05\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "Epoch 30/1000\n",
      "34452/34452 [==============================] - 6s 186us/step - loss: 3.3140e-05 - mean_squared_error: 3.0685e-05 - val_loss: 5.8787e-05 - val_mean_squared_error: 5.6331e-05\n",
      "Epoch 31/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34452/34452 [==============================] - 5s 138us/step - loss: 3.3140e-05 - mean_squared_error: 3.0685e-05 - val_loss: 5.8787e-05 - val_mean_squared_error: 5.6331e-05\n",
      "Epoch 32/1000\n",
      "34452/34452 [==============================] - 4s 114us/step - loss: 3.3140e-05 - mean_squared_error: 3.0685e-05 - val_loss: 5.8787e-05 - val_mean_squared_error: 5.6331e-05\n",
      "Epoch 33/1000\n",
      "34452/34452 [==============================] - 4s 114us/step - loss: 3.3140e-05 - mean_squared_error: 3.0685e-05 - val_loss: 5.8787e-05 - val_mean_squared_error: 5.6331e-05\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
      "Epoch 34/1000\n",
      "34452/34452 [==============================] - 4s 115us/step - loss: 3.3140e-05 - mean_squared_error: 3.0685e-05 - val_loss: 5.8787e-05 - val_mean_squared_error: 5.6331e-05\n",
      "Epoch 00034: early stopping\n",
      "Train on 34452 samples, validate on 8636 samples\n",
      "Epoch 1/1000\n",
      "34452/34452 [==============================] - 4s 115us/step - loss: 4.3158e-05 - mean_squared_error: 3.6314e-05 - val_loss: 6.4217e-05 - val_mean_squared_error: 5.9869e-05\n",
      "Epoch 2/1000\n",
      "34452/34452 [==============================] - 4s 116us/step - loss: 4.0088e-05 - mean_squared_error: 3.4932e-05 - val_loss: 6.4857e-05 - val_mean_squared_error: 6.0943e-05\n",
      "Epoch 3/1000\n",
      "34452/34452 [==============================] - 4s 103us/step - loss: 4.0145e-05 - mean_squared_error: 3.4866e-05 - val_loss: 6.3556e-05 - val_mean_squared_error: 5.8980e-05\n",
      "Epoch 4/1000\n",
      "34452/34452 [==============================] - 4s 102us/step - loss: 3.9846e-05 - mean_squared_error: 3.4736e-05 - val_loss: 6.6171e-05 - val_mean_squared_error: 6.0773e-05\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 5/1000\n",
      "34452/34452 [==============================] - 4s 109us/step - loss: 3.4325e-05 - mean_squared_error: 3.1339e-05 - val_loss: 5.9908e-05 - val_mean_squared_error: 5.7149e-05\n",
      "Epoch 6/1000\n",
      "34452/34452 [==============================] - 3s 98us/step - loss: 3.3970e-05 - mean_squared_error: 3.1148e-05 - val_loss: 5.9969e-05 - val_mean_squared_error: 5.7206e-05\n",
      "Epoch 7/1000\n",
      "34452/34452 [==============================] - 4s 118us/step - loss: 3.3856e-05 - mean_squared_error: 3.1116e-05 - val_loss: 5.9622e-05 - val_mean_squared_error: 5.6755e-05\n",
      "Epoch 8/1000\n",
      "34452/34452 [==============================] - 4s 117us/step - loss: 3.3687e-05 - mean_squared_error: 3.1015e-05 - val_loss: 5.9880e-05 - val_mean_squared_error: 5.7283e-05\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 9/1000\n",
      "34452/34452 [==============================] - 4s 118us/step - loss: 3.2976e-05 - mean_squared_error: 3.0523e-05 - val_loss: 5.8842e-05 - val_mean_squared_error: 5.6384e-05\n",
      "Epoch 10/1000\n",
      "34452/34452 [==============================] - 4s 120us/step - loss: 3.2910e-05 - mean_squared_error: 3.0452e-05 - val_loss: 5.9070e-05 - val_mean_squared_error: 5.6633e-05\n",
      "Epoch 11/1000\n",
      "34452/34452 [==============================] - 4s 120us/step - loss: 3.2884e-05 - mean_squared_error: 3.0445e-05 - val_loss: 5.8915e-05 - val_mean_squared_error: 5.6473e-05\n",
      "Epoch 12/1000\n",
      "34452/34452 [==============================] - 4s 120us/step - loss: 3.2852e-05 - mean_squared_error: 3.0423e-05 - val_loss: 5.8820e-05 - val_mean_squared_error: 5.6339e-05\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 13/1000\n",
      "34452/34452 [==============================] - 4s 119us/step - loss: 3.2780e-05 - mean_squared_error: 3.0323e-05 - val_loss: 5.8869e-05 - val_mean_squared_error: 5.6420e-05\n",
      "Epoch 14/1000\n",
      "34452/34452 [==============================] - 5s 157us/step - loss: 3.2761e-05 - mean_squared_error: 3.0319e-05 - val_loss: 5.8894e-05 - val_mean_squared_error: 5.6456e-05\n",
      "Epoch 15/1000\n",
      "34452/34452 [==============================] - 6s 163us/step - loss: 3.2756e-05 - mean_squared_error: 3.0322e-05 - val_loss: 5.8888e-05 - val_mean_squared_error: 5.6456e-05\n",
      "Epoch 16/1000\n",
      "34452/34452 [==============================] - 4s 121us/step - loss: 3.2753e-05 - mean_squared_error: 3.0322e-05 - val_loss: 5.8880e-05 - val_mean_squared_error: 5.6453e-05\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 17/1000\n",
      "34452/34452 [==============================] - 4s 117us/step - loss: 3.2741e-05 - mean_squared_error: 3.0313e-05 - val_loss: 5.8877e-05 - val_mean_squared_error: 5.6450e-05\n",
      "Epoch 18/1000\n",
      "34452/34452 [==============================] - 4s 125us/step - loss: 3.2740e-05 - mean_squared_error: 3.0312e-05 - val_loss: 5.8875e-05 - val_mean_squared_error: 5.6448e-05\n",
      "Epoch 19/1000\n",
      "34452/34452 [==============================] - 4s 120us/step - loss: 3.2739e-05 - mean_squared_error: 3.0313e-05 - val_loss: 5.8873e-05 - val_mean_squared_error: 5.6447e-05\n",
      "Epoch 20/1000\n",
      "34452/34452 [==============================] - 5s 150us/step - loss: 3.2739e-05 - mean_squared_error: 3.0312e-05 - val_loss: 5.8871e-05 - val_mean_squared_error: 5.6444e-05\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "Epoch 21/1000\n",
      "34452/34452 [==============================] - 6s 168us/step - loss: 3.2737e-05 - mean_squared_error: 3.0311e-05 - val_loss: 5.8871e-05 - val_mean_squared_error: 5.6444e-05\n",
      "Epoch 22/1000\n",
      "34452/34452 [==============================] - 4s 128us/step - loss: 3.2737e-05 - mean_squared_error: 3.0311e-05 - val_loss: 5.8870e-05 - val_mean_squared_error: 5.6444e-05\n",
      "Epoch 23/1000\n",
      "34452/34452 [==============================] - 4s 119us/step - loss: 3.2737e-05 - mean_squared_error: 3.0311e-05 - val_loss: 5.8870e-05 - val_mean_squared_error: 5.6444e-05\n",
      "Epoch 24/1000\n",
      "34452/34452 [==============================] - 4s 119us/step - loss: 3.2737e-05 - mean_squared_error: 3.0311e-05 - val_loss: 5.8870e-05 - val_mean_squared_error: 5.6444e-05\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "Epoch 25/1000\n",
      "34452/34452 [==============================] - 4s 121us/step - loss: 3.2737e-05 - mean_squared_error: 3.0311e-05 - val_loss: 5.8870e-05 - val_mean_squared_error: 5.6444e-05\n",
      "Epoch 26/1000\n",
      "34452/34452 [==============================] - 4s 121us/step - loss: 3.2737e-05 - mean_squared_error: 3.0311e-05 - val_loss: 5.8870e-05 - val_mean_squared_error: 5.6444e-05\n",
      "Epoch 27/1000\n",
      "34452/34452 [==============================] - 4s 122us/step - loss: 3.2737e-05 - mean_squared_error: 3.0311e-05 - val_loss: 5.8870e-05 - val_mean_squared_error: 5.6444e-05\n",
      "Epoch 28/1000\n",
      "34452/34452 [==============================] - 4s 123us/step - loss: 3.2737e-05 - mean_squared_error: 3.0311e-05 - val_loss: 5.8870e-05 - val_mean_squared_error: 5.6444e-05\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "Epoch 29/1000\n",
      "34452/34452 [==============================] - 4s 112us/step - loss: 3.2737e-05 - mean_squared_error: 3.0311e-05 - val_loss: 5.8870e-05 - val_mean_squared_error: 5.6444e-05\n",
      "Epoch 30/1000\n",
      "34452/34452 [==============================] - 3s 101us/step - loss: 3.2737e-05 - mean_squared_error: 3.0311e-05 - val_loss: 5.8870e-05 - val_mean_squared_error: 5.6444e-05\n",
      "Epoch 31/1000\n",
      "34452/34452 [==============================] - 4s 123us/step - loss: 3.2737e-05 - mean_squared_error: 3.0311e-05 - val_loss: 5.8870e-05 - val_mean_squared_error: 5.6444e-05\n",
      "Epoch 32/1000\n",
      "34452/34452 [==============================] - 4s 123us/step - loss: 3.2737e-05 - mean_squared_error: 3.0311e-05 - val_loss: 5.8870e-05 - val_mean_squared_error: 5.6444e-05\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
      "Epoch 00032: early stopping\n",
      "Train on 34452 samples, validate on 8636 samples\n",
      "Epoch 1/1000\n",
      "34452/34452 [==============================] - 4s 123us/step - loss: 4.2240e-05 - mean_squared_error: 3.5706e-05 - val_loss: 6.4737e-05 - val_mean_squared_error: 5.8930e-05\n",
      "Epoch 2/1000\n",
      "34452/34452 [==============================] - 6s 182us/step - loss: 3.9874e-05 - mean_squared_error: 3.4498e-05 - val_loss: 6.4560e-05 - val_mean_squared_error: 5.8803e-05\n",
      "Epoch 3/1000\n",
      "34452/34452 [==============================] - 8s 236us/step - loss: 3.9503e-05 - mean_squared_error: 3.4247e-05 - val_loss: 6.8078e-05 - val_mean_squared_error: 6.2961e-05\n",
      "Epoch 4/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34452/34452 [==============================] - 5s 148us/step - loss: 3.9325e-05 - mean_squared_error: 3.4085e-05 - val_loss: 6.4496e-05 - val_mean_squared_error: 6.0033e-05\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 5/1000\n",
      "34452/34452 [==============================] - 4s 116us/step - loss: 3.3630e-05 - mean_squared_error: 3.0645e-05 - val_loss: 5.9060e-05 - val_mean_squared_error: 5.6105e-05\n",
      "Epoch 6/1000\n",
      "34452/34452 [==============================] - 4s 113us/step - loss: 3.3406e-05 - mean_squared_error: 3.0502e-05 - val_loss: 5.9353e-05 - val_mean_squared_error: 5.6435e-05\n",
      "Epoch 7/1000\n",
      "34452/34452 [==============================] - 4s 116us/step - loss: 3.3207e-05 - mean_squared_error: 3.0408e-05 - val_loss: 5.9368e-05 - val_mean_squared_error: 5.6594e-05\n",
      "Epoch 8/1000\n",
      "34452/34452 [==============================] - 4s 115us/step - loss: 3.3065e-05 - mean_squared_error: 3.0340e-05 - val_loss: 5.8918e-05 - val_mean_squared_error: 5.6091e-05\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 9/1000\n",
      "34452/34452 [==============================] - 4s 117us/step - loss: 3.2332e-05 - mean_squared_error: 2.9805e-05 - val_loss: 5.9076e-05 - val_mean_squared_error: 5.6577e-05\n",
      "Epoch 10/1000\n",
      "34452/34452 [==============================] - 4s 113us/step - loss: 3.2241e-05 - mean_squared_error: 2.9732e-05 - val_loss: 5.8960e-05 - val_mean_squared_error: 5.6485e-05\n",
      "Epoch 11/1000\n",
      "34452/34452 [==============================] - 3s 94us/step - loss: 3.2224e-05 - mean_squared_error: 2.9739e-05 - val_loss: 5.8873e-05 - val_mean_squared_error: 5.6400e-05\n",
      "Epoch 12/1000\n",
      "34452/34452 [==============================] - 4s 115us/step - loss: 3.2195e-05 - mean_squared_error: 2.9710e-05 - val_loss: 5.8949e-05 - val_mean_squared_error: 5.6464e-05\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 13/1000\n",
      "34452/34452 [==============================] - 4s 118us/step - loss: 3.2114e-05 - mean_squared_error: 2.9641e-05 - val_loss: 5.8818e-05 - val_mean_squared_error: 5.6348e-05\n",
      "Epoch 14/1000\n",
      "34452/34452 [==============================] - 7s 194us/step - loss: 3.2095e-05 - mean_squared_error: 2.9624e-05 - val_loss: 5.8829e-05 - val_mean_squared_error: 5.6364e-05\n",
      "Epoch 15/1000\n",
      "34452/34452 [==============================] - 10s 280us/step - loss: 3.2089e-05 - mean_squared_error: 2.9625e-05 - val_loss: 5.8816e-05 - val_mean_squared_error: 5.6349e-05\n",
      "Epoch 16/1000\n",
      "34452/34452 [==============================] - 6s 184us/step - loss: 3.2085e-05 - mean_squared_error: 2.9619e-05 - val_loss: 5.8850e-05 - val_mean_squared_error: 5.6384e-05\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 17/1000\n",
      "34452/34452 [==============================] - 7s 196us/step - loss: 3.2072e-05 - mean_squared_error: 2.9607e-05 - val_loss: 5.8842e-05 - val_mean_squared_error: 5.6378e-05\n",
      "Epoch 18/1000\n",
      "34452/34452 [==============================] - 4s 124us/step - loss: 3.2071e-05 - mean_squared_error: 2.9607e-05 - val_loss: 5.8836e-05 - val_mean_squared_error: 5.6372e-05\n",
      "Epoch 19/1000\n",
      "34452/34452 [==============================] - 5s 146us/step - loss: 3.2071e-05 - mean_squared_error: 2.9606e-05 - val_loss: 5.8832e-05 - val_mean_squared_error: 5.6368e-05\n",
      "Epoch 20/1000\n",
      "34452/34452 [==============================] - 5s 143us/step - loss: 3.2070e-05 - mean_squared_error: 2.9606e-05 - val_loss: 5.8830e-05 - val_mean_squared_error: 5.6366e-05\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "Epoch 21/1000\n",
      "34452/34452 [==============================] - 4s 125us/step - loss: 3.2069e-05 - mean_squared_error: 2.9604e-05 - val_loss: 5.8830e-05 - val_mean_squared_error: 5.6365e-05\n",
      "Epoch 22/1000\n",
      "34452/34452 [==============================] - 4s 128us/step - loss: 3.2069e-05 - mean_squared_error: 2.9604e-05 - val_loss: 5.8829e-05 - val_mean_squared_error: 5.6365e-05\n",
      "Epoch 23/1000\n",
      "34452/34452 [==============================] - 5s 139us/step - loss: 3.2069e-05 - mean_squared_error: 2.9605e-05 - val_loss: 5.8829e-05 - val_mean_squared_error: 5.6365e-05\n",
      "Epoch 24/1000\n",
      "34452/34452 [==============================] - 6s 167us/step - loss: 3.2069e-05 - mean_squared_error: 2.9605e-05 - val_loss: 5.8829e-05 - val_mean_squared_error: 5.6365e-05\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "Epoch 25/1000\n",
      "34452/34452 [==============================] - 5s 135us/step - loss: 3.2068e-05 - mean_squared_error: 2.9604e-05 - val_loss: 5.8829e-05 - val_mean_squared_error: 5.6364e-05\n",
      "Epoch 26/1000\n",
      "34452/34452 [==============================] - 5s 134us/step - loss: 3.2068e-05 - mean_squared_error: 2.9604e-05 - val_loss: 5.8829e-05 - val_mean_squared_error: 5.6364e-05\n",
      "Epoch 27/1000\n",
      "34452/34452 [==============================] - 7s 213us/step - loss: 3.2068e-05 - mean_squared_error: 2.9604e-05 - val_loss: 5.8829e-05 - val_mean_squared_error: 5.6364e-05\n",
      "Epoch 28/1000\n",
      "34452/34452 [==============================] - 5s 147us/step - loss: 3.2068e-05 - mean_squared_error: 2.9604e-05 - val_loss: 5.8829e-05 - val_mean_squared_error: 5.6364e-05\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "Epoch 00028: early stopping\n",
      "Train on 34452 samples, validate on 8636 samples\n",
      "Epoch 1/1000\n",
      "34452/34452 [==============================] - 5s 131us/step - loss: 4.2090e-05 - mean_squared_error: 3.5230e-05 - val_loss: 6.4890e-05 - val_mean_squared_error: 5.9746e-05\n",
      "Epoch 2/1000\n",
      "34452/34452 [==============================] - 5s 131us/step - loss: 3.9130e-05 - mean_squared_error: 3.3747e-05 - val_loss: 6.3677e-05 - val_mean_squared_error: 5.8562e-05\n",
      "Epoch 3/1000\n",
      "34452/34452 [==============================] - 5s 132us/step - loss: 3.8782e-05 - mean_squared_error: 3.3594e-05 - val_loss: 6.5833e-05 - val_mean_squared_error: 5.8899e-05\n",
      "Epoch 4/1000\n",
      "34452/34452 [==============================] - 5s 133us/step - loss: 3.8792e-05 - mean_squared_error: 3.3553e-05 - val_loss: 6.5176e-05 - val_mean_squared_error: 6.0188e-05\n",
      "Epoch 5/1000\n",
      "34452/34452 [==============================] - 5s 133us/step - loss: 3.8412e-05 - mean_squared_error: 3.3389e-05 - val_loss: 6.7845e-05 - val_mean_squared_error: 6.1855e-05\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 6/1000\n",
      "34452/34452 [==============================] - 5s 136us/step - loss: 3.2994e-05 - mean_squared_error: 3.0059e-05 - val_loss: 6.0543e-05 - val_mean_squared_error: 5.7653e-05\n",
      "Epoch 7/1000\n",
      "34452/34452 [==============================] - 5s 134us/step - loss: 3.2731e-05 - mean_squared_error: 2.9913e-05 - val_loss: 6.1252e-05 - val_mean_squared_error: 5.8395e-05\n",
      "Epoch 8/1000\n",
      "34452/34452 [==============================] - 6s 161us/step - loss: 3.2580e-05 - mean_squared_error: 2.9864e-05 - val_loss: 5.9778e-05 - val_mean_squared_error: 5.6905e-05\n",
      "Epoch 9/1000\n",
      "34452/34452 [==============================] - 8s 226us/step - loss: 3.2454e-05 - mean_squared_error: 2.9794e-05 - val_loss: 6.0021e-05 - val_mean_squared_error: 5.7426e-05\n",
      "Epoch 10/1000\n",
      "34452/34452 [==============================] - 5s 138us/step - loss: 3.2302e-05 - mean_squared_error: 2.9715e-05 - val_loss: 6.0600e-05 - val_mean_squared_error: 5.8047e-05\n",
      "Epoch 11/1000\n",
      "34452/34452 [==============================] - 5s 132us/step - loss: 3.2173e-05 - mean_squared_error: 2.9640e-05 - val_loss: 5.9797e-05 - val_mean_squared_error: 5.7202e-05\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 12/1000\n",
      "34452/34452 [==============================] - 5s 136us/step - loss: 3.1424e-05 - mean_squared_error: 2.9083e-05 - val_loss: 5.8962e-05 - val_mean_squared_error: 5.6594e-05\n",
      "Epoch 13/1000\n",
      "34452/34452 [==============================] - 6s 173us/step - loss: 3.1376e-05 - mean_squared_error: 2.9041e-05 - val_loss: 5.8729e-05 - val_mean_squared_error: 5.6413e-05\n",
      "Epoch 14/1000\n",
      "34452/34452 [==============================] - 5s 156us/step - loss: 3.1354e-05 - mean_squared_error: 2.9041e-05 - val_loss: 5.9030e-05 - val_mean_squared_error: 5.6704e-05\n",
      "Epoch 15/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34452/34452 [==============================] - 4s 122us/step - loss: 3.1328e-05 - mean_squared_error: 2.9006e-05 - val_loss: 5.8848e-05 - val_mean_squared_error: 5.6538e-05\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 16/1000\n",
      "34452/34452 [==============================] - 4s 104us/step - loss: 3.1250e-05 - mean_squared_error: 2.8952e-05 - val_loss: 5.8910e-05 - val_mean_squared_error: 5.6616e-05\n",
      "Epoch 17/1000\n",
      "34452/34452 [==============================] - 4s 117us/step - loss: 3.1235e-05 - mean_squared_error: 2.8942e-05 - val_loss: 5.8859e-05 - val_mean_squared_error: 5.6565e-05\n",
      "Epoch 18/1000\n",
      "34452/34452 [==============================] - 6s 170us/step - loss: 3.1231e-05 - mean_squared_error: 2.8937e-05 - val_loss: 5.8865e-05 - val_mean_squared_error: 5.6570e-05\n",
      "Epoch 19/1000\n",
      "34452/34452 [==============================] - 5s 141us/step - loss: 3.1228e-05 - mean_squared_error: 2.8931e-05 - val_loss: 5.8871e-05 - val_mean_squared_error: 5.6582e-05\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 20/1000\n",
      "34452/34452 [==============================] - 4s 111us/step - loss: 3.1216e-05 - mean_squared_error: 2.8926e-05 - val_loss: 5.8869e-05 - val_mean_squared_error: 5.6579e-05\n",
      "Epoch 21/1000\n",
      "34452/34452 [==============================] - 4s 113us/step - loss: 3.1215e-05 - mean_squared_error: 2.8925e-05 - val_loss: 5.8870e-05 - val_mean_squared_error: 5.6580e-05\n",
      "Epoch 22/1000\n",
      "34452/34452 [==============================] - 4s 113us/step - loss: 3.1214e-05 - mean_squared_error: 2.8924e-05 - val_loss: 5.8871e-05 - val_mean_squared_error: 5.6581e-05\n",
      "Epoch 23/1000\n",
      "34452/34452 [==============================] - 4s 112us/step - loss: 3.1214e-05 - mean_squared_error: 2.8923e-05 - val_loss: 5.8872e-05 - val_mean_squared_error: 5.6581e-05\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "Epoch 24/1000\n",
      "34452/34452 [==============================] - 4s 113us/step - loss: 3.1213e-05 - mean_squared_error: 2.8922e-05 - val_loss: 5.8872e-05 - val_mean_squared_error: 5.6581e-05\n",
      "Epoch 25/1000\n",
      "34452/34452 [==============================] - 4s 111us/step - loss: 3.1213e-05 - mean_squared_error: 2.8922e-05 - val_loss: 5.8872e-05 - val_mean_squared_error: 5.6581e-05\n",
      "Epoch 26/1000\n",
      "34452/34452 [==============================] - 4s 116us/step - loss: 3.1213e-05 - mean_squared_error: 2.8922e-05 - val_loss: 5.8872e-05 - val_mean_squared_error: 5.6581e-05\n",
      "Epoch 27/1000\n",
      "34452/34452 [==============================] - 4s 111us/step - loss: 3.1213e-05 - mean_squared_error: 2.8922e-05 - val_loss: 5.8872e-05 - val_mean_squared_error: 5.6581e-05\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "Epoch 28/1000\n",
      "34452/34452 [==============================] - 5s 139us/step - loss: 3.1212e-05 - mean_squared_error: 2.8922e-05 - val_loss: 5.8872e-05 - val_mean_squared_error: 5.6581e-05\n",
      "Epoch 29/1000\n",
      "34452/34452 [==============================] - 6s 167us/step - loss: 3.1212e-05 - mean_squared_error: 2.8922e-05 - val_loss: 5.8872e-05 - val_mean_squared_error: 5.6581e-05\n",
      "Epoch 30/1000\n",
      "34452/34452 [==============================] - 4s 123us/step - loss: 3.1212e-05 - mean_squared_error: 2.8922e-05 - val_loss: 5.8872e-05 - val_mean_squared_error: 5.6581e-05\n",
      "Epoch 31/1000\n",
      "34452/34452 [==============================] - 4s 109us/step - loss: 3.1212e-05 - mean_squared_error: 2.8922e-05 - val_loss: 5.8872e-05 - val_mean_squared_error: 5.6581e-05\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "Epoch 32/1000\n",
      "34452/34452 [==============================] - 4s 111us/step - loss: 3.1212e-05 - mean_squared_error: 2.8922e-05 - val_loss: 5.8872e-05 - val_mean_squared_error: 5.6581e-05\n",
      "Epoch 33/1000\n",
      "34452/34452 [==============================] - 4s 113us/step - loss: 3.1212e-05 - mean_squared_error: 2.8922e-05 - val_loss: 5.8872e-05 - val_mean_squared_error: 5.6581e-05\n",
      "Epoch 00033: early stopping\n",
      "Train on 34452 samples, validate on 8636 samples\n",
      "Epoch 1/1000\n",
      "34452/34452 [==============================] - 4s 112us/step - loss: 4.1132e-05 - mean_squared_error: 3.4537e-05 - val_loss: 6.3477e-05 - val_mean_squared_error: 5.8914e-05\n",
      "Epoch 2/1000\n",
      "34452/34452 [==============================] - 4s 114us/step - loss: 3.8116e-05 - mean_squared_error: 3.3145e-05 - val_loss: 6.0553e-05 - val_mean_squared_error: 5.5987e-05\n",
      "Epoch 3/1000\n",
      "34452/34452 [==============================] - 5s 139us/step - loss: 3.8157e-05 - mean_squared_error: 3.3049e-05 - val_loss: 6.6860e-05 - val_mean_squared_error: 6.1059e-05\n",
      "Epoch 4/1000\n",
      "34452/34452 [==============================] - 4s 123us/step - loss: 3.8571e-05 - mean_squared_error: 3.3256e-05 - val_loss: 6.6047e-05 - val_mean_squared_error: 6.0519e-05\n",
      "Epoch 5/1000\n",
      "34452/34452 [==============================] - 5s 144us/step - loss: 3.8565e-05 - mean_squared_error: 3.3093e-05 - val_loss: 6.4958e-05 - val_mean_squared_error: 6.0199e-05\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 6/1000\n",
      "34452/34452 [==============================] - 4s 115us/step - loss: 3.2565e-05 - mean_squared_error: 2.9670e-05 - val_loss: 6.0122e-05 - val_mean_squared_error: 5.7046e-05\n",
      "Epoch 7/1000\n",
      "34452/34452 [==============================] - 4s 112us/step - loss: 3.2342e-05 - mean_squared_error: 2.9490e-05 - val_loss: 5.9533e-05 - val_mean_squared_error: 5.6749e-05\n",
      "Epoch 8/1000\n",
      "34452/34452 [==============================] - 4s 113us/step - loss: 3.2194e-05 - mean_squared_error: 2.9432e-05 - val_loss: 5.9891e-05 - val_mean_squared_error: 5.7278e-05\n",
      "Epoch 9/1000\n",
      "34452/34452 [==============================] - 4s 120us/step - loss: 3.2083e-05 - mean_squared_error: 2.9424e-05 - val_loss: 5.9268e-05 - val_mean_squared_error: 5.6703e-05\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 10/1000\n",
      "34452/34452 [==============================] - 5s 139us/step - loss: 3.1393e-05 - mean_squared_error: 2.8981e-05 - val_loss: 5.9324e-05 - val_mean_squared_error: 5.6847e-05\n",
      "Epoch 11/1000\n",
      "34452/34452 [==============================] - 5s 136us/step - loss: 3.1333e-05 - mean_squared_error: 2.8882e-05 - val_loss: 5.9310e-05 - val_mean_squared_error: 5.6869e-05\n",
      "Epoch 12/1000\n",
      "34452/34452 [==============================] - 5s 131us/step - loss: 3.1308e-05 - mean_squared_error: 2.8872e-05 - val_loss: 5.9210e-05 - val_mean_squared_error: 5.6801e-05\n",
      "Epoch 13/1000\n",
      "34452/34452 [==============================] - 4s 111us/step - loss: 3.1289e-05 - mean_squared_error: 2.8863e-05 - val_loss: 5.9179e-05 - val_mean_squared_error: 5.6757e-05\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 14/1000\n",
      "34452/34452 [==============================] - 4s 118us/step - loss: 3.1225e-05 - mean_squared_error: 2.8815e-05 - val_loss: 5.9127e-05 - val_mean_squared_error: 5.6722e-05\n",
      "Epoch 15/1000\n",
      "34452/34452 [==============================] - 6s 171us/step - loss: 3.1202e-05 - mean_squared_error: 2.8797e-05 - val_loss: 5.9124e-05 - val_mean_squared_error: 5.6718e-05\n",
      "Epoch 16/1000\n",
      "34452/34452 [==============================] - 5s 141us/step - loss: 3.1195e-05 - mean_squared_error: 2.8791e-05 - val_loss: 5.9168e-05 - val_mean_squared_error: 5.6766e-05\n",
      "Epoch 17/1000\n",
      "34452/34452 [==============================] - 5s 132us/step - loss: 3.1191e-05 - mean_squared_error: 2.8787e-05 - val_loss: 5.9228e-05 - val_mean_squared_error: 5.6828e-05\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 18/1000\n",
      "34452/34452 [==============================] - 5s 133us/step - loss: 3.1181e-05 - mean_squared_error: 2.8780e-05 - val_loss: 5.9214e-05 - val_mean_squared_error: 5.6814e-05\n",
      "Epoch 19/1000\n",
      "34452/34452 [==============================] - 4s 113us/step - loss: 3.1180e-05 - mean_squared_error: 2.8779e-05 - val_loss: 5.9207e-05 - val_mean_squared_error: 5.6806e-05\n",
      "Epoch 20/1000\n",
      "34452/34452 [==============================] - 4s 119us/step - loss: 3.1179e-05 - mean_squared_error: 2.8778e-05 - val_loss: 5.9200e-05 - val_mean_squared_error: 5.6799e-05\n",
      "Epoch 21/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34452/34452 [==============================] - 6s 166us/step - loss: 3.1179e-05 - mean_squared_error: 2.8778e-05 - val_loss: 5.9195e-05 - val_mean_squared_error: 5.6794e-05\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "Epoch 22/1000\n",
      "34452/34452 [==============================] - 5s 141us/step - loss: 3.1177e-05 - mean_squared_error: 2.8776e-05 - val_loss: 5.9194e-05 - val_mean_squared_error: 5.6793e-05\n",
      "Epoch 00022: early stopping\n",
      "Train on 34452 samples, validate on 8636 samples\n",
      "Epoch 1/1000\n",
      "34452/34452 [==============================] - 4s 114us/step - loss: 4.0269e-05 - mean_squared_error: 3.3900e-05 - val_loss: 6.3606e-05 - val_mean_squared_error: 5.9082e-05\n",
      "Epoch 2/1000\n",
      "34452/34452 [==============================] - 4s 109us/step - loss: 3.7722e-05 - mean_squared_error: 3.2792e-05 - val_loss: 6.4467e-05 - val_mean_squared_error: 5.9584e-05\n",
      "Epoch 3/1000\n",
      "34452/34452 [==============================] - 4s 118us/step - loss: 3.8255e-05 - mean_squared_error: 3.2809e-05 - val_loss: 6.2749e-05 - val_mean_squared_error: 5.8312e-05\n",
      "Epoch 4/1000\n",
      "34452/34452 [==============================] - 4s 108us/step - loss: 3.7736e-05 - mean_squared_error: 3.2689e-05 - val_loss: 6.2121e-05 - val_mean_squared_error: 5.7463e-05\n",
      "Epoch 5/1000\n",
      "34452/34452 [==============================] - 4s 116us/step - loss: 3.7837e-05 - mean_squared_error: 3.2667e-05 - val_loss: 6.6973e-05 - val_mean_squared_error: 6.2575e-05\n",
      "Epoch 6/1000\n",
      "34452/34452 [==============================] - 4s 107us/step - loss: 3.7760e-05 - mean_squared_error: 3.2692e-05 - val_loss: 6.5729e-05 - val_mean_squared_error: 6.0831e-05\n",
      "Epoch 7/1000\n",
      "34452/34452 [==============================] - 4s 111us/step - loss: 3.7452e-05 - mean_squared_error: 3.2454e-05 - val_loss: 6.5839e-05 - val_mean_squared_error: 6.1205e-05\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 8/1000\n",
      "34452/34452 [==============================] - 4s 109us/step - loss: 3.2077e-05 - mean_squared_error: 2.9251e-05 - val_loss: 5.8728e-05 - val_mean_squared_error: 5.6139e-05\n",
      "Epoch 9/1000\n",
      "34452/34452 [==============================] - 5s 143us/step - loss: 3.1878e-05 - mean_squared_error: 2.9119e-05 - val_loss: 6.0208e-05 - val_mean_squared_error: 5.7450e-05\n",
      "Epoch 10/1000\n",
      "34452/34452 [==============================] - 4s 115us/step - loss: 3.1786e-05 - mean_squared_error: 2.9104e-05 - val_loss: 5.9161e-05 - val_mean_squared_error: 5.6554e-05\n",
      "Epoch 11/1000\n",
      "34452/34452 [==============================] - 4s 109us/step - loss: 3.1586e-05 - mean_squared_error: 2.8993e-05 - val_loss: 5.9238e-05 - val_mean_squared_error: 5.6840e-05\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 12/1000\n",
      "34452/34452 [==============================] - 4s 110us/step - loss: 3.0959e-05 - mean_squared_error: 2.8612e-05 - val_loss: 5.9464e-05 - val_mean_squared_error: 5.7078e-05\n",
      "Epoch 13/1000\n",
      "34452/34452 [==============================] - 4s 113us/step - loss: 3.0893e-05 - mean_squared_error: 2.8507e-05 - val_loss: 5.9437e-05 - val_mean_squared_error: 5.7065e-05\n",
      "Epoch 14/1000\n",
      "34452/34452 [==============================] - 5s 143us/step - loss: 3.0864e-05 - mean_squared_error: 2.8498e-05 - val_loss: 5.9437e-05 - val_mean_squared_error: 5.7036e-05\n",
      "Epoch 15/1000\n",
      "34452/34452 [==============================] - 4s 116us/step - loss: 3.0856e-05 - mean_squared_error: 2.8468e-05 - val_loss: 5.9268e-05 - val_mean_squared_error: 5.6910e-05\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 16/1000\n",
      "34452/34452 [==============================] - 4s 112us/step - loss: 3.0782e-05 - mean_squared_error: 2.8436e-05 - val_loss: 5.9312e-05 - val_mean_squared_error: 5.6966e-05\n",
      "Epoch 17/1000\n",
      "34452/34452 [==============================] - 5s 138us/step - loss: 3.0766e-05 - mean_squared_error: 2.8422e-05 - val_loss: 5.9319e-05 - val_mean_squared_error: 5.6970e-05\n",
      "Epoch 18/1000\n",
      "34452/34452 [==============================] - 6s 167us/step - loss: 3.0762e-05 - mean_squared_error: 2.8411e-05 - val_loss: 5.9317e-05 - val_mean_squared_error: 5.6967e-05\n",
      "Epoch 19/1000\n",
      "34452/34452 [==============================] - 4s 124us/step - loss: 3.0758e-05 - mean_squared_error: 2.8407e-05 - val_loss: 5.9355e-05 - val_mean_squared_error: 5.7008e-05\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 20/1000\n",
      "34452/34452 [==============================] - 5s 142us/step - loss: 3.0747e-05 - mean_squared_error: 2.8401e-05 - val_loss: 5.9346e-05 - val_mean_squared_error: 5.6999e-05\n",
      "Epoch 21/1000\n",
      "34452/34452 [==============================] - 4s 118us/step - loss: 3.0746e-05 - mean_squared_error: 2.8399e-05 - val_loss: 5.9343e-05 - val_mean_squared_error: 5.6996e-05\n",
      "Epoch 22/1000\n",
      "34452/34452 [==============================] - 4s 111us/step - loss: 3.0746e-05 - mean_squared_error: 2.8398e-05 - val_loss: 5.9340e-05 - val_mean_squared_error: 5.6993e-05\n",
      "Epoch 23/1000\n",
      "34452/34452 [==============================] - 4s 118us/step - loss: 3.0746e-05 - mean_squared_error: 2.8398e-05 - val_loss: 5.9337e-05 - val_mean_squared_error: 5.6989e-05\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "Epoch 24/1000\n",
      "34452/34452 [==============================] - 4s 111us/step - loss: 3.0744e-05 - mean_squared_error: 2.8397e-05 - val_loss: 5.9336e-05 - val_mean_squared_error: 5.6989e-05\n",
      "Epoch 25/1000\n",
      "34452/34452 [==============================] - 4s 119us/step - loss: 3.0744e-05 - mean_squared_error: 2.8397e-05 - val_loss: 5.9336e-05 - val_mean_squared_error: 5.6989e-05\n",
      "Epoch 26/1000\n",
      "34452/34452 [==============================] - 4s 112us/step - loss: 3.0744e-05 - mean_squared_error: 2.8397e-05 - val_loss: 5.9336e-05 - val_mean_squared_error: 5.6988e-05\n",
      "Epoch 27/1000\n",
      "34452/34452 [==============================] - 5s 133us/step - loss: 3.0744e-05 - mean_squared_error: 2.8397e-05 - val_loss: 5.9335e-05 - val_mean_squared_error: 5.6988e-05\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "Epoch 28/1000\n",
      "34452/34452 [==============================] - 6s 180us/step - loss: 3.0744e-05 - mean_squared_error: 2.8397e-05 - val_loss: 5.9335e-05 - val_mean_squared_error: 5.6988e-05\n",
      "Epoch 00028: early stopping\n",
      "Train on 34452 samples, validate on 8636 samples\n",
      "Epoch 1/1000\n",
      "34452/34452 [==============================] - 4s 127us/step - loss: 4.0038e-05 - mean_squared_error: 3.3607e-05 - val_loss: 6.5263e-05 - val_mean_squared_error: 6.0290e-05\n",
      "Epoch 2/1000\n",
      "34452/34452 [==============================] - 5s 144us/step - loss: 3.7238e-05 - mean_squared_error: 3.2425e-05 - val_loss: 6.3545e-05 - val_mean_squared_error: 5.8333e-05\n",
      "Epoch 3/1000\n",
      "34452/34452 [==============================] - 4s 129us/step - loss: 3.7180e-05 - mean_squared_error: 3.2273e-05 - val_loss: 6.3994e-05 - val_mean_squared_error: 5.8536e-05\n",
      "Epoch 4/1000\n",
      "34452/34452 [==============================] - 5s 139us/step - loss: 3.7196e-05 - mean_squared_error: 3.2150e-05 - val_loss: 6.6111e-05 - val_mean_squared_error: 6.1178e-05\n",
      "Epoch 5/1000\n",
      "34452/34452 [==============================] - 4s 113us/step - loss: 3.7182e-05 - mean_squared_error: 3.2230e-05 - val_loss: 6.4102e-05 - val_mean_squared_error: 5.9797e-05\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 6/1000\n",
      "34452/34452 [==============================] - 4s 116us/step - loss: 3.1867e-05 - mean_squared_error: 2.9075e-05 - val_loss: 6.1116e-05 - val_mean_squared_error: 5.8314e-05\n",
      "Epoch 7/1000\n",
      "34452/34452 [==============================] - 5s 154us/step - loss: 3.1596e-05 - mean_squared_error: 2.8876e-05 - val_loss: 5.9917e-05 - val_mean_squared_error: 5.7164e-05\n",
      "Epoch 8/1000\n",
      "34452/34452 [==============================] - 6s 161us/step - loss: 3.1511e-05 - mean_squared_error: 2.8857e-05 - val_loss: 6.0314e-05 - val_mean_squared_error: 5.7720e-05\n",
      "Epoch 9/1000\n",
      "34452/34452 [==============================] - 4s 125us/step - loss: 3.1395e-05 - mean_squared_error: 2.8814e-05 - val_loss: 5.9469e-05 - val_mean_squared_error: 5.6882e-05\n",
      "Epoch 10/1000\n",
      "34452/34452 [==============================] - 5s 140us/step - loss: 3.1257e-05 - mean_squared_error: 2.8763e-05 - val_loss: 6.1292e-05 - val_mean_squared_error: 5.8732e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 11/1000\n",
      "34452/34452 [==============================] - 4s 128us/step - loss: 3.0591e-05 - mean_squared_error: 2.8265e-05 - val_loss: 5.9533e-05 - val_mean_squared_error: 5.7228e-05\n",
      "Epoch 12/1000\n",
      "34452/34452 [==============================] - 4s 129us/step - loss: 3.0524e-05 - mean_squared_error: 2.8221e-05 - val_loss: 5.9662e-05 - val_mean_squared_error: 5.7327e-05\n",
      "Epoch 13/1000\n",
      "34452/34452 [==============================] - 5s 138us/step - loss: 3.0497e-05 - mean_squared_error: 2.8193e-05 - val_loss: 5.9512e-05 - val_mean_squared_error: 5.7190e-05\n",
      "Epoch 14/1000\n",
      "34452/34452 [==============================] - 4s 122us/step - loss: 3.0475e-05 - mean_squared_error: 2.8182e-05 - val_loss: 5.9637e-05 - val_mean_squared_error: 5.7328e-05\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 15/1000\n",
      "34452/34452 [==============================] - 4s 106us/step - loss: 3.0400e-05 - mean_squared_error: 2.8103e-05 - val_loss: 5.9624e-05 - val_mean_squared_error: 5.7330e-05\n",
      "Epoch 16/1000\n",
      "34452/34452 [==============================] - 4s 115us/step - loss: 3.0386e-05 - mean_squared_error: 2.8093e-05 - val_loss: 5.9616e-05 - val_mean_squared_error: 5.7323e-05\n",
      "Epoch 17/1000\n",
      "34452/34452 [==============================] - 4s 108us/step - loss: 3.0382e-05 - mean_squared_error: 2.8091e-05 - val_loss: 5.9580e-05 - val_mean_squared_error: 5.7292e-05\n",
      "Epoch 18/1000\n",
      "34452/34452 [==============================] - 4s 117us/step - loss: 3.0379e-05 - mean_squared_error: 2.8092e-05 - val_loss: 5.9536e-05 - val_mean_squared_error: 5.7249e-05\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 19/1000\n",
      "34452/34452 [==============================] - 6s 173us/step - loss: 3.0368e-05 - mean_squared_error: 2.8081e-05 - val_loss: 5.9538e-05 - val_mean_squared_error: 5.7252e-05\n",
      "Epoch 20/1000\n",
      "34452/34452 [==============================] - 5s 138us/step - loss: 3.0367e-05 - mean_squared_error: 2.8081e-05 - val_loss: 5.9538e-05 - val_mean_squared_error: 5.7252e-05\n",
      "Epoch 21/1000\n",
      "34452/34452 [==============================] - 4s 115us/step - loss: 3.0367e-05 - mean_squared_error: 2.8081e-05 - val_loss: 5.9539e-05 - val_mean_squared_error: 5.7253e-05\n",
      "Epoch 22/1000\n",
      "34452/34452 [==============================] - 4s 113us/step - loss: 3.0367e-05 - mean_squared_error: 2.8081e-05 - val_loss: 5.9538e-05 - val_mean_squared_error: 5.7253e-05\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "Epoch 23/1000\n",
      "34452/34452 [==============================] - 5s 148us/step - loss: 3.0365e-05 - mean_squared_error: 2.8080e-05 - val_loss: 5.9538e-05 - val_mean_squared_error: 5.7253e-05\n",
      "Epoch 24/1000\n",
      "34452/34452 [==============================] - 6s 161us/step - loss: 3.0365e-05 - mean_squared_error: 2.8080e-05 - val_loss: 5.9538e-05 - val_mean_squared_error: 5.7253e-05\n",
      "Epoch 25/1000\n",
      "34452/34452 [==============================] - 4s 122us/step - loss: 3.0365e-05 - mean_squared_error: 2.8080e-05 - val_loss: 5.9538e-05 - val_mean_squared_error: 5.7253e-05\n",
      "Epoch 26/1000\n",
      "34452/34452 [==============================] - 5s 143us/step - loss: 3.0365e-05 - mean_squared_error: 2.8080e-05 - val_loss: 5.9538e-05 - val_mean_squared_error: 5.7253e-05\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "Epoch 27/1000\n",
      "34452/34452 [==============================] - 5s 131us/step - loss: 3.0365e-05 - mean_squared_error: 2.8080e-05 - val_loss: 5.9538e-05 - val_mean_squared_error: 5.7253e-05\n",
      "Epoch 28/1000\n",
      "34452/34452 [==============================] - 5s 133us/step - loss: 3.0365e-05 - mean_squared_error: 2.8080e-05 - val_loss: 5.9538e-05 - val_mean_squared_error: 5.7253e-05\n",
      "Epoch 29/1000\n",
      "34452/34452 [==============================] - 5s 138us/step - loss: 3.0365e-05 - mean_squared_error: 2.8080e-05 - val_loss: 5.9538e-05 - val_mean_squared_error: 5.7253e-05\n",
      "Epoch 00029: early stopping\n",
      "Train on 34452 samples, validate on 8636 samples\n",
      "Epoch 1/1000\n",
      "34452/34452 [==============================] - 4s 129us/step - loss: 3.9573e-05 - mean_squared_error: 3.3447e-05 - val_loss: 6.3287e-05 - val_mean_squared_error: 5.7645e-05\n",
      "Epoch 2/1000\n",
      "34452/34452 [==============================] - 5s 144us/step - loss: 3.6905e-05 - mean_squared_error: 3.2087e-05 - val_loss: 6.5597e-05 - val_mean_squared_error: 6.1169e-05\n",
      "Epoch 3/1000\n",
      "34452/34452 [==============================] - 4s 120us/step - loss: 3.6902e-05 - mean_squared_error: 3.2013e-05 - val_loss: 6.7061e-05 - val_mean_squared_error: 6.1351e-05\n",
      "Epoch 4/1000\n",
      "34452/34452 [==============================] - 4s 110us/step - loss: 3.7184e-05 - mean_squared_error: 3.2084e-05 - val_loss: 6.5418e-05 - val_mean_squared_error: 6.0718e-05\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 5/1000\n",
      "34452/34452 [==============================] - 4s 118us/step - loss: 3.1686e-05 - mean_squared_error: 2.8896e-05 - val_loss: 6.1153e-05 - val_mean_squared_error: 5.8350e-05\n",
      "Epoch 6/1000\n",
      "34452/34452 [==============================] - 4s 111us/step - loss: 3.1457e-05 - mean_squared_error: 2.8748e-05 - val_loss: 6.0733e-05 - val_mean_squared_error: 5.7913e-05\n",
      "Epoch 7/1000\n",
      "34452/34452 [==============================] - 4s 128us/step - loss: 3.1402e-05 - mean_squared_error: 2.8756e-05 - val_loss: 6.0366e-05 - val_mean_squared_error: 5.7775e-05\n",
      "Epoch 8/1000\n",
      "34452/34452 [==============================] - 6s 174us/step - loss: 3.1268e-05 - mean_squared_error: 2.8704e-05 - val_loss: 6.0430e-05 - val_mean_squared_error: 5.8075e-05\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 9/1000\n",
      "34452/34452 [==============================] - 4s 130us/step - loss: 3.0583e-05 - mean_squared_error: 2.8259e-05 - val_loss: 6.0170e-05 - val_mean_squared_error: 5.7840e-05\n",
      "Epoch 10/1000\n",
      "34452/34452 [==============================] - 4s 110us/step - loss: 3.0524e-05 - mean_squared_error: 2.8182e-05 - val_loss: 5.9971e-05 - val_mean_squared_error: 5.7623e-05\n",
      "Epoch 11/1000\n",
      "34452/34452 [==============================] - 4s 119us/step - loss: 3.0504e-05 - mean_squared_error: 2.8166e-05 - val_loss: 5.9873e-05 - val_mean_squared_error: 5.7541e-05\n",
      "Epoch 12/1000\n",
      "34452/34452 [==============================] - 6s 172us/step - loss: 3.0491e-05 - mean_squared_error: 2.8167e-05 - val_loss: 6.0100e-05 - val_mean_squared_error: 5.7744e-05\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 13/1000\n",
      "34452/34452 [==============================] - 5s 138us/step - loss: 3.0421e-05 - mean_squared_error: 2.8079e-05 - val_loss: 6.0108e-05 - val_mean_squared_error: 5.7775e-05\n",
      "Epoch 14/1000\n",
      "34452/34452 [==============================] - 5s 134us/step - loss: 3.0403e-05 - mean_squared_error: 2.8072e-05 - val_loss: 6.0055e-05 - val_mean_squared_error: 5.7730e-05\n",
      "Epoch 15/1000\n",
      "34452/34452 [==============================] - 5s 133us/step - loss: 3.0399e-05 - mean_squared_error: 2.8074e-05 - val_loss: 6.0025e-05 - val_mean_squared_error: 5.7701e-05\n",
      "Epoch 16/1000\n",
      "34452/34452 [==============================] - 5s 142us/step - loss: 3.0395e-05 - mean_squared_error: 2.8075e-05 - val_loss: 6.0011e-05 - val_mean_squared_error: 5.7691e-05\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 17/1000\n",
      "34452/34452 [==============================] - 4s 122us/step - loss: 3.0384e-05 - mean_squared_error: 2.8066e-05 - val_loss: 6.0014e-05 - val_mean_squared_error: 5.7696e-05\n",
      "Epoch 18/1000\n",
      "34452/34452 [==============================] - 5s 145us/step - loss: 3.0384e-05 - mean_squared_error: 2.8066e-05 - val_loss: 6.0016e-05 - val_mean_squared_error: 5.7698e-05\n",
      "Epoch 19/1000\n",
      "34452/34452 [==============================] - 4s 115us/step - loss: 3.0383e-05 - mean_squared_error: 2.8066e-05 - val_loss: 6.0019e-05 - val_mean_squared_error: 5.7702e-05\n",
      "Epoch 20/1000\n",
      "34452/34452 [==============================] - 4s 115us/step - loss: 3.0383e-05 - mean_squared_error: 2.8066e-05 - val_loss: 6.0022e-05 - val_mean_squared_error: 5.7705e-05\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "Epoch 21/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34452/34452 [==============================] - 5s 136us/step - loss: 3.0382e-05 - mean_squared_error: 2.8065e-05 - val_loss: 6.0022e-05 - val_mean_squared_error: 5.7705e-05\n",
      "Epoch 22/1000\n",
      "34452/34452 [==============================] - 6s 165us/step - loss: 3.0382e-05 - mean_squared_error: 2.8065e-05 - val_loss: 6.0022e-05 - val_mean_squared_error: 5.7705e-05\n",
      "Epoch 23/1000\n",
      "34452/34452 [==============================] - 4s 123us/step - loss: 3.0382e-05 - mean_squared_error: 2.8065e-05 - val_loss: 6.0022e-05 - val_mean_squared_error: 5.7705e-05\n",
      "Epoch 24/1000\n",
      "34452/34452 [==============================] - 4s 105us/step - loss: 3.0381e-05 - mean_squared_error: 2.8065e-05 - val_loss: 6.0022e-05 - val_mean_squared_error: 5.7705e-05\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "Epoch 25/1000\n",
      "34452/34452 [==============================] - 4s 117us/step - loss: 3.0381e-05 - mean_squared_error: 2.8065e-05 - val_loss: 6.0022e-05 - val_mean_squared_error: 5.7705e-05\n",
      "Epoch 26/1000\n",
      "34452/34452 [==============================] - 6s 171us/step - loss: 3.0381e-05 - mean_squared_error: 2.8065e-05 - val_loss: 6.0022e-05 - val_mean_squared_error: 5.7705e-05\n",
      "Epoch 27/1000\n",
      "34452/34452 [==============================] - 5s 137us/step - loss: 3.0381e-05 - mean_squared_error: 2.8065e-05 - val_loss: 6.0022e-05 - val_mean_squared_error: 5.7705e-05\n",
      "Epoch 28/1000\n",
      "34452/34452 [==============================] - 4s 112us/step - loss: 3.0381e-05 - mean_squared_error: 2.8065e-05 - val_loss: 6.0022e-05 - val_mean_squared_error: 5.7705e-05\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "Epoch 29/1000\n",
      "34452/34452 [==============================] - 4s 112us/step - loss: 3.0381e-05 - mean_squared_error: 2.8065e-05 - val_loss: 6.0022e-05 - val_mean_squared_error: 5.7705e-05\n",
      "Epoch 30/1000\n",
      "34452/34452 [==============================] - 4s 114us/step - loss: 3.0381e-05 - mean_squared_error: 2.8065e-05 - val_loss: 6.0022e-05 - val_mean_squared_error: 5.7705e-05\n",
      "Epoch 31/1000\n",
      "34452/34452 [==============================] - 4s 112us/step - loss: 3.0381e-05 - mean_squared_error: 2.8065e-05 - val_loss: 6.0022e-05 - val_mean_squared_error: 5.7705e-05\n",
      "Epoch 00031: early stopping\n",
      "Train on 34452 samples, validate on 8636 samples\n",
      "Epoch 1/1000\n",
      "34452/34452 [==============================] - 5s 146us/step - loss: 3.8750e-05 - mean_squared_error: 3.2811e-05 - val_loss: 6.8806e-05 - val_mean_squared_error: 6.4330e-05\n",
      "Epoch 2/1000\n",
      "34452/34452 [==============================] - 6s 163us/step - loss: 3.7349e-05 - mean_squared_error: 3.2100e-05 - val_loss: 6.2265e-05 - val_mean_squared_error: 5.8311e-05\n",
      "Epoch 3/1000\n",
      "34452/34452 [==============================] - 4s 119us/step - loss: 3.6660e-05 - mean_squared_error: 3.1863e-05 - val_loss: 6.3587e-05 - val_mean_squared_error: 5.9072e-05\n",
      "Epoch 4/1000\n",
      "34452/34452 [==============================] - 5s 143us/step - loss: 3.7150e-05 - mean_squared_error: 3.2065e-05 - val_loss: 6.6645e-05 - val_mean_squared_error: 6.1349e-05\n",
      "Epoch 5/1000\n",
      "34452/34452 [==============================] - 5s 131us/step - loss: 3.6941e-05 - mean_squared_error: 3.1988e-05 - val_loss: 6.4034e-05 - val_mean_squared_error: 5.9233e-05\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 6/1000\n",
      "34452/34452 [==============================] - 5s 134us/step - loss: 3.1580e-05 - mean_squared_error: 2.8753e-05 - val_loss: 6.0364e-05 - val_mean_squared_error: 5.7607e-05\n",
      "Epoch 7/1000\n",
      "34452/34452 [==============================] - 5s 136us/step - loss: 3.1403e-05 - mean_squared_error: 2.8658e-05 - val_loss: 5.9888e-05 - val_mean_squared_error: 5.7231e-05\n",
      "Epoch 8/1000\n",
      "34452/34452 [==============================] - 4s 128us/step - loss: 3.1262e-05 - mean_squared_error: 2.8605e-05 - val_loss: 6.0514e-05 - val_mean_squared_error: 5.7839e-05\n",
      "Epoch 9/1000\n",
      "34452/34452 [==============================] - 4s 111us/step - loss: 3.1098e-05 - mean_squared_error: 2.8498e-05 - val_loss: 6.1085e-05 - val_mean_squared_error: 5.8159e-05\n",
      "Epoch 10/1000\n",
      "34452/34452 [==============================] - 4s 116us/step - loss: 3.1039e-05 - mean_squared_error: 2.8507e-05 - val_loss: 6.0897e-05 - val_mean_squared_error: 5.8413e-05\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 11/1000\n",
      "34452/34452 [==============================] - 4s 110us/step - loss: 3.0345e-05 - mean_squared_error: 2.8001e-05 - val_loss: 5.9759e-05 - val_mean_squared_error: 5.7439e-05\n",
      "Epoch 12/1000\n",
      "34452/34452 [==============================] - 4s 118us/step - loss: 3.0281e-05 - mean_squared_error: 2.7966e-05 - val_loss: 5.9787e-05 - val_mean_squared_error: 5.7468e-05\n",
      "Epoch 13/1000\n",
      "34452/34452 [==============================] - 6s 171us/step - loss: 3.0258e-05 - mean_squared_error: 2.7940e-05 - val_loss: 5.9892e-05 - val_mean_squared_error: 5.7582e-05\n",
      "Epoch 14/1000\n",
      "34452/34452 [==============================] - 5s 140us/step - loss: 3.0230e-05 - mean_squared_error: 2.7921e-05 - val_loss: 6.0187e-05 - val_mean_squared_error: 5.7886e-05\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 15/1000\n",
      "34452/34452 [==============================] - 5s 133us/step - loss: 3.0163e-05 - mean_squared_error: 2.7876e-05 - val_loss: 5.9815e-05 - val_mean_squared_error: 5.7526e-05\n",
      "Epoch 16/1000\n",
      "34452/34452 [==============================] - 4s 130us/step - loss: 3.0145e-05 - mean_squared_error: 2.7858e-05 - val_loss: 5.9774e-05 - val_mean_squared_error: 5.7485e-05\n",
      "Epoch 17/1000\n",
      "34452/34452 [==============================] - 5s 140us/step - loss: 3.0140e-05 - mean_squared_error: 2.7852e-05 - val_loss: 5.9752e-05 - val_mean_squared_error: 5.7465e-05\n",
      "Epoch 18/1000\n",
      "34452/34452 [==============================] - 4s 125us/step - loss: 3.0136e-05 - mean_squared_error: 2.7849e-05 - val_loss: 5.9777e-05 - val_mean_squared_error: 5.7487e-05\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 19/1000\n",
      "34452/34452 [==============================] - 4s 110us/step - loss: 3.0125e-05 - mean_squared_error: 2.7835e-05 - val_loss: 5.9777e-05 - val_mean_squared_error: 5.7488e-05\n",
      "Epoch 20/1000\n",
      "34452/34452 [==============================] - 4s 121us/step - loss: 3.0124e-05 - mean_squared_error: 2.7835e-05 - val_loss: 5.9780e-05 - val_mean_squared_error: 5.7491e-05\n",
      "Epoch 21/1000\n",
      "34452/34452 [==============================] - 4s 111us/step - loss: 3.0124e-05 - mean_squared_error: 2.7836e-05 - val_loss: 5.9779e-05 - val_mean_squared_error: 5.7491e-05\n",
      "Epoch 22/1000\n",
      "34452/34452 [==============================] - 4s 119us/step - loss: 3.0123e-05 - mean_squared_error: 2.7835e-05 - val_loss: 5.9782e-05 - val_mean_squared_error: 5.7494e-05\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "Epoch 23/1000\n",
      "34452/34452 [==============================] - 6s 183us/step - loss: 3.0122e-05 - mean_squared_error: 2.7834e-05 - val_loss: 5.9781e-05 - val_mean_squared_error: 5.7494e-05\n",
      "Epoch 24/1000\n",
      "34452/34452 [==============================] - 5s 134us/step - loss: 3.0122e-05 - mean_squared_error: 2.7834e-05 - val_loss: 5.9781e-05 - val_mean_squared_error: 5.7493e-05\n",
      "Epoch 25/1000\n",
      "34452/34452 [==============================] - 5s 139us/step - loss: 3.0122e-05 - mean_squared_error: 2.7834e-05 - val_loss: 5.9781e-05 - val_mean_squared_error: 5.7493e-05\n",
      "Epoch 26/1000\n",
      "34452/34452 [==============================] - 4s 126us/step - loss: 3.0122e-05 - mean_squared_error: 2.7834e-05 - val_loss: 5.9781e-05 - val_mean_squared_error: 5.7493e-05\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "Epoch 27/1000\n",
      "34452/34452 [==============================] - 5s 144us/step - loss: 3.0122e-05 - mean_squared_error: 2.7834e-05 - val_loss: 5.9781e-05 - val_mean_squared_error: 5.7493e-05\n",
      "Epoch 00027: early stopping\n",
      "Train on 34452 samples, validate on 8636 samples\n",
      "Epoch 1/1000\n",
      "34452/34452 [==============================] - 4s 128us/step - loss: 3.9123e-05 - mean_squared_error: 3.2867e-05 - val_loss: 6.3715e-05 - val_mean_squared_error: 6.0191e-05\n",
      "Epoch 2/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34452/34452 [==============================] - 5s 136us/step - loss: 3.7020e-05 - mean_squared_error: 3.2008e-05 - val_loss: 6.3065e-05 - val_mean_squared_error: 5.8471e-05\n",
      "Epoch 3/1000\n",
      "34452/34452 [==============================] - 5s 132us/step - loss: 3.6639e-05 - mean_squared_error: 3.1762e-05 - val_loss: 6.4684e-05 - val_mean_squared_error: 5.9681e-05\n",
      "Epoch 4/1000\n",
      "34452/34452 [==============================] - 4s 129us/step - loss: 3.6744e-05 - mean_squared_error: 3.1772e-05 - val_loss: 6.5988e-05 - val_mean_squared_error: 6.0968e-05\n",
      "Epoch 5/1000\n",
      "34452/34452 [==============================] - 5s 139us/step - loss: 3.6715e-05 - mean_squared_error: 3.1784e-05 - val_loss: 6.3347e-05 - val_mean_squared_error: 5.9378e-05\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 6/1000\n",
      "34452/34452 [==============================] - 4s 120us/step - loss: 3.1410e-05 - mean_squared_error: 2.8681e-05 - val_loss: 5.9652e-05 - val_mean_squared_error: 5.7018e-05\n",
      "Epoch 7/1000\n",
      "34452/34452 [==============================] - 5s 141us/step - loss: 3.1216e-05 - mean_squared_error: 2.8563e-05 - val_loss: 6.0643e-05 - val_mean_squared_error: 5.7889e-05\n",
      "Epoch 8/1000\n",
      "34452/34452 [==============================] - 4s 116us/step - loss: 3.1067e-05 - mean_squared_error: 2.8458e-05 - val_loss: 6.0393e-05 - val_mean_squared_error: 5.7682e-05\n",
      "Epoch 9/1000\n",
      "34452/34452 [==============================] - 4s 107us/step - loss: 3.0998e-05 - mean_squared_error: 2.8458e-05 - val_loss: 5.9851e-05 - val_mean_squared_error: 5.7316e-05\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 10/1000\n",
      "34452/34452 [==============================] - 4s 126us/step - loss: 3.0333e-05 - mean_squared_error: 2.7990e-05 - val_loss: 6.0131e-05 - val_mean_squared_error: 5.7800e-05\n",
      "Epoch 11/1000\n",
      "34452/34452 [==============================] - 6s 177us/step - loss: 3.0273e-05 - mean_squared_error: 2.7946e-05 - val_loss: 5.9577e-05 - val_mean_squared_error: 5.7269e-05\n",
      "Epoch 12/1000\n",
      "34452/34452 [==============================] - 4s 127us/step - loss: 3.0251e-05 - mean_squared_error: 2.7936e-05 - val_loss: 5.9877e-05 - val_mean_squared_error: 5.7560e-05\n",
      "Epoch 13/1000\n",
      "34452/34452 [==============================] - 5s 141us/step - loss: 3.0222e-05 - mean_squared_error: 2.7911e-05 - val_loss: 5.9754e-05 - val_mean_squared_error: 5.7430e-05\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 14/1000\n",
      "34452/34452 [==============================] - 4s 122us/step - loss: 3.0167e-05 - mean_squared_error: 2.7859e-05 - val_loss: 5.9833e-05 - val_mean_squared_error: 5.7531e-05\n",
      "Epoch 15/1000\n",
      "34452/34452 [==============================] - 5s 143us/step - loss: 3.0147e-05 - mean_squared_error: 2.7847e-05 - val_loss: 5.9759e-05 - val_mean_squared_error: 5.7459e-05\n",
      "Epoch 16/1000\n",
      "34452/34452 [==============================] - 4s 128us/step - loss: 3.0142e-05 - mean_squared_error: 2.7845e-05 - val_loss: 5.9829e-05 - val_mean_squared_error: 5.7531e-05\n",
      "Epoch 17/1000\n",
      "34452/34452 [==============================] - 5s 135us/step - loss: 3.0138e-05 - mean_squared_error: 2.7844e-05 - val_loss: 5.9808e-05 - val_mean_squared_error: 5.7513e-05\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 18/1000\n",
      "34452/34452 [==============================] - 5s 136us/step - loss: 3.0127e-05 - mean_squared_error: 2.7832e-05 - val_loss: 5.9808e-05 - val_mean_squared_error: 5.7513e-05\n",
      "Epoch 19/1000\n",
      "34452/34452 [==============================] - 4s 127us/step - loss: 3.0126e-05 - mean_squared_error: 2.7831e-05 - val_loss: 5.9810e-05 - val_mean_squared_error: 5.7516e-05\n",
      "Epoch 20/1000\n",
      "34452/34452 [==============================] - 5s 146us/step - loss: 3.0126e-05 - mean_squared_error: 2.7831e-05 - val_loss: 5.9810e-05 - val_mean_squared_error: 5.7516e-05\n",
      "Epoch 21/1000\n",
      "34452/34452 [==============================] - 4s 126us/step - loss: 3.0125e-05 - mean_squared_error: 2.7831e-05 - val_loss: 5.9811e-05 - val_mean_squared_error: 5.7517e-05\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "Epoch 22/1000\n",
      "34452/34452 [==============================] - 5s 140us/step - loss: 3.0124e-05 - mean_squared_error: 2.7830e-05 - val_loss: 5.9811e-05 - val_mean_squared_error: 5.7517e-05\n",
      "Epoch 23/1000\n",
      "34452/34452 [==============================] - 5s 135us/step - loss: 3.0124e-05 - mean_squared_error: 2.7830e-05 - val_loss: 5.9811e-05 - val_mean_squared_error: 5.7517e-05\n",
      "Epoch 24/1000\n",
      "34452/34452 [==============================] - 5s 131us/step - loss: 3.0124e-05 - mean_squared_error: 2.7830e-05 - val_loss: 5.9811e-05 - val_mean_squared_error: 5.7517e-05\n",
      "Epoch 25/1000\n",
      "34452/34452 [==============================] - 5s 139us/step - loss: 3.0124e-05 - mean_squared_error: 2.7830e-05 - val_loss: 5.9811e-05 - val_mean_squared_error: 5.7517e-05\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "Epoch 26/1000\n",
      "34452/34452 [==============================] - 4s 124us/step - loss: 3.0124e-05 - mean_squared_error: 2.7829e-05 - val_loss: 5.9811e-05 - val_mean_squared_error: 5.7517e-05\n",
      "Epoch 00026: early stopping\n",
      "Train on 34452 samples, validate on 8636 samples\n",
      "Epoch 1/1000\n",
      "34452/34452 [==============================] - 5s 145us/step - loss: 3.8467e-05 - mean_squared_error: 3.2505e-05 - val_loss: 6.2207e-05 - val_mean_squared_error: 5.8483e-05\n",
      "Epoch 2/1000\n",
      "34452/34452 [==============================] - 4s 127us/step - loss: 3.6568e-05 - mean_squared_error: 3.1774e-05 - val_loss: 7.1702e-05 - val_mean_squared_error: 6.6882e-05\n",
      "Epoch 3/1000\n",
      "34452/34452 [==============================] - 5s 139us/step - loss: 3.6474e-05 - mean_squared_error: 3.1591e-05 - val_loss: 6.5727e-05 - val_mean_squared_error: 5.9869e-05\n",
      "Epoch 4/1000\n",
      "34452/34452 [==============================] - 5s 133us/step - loss: 3.6699e-05 - mean_squared_error: 3.1761e-05 - val_loss: 6.6334e-05 - val_mean_squared_error: 6.1411e-05\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 5/1000\n",
      "34452/34452 [==============================] - 5s 131us/step - loss: 3.1343e-05 - mean_squared_error: 2.8557e-05 - val_loss: 6.0978e-05 - val_mean_squared_error: 5.8172e-05\n",
      "Epoch 6/1000\n",
      "34452/34452 [==============================] - 5s 143us/step - loss: 3.1155e-05 - mean_squared_error: 2.8462e-05 - val_loss: 6.1351e-05 - val_mean_squared_error: 5.8762e-05\n",
      "Epoch 7/1000\n",
      "34452/34452 [==============================] - 4s 125us/step - loss: 3.0985e-05 - mean_squared_error: 2.8385e-05 - val_loss: 6.0893e-05 - val_mean_squared_error: 5.8171e-05\n",
      "Epoch 8/1000\n",
      "34452/34452 [==============================] - 5s 143us/step - loss: 3.0913e-05 - mean_squared_error: 2.8377e-05 - val_loss: 6.0394e-05 - val_mean_squared_error: 5.7850e-05\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 9/1000\n",
      "34452/34452 [==============================] - 5s 132us/step - loss: 3.0236e-05 - mean_squared_error: 2.7869e-05 - val_loss: 6.0164e-05 - val_mean_squared_error: 5.7836e-05\n",
      "Epoch 10/1000\n",
      "34452/34452 [==============================] - 5s 136us/step - loss: 3.0197e-05 - mean_squared_error: 2.7876e-05 - val_loss: 6.0163e-05 - val_mean_squared_error: 5.7843e-05\n",
      "Epoch 11/1000\n",
      "34452/34452 [==============================] - 5s 136us/step - loss: 3.0170e-05 - mean_squared_error: 2.7848e-05 - val_loss: 6.0059e-05 - val_mean_squared_error: 5.7722e-05\n",
      "Epoch 12/1000\n",
      "34452/34452 [==============================] - 4s 128us/step - loss: 3.0146e-05 - mean_squared_error: 2.7836e-05 - val_loss: 6.0059e-05 - val_mean_squared_error: 5.7737e-05\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 13/1000\n",
      "34452/34452 [==============================] - 5s 146us/step - loss: 3.0082e-05 - mean_squared_error: 2.7776e-05 - val_loss: 5.9986e-05 - val_mean_squared_error: 5.7681e-05\n",
      "Epoch 14/1000\n",
      "34452/34452 [==============================] - 4s 125us/step - loss: 3.0065e-05 - mean_squared_error: 2.7764e-05 - val_loss: 5.9940e-05 - val_mean_squared_error: 5.7639e-05\n",
      "Epoch 15/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34452/34452 [==============================] - 5s 141us/step - loss: 3.0059e-05 - mean_squared_error: 2.7762e-05 - val_loss: 5.9977e-05 - val_mean_squared_error: 5.7683e-05\n",
      "Epoch 16/1000\n",
      "34452/34452 [==============================] - 4s 127us/step - loss: 3.0056e-05 - mean_squared_error: 2.7761e-05 - val_loss: 5.9936e-05 - val_mean_squared_error: 5.7639e-05\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 17/1000\n",
      "34452/34452 [==============================] - 5s 134us/step - loss: 3.0045e-05 - mean_squared_error: 2.7749e-05 - val_loss: 5.9934e-05 - val_mean_squared_error: 5.7639e-05\n",
      "Epoch 18/1000\n",
      "34452/34452 [==============================] - 5s 136us/step - loss: 3.0044e-05 - mean_squared_error: 2.7750e-05 - val_loss: 5.9935e-05 - val_mean_squared_error: 5.7640e-05\n",
      "Epoch 19/1000\n",
      "34452/34452 [==============================] - 4s 124us/step - loss: 3.0044e-05 - mean_squared_error: 2.7750e-05 - val_loss: 5.9935e-05 - val_mean_squared_error: 5.7641e-05\n",
      "Epoch 20/1000\n",
      "34452/34452 [==============================] - 5s 144us/step - loss: 3.0044e-05 - mean_squared_error: 2.7750e-05 - val_loss: 5.9933e-05 - val_mean_squared_error: 5.7640e-05\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "Epoch 21/1000\n",
      "34452/34452 [==============================] - 4s 124us/step - loss: 3.0042e-05 - mean_squared_error: 2.7749e-05 - val_loss: 5.9933e-05 - val_mean_squared_error: 5.7640e-05\n",
      "Epoch 22/1000\n",
      "34452/34452 [==============================] - 5s 139us/step - loss: 3.0042e-05 - mean_squared_error: 2.7749e-05 - val_loss: 5.9933e-05 - val_mean_squared_error: 5.7639e-05\n",
      "Epoch 23/1000\n",
      "34452/34452 [==============================] - 5s 131us/step - loss: 3.0042e-05 - mean_squared_error: 2.7749e-05 - val_loss: 5.9933e-05 - val_mean_squared_error: 5.7639e-05\n",
      "Epoch 24/1000\n",
      "34452/34452 [==============================] - 5s 133us/step - loss: 3.0042e-05 - mean_squared_error: 2.7749e-05 - val_loss: 5.9933e-05 - val_mean_squared_error: 5.7639e-05\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "Epoch 25/1000\n",
      "34452/34452 [==============================] - 5s 137us/step - loss: 3.0042e-05 - mean_squared_error: 2.7748e-05 - val_loss: 5.9933e-05 - val_mean_squared_error: 5.7639e-05\n",
      "Epoch 26/1000\n",
      "34452/34452 [==============================] - 4s 125us/step - loss: 3.0042e-05 - mean_squared_error: 2.7749e-05 - val_loss: 5.9933e-05 - val_mean_squared_error: 5.7639e-05\n",
      "Epoch 27/1000\n",
      "34452/34452 [==============================] - 5s 143us/step - loss: 3.0042e-05 - mean_squared_error: 2.7749e-05 - val_loss: 5.9933e-05 - val_mean_squared_error: 5.7639e-05\n",
      "Epoch 28/1000\n",
      "34452/34452 [==============================] - 4s 125us/step - loss: 3.0042e-05 - mean_squared_error: 2.7749e-05 - val_loss: 5.9933e-05 - val_mean_squared_error: 5.7639e-05\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "Epoch 29/1000\n",
      "34452/34452 [==============================] - 5s 139us/step - loss: 3.0042e-05 - mean_squared_error: 2.7748e-05 - val_loss: 5.9933e-05 - val_mean_squared_error: 5.7639e-05\n",
      "Epoch 30/1000\n",
      "34452/34452 [==============================] - 4s 114us/step - loss: 3.0042e-05 - mean_squared_error: 2.7748e-05 - val_loss: 5.9933e-05 - val_mean_squared_error: 5.7639e-05\n",
      "Epoch 31/1000\n",
      "34452/34452 [==============================] - 4s 114us/step - loss: 3.0042e-05 - mean_squared_error: 2.7748e-05 - val_loss: 5.9933e-05 - val_mean_squared_error: 5.7639e-05\n",
      "Epoch 32/1000\n",
      "34452/34452 [==============================] - 5s 148us/step - loss: 3.0042e-05 - mean_squared_error: 2.7748e-05 - val_loss: 5.9933e-05 - val_mean_squared_error: 5.7639e-05\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
      "Epoch 33/1000\n",
      "34452/34452 [==============================] - 6s 164us/step - loss: 3.0042e-05 - mean_squared_error: 2.7748e-05 - val_loss: 5.9933e-05 - val_mean_squared_error: 5.7639e-05\n",
      "Epoch 34/1000\n",
      "34452/34452 [==============================] - 4s 123us/step - loss: 3.0042e-05 - mean_squared_error: 2.7748e-05 - val_loss: 5.9933e-05 - val_mean_squared_error: 5.7639e-05\n",
      "Epoch 00034: early stopping\n",
      "Train on 34452 samples, validate on 8636 samples\n",
      "Epoch 1/1000\n",
      "34452/34452 [==============================] - 5s 142us/step - loss: 3.8401e-05 - mean_squared_error: 3.2405e-05 - val_loss: 6.4176e-05 - val_mean_squared_error: 5.9789e-05\n",
      "Epoch 2/1000\n",
      "34452/34452 [==============================] - 4s 129us/step - loss: 3.6691e-05 - mean_squared_error: 3.1756e-05 - val_loss: 6.4093e-05 - val_mean_squared_error: 5.9694e-05\n",
      "Epoch 3/1000\n",
      "34452/34452 [==============================] - 5s 134us/step - loss: 3.6253e-05 - mean_squared_error: 3.1485e-05 - val_loss: 6.6651e-05 - val_mean_squared_error: 6.2894e-05\n",
      "Epoch 4/1000\n",
      "34452/34452 [==============================] - 5s 139us/step - loss: 3.6598e-05 - mean_squared_error: 3.1643e-05 - val_loss: 6.4075e-05 - val_mean_squared_error: 5.9378e-05\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 5/1000\n",
      "34452/34452 [==============================] - 4s 128us/step - loss: 3.1194e-05 - mean_squared_error: 2.8469e-05 - val_loss: 6.0700e-05 - val_mean_squared_error: 5.8068e-05\n",
      "Epoch 6/1000\n",
      "34452/34452 [==============================] - 5s 146us/step - loss: 3.0983e-05 - mean_squared_error: 2.8351e-05 - val_loss: 6.1359e-05 - val_mean_squared_error: 5.8796e-05\n",
      "Epoch 7/1000\n",
      "34452/34452 [==============================] - 4s 126us/step - loss: 3.0859e-05 - mean_squared_error: 2.8288e-05 - val_loss: 6.0259e-05 - val_mean_squared_error: 5.7732e-05\n",
      "Epoch 8/1000\n",
      "34452/34452 [==============================] - 5s 138us/step - loss: 3.0763e-05 - mean_squared_error: 2.8269e-05 - val_loss: 6.0754e-05 - val_mean_squared_error: 5.8204e-05\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 9/1000\n",
      "34452/34452 [==============================] - 5s 137us/step - loss: 3.0095e-05 - mean_squared_error: 2.7753e-05 - val_loss: 6.0414e-05 - val_mean_squared_error: 5.8119e-05\n",
      "Epoch 10/1000\n",
      "34452/34452 [==============================] - 4s 130us/step - loss: 3.0060e-05 - mean_squared_error: 2.7741e-05 - val_loss: 6.0172e-05 - val_mean_squared_error: 5.7892e-05\n",
      "Epoch 11/1000\n",
      "34452/34452 [==============================] - 5s 145us/step - loss: 3.0032e-05 - mean_squared_error: 2.7733e-05 - val_loss: 6.0165e-05 - val_mean_squared_error: 5.7878e-05\n",
      "Epoch 12/1000\n",
      "34452/34452 [==============================] - 8s 224us/step - loss: 3.0015e-05 - mean_squared_error: 2.7719e-05 - val_loss: 5.9951e-05 - val_mean_squared_error: 5.7655e-05\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 13/1000\n",
      "34452/34452 [==============================] - 5s 152us/step - loss: 2.9947e-05 - mean_squared_error: 2.7665e-05 - val_loss: 6.0183e-05 - val_mean_squared_error: 5.7905e-05\n",
      "Epoch 14/1000\n",
      "34452/34452 [==============================] - 4s 129us/step - loss: 2.9929e-05 - mean_squared_error: 2.7651e-05 - val_loss: 6.0217e-05 - val_mean_squared_error: 5.7939e-05\n",
      "Epoch 15/1000\n",
      "34452/34452 [==============================] - 5s 136us/step - loss: 2.9924e-05 - mean_squared_error: 2.7645e-05 - val_loss: 6.0237e-05 - val_mean_squared_error: 5.7958e-05\n",
      "Epoch 16/1000\n",
      "34452/34452 [==============================] - 5s 136us/step - loss: 2.9920e-05 - mean_squared_error: 2.7641e-05 - val_loss: 6.0276e-05 - val_mean_squared_error: 5.7999e-05\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 17/1000\n",
      "34452/34452 [==============================] - 5s 132us/step - loss: 2.9910e-05 - mean_squared_error: 2.7633e-05 - val_loss: 6.0265e-05 - val_mean_squared_error: 5.7988e-05\n",
      "Epoch 18/1000\n",
      "34452/34452 [==============================] - 5s 145us/step - loss: 2.9909e-05 - mean_squared_error: 2.7632e-05 - val_loss: 6.0255e-05 - val_mean_squared_error: 5.7978e-05\n",
      "Epoch 19/1000\n",
      "34452/34452 [==============================] - 4s 129us/step - loss: 2.9909e-05 - mean_squared_error: 2.7632e-05 - val_loss: 6.0250e-05 - val_mean_squared_error: 5.7973e-05\n",
      "Epoch 20/1000\n",
      "34452/34452 [==============================] - 5s 142us/step - loss: 2.9908e-05 - mean_squared_error: 2.7631e-05 - val_loss: 6.0244e-05 - val_mean_squared_error: 5.7967e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "Epoch 21/1000\n",
      "34452/34452 [==============================] - 5s 132us/step - loss: 2.9907e-05 - mean_squared_error: 2.7630e-05 - val_loss: 6.0244e-05 - val_mean_squared_error: 5.7967e-05\n",
      "Epoch 22/1000\n",
      "34452/34452 [==============================] - 4s 130us/step - loss: 2.9907e-05 - mean_squared_error: 2.7630e-05 - val_loss: 6.0243e-05 - val_mean_squared_error: 5.7966e-05\n",
      "Epoch 23/1000\n",
      "34452/34452 [==============================] - 4s 108us/step - loss: 2.9907e-05 - mean_squared_error: 2.7630e-05 - val_loss: 6.0243e-05 - val_mean_squared_error: 5.7966e-05\n",
      "Epoch 24/1000\n",
      "34452/34452 [==============================] - 4s 113us/step - loss: 2.9907e-05 - mean_squared_error: 2.7629e-05 - val_loss: 6.0242e-05 - val_mean_squared_error: 5.7965e-05\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "Epoch 25/1000\n",
      "34452/34452 [==============================] - 6s 162us/step - loss: 2.9907e-05 - mean_squared_error: 2.7629e-05 - val_loss: 6.0242e-05 - val_mean_squared_error: 5.7965e-05\n",
      "Epoch 26/1000\n",
      "34452/34452 [==============================] - 5s 146us/step - loss: 2.9907e-05 - mean_squared_error: 2.7629e-05 - val_loss: 6.0242e-05 - val_mean_squared_error: 5.7965e-05\n",
      "Epoch 27/1000\n",
      "34452/34452 [==============================] - 4s 124us/step - loss: 2.9907e-05 - mean_squared_error: 2.7629e-05 - val_loss: 6.0242e-05 - val_mean_squared_error: 5.7965e-05\n",
      "Epoch 28/1000\n",
      "34452/34452 [==============================] - 5s 138us/step - loss: 2.9907e-05 - mean_squared_error: 2.7629e-05 - val_loss: 6.0242e-05 - val_mean_squared_error: 5.7965e-05\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "Epoch 29/1000\n",
      "34452/34452 [==============================] - 5s 131us/step - loss: 2.9907e-05 - mean_squared_error: 2.7629e-05 - val_loss: 6.0242e-05 - val_mean_squared_error: 5.7965e-05\n",
      "Epoch 30/1000\n",
      "34452/34452 [==============================] - 4s 130us/step - loss: 2.9907e-05 - mean_squared_error: 2.7629e-05 - val_loss: 6.0242e-05 - val_mean_squared_error: 5.7965e-05\n",
      "Epoch 31/1000\n",
      "34452/34452 [==============================] - 5s 140us/step - loss: 2.9907e-05 - mean_squared_error: 2.7629e-05 - val_loss: 6.0242e-05 - val_mean_squared_error: 5.7965e-05\n",
      "Epoch 32/1000\n",
      "34452/34452 [==============================] - 4s 121us/step - loss: 2.9907e-05 - mean_squared_error: 2.7629e-05 - val_loss: 6.0242e-05 - val_mean_squared_error: 5.7965e-05\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
      "Epoch 00032: early stopping\n",
      "Train on 34452 samples, validate on 8636 samples\n",
      "Epoch 1/1000\n",
      "34452/34452 [==============================] - 5s 145us/step - loss: 3.8833e-05 - mean_squared_error: 3.2641e-05 - val_loss: 6.4658e-05 - val_mean_squared_error: 5.9906e-05\n",
      "Epoch 2/1000\n",
      "34452/34452 [==============================] - 4s 127us/step - loss: 3.6539e-05 - mean_squared_error: 3.1589e-05 - val_loss: 6.4842e-05 - val_mean_squared_error: 6.1029e-05\n",
      "Epoch 3/1000\n",
      "34452/34452 [==============================] - 5s 137us/step - loss: 3.6158e-05 - mean_squared_error: 3.1359e-05 - val_loss: 6.7855e-05 - val_mean_squared_error: 6.2497e-05\n",
      "Epoch 4/1000\n",
      "34452/34452 [==============================] - 5s 134us/step - loss: 3.6460e-05 - mean_squared_error: 3.1487e-05 - val_loss: 6.8214e-05 - val_mean_squared_error: 6.4049e-05\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 5/1000\n",
      "34452/34452 [==============================] - 5s 131us/step - loss: 3.1087e-05 - mean_squared_error: 2.8403e-05 - val_loss: 6.1418e-05 - val_mean_squared_error: 5.8752e-05\n",
      "Epoch 6/1000\n",
      "34452/34452 [==============================] - 5s 142us/step - loss: 3.0897e-05 - mean_squared_error: 2.8268e-05 - val_loss: 6.0809e-05 - val_mean_squared_error: 5.8228e-05\n",
      "Epoch 7/1000\n",
      "34452/34452 [==============================] - 8s 226us/step - loss: 3.0808e-05 - mean_squared_error: 2.8238e-05 - val_loss: 6.1062e-05 - val_mean_squared_error: 5.8563e-05\n",
      "Epoch 8/1000\n",
      "34452/34452 [==============================] - 5s 149us/step - loss: 3.0699e-05 - mean_squared_error: 2.8204e-05 - val_loss: 6.1444e-05 - val_mean_squared_error: 5.9058e-05\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 9/1000\n",
      "34452/34452 [==============================] - 4s 119us/step - loss: 3.0032e-05 - mean_squared_error: 2.7751e-05 - val_loss: 6.0183e-05 - val_mean_squared_error: 5.7876e-05\n",
      "Epoch 10/1000\n",
      "34452/34452 [==============================] - 4s 109us/step - loss: 2.9987e-05 - mean_squared_error: 2.7692e-05 - val_loss: 6.0662e-05 - val_mean_squared_error: 5.8376e-05\n",
      "Epoch 11/1000\n",
      "34452/34452 [==============================] - 4s 114us/step - loss: 2.9970e-05 - mean_squared_error: 2.7673e-05 - val_loss: 6.0144e-05 - val_mean_squared_error: 5.7870e-05\n",
      "Epoch 12/1000\n",
      "34452/34452 [==============================] - 4s 116us/step - loss: 2.9950e-05 - mean_squared_error: 2.7682e-05 - val_loss: 6.0266e-05 - val_mean_squared_error: 5.7983e-05\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 13/1000\n",
      "34452/34452 [==============================] - 5s 141us/step - loss: 2.9886e-05 - mean_squared_error: 2.7615e-05 - val_loss: 6.0447e-05 - val_mean_squared_error: 5.8176e-05\n",
      "Epoch 14/1000\n",
      "34452/34452 [==============================] - 5s 131us/step - loss: 2.9868e-05 - mean_squared_error: 2.7598e-05 - val_loss: 6.0456e-05 - val_mean_squared_error: 5.8187e-05\n",
      "Epoch 15/1000\n",
      "34452/34452 [==============================] - 5s 135us/step - loss: 2.9863e-05 - mean_squared_error: 2.7595e-05 - val_loss: 6.0436e-05 - val_mean_squared_error: 5.8169e-05\n",
      "Epoch 16/1000\n",
      "34452/34452 [==============================] - 5s 139us/step - loss: 2.9861e-05 - mean_squared_error: 2.7594e-05 - val_loss: 6.0433e-05 - val_mean_squared_error: 5.8167e-05\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 17/1000\n",
      "34452/34452 [==============================] - 4s 126us/step - loss: 2.9850e-05 - mean_squared_error: 2.7584e-05 - val_loss: 6.0438e-05 - val_mean_squared_error: 5.8172e-05\n",
      "Epoch 18/1000\n",
      "34452/34452 [==============================] - 5s 146us/step - loss: 2.9849e-05 - mean_squared_error: 2.7583e-05 - val_loss: 6.0438e-05 - val_mean_squared_error: 5.8173e-05\n",
      "Epoch 19/1000\n",
      "34452/34452 [==============================] - 4s 127us/step - loss: 2.9849e-05 - mean_squared_error: 2.7584e-05 - val_loss: 6.0442e-05 - val_mean_squared_error: 5.8176e-05\n",
      "Epoch 20/1000\n",
      "34452/34452 [==============================] - 5s 139us/step - loss: 2.9848e-05 - mean_squared_error: 2.7583e-05 - val_loss: 6.0442e-05 - val_mean_squared_error: 5.8177e-05\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "Epoch 21/1000\n",
      "34452/34452 [==============================] - 5s 135us/step - loss: 2.9847e-05 - mean_squared_error: 2.7582e-05 - val_loss: 6.0442e-05 - val_mean_squared_error: 5.8177e-05\n",
      "Epoch 22/1000\n",
      "34452/34452 [==============================] - 5s 131us/step - loss: 2.9847e-05 - mean_squared_error: 2.7582e-05 - val_loss: 6.0442e-05 - val_mean_squared_error: 5.8177e-05\n",
      "Epoch 23/1000\n",
      "34452/34452 [==============================] - 5s 144us/step - loss: 2.9847e-05 - mean_squared_error: 2.7582e-05 - val_loss: 6.0442e-05 - val_mean_squared_error: 5.8177e-05\n",
      "Epoch 24/1000\n",
      "34452/34452 [==============================] - 4s 126us/step - loss: 2.9847e-05 - mean_squared_error: 2.7582e-05 - val_loss: 6.0442e-05 - val_mean_squared_error: 5.8177e-05\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "Epoch 25/1000\n",
      "34452/34452 [==============================] - 5s 144us/step - loss: 2.9847e-05 - mean_squared_error: 2.7582e-05 - val_loss: 6.0442e-05 - val_mean_squared_error: 5.8177e-05\n",
      "Epoch 26/1000\n",
      "34452/34452 [==============================] - 5s 133us/step - loss: 2.9847e-05 - mean_squared_error: 2.7582e-05 - val_loss: 6.0442e-05 - val_mean_squared_error: 5.8177e-05\n",
      "Epoch 27/1000\n",
      "34452/34452 [==============================] - 5s 133us/step - loss: 2.9847e-05 - mean_squared_error: 2.7582e-05 - val_loss: 6.0442e-05 - val_mean_squared_error: 5.8177e-05\n",
      "Epoch 28/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34452/34452 [==============================] - 5s 136us/step - loss: 2.9847e-05 - mean_squared_error: 2.7582e-05 - val_loss: 6.0442e-05 - val_mean_squared_error: 5.8177e-05\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "Epoch 29/1000\n",
      "34452/34452 [==============================] - 4s 124us/step - loss: 2.9847e-05 - mean_squared_error: 2.7582e-05 - val_loss: 6.0442e-05 - val_mean_squared_error: 5.8177e-05\n",
      "Epoch 00029: early stopping\n",
      "Train on 34452 samples, validate on 8636 samples\n",
      "Epoch 1/1000\n",
      "34452/34452 [==============================] - 5s 142us/step - loss: 3.8409e-05 - mean_squared_error: 3.2428e-05 - val_loss: 6.4779e-05 - val_mean_squared_error: 6.0340e-05\n",
      "Epoch 2/1000\n",
      "34452/34452 [==============================] - 4s 121us/step - loss: 3.5981e-05 - mean_squared_error: 3.1345e-05 - val_loss: 6.6286e-05 - val_mean_squared_error: 6.2137e-05\n",
      "Epoch 3/1000\n",
      "34452/34452 [==============================] - 5s 140us/step - loss: 3.6341e-05 - mean_squared_error: 3.1425e-05 - val_loss: 6.6857e-05 - val_mean_squared_error: 6.2580e-05\n",
      "Epoch 4/1000\n",
      "34452/34452 [==============================] - 4s 129us/step - loss: 3.6204e-05 - mean_squared_error: 3.1304e-05 - val_loss: 6.6036e-05 - val_mean_squared_error: 6.1777e-05\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 5/1000\n",
      "34452/34452 [==============================] - 5s 131us/step - loss: 3.1010e-05 - mean_squared_error: 2.8308e-05 - val_loss: 6.1119e-05 - val_mean_squared_error: 5.8373e-05\n",
      "Epoch 6/1000\n",
      "34452/34452 [==============================] - 5s 139us/step - loss: 3.0781e-05 - mean_squared_error: 2.8150e-05 - val_loss: 6.0462e-05 - val_mean_squared_error: 5.7945e-05\n",
      "Epoch 7/1000\n",
      "34452/34452 [==============================] - 4s 126us/step - loss: 3.0737e-05 - mean_squared_error: 2.8173e-05 - val_loss: 6.1266e-05 - val_mean_squared_error: 5.8703e-05\n",
      "Epoch 8/1000\n",
      "34452/34452 [==============================] - 5s 143us/step - loss: 3.0579e-05 - mean_squared_error: 2.8095e-05 - val_loss: 6.1806e-05 - val_mean_squared_error: 5.9314e-05\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 9/1000\n",
      "34452/34452 [==============================] - 4s 122us/step - loss: 2.9967e-05 - mean_squared_error: 2.7645e-05 - val_loss: 6.0756e-05 - val_mean_squared_error: 5.8440e-05\n",
      "Epoch 10/1000\n",
      "34452/34452 [==============================] - 5s 141us/step - loss: 2.9913e-05 - mean_squared_error: 2.7614e-05 - val_loss: 6.0331e-05 - val_mean_squared_error: 5.8055e-05\n",
      "Epoch 11/1000\n",
      "34452/34452 [==============================] - 4s 130us/step - loss: 2.9897e-05 - mean_squared_error: 2.7619e-05 - val_loss: 6.0686e-05 - val_mean_squared_error: 5.8409e-05\n",
      "Epoch 12/1000\n",
      "34452/34452 [==============================] - 5s 133us/step - loss: 2.9876e-05 - mean_squared_error: 2.7600e-05 - val_loss: 6.0545e-05 - val_mean_squared_error: 5.8284e-05\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 13/1000\n",
      "34452/34452 [==============================] - 5s 136us/step - loss: 2.9801e-05 - mean_squared_error: 2.7546e-05 - val_loss: 6.0585e-05 - val_mean_squared_error: 5.8327e-05\n",
      "Epoch 14/1000\n",
      "34452/34452 [==============================] - 4s 126us/step - loss: 2.9790e-05 - mean_squared_error: 2.7530e-05 - val_loss: 6.0574e-05 - val_mean_squared_error: 5.8315e-05\n",
      "Epoch 15/1000\n",
      "34452/34452 [==============================] - 5s 143us/step - loss: 2.9787e-05 - mean_squared_error: 2.7528e-05 - val_loss: 6.0555e-05 - val_mean_squared_error: 5.8298e-05\n",
      "Epoch 16/1000\n",
      "34452/34452 [==============================] - 4s 125us/step - loss: 2.9784e-05 - mean_squared_error: 2.7529e-05 - val_loss: 6.0559e-05 - val_mean_squared_error: 5.8303e-05\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 17/1000\n",
      "34452/34452 [==============================] - 7s 191us/step - loss: 2.9774e-05 - mean_squared_error: 2.7518e-05 - val_loss: 6.0554e-05 - val_mean_squared_error: 5.8299e-05\n",
      "Epoch 18/1000\n",
      "34452/34452 [==============================] - 7s 189us/step - loss: 2.9773e-05 - mean_squared_error: 2.7518e-05 - val_loss: 6.0553e-05 - val_mean_squared_error: 5.8298e-05\n",
      "Epoch 19/1000\n",
      "34452/34452 [==============================] - 5s 133us/step - loss: 2.9773e-05 - mean_squared_error: 2.7518e-05 - val_loss: 6.0550e-05 - val_mean_squared_error: 5.8295e-05\n",
      "Epoch 20/1000\n",
      "34452/34452 [==============================] - 5s 140us/step - loss: 2.9772e-05 - mean_squared_error: 2.7518e-05 - val_loss: 6.0549e-05 - val_mean_squared_error: 5.8294e-05\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "Epoch 21/1000\n",
      "34452/34452 [==============================] - 4s 125us/step - loss: 2.9771e-05 - mean_squared_error: 2.7516e-05 - val_loss: 6.0548e-05 - val_mean_squared_error: 5.8294e-05\n",
      "Epoch 22/1000\n",
      "34452/34452 [==============================] - 5s 146us/step - loss: 2.9771e-05 - mean_squared_error: 2.7516e-05 - val_loss: 6.0548e-05 - val_mean_squared_error: 5.8293e-05\n",
      "Epoch 23/1000\n",
      "34452/34452 [==============================] - 4s 126us/step - loss: 2.9771e-05 - mean_squared_error: 2.7516e-05 - val_loss: 6.0548e-05 - val_mean_squared_error: 5.8293e-05\n",
      "Epoch 24/1000\n",
      "34452/34452 [==============================] - 5s 140us/step - loss: 2.9771e-05 - mean_squared_error: 2.7516e-05 - val_loss: 6.0548e-05 - val_mean_squared_error: 5.8293e-05\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "Epoch 25/1000\n",
      "34452/34452 [==============================] - 5s 136us/step - loss: 2.9771e-05 - mean_squared_error: 2.7516e-05 - val_loss: 6.0548e-05 - val_mean_squared_error: 5.8293e-05\n",
      "Epoch 26/1000\n",
      "34452/34452 [==============================] - 5s 131us/step - loss: 2.9771e-05 - mean_squared_error: 2.7516e-05 - val_loss: 6.0548e-05 - val_mean_squared_error: 5.8293e-05\n",
      "Epoch 00026: early stopping\n",
      "Train on 34452 samples, validate on 8636 samples\n",
      "Epoch 1/1000\n",
      "34452/34452 [==============================] - 5s 144us/step - loss: 3.8773e-05 - mean_squared_error: 3.2582e-05 - val_loss: 6.6827e-05 - val_mean_squared_error: 6.2459e-05\n",
      "Epoch 2/1000\n",
      "34452/34452 [==============================] - 4s 122us/step - loss: 3.6148e-05 - mean_squared_error: 3.1361e-05 - val_loss: 6.4665e-05 - val_mean_squared_error: 5.9896e-05\n",
      "Epoch 3/1000\n",
      "34452/34452 [==============================] - 5s 143us/step - loss: 3.5952e-05 - mean_squared_error: 3.1180e-05 - val_loss: 6.7071e-05 - val_mean_squared_error: 6.2345e-05\n",
      "Epoch 4/1000\n",
      "34452/34452 [==============================] - 4s 131us/step - loss: 3.6199e-05 - mean_squared_error: 3.1248e-05 - val_loss: 6.4790e-05 - val_mean_squared_error: 6.0810e-05\n",
      "Epoch 5/1000\n",
      "34452/34452 [==============================] - 5s 135us/step - loss: 3.5876e-05 - mean_squared_error: 3.1099e-05 - val_loss: 6.5592e-05 - val_mean_squared_error: 6.1837e-05\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 6/1000\n",
      "34452/34452 [==============================] - 5s 137us/step - loss: 3.0870e-05 - mean_squared_error: 2.8250e-05 - val_loss: 6.0437e-05 - val_mean_squared_error: 5.7770e-05\n",
      "Epoch 7/1000\n",
      "34452/34452 [==============================] - 7s 217us/step - loss: 3.0655e-05 - mean_squared_error: 2.8077e-05 - val_loss: 6.1048e-05 - val_mean_squared_error: 5.8399e-05\n",
      "Epoch 8/1000\n",
      "34452/34452 [==============================] - 6s 168us/step - loss: 3.0547e-05 - mean_squared_error: 2.8017e-05 - val_loss: 6.1109e-05 - val_mean_squared_error: 5.8549e-05\n",
      "Epoch 9/1000\n",
      "34452/34452 [==============================] - 4s 128us/step - loss: 3.0502e-05 - mean_squared_error: 2.8009e-05 - val_loss: 6.1498e-05 - val_mean_squared_error: 5.9067e-05\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 10/1000\n",
      "34452/34452 [==============================] - 5s 141us/step - loss: 2.9828e-05 - mean_squared_error: 2.7556e-05 - val_loss: 6.0647e-05 - val_mean_squared_error: 5.8378e-05\n",
      "Epoch 11/1000\n",
      "34452/34452 [==============================] - 5s 133us/step - loss: 2.9763e-05 - mean_squared_error: 2.7492e-05 - val_loss: 6.1053e-05 - val_mean_squared_error: 5.8832e-05\n",
      "Epoch 12/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34452/34452 [==============================] - 4s 130us/step - loss: 2.9746e-05 - mean_squared_error: 2.7491e-05 - val_loss: 6.0620e-05 - val_mean_squared_error: 5.8381e-05\n",
      "Epoch 13/1000\n",
      "34452/34452 [==============================] - 5s 136us/step - loss: 2.9730e-05 - mean_squared_error: 2.7487e-05 - val_loss: 6.0700e-05 - val_mean_squared_error: 5.8468e-05\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 14/1000\n",
      "34452/34452 [==============================] - 4s 124us/step - loss: 2.9667e-05 - mean_squared_error: 2.7441e-05 - val_loss: 6.0507e-05 - val_mean_squared_error: 5.8279e-05\n",
      "Epoch 15/1000\n",
      "34452/34452 [==============================] - 5s 141us/step - loss: 2.9648e-05 - mean_squared_error: 2.7419e-05 - val_loss: 6.0522e-05 - val_mean_squared_error: 5.8294e-05\n",
      "Epoch 16/1000\n",
      "34452/34452 [==============================] - 4s 120us/step - loss: 2.9644e-05 - mean_squared_error: 2.7417e-05 - val_loss: 6.0559e-05 - val_mean_squared_error: 5.8336e-05\n",
      "Epoch 17/1000\n",
      "34452/34452 [==============================] - 5s 140us/step - loss: 2.9641e-05 - mean_squared_error: 2.7417e-05 - val_loss: 6.0561e-05 - val_mean_squared_error: 5.8333e-05\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 18/1000\n",
      "34452/34452 [==============================] - 4s 129us/step - loss: 2.9630e-05 - mean_squared_error: 2.7402e-05 - val_loss: 6.0555e-05 - val_mean_squared_error: 5.8328e-05\n",
      "Epoch 19/1000\n",
      "34452/34452 [==============================] - 5s 133us/step - loss: 2.9629e-05 - mean_squared_error: 2.7402e-05 - val_loss: 6.0551e-05 - val_mean_squared_error: 5.8324e-05\n",
      "Epoch 20/1000\n",
      "34452/34452 [==============================] - 5s 138us/step - loss: 2.9629e-05 - mean_squared_error: 2.7402e-05 - val_loss: 6.0548e-05 - val_mean_squared_error: 5.8322e-05\n",
      "Epoch 21/1000\n",
      "34452/34452 [==============================] - 4s 124us/step - loss: 2.9628e-05 - mean_squared_error: 2.7402e-05 - val_loss: 6.0544e-05 - val_mean_squared_error: 5.8318e-05\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "Epoch 22/1000\n",
      "34452/34452 [==============================] - 5s 149us/step - loss: 2.9627e-05 - mean_squared_error: 2.7400e-05 - val_loss: 6.0544e-05 - val_mean_squared_error: 5.8317e-05\n",
      "Epoch 23/1000\n",
      "34452/34452 [==============================] - 8s 219us/step - loss: 2.9627e-05 - mean_squared_error: 2.7400e-05 - val_loss: 6.0544e-05 - val_mean_squared_error: 5.8317e-05\n",
      "Epoch 24/1000\n",
      "34452/34452 [==============================] - 5s 144us/step - loss: 2.9627e-05 - mean_squared_error: 2.7400e-05 - val_loss: 6.0544e-05 - val_mean_squared_error: 5.8317e-05\n",
      "Epoch 25/1000\n",
      "34452/34452 [==============================] - 4s 128us/step - loss: 2.9627e-05 - mean_squared_error: 2.7400e-05 - val_loss: 6.0543e-05 - val_mean_squared_error: 5.8317e-05\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "Epoch 26/1000\n",
      "34452/34452 [==============================] - 5s 137us/step - loss: 2.9627e-05 - mean_squared_error: 2.7400e-05 - val_loss: 6.0543e-05 - val_mean_squared_error: 5.8317e-05\n",
      "Epoch 00026: early stopping\n",
      "Train on 34452 samples, validate on 8636 samples\n",
      "Epoch 1/1000\n",
      "34452/34452 [==============================] - 5s 136us/step - loss: 3.7699e-05 - mean_squared_error: 3.1920e-05 - val_loss: 6.4962e-05 - val_mean_squared_error: 6.0747e-05\n",
      "Epoch 2/1000\n",
      "34452/34452 [==============================] - 4s 128us/step - loss: 3.6292e-05 - mean_squared_error: 3.1424e-05 - val_loss: 6.2891e-05 - val_mean_squared_error: 5.7992e-05\n",
      "Epoch 3/1000\n",
      "34452/34452 [==============================] - 5s 143us/step - loss: 3.5828e-05 - mean_squared_error: 3.1116e-05 - val_loss: 6.4482e-05 - val_mean_squared_error: 5.9293e-05\n",
      "Epoch 4/1000\n",
      "34452/34452 [==============================] - 4s 123us/step - loss: 3.5987e-05 - mean_squared_error: 3.1144e-05 - val_loss: 6.8889e-05 - val_mean_squared_error: 6.4266e-05\n",
      "Epoch 5/1000\n",
      "34452/34452 [==============================] - 5s 145us/step - loss: 3.5680e-05 - mean_squared_error: 3.1045e-05 - val_loss: 6.0702e-05 - val_mean_squared_error: 5.7328e-05\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 6/1000\n",
      "34452/34452 [==============================] - 5s 131us/step - loss: 3.0757e-05 - mean_squared_error: 2.8135e-05 - val_loss: 6.0479e-05 - val_mean_squared_error: 5.7960e-05\n",
      "Epoch 7/1000\n",
      "34452/34452 [==============================] - 5s 133us/step - loss: 3.0565e-05 - mean_squared_error: 2.7993e-05 - val_loss: 6.1210e-05 - val_mean_squared_error: 5.8745e-05\n",
      "Epoch 8/1000\n",
      "34452/34452 [==============================] - 5s 140us/step - loss: 3.0449e-05 - mean_squared_error: 2.7953e-05 - val_loss: 6.0781e-05 - val_mean_squared_error: 5.8452e-05\n",
      "Epoch 9/1000\n",
      "34452/34452 [==============================] - 7s 217us/step - loss: 3.0408e-05 - mean_squared_error: 2.7985e-05 - val_loss: 6.1233e-05 - val_mean_squared_error: 5.8715e-05\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 10/1000\n",
      "34452/34452 [==============================] - 5s 159us/step - loss: 2.9791e-05 - mean_squared_error: 2.7515e-05 - val_loss: 6.0642e-05 - val_mean_squared_error: 5.8390e-05\n",
      "Epoch 11/1000\n",
      "34452/34452 [==============================] - 4s 126us/step - loss: 2.9703e-05 - mean_squared_error: 2.7461e-05 - val_loss: 6.0873e-05 - val_mean_squared_error: 5.8665e-05\n",
      "Epoch 12/1000\n",
      "34452/34452 [==============================] - 5s 140us/step - loss: 2.9689e-05 - mean_squared_error: 2.7477e-05 - val_loss: 6.0812e-05 - val_mean_squared_error: 5.8572e-05\n",
      "Epoch 13/1000\n",
      "34452/34452 [==============================] - 5s 132us/step - loss: 2.9675e-05 - mean_squared_error: 2.7449e-05 - val_loss: 6.0693e-05 - val_mean_squared_error: 5.8477e-05\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 14/1000\n",
      "34452/34452 [==============================] - 5s 133us/step - loss: 2.9604e-05 - mean_squared_error: 2.7402e-05 - val_loss: 6.0636e-05 - val_mean_squared_error: 5.8437e-05\n",
      "Epoch 15/1000\n",
      "34452/34452 [==============================] - 5s 141us/step - loss: 2.9592e-05 - mean_squared_error: 2.7393e-05 - val_loss: 6.0613e-05 - val_mean_squared_error: 5.8417e-05\n",
      "Epoch 16/1000\n",
      "34452/34452 [==============================] - 4s 125us/step - loss: 2.9588e-05 - mean_squared_error: 2.7391e-05 - val_loss: 6.0636e-05 - val_mean_squared_error: 5.8442e-05\n",
      "Epoch 17/1000\n",
      "34452/34452 [==============================] - 6s 162us/step - loss: 2.9585e-05 - mean_squared_error: 2.7390e-05 - val_loss: 6.0629e-05 - val_mean_squared_error: 5.8434e-05\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 18/1000\n",
      "34452/34452 [==============================] - 7s 212us/step - loss: 2.9575e-05 - mean_squared_error: 2.7381e-05 - val_loss: 6.0631e-05 - val_mean_squared_error: 5.8436e-05\n",
      "Epoch 19/1000\n",
      "34452/34452 [==============================] - 5s 142us/step - loss: 2.9574e-05 - mean_squared_error: 2.7379e-05 - val_loss: 6.0632e-05 - val_mean_squared_error: 5.8438e-05\n",
      "Epoch 20/1000\n",
      "34452/34452 [==============================] - 5s 135us/step - loss: 2.9574e-05 - mean_squared_error: 2.7379e-05 - val_loss: 6.0634e-05 - val_mean_squared_error: 5.8440e-05\n",
      "Epoch 21/1000\n",
      "34452/34452 [==============================] - 7s 212us/step - loss: 2.9573e-05 - mean_squared_error: 2.7379e-05 - val_loss: 6.0634e-05 - val_mean_squared_error: 5.8440e-05\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "Epoch 22/1000\n",
      "34452/34452 [==============================] - 6s 171us/step - loss: 2.9572e-05 - mean_squared_error: 2.7378e-05 - val_loss: 6.0634e-05 - val_mean_squared_error: 5.8440e-05\n",
      "Epoch 23/1000\n",
      "34452/34452 [==============================] - 4s 126us/step - loss: 2.9572e-05 - mean_squared_error: 2.7378e-05 - val_loss: 6.0634e-05 - val_mean_squared_error: 5.8440e-05\n",
      "Epoch 24/1000\n",
      "34452/34452 [==============================] - 5s 144us/step - loss: 2.9572e-05 - mean_squared_error: 2.7378e-05 - val_loss: 6.0634e-05 - val_mean_squared_error: 5.8440e-05\n",
      "Epoch 25/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34452/34452 [==============================] - 4s 124us/step - loss: 2.9572e-05 - mean_squared_error: 2.7378e-05 - val_loss: 6.0635e-05 - val_mean_squared_error: 5.8440e-05\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "Epoch 00025: early stopping\n",
      "Train on 34452 samples, validate on 8636 samples\n",
      "Epoch 1/1000\n",
      "34452/34452 [==============================] - 5s 139us/step - loss: 3.7458e-05 - mean_squared_error: 3.1752e-05 - val_loss: 6.4905e-05 - val_mean_squared_error: 5.9484e-05\n",
      "Epoch 2/1000\n",
      "34452/34452 [==============================] - 5s 132us/step - loss: 3.5695e-05 - mean_squared_error: 3.0996e-05 - val_loss: 7.0458e-05 - val_mean_squared_error: 6.5588e-05\n",
      "Epoch 3/1000\n",
      "34452/34452 [==============================] - 4s 128us/step - loss: 3.5874e-05 - mean_squared_error: 3.1039e-05 - val_loss: 6.3809e-05 - val_mean_squared_error: 5.9039e-05\n",
      "Epoch 4/1000\n",
      "34452/34452 [==============================] - 5s 139us/step - loss: 3.5546e-05 - mean_squared_error: 3.0926e-05 - val_loss: 6.9472e-05 - val_mean_squared_error: 6.2767e-05\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 5/1000\n",
      "34452/34452 [==============================] - 4s 122us/step - loss: 3.0687e-05 - mean_squared_error: 2.8029e-05 - val_loss: 6.2473e-05 - val_mean_squared_error: 5.9779e-05\n",
      "Epoch 6/1000\n",
      "34452/34452 [==============================] - 6s 160us/step - loss: 3.0508e-05 - mean_squared_error: 2.7939e-05 - val_loss: 6.1356e-05 - val_mean_squared_error: 5.8820e-05\n",
      "Epoch 7/1000\n",
      "34452/34452 [==============================] - 7s 212us/step - loss: 3.0412e-05 - mean_squared_error: 2.7901e-05 - val_loss: 6.1997e-05 - val_mean_squared_error: 5.9615e-05\n",
      "Epoch 8/1000\n",
      "34452/34452 [==============================] - 5s 140us/step - loss: 3.0314e-05 - mean_squared_error: 2.7867e-05 - val_loss: 6.1230e-05 - val_mean_squared_error: 5.8660e-05\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 9/1000\n",
      "34452/34452 [==============================] - 4s 129us/step - loss: 2.9653e-05 - mean_squared_error: 2.7365e-05 - val_loss: 6.1131e-05 - val_mean_squared_error: 5.8882e-05\n",
      "Epoch 10/1000\n",
      "34452/34452 [==============================] - 5s 135us/step - loss: 2.9586e-05 - mean_squared_error: 2.7339e-05 - val_loss: 6.0661e-05 - val_mean_squared_error: 5.8392e-05\n",
      "Epoch 11/1000\n",
      "34452/34452 [==============================] - 5s 137us/step - loss: 2.9578e-05 - mean_squared_error: 2.7336e-05 - val_loss: 6.0901e-05 - val_mean_squared_error: 5.8645e-05\n",
      "Epoch 12/1000\n",
      "34452/34452 [==============================] - 4s 125us/step - loss: 2.9548e-05 - mean_squared_error: 2.7314e-05 - val_loss: 6.0993e-05 - val_mean_squared_error: 5.8761e-05\n",
      "Epoch 13/1000\n",
      "34452/34452 [==============================] - 5s 142us/step - loss: 2.9533e-05 - mean_squared_error: 2.7298e-05 - val_loss: 6.0626e-05 - val_mean_squared_error: 5.8396e-05\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 14/1000\n",
      "34452/34452 [==============================] - 4s 124us/step - loss: 2.9464e-05 - mean_squared_error: 2.7246e-05 - val_loss: 6.0818e-05 - val_mean_squared_error: 5.8603e-05\n",
      "Epoch 15/1000\n",
      "34452/34452 [==============================] - 5s 139us/step - loss: 2.9445e-05 - mean_squared_error: 2.7231e-05 - val_loss: 6.0824e-05 - val_mean_squared_error: 5.8609e-05\n",
      "Epoch 16/1000\n",
      "34452/34452 [==============================] - 5s 133us/step - loss: 2.9441e-05 - mean_squared_error: 2.7229e-05 - val_loss: 6.0814e-05 - val_mean_squared_error: 5.8598e-05\n",
      "Epoch 17/1000\n",
      "34452/34452 [==============================] - 5s 134us/step - loss: 2.9438e-05 - mean_squared_error: 2.7223e-05 - val_loss: 6.0825e-05 - val_mean_squared_error: 5.8613e-05\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 18/1000\n",
      "34452/34452 [==============================] - 5s 141us/step - loss: 2.9427e-05 - mean_squared_error: 2.7215e-05 - val_loss: 6.0824e-05 - val_mean_squared_error: 5.8612e-05\n",
      "Epoch 19/1000\n",
      "34452/34452 [==============================] - 4s 125us/step - loss: 2.9426e-05 - mean_squared_error: 2.7214e-05 - val_loss: 6.0824e-05 - val_mean_squared_error: 5.8612e-05\n",
      "Epoch 20/1000\n",
      "34452/34452 [==============================] - 5s 143us/step - loss: 2.9426e-05 - mean_squared_error: 2.7214e-05 - val_loss: 6.0825e-05 - val_mean_squared_error: 5.8613e-05\n",
      "Epoch 21/1000\n",
      "34452/34452 [==============================] - 4s 128us/step - loss: 2.9425e-05 - mean_squared_error: 2.7213e-05 - val_loss: 6.0825e-05 - val_mean_squared_error: 5.8612e-05\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "Epoch 22/1000\n",
      "34452/34452 [==============================] - 5s 140us/step - loss: 2.9424e-05 - mean_squared_error: 2.7212e-05 - val_loss: 6.0825e-05 - val_mean_squared_error: 5.8612e-05\n",
      "Epoch 23/1000\n",
      "34452/34452 [==============================] - 5s 136us/step - loss: 2.9424e-05 - mean_squared_error: 2.7212e-05 - val_loss: 6.0824e-05 - val_mean_squared_error: 5.8612e-05\n",
      "Epoch 24/1000\n",
      "34452/34452 [==============================] - 4s 129us/step - loss: 2.9424e-05 - mean_squared_error: 2.7212e-05 - val_loss: 6.0825e-05 - val_mean_squared_error: 5.8612e-05\n",
      "Epoch 25/1000\n",
      "34452/34452 [==============================] - 5s 150us/step - loss: 2.9424e-05 - mean_squared_error: 2.7212e-05 - val_loss: 6.0825e-05 - val_mean_squared_error: 5.8613e-05\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "Epoch 26/1000\n",
      "34452/34452 [==============================] - 8s 224us/step - loss: 2.9424e-05 - mean_squared_error: 2.7212e-05 - val_loss: 6.0825e-05 - val_mean_squared_error: 5.8613e-05\n",
      "Epoch 27/1000\n",
      "34452/34452 [==============================] - 5s 149us/step - loss: 2.9424e-05 - mean_squared_error: 2.7212e-05 - val_loss: 6.0825e-05 - val_mean_squared_error: 5.8613e-05\n",
      "Epoch 28/1000\n",
      "34452/34452 [==============================] - 4s 131us/step - loss: 2.9424e-05 - mean_squared_error: 2.7212e-05 - val_loss: 6.0825e-05 - val_mean_squared_error: 5.8613e-05\n",
      "Epoch 29/1000\n",
      "34452/34452 [==============================] - 5s 135us/step - loss: 2.9424e-05 - mean_squared_error: 2.7212e-05 - val_loss: 6.0825e-05 - val_mean_squared_error: 5.8613e-05\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "Epoch 30/1000\n",
      "34452/34452 [==============================] - 5s 140us/step - loss: 2.9424e-05 - mean_squared_error: 2.7212e-05 - val_loss: 6.0825e-05 - val_mean_squared_error: 5.8613e-05\n",
      "Epoch 00030: early stopping\n",
      "Train on 34452 samples, validate on 8636 samples\n",
      "Epoch 1/1000\n",
      "34452/34452 [==============================] - 4s 127us/step - loss: 3.7634e-05 - mean_squared_error: 3.1909e-05 - val_loss: 6.4996e-05 - val_mean_squared_error: 6.1100e-05\n",
      "Epoch 2/1000\n",
      "34452/34452 [==============================] - 5s 159us/step - loss: 3.5893e-05 - mean_squared_error: 3.1129e-05 - val_loss: 6.6603e-05 - val_mean_squared_error: 6.2439e-05\n",
      "Epoch 3/1000\n",
      "34452/34452 [==============================] - 8s 222us/step - loss: 3.5716e-05 - mean_squared_error: 3.1015e-05 - val_loss: 6.3183e-05 - val_mean_squared_error: 5.8705e-05\n",
      "Epoch 4/1000\n",
      "34452/34452 [==============================] - 5s 148us/step - loss: 3.5796e-05 - mean_squared_error: 3.1049e-05 - val_loss: 7.1434e-05 - val_mean_squared_error: 6.6902e-05\n",
      "Epoch 5/1000\n",
      "34452/34452 [==============================] - 5s 134us/step - loss: 3.5299e-05 - mean_squared_error: 3.0737e-05 - val_loss: 6.4488e-05 - val_mean_squared_error: 6.0529e-05\n",
      "Epoch 6/1000\n",
      "34452/34452 [==============================] - 5s 134us/step - loss: 3.5835e-05 - mean_squared_error: 3.0971e-05 - val_loss: 6.6172e-05 - val_mean_squared_error: 6.1857e-05\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 7/1000\n",
      "34452/34452 [==============================] - 5s 143us/step - loss: 3.0512e-05 - mean_squared_error: 2.7906e-05 - val_loss: 6.1497e-05 - val_mean_squared_error: 5.8864e-05\n",
      "Epoch 8/1000\n",
      "34452/34452 [==============================] - 4s 122us/step - loss: 3.0315e-05 - mean_squared_error: 2.7787e-05 - val_loss: 6.0907e-05 - val_mean_squared_error: 5.8458e-05\n",
      "Epoch 9/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34452/34452 [==============================] - 5s 141us/step - loss: 3.0203e-05 - mean_squared_error: 2.7728e-05 - val_loss: 6.1386e-05 - val_mean_squared_error: 5.9023e-05\n",
      "Epoch 10/1000\n",
      "34452/34452 [==============================] - 4s 114us/step - loss: 3.0131e-05 - mean_squared_error: 2.7686e-05 - val_loss: 6.1248e-05 - val_mean_squared_error: 5.8916e-05\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 11/1000\n",
      "34452/34452 [==============================] - 4s 108us/step - loss: 2.9497e-05 - mean_squared_error: 2.7277e-05 - val_loss: 6.0817e-05 - val_mean_squared_error: 5.8579e-05\n",
      "Epoch 12/1000\n",
      "34452/34452 [==============================] - 4s 117us/step - loss: 2.9444e-05 - mean_squared_error: 2.7206e-05 - val_loss: 6.0818e-05 - val_mean_squared_error: 5.8613e-05\n",
      "Epoch 13/1000\n",
      "34452/34452 [==============================] - 4s 106us/step - loss: 2.9420e-05 - mean_squared_error: 2.7193e-05 - val_loss: 6.0640e-05 - val_mean_squared_error: 5.8416e-05\n",
      "Epoch 14/1000\n",
      "34452/34452 [==============================] - 4s 123us/step - loss: 2.9401e-05 - mean_squared_error: 2.7175e-05 - val_loss: 6.0570e-05 - val_mean_squared_error: 5.8355e-05\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 15/1000\n",
      "34452/34452 [==============================] - 6s 176us/step - loss: 2.9327e-05 - mean_squared_error: 2.7119e-05 - val_loss: 6.0649e-05 - val_mean_squared_error: 5.8444e-05\n",
      "Epoch 16/1000\n",
      "34452/34452 [==============================] - 5s 133us/step - loss: 2.9316e-05 - mean_squared_error: 2.7113e-05 - val_loss: 6.0702e-05 - val_mean_squared_error: 5.8497e-05\n",
      "Epoch 17/1000\n",
      "34452/34452 [==============================] - 5s 142us/step - loss: 2.9313e-05 - mean_squared_error: 2.7108e-05 - val_loss: 6.0685e-05 - val_mean_squared_error: 5.8483e-05\n",
      "Epoch 18/1000\n",
      "34452/34452 [==============================] - 4s 123us/step - loss: 2.9309e-05 - mean_squared_error: 2.7104e-05 - val_loss: 6.0683e-05 - val_mean_squared_error: 5.8480e-05\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 19/1000\n",
      "34452/34452 [==============================] - 5s 142us/step - loss: 2.9299e-05 - mean_squared_error: 2.7097e-05 - val_loss: 6.0677e-05 - val_mean_squared_error: 5.8474e-05\n",
      "Epoch 20/1000\n",
      "34452/34452 [==============================] - 4s 130us/step - loss: 2.9299e-05 - mean_squared_error: 2.7096e-05 - val_loss: 6.0673e-05 - val_mean_squared_error: 5.8470e-05\n",
      "Epoch 21/1000\n",
      "34452/34452 [==============================] - 7s 201us/step - loss: 2.9298e-05 - mean_squared_error: 2.7096e-05 - val_loss: 6.0669e-05 - val_mean_squared_error: 5.8467e-05\n",
      "Epoch 22/1000\n",
      "34452/34452 [==============================] - 6s 175us/step - loss: 2.9298e-05 - mean_squared_error: 2.7095e-05 - val_loss: 6.0667e-05 - val_mean_squared_error: 5.8465e-05\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "Epoch 23/1000\n",
      "34452/34452 [==============================] - 4s 129us/step - loss: 2.9296e-05 - mean_squared_error: 2.7094e-05 - val_loss: 6.0667e-05 - val_mean_squared_error: 5.8464e-05\n",
      "Epoch 24/1000\n",
      "34452/34452 [==============================] - 5s 143us/step - loss: 2.9296e-05 - mean_squared_error: 2.7094e-05 - val_loss: 6.0666e-05 - val_mean_squared_error: 5.8464e-05\n",
      "Epoch 25/1000\n",
      "34452/34452 [==============================] - 4s 121us/step - loss: 2.9296e-05 - mean_squared_error: 2.7094e-05 - val_loss: 6.0666e-05 - val_mean_squared_error: 5.8464e-05\n",
      "Epoch 26/1000\n",
      "34452/34452 [==============================] - 5s 145us/step - loss: 2.9296e-05 - mean_squared_error: 2.7094e-05 - val_loss: 6.0666e-05 - val_mean_squared_error: 5.8464e-05\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "Epoch 27/1000\n",
      "34452/34452 [==============================] - 5s 131us/step - loss: 2.9296e-05 - mean_squared_error: 2.7094e-05 - val_loss: 6.0666e-05 - val_mean_squared_error: 5.8464e-05\n",
      "Epoch 28/1000\n",
      "34452/34452 [==============================] - 5s 135us/step - loss: 2.9296e-05 - mean_squared_error: 2.7094e-05 - val_loss: 6.0666e-05 - val_mean_squared_error: 5.8464e-05\n",
      "Epoch 29/1000\n",
      "34452/34452 [==============================] - 5s 139us/step - loss: 2.9296e-05 - mean_squared_error: 2.7094e-05 - val_loss: 6.0666e-05 - val_mean_squared_error: 5.8464e-05\n",
      "Epoch 30/1000\n",
      "34452/34452 [==============================] - 4s 126us/step - loss: 2.9296e-05 - mean_squared_error: 2.7094e-05 - val_loss: 6.0666e-05 - val_mean_squared_error: 5.8464e-05\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "Epoch 31/1000\n",
      "34452/34452 [==============================] - 6s 160us/step - loss: 2.9296e-05 - mean_squared_error: 2.7094e-05 - val_loss: 6.0666e-05 - val_mean_squared_error: 5.8464e-05\n",
      "Epoch 32/1000\n",
      "34452/34452 [==============================] - 7s 217us/step - loss: 2.9296e-05 - mean_squared_error: 2.7094e-05 - val_loss: 6.0666e-05 - val_mean_squared_error: 5.8464e-05\n",
      "Epoch 33/1000\n",
      "34452/34452 [==============================] - 6s 169us/step - loss: 2.9296e-05 - mean_squared_error: 2.7094e-05 - val_loss: 6.0666e-05 - val_mean_squared_error: 5.8464e-05\n",
      "Epoch 34/1000\n",
      "34452/34452 [==============================] - 6s 165us/step - loss: 2.9296e-05 - mean_squared_error: 2.7094e-05 - val_loss: 6.0666e-05 - val_mean_squared_error: 5.8464e-05\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
      "Epoch 00034: early stopping\n",
      "Train on 34452 samples, validate on 8636 samples\n",
      "Epoch 1/1000\n",
      "34452/34452 [==============================] - 4s 122us/step - loss: 3.7692e-05 - mean_squared_error: 3.1755e-05 - val_loss: 6.4350e-05 - val_mean_squared_error: 6.0021e-05\n",
      "Epoch 2/1000\n",
      "34452/34452 [==============================] - 5s 143us/step - loss: 3.5873e-05 - mean_squared_error: 3.0921e-05 - val_loss: 6.0934e-05 - val_mean_squared_error: 5.7322e-05\n",
      "Epoch 3/1000\n",
      "34452/34452 [==============================] - 5s 131us/step - loss: 3.5568e-05 - mean_squared_error: 3.0782e-05 - val_loss: 6.5695e-05 - val_mean_squared_error: 6.0901e-05\n",
      "Epoch 4/1000\n",
      "34452/34452 [==============================] - 5s 136us/step - loss: 3.5240e-05 - mean_squared_error: 3.0588e-05 - val_loss: 6.4807e-05 - val_mean_squared_error: 5.9975e-05\n",
      "Epoch 5/1000\n",
      "34452/34452 [==============================] - 5s 137us/step - loss: 3.5244e-05 - mean_squared_error: 3.0509e-05 - val_loss: 6.5068e-05 - val_mean_squared_error: 6.0628e-05\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 6/1000\n",
      "34452/34452 [==============================] - 4s 127us/step - loss: 3.0319e-05 - mean_squared_error: 2.7676e-05 - val_loss: 6.0876e-05 - val_mean_squared_error: 5.8230e-05\n",
      "Epoch 7/1000\n",
      "34452/34452 [==============================] - 5s 151us/step - loss: 3.0118e-05 - mean_squared_error: 2.7540e-05 - val_loss: 6.1017e-05 - val_mean_squared_error: 5.8425e-05\n",
      "Epoch 8/1000\n",
      "34452/34452 [==============================] - 8s 222us/step - loss: 2.9985e-05 - mean_squared_error: 2.7466e-05 - val_loss: 6.1361e-05 - val_mean_squared_error: 5.8866e-05\n",
      "Epoch 9/1000\n",
      "34452/34452 [==============================] - 6s 169us/step - loss: 2.9893e-05 - mean_squared_error: 2.7448e-05 - val_loss: 6.0964e-05 - val_mean_squared_error: 5.8655e-05\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 10/1000\n",
      "34452/34452 [==============================] - 6s 167us/step - loss: 2.9273e-05 - mean_squared_error: 2.7036e-05 - val_loss: 6.1350e-05 - val_mean_squared_error: 5.9092e-05\n",
      "Epoch 11/1000\n",
      "34452/34452 [==============================] - 4s 124us/step - loss: 2.9220e-05 - mean_squared_error: 2.6970e-05 - val_loss: 6.0748e-05 - val_mean_squared_error: 5.8518e-05\n",
      "Epoch 12/1000\n",
      "34452/34452 [==============================] - 5s 145us/step - loss: 2.9198e-05 - mean_squared_error: 2.6960e-05 - val_loss: 6.1305e-05 - val_mean_squared_error: 5.9062e-05\n",
      "Epoch 13/1000\n",
      "34452/34452 [==============================] - 4s 129us/step - loss: 2.9185e-05 - mean_squared_error: 2.6947e-05 - val_loss: 6.1122e-05 - val_mean_squared_error: 5.8901e-05\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 14/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34452/34452 [==============================] - 5s 136us/step - loss: 2.9118e-05 - mean_squared_error: 2.6906e-05 - val_loss: 6.0952e-05 - val_mean_squared_error: 5.8744e-05\n",
      "Epoch 15/1000\n",
      "34452/34452 [==============================] - 5s 134us/step - loss: 2.9103e-05 - mean_squared_error: 2.6895e-05 - val_loss: 6.0956e-05 - val_mean_squared_error: 5.8745e-05\n",
      "Epoch 16/1000\n",
      "34452/34452 [==============================] - 7s 209us/step - loss: 2.9100e-05 - mean_squared_error: 2.6888e-05 - val_loss: 6.0962e-05 - val_mean_squared_error: 5.8753e-05\n",
      "Epoch 17/1000\n",
      "34452/34452 [==============================] - 6s 163us/step - loss: 2.9096e-05 - mean_squared_error: 2.6886e-05 - val_loss: 6.0961e-05 - val_mean_squared_error: 5.8751e-05\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 18/1000\n",
      "34452/34452 [==============================] - 4s 124us/step - loss: 2.9087e-05 - mean_squared_error: 2.6877e-05 - val_loss: 6.0966e-05 - val_mean_squared_error: 5.8756e-05\n",
      "Epoch 19/1000\n",
      "34452/34452 [==============================] - 5s 142us/step - loss: 2.9086e-05 - mean_squared_error: 2.6876e-05 - val_loss: 6.0970e-05 - val_mean_squared_error: 5.8760e-05\n",
      "Epoch 20/1000\n",
      "34452/34452 [==============================] - 4s 126us/step - loss: 2.9085e-05 - mean_squared_error: 2.6875e-05 - val_loss: 6.0973e-05 - val_mean_squared_error: 5.8763e-05\n",
      "Epoch 21/1000\n",
      "34452/34452 [==============================] - 5s 135us/step - loss: 2.9085e-05 - mean_squared_error: 2.6875e-05 - val_loss: 6.0978e-05 - val_mean_squared_error: 5.8768e-05\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "Epoch 22/1000\n",
      "34452/34452 [==============================] - 5s 133us/step - loss: 2.9084e-05 - mean_squared_error: 2.6874e-05 - val_loss: 6.0978e-05 - val_mean_squared_error: 5.8768e-05\n",
      "Epoch 00022: early stopping\n",
      "Train on 34452 samples, validate on 8636 samples\n",
      "Epoch 1/1000\n",
      "34452/34452 [==============================] - 7s 208us/step - loss: 3.7415e-05 - mean_squared_error: 3.1618e-05 - val_loss: 6.5791e-05 - val_mean_squared_error: 6.0795e-05\n",
      "Epoch 2/1000\n",
      "34452/34452 [==============================] - 6s 167us/step - loss: 3.5395e-05 - mean_squared_error: 3.0649e-05 - val_loss: 6.8972e-05 - val_mean_squared_error: 6.3150e-05\n",
      "Epoch 3/1000\n",
      "34452/34452 [==============================] - 4s 126us/step - loss: 3.5301e-05 - mean_squared_error: 3.0464e-05 - val_loss: 7.1523e-05 - val_mean_squared_error: 6.6843e-05\n",
      "Epoch 4/1000\n",
      "34452/34452 [==============================] - 5s 142us/step - loss: 3.5275e-05 - mean_squared_error: 3.0459e-05 - val_loss: 6.5923e-05 - val_mean_squared_error: 6.1665e-05\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 5/1000\n",
      "34452/34452 [==============================] - 4s 125us/step - loss: 3.0170e-05 - mean_squared_error: 2.7522e-05 - val_loss: 6.1830e-05 - val_mean_squared_error: 5.9222e-05\n",
      "Epoch 6/1000\n",
      "34452/34452 [==============================] - 5s 138us/step - loss: 2.9971e-05 - mean_squared_error: 2.7388e-05 - val_loss: 6.1617e-05 - val_mean_squared_error: 5.9122e-05\n",
      "Epoch 7/1000\n",
      "34452/34452 [==============================] - 5s 133us/step - loss: 2.9889e-05 - mean_squared_error: 2.7367e-05 - val_loss: 6.2086e-05 - val_mean_squared_error: 5.9539e-05\n",
      "Epoch 8/1000\n",
      "34452/34452 [==============================] - 4s 130us/step - loss: 2.9778e-05 - mean_squared_error: 2.7320e-05 - val_loss: 6.2395e-05 - val_mean_squared_error: 5.9931e-05\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 9/1000\n",
      "34452/34452 [==============================] - 5s 141us/step - loss: 2.9127e-05 - mean_squared_error: 2.6838e-05 - val_loss: 6.1272e-05 - val_mean_squared_error: 5.9009e-05\n",
      "Epoch 10/1000\n",
      "34452/34452 [==============================] - 4s 124us/step - loss: 2.9082e-05 - mean_squared_error: 2.6828e-05 - val_loss: 6.0953e-05 - val_mean_squared_error: 5.8701e-05\n",
      "Epoch 11/1000\n",
      "34452/34452 [==============================] - 5s 145us/step - loss: 2.9060e-05 - mean_squared_error: 2.6805e-05 - val_loss: 6.1481e-05 - val_mean_squared_error: 5.9238e-05\n",
      "Epoch 12/1000\n",
      "34452/34452 [==============================] - 4s 128us/step - loss: 2.9038e-05 - mean_squared_error: 2.6793e-05 - val_loss: 6.1247e-05 - val_mean_squared_error: 5.8998e-05\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 13/1000\n",
      "34452/34452 [==============================] - 5s 136us/step - loss: 2.8976e-05 - mean_squared_error: 2.6737e-05 - val_loss: 6.1238e-05 - val_mean_squared_error: 5.9003e-05\n",
      "Epoch 14/1000\n",
      "34452/34452 [==============================] - 5s 135us/step - loss: 2.8960e-05 - mean_squared_error: 2.6728e-05 - val_loss: 6.1246e-05 - val_mean_squared_error: 5.9015e-05\n",
      "Epoch 15/1000\n",
      "34452/34452 [==============================] - 7s 210us/step - loss: 2.8955e-05 - mean_squared_error: 2.6723e-05 - val_loss: 6.1201e-05 - val_mean_squared_error: 5.8974e-05\n",
      "Epoch 16/1000\n",
      "34452/34452 [==============================] - 6s 167us/step - loss: 2.8953e-05 - mean_squared_error: 2.6725e-05 - val_loss: 6.1307e-05 - val_mean_squared_error: 5.9081e-05\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 17/1000\n",
      "34452/34452 [==============================] - 4s 126us/step - loss: 2.8943e-05 - mean_squared_error: 2.6717e-05 - val_loss: 6.1291e-05 - val_mean_squared_error: 5.9065e-05\n",
      "Epoch 18/1000\n",
      "34452/34452 [==============================] - 6s 164us/step - loss: 2.8942e-05 - mean_squared_error: 2.6716e-05 - val_loss: 6.1279e-05 - val_mean_squared_error: 5.9053e-05\n",
      "Epoch 19/1000\n",
      "34452/34452 [==============================] - 7s 213us/step - loss: 2.8942e-05 - mean_squared_error: 2.6716e-05 - val_loss: 6.1273e-05 - val_mean_squared_error: 5.9047e-05\n",
      "Epoch 20/1000\n",
      "34452/34452 [==============================] - 6s 171us/step - loss: 2.8941e-05 - mean_squared_error: 2.6715e-05 - val_loss: 6.1267e-05 - val_mean_squared_error: 5.9041e-05\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "Epoch 21/1000\n",
      "34452/34452 [==============================] - 6s 161us/step - loss: 2.8940e-05 - mean_squared_error: 2.6714e-05 - val_loss: 6.1267e-05 - val_mean_squared_error: 5.9041e-05\n",
      "Epoch 22/1000\n",
      "34452/34452 [==============================] - 4s 124us/step - loss: 2.8940e-05 - mean_squared_error: 2.6714e-05 - val_loss: 6.1266e-05 - val_mean_squared_error: 5.9040e-05\n",
      "Epoch 23/1000\n",
      "34452/34452 [==============================] - 6s 185us/step - loss: 2.8940e-05 - mean_squared_error: 2.6714e-05 - val_loss: 6.1266e-05 - val_mean_squared_error: 5.9040e-05\n",
      "Epoch 24/1000\n",
      "34452/34452 [==============================] - 7s 195us/step - loss: 2.8940e-05 - mean_squared_error: 2.6714e-05 - val_loss: 6.1265e-05 - val_mean_squared_error: 5.9039e-05\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "Epoch 25/1000\n",
      "34452/34452 [==============================] - 5s 135us/step - loss: 2.8940e-05 - mean_squared_error: 2.6714e-05 - val_loss: 6.1265e-05 - val_mean_squared_error: 5.9039e-05\n",
      "Epoch 26/1000\n",
      "34452/34452 [==============================] - 5s 139us/step - loss: 2.8940e-05 - mean_squared_error: 2.6714e-05 - val_loss: 6.1265e-05 - val_mean_squared_error: 5.9039e-05\n",
      "Epoch 27/1000\n",
      "34452/34452 [==============================] - 4s 127us/step - loss: 2.8940e-05 - mean_squared_error: 2.6714e-05 - val_loss: 6.1265e-05 - val_mean_squared_error: 5.9039e-05\n",
      "Epoch 28/1000\n",
      "34452/34452 [==============================] - 5s 146us/step - loss: 2.8940e-05 - mean_squared_error: 2.6714e-05 - val_loss: 6.1265e-05 - val_mean_squared_error: 5.9039e-05\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "Epoch 29/1000\n",
      "34452/34452 [==============================] - 4s 128us/step - loss: 2.8940e-05 - mean_squared_error: 2.6714e-05 - val_loss: 6.1265e-05 - val_mean_squared_error: 5.9039e-05\n",
      "Epoch 30/1000\n",
      "34452/34452 [==============================] - 5s 139us/step - loss: 2.8940e-05 - mean_squared_error: 2.6714e-05 - val_loss: 6.1265e-05 - val_mean_squared_error: 5.9039e-05\n",
      "Epoch 00030: early stopping\n",
      "Train on 34452 samples, validate on 8636 samples\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34452/34452 [==============================] - 4s 128us/step - loss: 3.7293e-05 - mean_squared_error: 3.1395e-05 - val_loss: 7.0546e-05 - val_mean_squared_error: 6.2944e-05\n",
      "Epoch 2/1000\n",
      "34452/34452 [==============================] - 4s 130us/step - loss: 3.5583e-05 - mean_squared_error: 3.0607e-05 - val_loss: 6.8827e-05 - val_mean_squared_error: 6.3331e-05\n",
      "Epoch 3/1000\n",
      "34452/34452 [==============================] - 5s 137us/step - loss: 3.4758e-05 - mean_squared_error: 3.0217e-05 - val_loss: 7.5187e-05 - val_mean_squared_error: 7.0041e-05\n",
      "Epoch 4/1000\n",
      "34452/34452 [==============================] - 7s 216us/step - loss: 3.5226e-05 - mean_squared_error: 3.0431e-05 - val_loss: 6.6145e-05 - val_mean_squared_error: 6.1159e-05\n",
      "Epoch 5/1000\n",
      "34452/34452 [==============================] - 5s 159us/step - loss: 3.5105e-05 - mean_squared_error: 3.0319e-05 - val_loss: 7.2485e-05 - val_mean_squared_error: 6.6085e-05\n",
      "Epoch 6/1000\n",
      "34452/34452 [==============================] - 4s 124us/step - loss: 3.4986e-05 - mean_squared_error: 3.0259e-05 - val_loss: 6.4412e-05 - val_mean_squared_error: 6.0927e-05\n",
      "Epoch 7/1000\n",
      "34452/34452 [==============================] - 5s 142us/step - loss: 3.5204e-05 - mean_squared_error: 3.0394e-05 - val_loss: 6.7006e-05 - val_mean_squared_error: 6.2301e-05\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 8/1000\n",
      "34452/34452 [==============================] - 4s 128us/step - loss: 3.0053e-05 - mean_squared_error: 2.7446e-05 - val_loss: 6.2621e-05 - val_mean_squared_error: 5.9980e-05\n",
      "Epoch 9/1000\n",
      "34452/34452 [==============================] - 5s 133us/step - loss: 2.9837e-05 - mean_squared_error: 2.7292e-05 - val_loss: 6.1496e-05 - val_mean_squared_error: 5.8956e-05\n",
      "Epoch 10/1000\n",
      "34452/34452 [==============================] - 5s 138us/step - loss: 2.9729e-05 - mean_squared_error: 2.7230e-05 - val_loss: 6.2084e-05 - val_mean_squared_error: 5.9561e-05\n",
      "Epoch 11/1000\n",
      "34452/34452 [==============================] - 4s 124us/step - loss: 2.9618e-05 - mean_squared_error: 2.7178e-05 - val_loss: 6.1897e-05 - val_mean_squared_error: 5.9496e-05\n",
      "Epoch 12/1000\n",
      "34452/34452 [==============================] - 5s 143us/step - loss: 2.9472e-05 - mean_squared_error: 2.7082e-05 - val_loss: 6.1616e-05 - val_mean_squared_error: 5.9197e-05\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 13/1000\n",
      "34452/34452 [==============================] - 4s 123us/step - loss: 2.8866e-05 - mean_squared_error: 2.6678e-05 - val_loss: 6.1651e-05 - val_mean_squared_error: 5.9443e-05\n",
      "Epoch 14/1000\n",
      "34452/34452 [==============================] - 6s 183us/step - loss: 2.8810e-05 - mean_squared_error: 2.6616e-05 - val_loss: 6.1360e-05 - val_mean_squared_error: 5.9187e-05\n",
      "Epoch 15/1000\n",
      "34452/34452 [==============================] - 7s 193us/step - loss: 2.8793e-05 - mean_squared_error: 2.6615e-05 - val_loss: 6.1573e-05 - val_mean_squared_error: 5.9385e-05\n",
      "Epoch 16/1000\n",
      "34452/34452 [==============================] - 5s 135us/step - loss: 2.8777e-05 - mean_squared_error: 2.6591e-05 - val_loss: 6.1612e-05 - val_mean_squared_error: 5.9441e-05\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 17/1000\n",
      "34452/34452 [==============================] - 5s 135us/step - loss: 2.8701e-05 - mean_squared_error: 2.6533e-05 - val_loss: 6.1477e-05 - val_mean_squared_error: 5.9311e-05\n",
      "Epoch 18/1000\n",
      "34452/34452 [==============================] - 7s 217us/step - loss: 2.8687e-05 - mean_squared_error: 2.6519e-05 - val_loss: 6.1482e-05 - val_mean_squared_error: 5.9318e-05\n",
      "Epoch 19/1000\n",
      "34452/34452 [==============================] - 6s 167us/step - loss: 2.8683e-05 - mean_squared_error: 2.6516e-05 - val_loss: 6.1435e-05 - val_mean_squared_error: 5.9273e-05\n",
      "Epoch 20/1000\n",
      "34452/34452 [==============================] - 6s 179us/step - loss: 2.8680e-05 - mean_squared_error: 2.6516e-05 - val_loss: 6.1433e-05 - val_mean_squared_error: 5.9273e-05\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 21/1000\n",
      "34452/34452 [==============================] - 5s 132us/step - loss: 2.8669e-05 - mean_squared_error: 2.6509e-05 - val_loss: 6.1431e-05 - val_mean_squared_error: 5.9272e-05\n",
      "Epoch 22/1000\n",
      "34452/34452 [==============================] - 5s 141us/step - loss: 2.8668e-05 - mean_squared_error: 2.6508e-05 - val_loss: 6.1431e-05 - val_mean_squared_error: 5.9271e-05\n",
      "Epoch 23/1000\n",
      "34452/34452 [==============================] - 4s 123us/step - loss: 2.8668e-05 - mean_squared_error: 2.6508e-05 - val_loss: 6.1431e-05 - val_mean_squared_error: 5.9270e-05\n",
      "Epoch 24/1000\n",
      "34452/34452 [==============================] - 5s 144us/step - loss: 2.8668e-05 - mean_squared_error: 2.6508e-05 - val_loss: 6.1431e-05 - val_mean_squared_error: 5.9271e-05\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "Epoch 25/1000\n",
      "34452/34452 [==============================] - 4s 127us/step - loss: 2.8666e-05 - mean_squared_error: 2.6506e-05 - val_loss: 6.1431e-05 - val_mean_squared_error: 5.9270e-05\n",
      "Epoch 26/1000\n",
      "34452/34452 [==============================] - 5s 136us/step - loss: 2.8666e-05 - mean_squared_error: 2.6506e-05 - val_loss: 6.1431e-05 - val_mean_squared_error: 5.9270e-05\n",
      "Epoch 27/1000\n",
      "34452/34452 [==============================] - 5s 135us/step - loss: 2.8666e-05 - mean_squared_error: 2.6506e-05 - val_loss: 6.1431e-05 - val_mean_squared_error: 5.9270e-05\n",
      "Epoch 28/1000\n",
      "34452/34452 [==============================] - 7s 211us/step - loss: 2.8666e-05 - mean_squared_error: 2.6506e-05 - val_loss: 6.1430e-05 - val_mean_squared_error: 5.9270e-05\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "Epoch 29/1000\n",
      "34452/34452 [==============================] - 6s 170us/step - loss: 2.8666e-05 - mean_squared_error: 2.6506e-05 - val_loss: 6.1430e-05 - val_mean_squared_error: 5.9270e-05\n",
      "Epoch 00029: early stopping\n",
      "Train on 34452 samples, validate on 8636 samples\n",
      "Epoch 1/1000\n",
      "34452/34452 [==============================] - 4s 123us/step - loss: 3.7139e-05 - mean_squared_error: 3.1288e-05 - val_loss: 6.8075e-05 - val_mean_squared_error: 6.3883e-05\n",
      "Epoch 2/1000\n",
      "34452/34452 [==============================] - 5s 143us/step - loss: 3.4917e-05 - mean_squared_error: 3.0340e-05 - val_loss: 6.7747e-05 - val_mean_squared_error: 6.1969e-05\n",
      "Epoch 3/1000\n",
      "34452/34452 [==============================] - 4s 128us/step - loss: 3.4961e-05 - mean_squared_error: 3.0272e-05 - val_loss: 6.6254e-05 - val_mean_squared_error: 6.2244e-05\n",
      "Epoch 4/1000\n",
      "34452/34452 [==============================] - 5s 136us/step - loss: 3.5062e-05 - mean_squared_error: 3.0221e-05 - val_loss: 6.7022e-05 - val_mean_squared_error: 6.3237e-05\n",
      "Epoch 5/1000\n",
      "34452/34452 [==============================] - 5s 135us/step - loss: 3.4791e-05 - mean_squared_error: 3.0127e-05 - val_loss: 6.4573e-05 - val_mean_squared_error: 6.0345e-05\n",
      "Epoch 6/1000\n",
      "34452/34452 [==============================] - 7s 213us/step - loss: 3.5099e-05 - mean_squared_error: 3.0277e-05 - val_loss: 6.7744e-05 - val_mean_squared_error: 6.3234e-05\n",
      "Epoch 7/1000\n",
      "34452/34452 [==============================] - 6s 172us/step - loss: 3.5058e-05 - mean_squared_error: 3.0284e-05 - val_loss: 6.3128e-05 - val_mean_squared_error: 5.8729e-05\n",
      "Epoch 8/1000\n",
      "34452/34452 [==============================] - 4s 123us/step - loss: 3.4789e-05 - mean_squared_error: 3.0129e-05 - val_loss: 6.2279e-05 - val_mean_squared_error: 5.8625e-05\n",
      "Epoch 9/1000\n",
      "34452/34452 [==============================] - 5s 145us/step - loss: 3.4952e-05 - mean_squared_error: 3.0205e-05 - val_loss: 6.6416e-05 - val_mean_squared_error: 6.1883e-05\n",
      "Epoch 10/1000\n",
      "34452/34452 [==============================] - 5s 131us/step - loss: 3.4884e-05 - mean_squared_error: 3.0120e-05 - val_loss: 6.4089e-05 - val_mean_squared_error: 5.9934e-05\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 11/1000\n",
      "34452/34452 [==============================] - 7s 203us/step - loss: 2.9817e-05 - mean_squared_error: 2.7209e-05 - val_loss: 6.2480e-05 - val_mean_squared_error: 5.9831e-05\n",
      "Epoch 12/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34452/34452 [==============================] - 6s 172us/step - loss: 2.9686e-05 - mean_squared_error: 2.7152e-05 - val_loss: 6.2266e-05 - val_mean_squared_error: 5.9717e-05\n",
      "Epoch 13/1000\n",
      "34452/34452 [==============================] - 4s 128us/step - loss: 2.9579e-05 - mean_squared_error: 2.7116e-05 - val_loss: 6.1831e-05 - val_mean_squared_error: 5.9362e-05\n",
      "Epoch 14/1000\n",
      "34452/34452 [==============================] - 5s 140us/step - loss: 2.9501e-05 - mean_squared_error: 2.7084e-05 - val_loss: 6.1563e-05 - val_mean_squared_error: 5.9364e-05\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 15/1000\n",
      "34452/34452 [==============================] - 4s 121us/step - loss: 2.8883e-05 - mean_squared_error: 2.6704e-05 - val_loss: 6.1269e-05 - val_mean_squared_error: 5.9095e-05\n",
      "Epoch 16/1000\n",
      "34452/34452 [==============================] - 5s 142us/step - loss: 2.8822e-05 - mean_squared_error: 2.6621e-05 - val_loss: 6.1368e-05 - val_mean_squared_error: 5.9196e-05\n",
      "Epoch 17/1000\n",
      "34452/34452 [==============================] - 4s 126us/step - loss: 2.8793e-05 - mean_squared_error: 2.6600e-05 - val_loss: 6.1430e-05 - val_mean_squared_error: 5.9225e-05\n",
      "Epoch 18/1000\n",
      "34452/34452 [==============================] - 5s 138us/step - loss: 2.8789e-05 - mean_squared_error: 2.6592e-05 - val_loss: 6.1197e-05 - val_mean_squared_error: 5.9005e-05\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 19/1000\n",
      "34452/34452 [==============================] - 5s 134us/step - loss: 2.8719e-05 - mean_squared_error: 2.6539e-05 - val_loss: 6.1331e-05 - val_mean_squared_error: 5.9155e-05\n",
      "Epoch 20/1000\n",
      "34452/34452 [==============================] - 4s 128us/step - loss: 2.8704e-05 - mean_squared_error: 2.6529e-05 - val_loss: 6.1363e-05 - val_mean_squared_error: 5.9186e-05\n",
      "Epoch 21/1000\n",
      "34452/34452 [==============================] - 5s 142us/step - loss: 2.8699e-05 - mean_squared_error: 2.6524e-05 - val_loss: 6.1340e-05 - val_mean_squared_error: 5.9163e-05\n",
      "Epoch 22/1000\n",
      "34452/34452 [==============================] - 4s 121us/step - loss: 2.8697e-05 - mean_squared_error: 2.6521e-05 - val_loss: 6.1347e-05 - val_mean_squared_error: 5.9173e-05\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 23/1000\n",
      "34452/34452 [==============================] - 5s 144us/step - loss: 2.8687e-05 - mean_squared_error: 2.6513e-05 - val_loss: 6.1354e-05 - val_mean_squared_error: 5.9180e-05\n",
      "Epoch 24/1000\n",
      "34452/34452 [==============================] - 4s 127us/step - loss: 2.8687e-05 - mean_squared_error: 2.6513e-05 - val_loss: 6.1362e-05 - val_mean_squared_error: 5.9188e-05\n",
      "Epoch 25/1000\n",
      "34452/34452 [==============================] - 5s 135us/step - loss: 2.8686e-05 - mean_squared_error: 2.6512e-05 - val_loss: 6.1367e-05 - val_mean_squared_error: 5.9193e-05\n",
      "Epoch 26/1000\n",
      "34452/34452 [==============================] - 5s 133us/step - loss: 2.8686e-05 - mean_squared_error: 2.6511e-05 - val_loss: 6.1373e-05 - val_mean_squared_error: 5.9199e-05\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "Epoch 27/1000\n",
      "34452/34452 [==============================] - 4s 130us/step - loss: 2.8684e-05 - mean_squared_error: 2.6510e-05 - val_loss: 6.1373e-05 - val_mean_squared_error: 5.9199e-05\n",
      "Epoch 28/1000\n",
      "34452/34452 [==============================] - 5s 142us/step - loss: 2.8684e-05 - mean_squared_error: 2.6510e-05 - val_loss: 6.1374e-05 - val_mean_squared_error: 5.9200e-05\n",
      "Epoch 00028: early stopping\n",
      "Train on 34452 samples, validate on 8636 samples\n",
      "Epoch 1/1000\n",
      "34452/34452 [==============================] - 4s 127us/step - loss: 3.6841e-05 - mean_squared_error: 3.1080e-05 - val_loss: 6.5270e-05 - val_mean_squared_error: 6.0416e-05\n",
      "Epoch 2/1000\n",
      "34452/34452 [==============================] - 6s 182us/step - loss: 3.5296e-05 - mean_squared_error: 3.0364e-05 - val_loss: 7.1347e-05 - val_mean_squared_error: 6.3334e-05\n",
      "Epoch 3/1000\n",
      "34452/34452 [==============================] - 7s 196us/step - loss: 3.4576e-05 - mean_squared_error: 2.9974e-05 - val_loss: 6.5265e-05 - val_mean_squared_error: 6.0550e-05\n",
      "Epoch 4/1000\n",
      "34452/34452 [==============================] - 5s 137us/step - loss: 3.5514e-05 - mean_squared_error: 3.0463e-05 - val_loss: 6.8547e-05 - val_mean_squared_error: 6.2643e-05\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 5/1000\n",
      "34452/34452 [==============================] - 5s 136us/step - loss: 2.9913e-05 - mean_squared_error: 2.7246e-05 - val_loss: 6.2208e-05 - val_mean_squared_error: 5.9594e-05\n",
      "Epoch 6/1000\n",
      "34452/34452 [==============================] - 4s 128us/step - loss: 2.9653e-05 - mean_squared_error: 2.7097e-05 - val_loss: 6.2376e-05 - val_mean_squared_error: 5.9742e-05\n",
      "Epoch 7/1000\n",
      "34452/34452 [==============================] - 5s 144us/step - loss: 2.9559e-05 - mean_squared_error: 2.7061e-05 - val_loss: 6.1079e-05 - val_mean_squared_error: 5.8660e-05\n",
      "Epoch 8/1000\n",
      "34452/34452 [==============================] - 8s 225us/step - loss: 2.9499e-05 - mean_squared_error: 2.7063e-05 - val_loss: 6.1543e-05 - val_mean_squared_error: 5.9167e-05\n",
      "Epoch 9/1000\n",
      "34452/34452 [==============================] - 5s 148us/step - loss: 2.9355e-05 - mean_squared_error: 2.6994e-05 - val_loss: 6.1851e-05 - val_mean_squared_error: 5.9466e-05\n",
      "Epoch 10/1000\n",
      "34452/34452 [==============================] - 4s 129us/step - loss: 2.9297e-05 - mean_squared_error: 2.6954e-05 - val_loss: 6.1885e-05 - val_mean_squared_error: 5.9410e-05\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 11/1000\n",
      "34452/34452 [==============================] - 5s 138us/step - loss: 2.8606e-05 - mean_squared_error: 2.6433e-05 - val_loss: 6.1050e-05 - val_mean_squared_error: 5.8900e-05\n",
      "Epoch 12/1000\n",
      "34452/34452 [==============================] - 5s 136us/step - loss: 2.8553e-05 - mean_squared_error: 2.6408e-05 - val_loss: 6.1206e-05 - val_mean_squared_error: 5.9084e-05\n",
      "Epoch 13/1000\n",
      "34452/34452 [==============================] - 4s 130us/step - loss: 2.8529e-05 - mean_squared_error: 2.6399e-05 - val_loss: 6.1424e-05 - val_mean_squared_error: 5.9271e-05\n",
      "Epoch 14/1000\n",
      "34452/34452 [==============================] - 5s 154us/step - loss: 2.8512e-05 - mean_squared_error: 2.6371e-05 - val_loss: 6.1251e-05 - val_mean_squared_error: 5.9119e-05\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 15/1000\n",
      "34452/34452 [==============================] - 8s 224us/step - loss: 2.8438e-05 - mean_squared_error: 2.6316e-05 - val_loss: 6.1273e-05 - val_mean_squared_error: 5.9152e-05\n",
      "Epoch 16/1000\n",
      "34452/34452 [==============================] - 5s 144us/step - loss: 2.8422e-05 - mean_squared_error: 2.6304e-05 - val_loss: 6.1290e-05 - val_mean_squared_error: 5.9172e-05\n",
      "Epoch 17/1000\n",
      "34452/34452 [==============================] - 5s 131us/step - loss: 2.8418e-05 - mean_squared_error: 2.6298e-05 - val_loss: 6.1308e-05 - val_mean_squared_error: 5.9194e-05\n",
      "Epoch 18/1000\n",
      "34452/34452 [==============================] - 5s 136us/step - loss: 2.8414e-05 - mean_squared_error: 2.6297e-05 - val_loss: 6.1259e-05 - val_mean_squared_error: 5.9143e-05\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 19/1000\n",
      "34452/34452 [==============================] - 5s 138us/step - loss: 2.8404e-05 - mean_squared_error: 2.6287e-05 - val_loss: 6.1266e-05 - val_mean_squared_error: 5.9150e-05\n",
      "Epoch 20/1000\n",
      "34452/34452 [==============================] - 8s 221us/step - loss: 2.8403e-05 - mean_squared_error: 2.6286e-05 - val_loss: 6.1273e-05 - val_mean_squared_error: 5.9156e-05\n",
      "Epoch 21/1000\n",
      "34452/34452 [==============================] - 6s 163us/step - loss: 2.8403e-05 - mean_squared_error: 2.6286e-05 - val_loss: 6.1277e-05 - val_mean_squared_error: 5.9161e-05\n",
      "Epoch 22/1000\n",
      "34452/34452 [==============================] - 4s 124us/step - loss: 2.8402e-05 - mean_squared_error: 2.6285e-05 - val_loss: 6.1284e-05 - val_mean_squared_error: 5.9167e-05\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "Epoch 23/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34452/34452 [==============================] - 6s 183us/step - loss: 2.8401e-05 - mean_squared_error: 2.6284e-05 - val_loss: 6.1284e-05 - val_mean_squared_error: 5.9167e-05\n",
      "Epoch 24/1000\n",
      "34452/34452 [==============================] - 7s 190us/step - loss: 2.8401e-05 - mean_squared_error: 2.6284e-05 - val_loss: 6.1284e-05 - val_mean_squared_error: 5.9167e-05\n",
      "Epoch 25/1000\n",
      "34452/34452 [==============================] - 5s 133us/step - loss: 2.8401e-05 - mean_squared_error: 2.6284e-05 - val_loss: 6.1284e-05 - val_mean_squared_error: 5.9167e-05\n",
      "Epoch 26/1000\n",
      "34452/34452 [==============================] - 5s 135us/step - loss: 2.8401e-05 - mean_squared_error: 2.6284e-05 - val_loss: 6.1284e-05 - val_mean_squared_error: 5.9167e-05\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "Epoch 27/1000\n",
      "34452/34452 [==============================] - 4s 128us/step - loss: 2.8401e-05 - mean_squared_error: 2.6284e-05 - val_loss: 6.1284e-05 - val_mean_squared_error: 5.9167e-05\n",
      "Epoch 00027: early stopping\n",
      "Train on 34452 samples, validate on 8636 samples\n",
      "Epoch 1/1000\n",
      "34452/34452 [==============================] - 5s 142us/step - loss: 3.6688e-05 - mean_squared_error: 3.1070e-05 - val_loss: 6.6840e-05 - val_mean_squared_error: 6.2889e-05\n",
      "Epoch 2/1000\n",
      "34452/34452 [==============================] - 4s 122us/step - loss: 3.4880e-05 - mean_squared_error: 3.0198e-05 - val_loss: 6.6966e-05 - val_mean_squared_error: 6.2386e-05\n",
      "Epoch 3/1000\n",
      "34452/34452 [==============================] - 5s 141us/step - loss: 3.4763e-05 - mean_squared_error: 3.0165e-05 - val_loss: 6.9169e-05 - val_mean_squared_error: 6.2262e-05\n",
      "Epoch 4/1000\n",
      "34452/34452 [==============================] - 4s 129us/step - loss: 3.4591e-05 - mean_squared_error: 2.9945e-05 - val_loss: 6.5739e-05 - val_mean_squared_error: 6.0676e-05\n",
      "Epoch 5/1000\n",
      "34452/34452 [==============================] - 5s 133us/step - loss: 3.4991e-05 - mean_squared_error: 3.0216e-05 - val_loss: 6.7243e-05 - val_mean_squared_error: 6.1088e-05\n",
      "Epoch 6/1000\n",
      "34452/34452 [==============================] - 5s 137us/step - loss: 3.4883e-05 - mean_squared_error: 3.0139e-05 - val_loss: 6.3925e-05 - val_mean_squared_error: 5.8573e-05\n",
      "Epoch 7/1000\n",
      "34452/34452 [==============================] - 4s 125us/step - loss: 3.4841e-05 - mean_squared_error: 3.0036e-05 - val_loss: 6.3653e-05 - val_mean_squared_error: 5.9819e-05\n",
      "Epoch 8/1000\n",
      "34452/34452 [==============================] - 5s 143us/step - loss: 3.4715e-05 - mean_squared_error: 3.0006e-05 - val_loss: 7.1055e-05 - val_mean_squared_error: 6.5243e-05\n",
      "Epoch 9/1000\n",
      "34452/34452 [==============================] - 4s 123us/step - loss: 3.4674e-05 - mean_squared_error: 2.9954e-05 - val_loss: 6.6768e-05 - val_mean_squared_error: 6.1645e-05\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 10/1000\n",
      "34452/34452 [==============================] - 6s 180us/step - loss: 2.9783e-05 - mean_squared_error: 2.7168e-05 - val_loss: 6.1843e-05 - val_mean_squared_error: 5.9296e-05\n",
      "Epoch 11/1000\n",
      "34452/34452 [==============================] - 7s 198us/step - loss: 2.9596e-05 - mean_squared_error: 2.7061e-05 - val_loss: 6.3008e-05 - val_mean_squared_error: 6.0269e-05\n",
      "Epoch 12/1000\n",
      "34452/34452 [==============================] - 6s 176us/step - loss: 2.9509e-05 - mean_squared_error: 2.7047e-05 - val_loss: 6.2037e-05 - val_mean_squared_error: 5.9398e-05\n",
      "Epoch 13/1000\n",
      "34452/34452 [==============================] - 5s 153us/step - loss: 2.9359e-05 - mean_squared_error: 2.6961e-05 - val_loss: 6.1458e-05 - val_mean_squared_error: 5.9137e-05\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 14/1000\n",
      "34452/34452 [==============================] - 4s 127us/step - loss: 2.8743e-05 - mean_squared_error: 2.6550e-05 - val_loss: 6.1354e-05 - val_mean_squared_error: 5.9156e-05\n",
      "Epoch 15/1000\n",
      "34452/34452 [==============================] - 5s 139us/step - loss: 2.8713e-05 - mean_squared_error: 2.6536e-05 - val_loss: 6.1372e-05 - val_mean_squared_error: 5.9201e-05\n",
      "Epoch 16/1000\n",
      "34452/34452 [==============================] - 5s 138us/step - loss: 2.8692e-05 - mean_squared_error: 2.6525e-05 - val_loss: 6.1364e-05 - val_mean_squared_error: 5.9165e-05\n",
      "Epoch 17/1000\n",
      "34452/34452 [==============================] - 7s 210us/step - loss: 2.8667e-05 - mean_squared_error: 2.6491e-05 - val_loss: 6.1206e-05 - val_mean_squared_error: 5.9013e-05\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 18/1000\n",
      "34452/34452 [==============================] - 6s 167us/step - loss: 2.8610e-05 - mean_squared_error: 2.6440e-05 - val_loss: 6.1387e-05 - val_mean_squared_error: 5.9225e-05\n",
      "Epoch 19/1000\n",
      "34452/34452 [==============================] - 4s 123us/step - loss: 2.8592e-05 - mean_squared_error: 2.6430e-05 - val_loss: 6.1392e-05 - val_mean_squared_error: 5.9239e-05\n",
      "Epoch 20/1000\n",
      "34452/34452 [==============================] - 6s 168us/step - loss: 2.8587e-05 - mean_squared_error: 2.6435e-05 - val_loss: 6.1407e-05 - val_mean_squared_error: 5.9255e-05\n",
      "Epoch 21/1000\n",
      "34452/34452 [==============================] - 7s 208us/step - loss: 2.8585e-05 - mean_squared_error: 2.6433e-05 - val_loss: 6.1387e-05 - val_mean_squared_error: 5.9238e-05\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 22/1000\n",
      "34452/34452 [==============================] - 5s 140us/step - loss: 2.8574e-05 - mean_squared_error: 2.6425e-05 - val_loss: 6.1386e-05 - val_mean_squared_error: 5.9237e-05\n",
      "Epoch 23/1000\n",
      "34452/34452 [==============================] - 5s 135us/step - loss: 2.8574e-05 - mean_squared_error: 2.6425e-05 - val_loss: 6.1387e-05 - val_mean_squared_error: 5.9238e-05\n",
      "Epoch 24/1000\n",
      "34452/34452 [==============================] - 5s 132us/step - loss: 2.8573e-05 - mean_squared_error: 2.6424e-05 - val_loss: 6.1388e-05 - val_mean_squared_error: 5.9239e-05\n",
      "Epoch 25/1000\n",
      "34452/34452 [==============================] - 5s 145us/step - loss: 2.8573e-05 - mean_squared_error: 2.6424e-05 - val_loss: 6.1388e-05 - val_mean_squared_error: 5.9239e-05\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "Epoch 26/1000\n",
      "34452/34452 [==============================] - 4s 124us/step - loss: 2.8572e-05 - mean_squared_error: 2.6423e-05 - val_loss: 6.1388e-05 - val_mean_squared_error: 5.9239e-05\n",
      "Epoch 00026: early stopping\n",
      "Train on 34452 samples, validate on 8636 samples\n",
      "Epoch 1/1000\n",
      "34452/34452 [==============================] - 5s 145us/step - loss: 3.6811e-05 - mean_squared_error: 3.0960e-05 - val_loss: 6.6407e-05 - val_mean_squared_error: 6.1613e-05\n",
      "Epoch 2/1000\n",
      "34452/34452 [==============================] - 4s 130us/step - loss: 3.4742e-05 - mean_squared_error: 3.0054e-05 - val_loss: 6.5306e-05 - val_mean_squared_error: 6.1290e-05\n",
      "Epoch 3/1000\n",
      "34452/34452 [==============================] - 7s 203us/step - loss: 3.4621e-05 - mean_squared_error: 2.9926e-05 - val_loss: 6.6823e-05 - val_mean_squared_error: 6.1907e-05\n",
      "Epoch 4/1000\n",
      "34452/34452 [==============================] - 6s 177us/step - loss: 3.4664e-05 - mean_squared_error: 2.9984e-05 - val_loss: 6.6238e-05 - val_mean_squared_error: 6.1667e-05\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 5/1000\n",
      "34452/34452 [==============================] - 6s 181us/step - loss: 2.9684e-05 - mean_squared_error: 2.7123e-05 - val_loss: 6.2200e-05 - val_mean_squared_error: 5.9672e-05\n",
      "Epoch 6/1000\n",
      "34452/34452 [==============================] - 5s 138us/step - loss: 2.9465e-05 - mean_squared_error: 2.6980e-05 - val_loss: 6.1292e-05 - val_mean_squared_error: 5.8801e-05\n",
      "Epoch 7/1000\n",
      "34452/34452 [==============================] - 5s 136us/step - loss: 2.9383e-05 - mean_squared_error: 2.6960e-05 - val_loss: 6.3409e-05 - val_mean_squared_error: 6.0982e-05\n",
      "Epoch 8/1000\n",
      "34452/34452 [==============================] - 7s 211us/step - loss: 2.9271e-05 - mean_squared_error: 2.6904e-05 - val_loss: 6.1492e-05 - val_mean_squared_error: 5.9240e-05\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 9/1000\n",
      "34452/34452 [==============================] - 6s 171us/step - loss: 2.8686e-05 - mean_squared_error: 2.6517e-05 - val_loss: 6.1185e-05 - val_mean_squared_error: 5.9008e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/1000\n",
      "34452/34452 [==============================] - 4s 121us/step - loss: 2.8620e-05 - mean_squared_error: 2.6457e-05 - val_loss: 6.1766e-05 - val_mean_squared_error: 5.9582e-05\n",
      "Epoch 11/1000\n",
      "34452/34452 [==============================] - 5s 143us/step - loss: 2.8619e-05 - mean_squared_error: 2.6453e-05 - val_loss: 6.1251e-05 - val_mean_squared_error: 5.9072e-05\n",
      "Epoch 12/1000\n",
      "34452/34452 [==============================] - 4s 122us/step - loss: 2.8592e-05 - mean_squared_error: 2.6426e-05 - val_loss: 6.1322e-05 - val_mean_squared_error: 5.9171e-05\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 13/1000\n",
      "34452/34452 [==============================] - 6s 185us/step - loss: 2.8522e-05 - mean_squared_error: 2.6375e-05 - val_loss: 6.1294e-05 - val_mean_squared_error: 5.9152e-05\n",
      "Epoch 14/1000\n",
      "34452/34452 [==============================] - 6s 188us/step - loss: 2.8511e-05 - mean_squared_error: 2.6367e-05 - val_loss: 6.1257e-05 - val_mean_squared_error: 5.9114e-05\n",
      "Epoch 15/1000\n",
      "34452/34452 [==============================] - 5s 133us/step - loss: 2.8508e-05 - mean_squared_error: 2.6366e-05 - val_loss: 6.1260e-05 - val_mean_squared_error: 5.9119e-05\n",
      "Epoch 16/1000\n",
      "34452/34452 [==============================] - 5s 137us/step - loss: 2.8505e-05 - mean_squared_error: 2.6365e-05 - val_loss: 6.1237e-05 - val_mean_squared_error: 5.9098e-05\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 17/1000\n",
      "34452/34452 [==============================] - 7s 214us/step - loss: 2.8495e-05 - mean_squared_error: 2.6356e-05 - val_loss: 6.1238e-05 - val_mean_squared_error: 5.9099e-05\n",
      "Epoch 18/1000\n",
      "34452/34452 [==============================] - 6s 161us/step - loss: 2.8494e-05 - mean_squared_error: 2.6355e-05 - val_loss: 6.1242e-05 - val_mean_squared_error: 5.9103e-05\n",
      "Epoch 19/1000\n",
      "34452/34452 [==============================] - 4s 121us/step - loss: 2.8494e-05 - mean_squared_error: 2.6354e-05 - val_loss: 6.1243e-05 - val_mean_squared_error: 5.9104e-05\n",
      "Epoch 20/1000\n",
      "34452/34452 [==============================] - 5s 144us/step - loss: 2.8493e-05 - mean_squared_error: 2.6354e-05 - val_loss: 6.1244e-05 - val_mean_squared_error: 5.9105e-05\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "Epoch 21/1000\n",
      "34452/34452 [==============================] - 4s 128us/step - loss: 2.8492e-05 - mean_squared_error: 2.6353e-05 - val_loss: 6.1244e-05 - val_mean_squared_error: 5.9104e-05\n",
      "Epoch 22/1000\n",
      "34452/34452 [==============================] - 7s 199us/step - loss: 2.8492e-05 - mean_squared_error: 2.6353e-05 - val_loss: 6.1244e-05 - val_mean_squared_error: 5.9105e-05\n",
      "Epoch 23/1000\n",
      "34452/34452 [==============================] - 6s 179us/step - loss: 2.8492e-05 - mean_squared_error: 2.6353e-05 - val_loss: 6.1244e-05 - val_mean_squared_error: 5.9105e-05\n",
      "Epoch 24/1000\n",
      "34452/34452 [==============================] - 6s 180us/step - loss: 2.8492e-05 - mean_squared_error: 2.6353e-05 - val_loss: 6.1244e-05 - val_mean_squared_error: 5.9105e-05\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "Epoch 25/1000\n",
      "34452/34452 [==============================] - 5s 141us/step - loss: 2.8492e-05 - mean_squared_error: 2.6353e-05 - val_loss: 6.1244e-05 - val_mean_squared_error: 5.9105e-05\n",
      "Epoch 26/1000\n",
      "34452/34452 [==============================] - 5s 131us/step - loss: 2.8492e-05 - mean_squared_error: 2.6353e-05 - val_loss: 6.1244e-05 - val_mean_squared_error: 5.9105e-05\n",
      "Epoch 00026: early stopping\n",
      "Train on 34452 samples, validate on 8636 samples\n",
      "Epoch 1/1000\n",
      "34452/34452 [==============================] - 5s 133us/step - loss: 3.6681e-05 - mean_squared_error: 3.0812e-05 - val_loss: 7.4065e-05 - val_mean_squared_error: 6.7150e-05\n",
      "Epoch 2/1000\n",
      "34452/34452 [==============================] - 5s 140us/step - loss: 3.5132e-05 - mean_squared_error: 3.0201e-05 - val_loss: 6.6963e-05 - val_mean_squared_error: 6.2597e-05\n",
      "Epoch 3/1000\n",
      "34452/34452 [==============================] - 4s 125us/step - loss: 3.4827e-05 - mean_squared_error: 3.0101e-05 - val_loss: 6.9136e-05 - val_mean_squared_error: 6.3409e-05\n",
      "Epoch 4/1000\n",
      "34452/34452 [==============================] - 6s 171us/step - loss: 3.4694e-05 - mean_squared_error: 2.9970e-05 - val_loss: 6.5487e-05 - val_mean_squared_error: 6.0692e-05\n",
      "Epoch 5/1000\n",
      "34452/34452 [==============================] - 7s 208us/step - loss: 3.4736e-05 - mean_squared_error: 2.9965e-05 - val_loss: 6.4785e-05 - val_mean_squared_error: 6.0475e-05\n",
      "Epoch 6/1000\n",
      "34452/34452 [==============================] - 5s 140us/step - loss: 3.4477e-05 - mean_squared_error: 2.9864e-05 - val_loss: 6.5708e-05 - val_mean_squared_error: 6.1190e-05\n",
      "Epoch 7/1000\n",
      "34452/34452 [==============================] - 5s 136us/step - loss: 3.4784e-05 - mean_squared_error: 3.0009e-05 - val_loss: 6.3124e-05 - val_mean_squared_error: 5.9011e-05\n",
      "Epoch 8/1000\n",
      "34452/34452 [==============================] - 5s 131us/step - loss: 3.4490e-05 - mean_squared_error: 2.9924e-05 - val_loss: 6.6739e-05 - val_mean_squared_error: 6.1873e-05\n",
      "Epoch 9/1000\n",
      "34452/34452 [==============================] - 5s 141us/step - loss: 3.4371e-05 - mean_squared_error: 2.9883e-05 - val_loss: 6.9212e-05 - val_mean_squared_error: 6.2949e-05\n",
      "Epoch 10/1000\n",
      "34452/34452 [==============================] - 8s 222us/step - loss: 3.4602e-05 - mean_squared_error: 2.9897e-05 - val_loss: 6.8513e-05 - val_mean_squared_error: 6.3949e-05\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 11/1000\n",
      "34452/34452 [==============================] - 5s 152us/step - loss: 2.9665e-05 - mean_squared_error: 2.7089e-05 - val_loss: 6.1945e-05 - val_mean_squared_error: 5.9402e-05\n",
      "Epoch 12/1000\n",
      "34452/34452 [==============================] - 4s 127us/step - loss: 2.9472e-05 - mean_squared_error: 2.6968e-05 - val_loss: 6.1833e-05 - val_mean_squared_error: 5.9351e-05\n",
      "Epoch 13/1000\n",
      "34452/34452 [==============================] - 5s 140us/step - loss: 2.9355e-05 - mean_squared_error: 2.6924e-05 - val_loss: 6.1901e-05 - val_mean_squared_error: 5.9466e-05\n",
      "Epoch 14/1000\n",
      "34452/34452 [==============================] - 5s 133us/step - loss: 2.9223e-05 - mean_squared_error: 2.6845e-05 - val_loss: 6.1726e-05 - val_mean_squared_error: 5.9359e-05\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 15/1000\n",
      "34452/34452 [==============================] - 5s 133us/step - loss: 2.8637e-05 - mean_squared_error: 2.6451e-05 - val_loss: 6.0987e-05 - val_mean_squared_error: 5.8853e-05\n",
      "Epoch 16/1000\n",
      "34452/34452 [==============================] - 5s 143us/step - loss: 2.8588e-05 - mean_squared_error: 2.6430e-05 - val_loss: 6.1395e-05 - val_mean_squared_error: 5.9255e-05\n",
      "Epoch 17/1000\n",
      "34452/34452 [==============================] - 4s 123us/step - loss: 2.8572e-05 - mean_squared_error: 2.6424e-05 - val_loss: 6.1163e-05 - val_mean_squared_error: 5.9006e-05\n",
      "Epoch 18/1000\n",
      "34452/34452 [==============================] - 6s 176us/step - loss: 2.8552e-05 - mean_squared_error: 2.6400e-05 - val_loss: 6.0880e-05 - val_mean_squared_error: 5.8726e-05\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 19/1000\n",
      "34452/34452 [==============================] - 7s 206us/step - loss: 2.8494e-05 - mean_squared_error: 2.6355e-05 - val_loss: 6.1113e-05 - val_mean_squared_error: 5.8975e-05\n",
      "Epoch 20/1000\n",
      "34452/34452 [==============================] - 5s 136us/step - loss: 2.8473e-05 - mean_squared_error: 2.6337e-05 - val_loss: 6.1159e-05 - val_mean_squared_error: 5.9025e-05\n",
      "Epoch 21/1000\n",
      "34452/34452 [==============================] - 5s 136us/step - loss: 2.8468e-05 - mean_squared_error: 2.6335e-05 - val_loss: 6.1177e-05 - val_mean_squared_error: 5.9047e-05\n",
      "Epoch 22/1000\n",
      "34452/34452 [==============================] - 5s 132us/step - loss: 2.8466e-05 - mean_squared_error: 2.6335e-05 - val_loss: 6.1198e-05 - val_mean_squared_error: 5.9067e-05\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 23/1000\n",
      "34452/34452 [==============================] - 5s 148us/step - loss: 2.8456e-05 - mean_squared_error: 2.6325e-05 - val_loss: 6.1189e-05 - val_mean_squared_error: 5.9058e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/1000\n",
      "34452/34452 [==============================] - 8s 221us/step - loss: 2.8455e-05 - mean_squared_error: 2.6325e-05 - val_loss: 6.1184e-05 - val_mean_squared_error: 5.9054e-05\n",
      "Epoch 25/1000\n",
      "34452/34452 [==============================] - 5s 144us/step - loss: 2.8455e-05 - mean_squared_error: 2.6323e-05 - val_loss: 6.1180e-05 - val_mean_squared_error: 5.9049e-05\n",
      "Epoch 26/1000\n",
      "34452/34452 [==============================] - 4s 123us/step - loss: 2.8454e-05 - mean_squared_error: 2.6324e-05 - val_loss: 6.1176e-05 - val_mean_squared_error: 5.9046e-05\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "Epoch 27/1000\n",
      "34452/34452 [==============================] - 7s 191us/step - loss: 2.8453e-05 - mean_squared_error: 2.6322e-05 - val_loss: 6.1176e-05 - val_mean_squared_error: 5.9045e-05\n",
      "Epoch 28/1000\n",
      "34452/34452 [==============================] - 6s 183us/step - loss: 2.8453e-05 - mean_squared_error: 2.6323e-05 - val_loss: 6.1175e-05 - val_mean_squared_error: 5.9045e-05\n",
      "Epoch 29/1000\n",
      "34452/34452 [==============================] - 5s 131us/step - loss: 2.8453e-05 - mean_squared_error: 2.6322e-05 - val_loss: 6.1175e-05 - val_mean_squared_error: 5.9044e-05\n",
      "Epoch 30/1000\n",
      "34452/34452 [==============================] - 5s 140us/step - loss: 2.8453e-05 - mean_squared_error: 2.6322e-05 - val_loss: 6.1174e-05 - val_mean_squared_error: 5.9044e-05\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "Epoch 31/1000\n",
      "34452/34452 [==============================] - 8s 219us/step - loss: 2.8453e-05 - mean_squared_error: 2.6322e-05 - val_loss: 6.1174e-05 - val_mean_squared_error: 5.9044e-05\n",
      "Epoch 32/1000\n",
      "34452/34452 [==============================] - 5s 159us/step - loss: 2.8453e-05 - mean_squared_error: 2.6322e-05 - val_loss: 6.1174e-05 - val_mean_squared_error: 5.9044e-05\n",
      "Epoch 33/1000\n",
      "34452/34452 [==============================] - 4s 124us/step - loss: 2.8453e-05 - mean_squared_error: 2.6322e-05 - val_loss: 6.1174e-05 - val_mean_squared_error: 5.9044e-05\n",
      "Epoch 34/1000\n",
      "34452/34452 [==============================] - 5s 140us/step - loss: 2.8453e-05 - mean_squared_error: 2.6322e-05 - val_loss: 6.1174e-05 - val_mean_squared_error: 5.9044e-05\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "Epoch 35/1000\n",
      "34452/34452 [==============================] - 4s 130us/step - loss: 2.8453e-05 - mean_squared_error: 2.6322e-05 - val_loss: 6.1174e-05 - val_mean_squared_error: 5.9044e-05\n",
      "Epoch 36/1000\n",
      "34452/34452 [==============================] - 5s 131us/step - loss: 2.8453e-05 - mean_squared_error: 2.6322e-05 - val_loss: 6.1174e-05 - val_mean_squared_error: 5.9044e-05\n",
      "Epoch 37/1000\n",
      "34452/34452 [==============================] - 5s 136us/step - loss: 2.8453e-05 - mean_squared_error: 2.6322e-05 - val_loss: 6.1174e-05 - val_mean_squared_error: 5.9044e-05\n",
      "Epoch 38/1000\n",
      "34452/34452 [==============================] - 4s 126us/step - loss: 2.8453e-05 - mean_squared_error: 2.6322e-05 - val_loss: 6.1174e-05 - val_mean_squared_error: 5.9044e-05\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
      "Epoch 00038: early stopping\n",
      "Train on 34452 samples, validate on 8636 samples\n",
      "Epoch 1/1000\n",
      "34452/34452 [==============================] - 5s 144us/step - loss: 3.6332e-05 - mean_squared_error: 3.0659e-05 - val_loss: 6.4844e-05 - val_mean_squared_error: 6.0764e-05\n",
      "Epoch 2/1000\n",
      "34452/34452 [==============================] - 4s 123us/step - loss: 3.4680e-05 - mean_squared_error: 3.0034e-05 - val_loss: 6.7756e-05 - val_mean_squared_error: 6.2665e-05\n",
      "Epoch 3/1000\n",
      "34452/34452 [==============================] - 6s 186us/step - loss: 3.4807e-05 - mean_squared_error: 2.9962e-05 - val_loss: 7.2033e-05 - val_mean_squared_error: 6.6625e-05\n",
      "Epoch 4/1000\n",
      "34452/34452 [==============================] - 7s 193us/step - loss: 3.4497e-05 - mean_squared_error: 2.9901e-05 - val_loss: 6.6428e-05 - val_mean_squared_error: 6.1506e-05\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 5/1000\n",
      "34452/34452 [==============================] - 5s 135us/step - loss: 2.9641e-05 - mean_squared_error: 2.7035e-05 - val_loss: 6.1400e-05 - val_mean_squared_error: 5.8841e-05\n",
      "Epoch 6/1000\n",
      "34452/34452 [==============================] - 5s 139us/step - loss: 2.9379e-05 - mean_squared_error: 2.6894e-05 - val_loss: 6.2110e-05 - val_mean_squared_error: 5.9457e-05\n",
      "Epoch 7/1000\n",
      "34452/34452 [==============================] - 7s 216us/step - loss: 2.9300e-05 - mean_squared_error: 2.6851e-05 - val_loss: 6.2695e-05 - val_mean_squared_error: 6.0188e-05\n",
      "Epoch 8/1000\n",
      "34452/34452 [==============================] - 6s 164us/step - loss: 2.9203e-05 - mean_squared_error: 2.6826e-05 - val_loss: 6.1774e-05 - val_mean_squared_error: 5.9376e-05\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 9/1000\n",
      "34452/34452 [==============================] - 4s 126us/step - loss: 2.8597e-05 - mean_squared_error: 2.6393e-05 - val_loss: 6.1481e-05 - val_mean_squared_error: 5.9263e-05\n",
      "Epoch 10/1000\n",
      "34452/34452 [==============================] - 6s 186us/step - loss: 2.8531e-05 - mean_squared_error: 2.6337e-05 - val_loss: 6.0879e-05 - val_mean_squared_error: 5.8732e-05\n",
      "Epoch 11/1000\n",
      "34452/34452 [==============================] - 7s 196us/step - loss: 2.8500e-05 - mean_squared_error: 2.6335e-05 - val_loss: 6.1296e-05 - val_mean_squared_error: 5.9127e-05\n",
      "Epoch 12/1000\n",
      "34452/34452 [==============================] - 6s 177us/step - loss: 2.8503e-05 - mean_squared_error: 2.6337e-05 - val_loss: 6.1286e-05 - val_mean_squared_error: 5.9112e-05\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 13/1000\n",
      "34452/34452 [==============================] - 5s 148us/step - loss: 2.8429e-05 - mean_squared_error: 2.6269e-05 - val_loss: 6.1129e-05 - val_mean_squared_error: 5.8970e-05\n",
      "Epoch 14/1000\n",
      "34452/34452 [==============================] - 4s 129us/step - loss: 2.8416e-05 - mean_squared_error: 2.6261e-05 - val_loss: 6.1099e-05 - val_mean_squared_error: 5.8947e-05\n",
      "Epoch 15/1000\n",
      "34452/34452 [==============================] - 5s 141us/step - loss: 2.8414e-05 - mean_squared_error: 2.6263e-05 - val_loss: 6.1089e-05 - val_mean_squared_error: 5.8938e-05\n",
      "Epoch 16/1000\n",
      "34452/34452 [==============================] - 5s 135us/step - loss: 2.8411e-05 - mean_squared_error: 2.6260e-05 - val_loss: 6.1065e-05 - val_mean_squared_error: 5.8916e-05\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 17/1000\n",
      "34452/34452 [==============================] - 4s 128us/step - loss: 2.8401e-05 - mean_squared_error: 2.6253e-05 - val_loss: 6.1065e-05 - val_mean_squared_error: 5.8916e-05\n",
      "Epoch 18/1000\n",
      "34452/34452 [==============================] - 5s 149us/step - loss: 2.8400e-05 - mean_squared_error: 2.6251e-05 - val_loss: 6.1066e-05 - val_mean_squared_error: 5.8918e-05\n",
      "Epoch 19/1000\n",
      "34452/34452 [==============================] - 8s 223us/step - loss: 2.8400e-05 - mean_squared_error: 2.6252e-05 - val_loss: 6.1067e-05 - val_mean_squared_error: 5.8918e-05\n",
      "Epoch 20/1000\n",
      "34452/34452 [==============================] - 5s 150us/step - loss: 2.8400e-05 - mean_squared_error: 2.6251e-05 - val_loss: 6.1067e-05 - val_mean_squared_error: 5.8919e-05\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "Epoch 21/1000\n",
      "34452/34452 [==============================] - 5s 131us/step - loss: 2.8398e-05 - mean_squared_error: 2.6250e-05 - val_loss: 6.1067e-05 - val_mean_squared_error: 5.8919e-05\n",
      "Epoch 22/1000\n",
      "34452/34452 [==============================] - 7s 202us/step - loss: 2.8398e-05 - mean_squared_error: 2.6250e-05 - val_loss: 6.1067e-05 - val_mean_squared_error: 5.8919e-05\n",
      "Epoch 23/1000\n",
      "34452/34452 [==============================] - 6s 183us/step - loss: 2.8398e-05 - mean_squared_error: 2.6250e-05 - val_loss: 6.1067e-05 - val_mean_squared_error: 5.8919e-05\n",
      "Epoch 24/1000\n",
      "34452/34452 [==============================] - 6s 182us/step - loss: 2.8398e-05 - mean_squared_error: 2.6250e-05 - val_loss: 6.1067e-05 - val_mean_squared_error: 5.8919e-05\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "Epoch 25/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34452/34452 [==============================] - 5s 134us/step - loss: 2.8398e-05 - mean_squared_error: 2.6250e-05 - val_loss: 6.1067e-05 - val_mean_squared_error: 5.8919e-05\n",
      "Epoch 26/1000\n",
      "34452/34452 [==============================] - 5s 131us/step - loss: 2.8398e-05 - mean_squared_error: 2.6250e-05 - val_loss: 6.1067e-05 - val_mean_squared_error: 5.8919e-05\n",
      "Epoch 27/1000\n",
      "34452/34452 [==============================] - 7s 207us/step - loss: 2.8398e-05 - mean_squared_error: 2.6250e-05 - val_loss: 6.1067e-05 - val_mean_squared_error: 5.8919e-05\n",
      "Epoch 28/1000\n",
      "34452/34452 [==============================] - 6s 168us/step - loss: 2.8398e-05 - mean_squared_error: 2.6250e-05 - val_loss: 6.1067e-05 - val_mean_squared_error: 5.8919e-05\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "Epoch 29/1000\n",
      "34452/34452 [==============================] - 4s 124us/step - loss: 2.8398e-05 - mean_squared_error: 2.6250e-05 - val_loss: 6.1067e-05 - val_mean_squared_error: 5.8919e-05\n",
      "Epoch 30/1000\n",
      "34452/34452 [==============================] - 4s 106us/step - loss: 2.8398e-05 - mean_squared_error: 2.6250e-05 - val_loss: 6.1067e-05 - val_mean_squared_error: 5.8919e-05\n",
      "Epoch 00030: early stopping\n",
      "Train on 34452 samples, validate on 8636 samples\n",
      "Epoch 1/1000\n",
      "34452/34452 [==============================] - 4s 119us/step - loss: 3.6359e-05 - mean_squared_error: 3.0806e-05 - val_loss: 6.5242e-05 - val_mean_squared_error: 6.0270e-05\n",
      "Epoch 2/1000\n",
      "34452/34452 [==============================] - 6s 173us/step - loss: 3.4943e-05 - mean_squared_error: 3.0059e-05 - val_loss: 6.3839e-05 - val_mean_squared_error: 5.9320e-05\n",
      "Epoch 3/1000\n",
      "34452/34452 [==============================] - 5s 136us/step - loss: 3.4247e-05 - mean_squared_error: 2.9656e-05 - val_loss: 6.5428e-05 - val_mean_squared_error: 6.1396e-05\n",
      "Epoch 4/1000\n",
      "34452/34452 [==============================] - 5s 135us/step - loss: 3.4478e-05 - mean_squared_error: 2.9820e-05 - val_loss: 6.7481e-05 - val_mean_squared_error: 6.2202e-05\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 5/1000\n",
      "34452/34452 [==============================] - 4s 128us/step - loss: 2.9549e-05 - mean_squared_error: 2.6954e-05 - val_loss: 6.1890e-05 - val_mean_squared_error: 5.9392e-05\n",
      "Epoch 6/1000\n",
      "34452/34452 [==============================] - 5s 142us/step - loss: 2.9338e-05 - mean_squared_error: 2.6843e-05 - val_loss: 6.1001e-05 - val_mean_squared_error: 5.8586e-05\n",
      "Epoch 7/1000\n",
      "34452/34452 [==============================] - 4s 122us/step - loss: 2.9233e-05 - mean_squared_error: 2.6812e-05 - val_loss: 6.2039e-05 - val_mean_squared_error: 5.9760e-05\n",
      "Epoch 8/1000\n",
      "34452/34452 [==============================] - 5s 143us/step - loss: 2.9116e-05 - mean_squared_error: 2.6752e-05 - val_loss: 6.1788e-05 - val_mean_squared_error: 5.9524e-05\n",
      "Epoch 9/1000\n",
      "34452/34452 [==============================] - 4s 127us/step - loss: 2.9064e-05 - mean_squared_error: 2.6738e-05 - val_loss: 6.1618e-05 - val_mean_squared_error: 5.9370e-05\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 10/1000\n",
      "34452/34452 [==============================] - 7s 198us/step - loss: 2.8426e-05 - mean_squared_error: 2.6316e-05 - val_loss: 6.1494e-05 - val_mean_squared_error: 5.9344e-05\n",
      "Epoch 11/1000\n",
      "34452/34452 [==============================] - 6s 182us/step - loss: 2.8365e-05 - mean_squared_error: 2.6246e-05 - val_loss: 6.1547e-05 - val_mean_squared_error: 5.9404e-05\n",
      "Epoch 12/1000\n",
      "34452/34452 [==============================] - 6s 180us/step - loss: 2.8356e-05 - mean_squared_error: 2.6235e-05 - val_loss: 6.1485e-05 - val_mean_squared_error: 5.9373e-05\n",
      "Epoch 13/1000\n",
      "34452/34452 [==============================] - 5s 141us/step - loss: 2.8333e-05 - mean_squared_error: 2.6217e-05 - val_loss: 6.1157e-05 - val_mean_squared_error: 5.9048e-05\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 14/1000\n",
      "34452/34452 [==============================] - 5s 131us/step - loss: 2.8257e-05 - mean_squared_error: 2.6156e-05 - val_loss: 6.1218e-05 - val_mean_squared_error: 5.9121e-05\n",
      "Epoch 15/1000\n",
      "34452/34452 [==============================] - 5s 134us/step - loss: 2.8247e-05 - mean_squared_error: 2.6151e-05 - val_loss: 6.1176e-05 - val_mean_squared_error: 5.9079e-05\n",
      "Epoch 16/1000\n",
      "34452/34452 [==============================] - 5s 141us/step - loss: 2.8243e-05 - mean_squared_error: 2.6145e-05 - val_loss: 6.1151e-05 - val_mean_squared_error: 5.9057e-05\n",
      "Epoch 17/1000\n",
      "34452/34452 [==============================] - 8s 218us/step - loss: 2.8240e-05 - mean_squared_error: 2.6144e-05 - val_loss: 6.1165e-05 - val_mean_squared_error: 5.9071e-05\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 18/1000\n",
      "34452/34452 [==============================] - 6s 162us/step - loss: 2.8230e-05 - mean_squared_error: 2.6136e-05 - val_loss: 6.1171e-05 - val_mean_squared_error: 5.9077e-05\n",
      "Epoch 19/1000\n",
      "34452/34452 [==============================] - 6s 176us/step - loss: 2.8229e-05 - mean_squared_error: 2.6136e-05 - val_loss: 6.1176e-05 - val_mean_squared_error: 5.9082e-05\n",
      "Epoch 20/1000\n",
      "34452/34452 [==============================] - 4s 129us/step - loss: 2.8228e-05 - mean_squared_error: 2.6135e-05 - val_loss: 6.1181e-05 - val_mean_squared_error: 5.9087e-05\n",
      "Epoch 21/1000\n",
      "34452/34452 [==============================] - 5s 147us/step - loss: 2.8228e-05 - mean_squared_error: 2.6134e-05 - val_loss: 6.1183e-05 - val_mean_squared_error: 5.9090e-05\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "Epoch 22/1000\n",
      "34452/34452 [==============================] - 4s 126us/step - loss: 2.8227e-05 - mean_squared_error: 2.6133e-05 - val_loss: 6.1183e-05 - val_mean_squared_error: 5.9090e-05\n",
      "Epoch 23/1000\n",
      "34452/34452 [==============================] - 6s 186us/step - loss: 2.8227e-05 - mean_squared_error: 2.6133e-05 - val_loss: 6.1183e-05 - val_mean_squared_error: 5.9090e-05\n",
      "Epoch 24/1000\n",
      "34452/34452 [==============================] - 7s 193us/step - loss: 2.8227e-05 - mean_squared_error: 2.6133e-05 - val_loss: 6.1184e-05 - val_mean_squared_error: 5.9090e-05\n",
      "Epoch 25/1000\n",
      "34452/34452 [==============================] - 5s 134us/step - loss: 2.8227e-05 - mean_squared_error: 2.6133e-05 - val_loss: 6.1184e-05 - val_mean_squared_error: 5.9090e-05\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "Epoch 26/1000\n",
      "34452/34452 [==============================] - 5s 136us/step - loss: 2.8226e-05 - mean_squared_error: 2.6133e-05 - val_loss: 6.1184e-05 - val_mean_squared_error: 5.9090e-05\n",
      "Epoch 00026: early stopping\n",
      "Train on 34452 samples, validate on 8636 samples\n",
      "Epoch 1/1000\n",
      "34452/34452 [==============================] - 7s 215us/step - loss: 3.7052e-05 - mean_squared_error: 3.0989e-05 - val_loss: 6.6139e-05 - val_mean_squared_error: 6.2500e-05\n",
      "Epoch 2/1000\n",
      "34452/34452 [==============================] - 6s 165us/step - loss: 3.4691e-05 - mean_squared_error: 3.0029e-05 - val_loss: 6.5137e-05 - val_mean_squared_error: 6.0619e-05\n",
      "Epoch 3/1000\n",
      "34452/34452 [==============================] - 6s 186us/step - loss: 3.4252e-05 - mean_squared_error: 2.9733e-05 - val_loss: 7.0146e-05 - val_mean_squared_error: 6.5638e-05\n",
      "Epoch 4/1000\n",
      "34452/34452 [==============================] - 4s 130us/step - loss: 3.4771e-05 - mean_squared_error: 2.9863e-05 - val_loss: 6.4446e-05 - val_mean_squared_error: 6.0238e-05\n",
      "Epoch 5/1000\n",
      "34452/34452 [==============================] - 5s 144us/step - loss: 3.4433e-05 - mean_squared_error: 2.9906e-05 - val_loss: 6.3562e-05 - val_mean_squared_error: 5.9663e-05\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 6/1000\n",
      "34452/34452 [==============================] - 4s 123us/step - loss: 2.9499e-05 - mean_squared_error: 2.6936e-05 - val_loss: 6.1500e-05 - val_mean_squared_error: 5.8987e-05\n",
      "Epoch 7/1000\n",
      "34452/34452 [==============================] - 5s 144us/step - loss: 2.9294e-05 - mean_squared_error: 2.6800e-05 - val_loss: 6.1416e-05 - val_mean_squared_error: 5.8900e-05\n",
      "Epoch 8/1000\n",
      "34452/34452 [==============================] - 4s 130us/step - loss: 2.9206e-05 - mean_squared_error: 2.6774e-05 - val_loss: 6.1643e-05 - val_mean_squared_error: 5.9306e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/1000\n",
      "34452/34452 [==============================] - 7s 197us/step - loss: 2.9091e-05 - mean_squared_error: 2.6725e-05 - val_loss: 6.2016e-05 - val_mean_squared_error: 5.9581e-05\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 10/1000\n",
      "34452/34452 [==============================] - 6s 175us/step - loss: 2.8509e-05 - mean_squared_error: 2.6287e-05 - val_loss: 6.1419e-05 - val_mean_squared_error: 5.9236e-05\n",
      "Epoch 11/1000\n",
      "34452/34452 [==============================] - 4s 130us/step - loss: 2.8456e-05 - mean_squared_error: 2.6280e-05 - val_loss: 6.1483e-05 - val_mean_squared_error: 5.9306e-05\n",
      "Epoch 12/1000\n",
      "34452/34452 [==============================] - 5s 139us/step - loss: 2.8435e-05 - mean_squared_error: 2.6261e-05 - val_loss: 6.1408e-05 - val_mean_squared_error: 5.9240e-05\n",
      "Epoch 13/1000\n",
      "34452/34452 [==============================] - 8s 220us/step - loss: 2.8415e-05 - mean_squared_error: 2.6246e-05 - val_loss: 6.1153e-05 - val_mean_squared_error: 5.8982e-05\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 14/1000\n",
      "34452/34452 [==============================] - 5s 154us/step - loss: 2.8355e-05 - mean_squared_error: 2.6195e-05 - val_loss: 6.1229e-05 - val_mean_squared_error: 5.9078e-05\n",
      "Epoch 15/1000\n",
      "34452/34452 [==============================] - 4s 124us/step - loss: 2.8339e-05 - mean_squared_error: 2.6186e-05 - val_loss: 6.1256e-05 - val_mean_squared_error: 5.9105e-05\n",
      "Epoch 16/1000\n",
      "34452/34452 [==============================] - 6s 186us/step - loss: 2.8335e-05 - mean_squared_error: 2.6184e-05 - val_loss: 6.1255e-05 - val_mean_squared_error: 5.9104e-05\n",
      "Epoch 17/1000\n",
      "34452/34452 [==============================] - 7s 190us/step - loss: 2.8333e-05 - mean_squared_error: 2.6185e-05 - val_loss: 6.1260e-05 - val_mean_squared_error: 5.9111e-05\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 18/1000\n",
      "34452/34452 [==============================] - 5s 133us/step - loss: 2.8323e-05 - mean_squared_error: 2.6174e-05 - val_loss: 6.1258e-05 - val_mean_squared_error: 5.9110e-05\n",
      "Epoch 19/1000\n",
      "34452/34452 [==============================] - 5s 139us/step - loss: 2.8322e-05 - mean_squared_error: 2.6173e-05 - val_loss: 6.1257e-05 - val_mean_squared_error: 5.9108e-05\n",
      "Epoch 20/1000\n",
      "34452/34452 [==============================] - 4s 125us/step - loss: 2.8322e-05 - mean_squared_error: 2.6173e-05 - val_loss: 6.1256e-05 - val_mean_squared_error: 5.9108e-05\n",
      "Epoch 21/1000\n",
      "34452/34452 [==============================] - 5s 144us/step - loss: 2.8321e-05 - mean_squared_error: 2.6173e-05 - val_loss: 6.1255e-05 - val_mean_squared_error: 5.9107e-05\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "Epoch 22/1000\n",
      "34452/34452 [==============================] - 4s 123us/step - loss: 2.8320e-05 - mean_squared_error: 2.6172e-05 - val_loss: 6.1255e-05 - val_mean_squared_error: 5.9107e-05\n",
      "Epoch 23/1000\n",
      "34452/34452 [==============================] - 5s 141us/step - loss: 2.8320e-05 - mean_squared_error: 2.6172e-05 - val_loss: 6.1254e-05 - val_mean_squared_error: 5.9107e-05\n",
      "Epoch 24/1000\n",
      "34452/34452 [==============================] - 4s 129us/step - loss: 2.8320e-05 - mean_squared_error: 2.6172e-05 - val_loss: 6.1254e-05 - val_mean_squared_error: 5.9106e-05\n",
      "Epoch 25/1000\n",
      "34452/34452 [==============================] - 7s 206us/step - loss: 2.8320e-05 - mean_squared_error: 2.6172e-05 - val_loss: 6.1254e-05 - val_mean_squared_error: 5.9106e-05\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "Epoch 26/1000\n",
      "34452/34452 [==============================] - 6s 173us/step - loss: 2.8320e-05 - mean_squared_error: 2.6172e-05 - val_loss: 6.1254e-05 - val_mean_squared_error: 5.9106e-05\n",
      "Epoch 27/1000\n",
      "34452/34452 [==============================] - 4s 127us/step - loss: 2.8320e-05 - mean_squared_error: 2.6172e-05 - val_loss: 6.1254e-05 - val_mean_squared_error: 5.9106e-05\n",
      "Epoch 00027: early stopping\n",
      "Train on 34452 samples, validate on 8636 samples\n",
      "Epoch 1/1000\n",
      "34452/34452 [==============================] - 5s 155us/step - loss: 3.6908e-05 - mean_squared_error: 3.0906e-05 - val_loss: 6.9639e-05 - val_mean_squared_error: 6.4516e-05\n",
      "Epoch 2/1000\n",
      "34452/34452 [==============================] - 8s 222us/step - loss: 3.4862e-05 - mean_squared_error: 2.9959e-05 - val_loss: 6.6521e-05 - val_mean_squared_error: 6.2712e-05\n",
      "Epoch 3/1000\n",
      "34452/34452 [==============================] - 5s 144us/step - loss: 3.4100e-05 - mean_squared_error: 2.9667e-05 - val_loss: 6.6024e-05 - val_mean_squared_error: 6.1567e-05\n",
      "Epoch 4/1000\n",
      "34452/34452 [==============================] - 5s 133us/step - loss: 3.4445e-05 - mean_squared_error: 2.9735e-05 - val_loss: 6.5099e-05 - val_mean_squared_error: 6.0804e-05\n",
      "Epoch 5/1000\n",
      "34452/34452 [==============================] - 7s 203us/step - loss: 3.4285e-05 - mean_squared_error: 2.9610e-05 - val_loss: 6.7874e-05 - val_mean_squared_error: 6.3126e-05\n",
      "Epoch 6/1000\n",
      "34452/34452 [==============================] - 6s 178us/step - loss: 3.4504e-05 - mean_squared_error: 2.9849e-05 - val_loss: 6.2801e-05 - val_mean_squared_error: 5.8807e-05\n",
      "Epoch 7/1000\n",
      "34452/34452 [==============================] - 4s 127us/step - loss: 3.4387e-05 - mean_squared_error: 2.9706e-05 - val_loss: 6.7342e-05 - val_mean_squared_error: 6.2699e-05\n",
      "Epoch 8/1000\n",
      "34452/34452 [==============================] - 5s 145us/step - loss: 3.4488e-05 - mean_squared_error: 2.9790e-05 - val_loss: 6.7663e-05 - val_mean_squared_error: 6.2240e-05\n",
      "Epoch 9/1000\n",
      "34452/34452 [==============================] - 4s 128us/step - loss: 3.4172e-05 - mean_squared_error: 2.9726e-05 - val_loss: 6.7742e-05 - val_mean_squared_error: 6.2383e-05\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 10/1000\n",
      "34452/34452 [==============================] - 6s 185us/step - loss: 2.9403e-05 - mean_squared_error: 2.6835e-05 - val_loss: 6.1460e-05 - val_mean_squared_error: 5.9031e-05\n",
      "Epoch 11/1000\n",
      "34452/34452 [==============================] - 7s 192us/step - loss: 2.9252e-05 - mean_squared_error: 2.6791e-05 - val_loss: 6.1377e-05 - val_mean_squared_error: 5.8953e-05\n",
      "Epoch 12/1000\n",
      "34452/34452 [==============================] - 6s 181us/step - loss: 2.9133e-05 - mean_squared_error: 2.6730e-05 - val_loss: 6.2157e-05 - val_mean_squared_error: 5.9781e-05\n",
      "Epoch 13/1000\n",
      "34452/34452 [==============================] - 5s 147us/step - loss: 2.9033e-05 - mean_squared_error: 2.6692e-05 - val_loss: 6.2549e-05 - val_mean_squared_error: 6.0059e-05\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 14/1000\n",
      "34452/34452 [==============================] - 4s 130us/step - loss: 2.8460e-05 - mean_squared_error: 2.6272e-05 - val_loss: 6.1389e-05 - val_mean_squared_error: 5.9228e-05\n",
      "Epoch 15/1000\n",
      "34452/34452 [==============================] - 7s 202us/step - loss: 2.8395e-05 - mean_squared_error: 2.6264e-05 - val_loss: 6.1119e-05 - val_mean_squared_error: 5.8987e-05\n",
      "Epoch 16/1000\n",
      "34452/34452 [==============================] - 6s 178us/step - loss: 2.8390e-05 - mean_squared_error: 2.6270e-05 - val_loss: 6.1346e-05 - val_mean_squared_error: 5.9231e-05\n",
      "Epoch 17/1000\n",
      "34452/34452 [==============================] - 5s 132us/step - loss: 2.8379e-05 - mean_squared_error: 2.6264e-05 - val_loss: 6.1212e-05 - val_mean_squared_error: 5.9097e-05\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 18/1000\n",
      "34452/34452 [==============================] - 5s 143us/step - loss: 2.8304e-05 - mean_squared_error: 2.6207e-05 - val_loss: 6.1318e-05 - val_mean_squared_error: 5.9221e-05\n",
      "Epoch 19/1000\n",
      "34452/34452 [==============================] - 8s 224us/step - loss: 2.8292e-05 - mean_squared_error: 2.6201e-05 - val_loss: 6.1288e-05 - val_mean_squared_error: 5.9189e-05\n",
      "Epoch 20/1000\n",
      "34452/34452 [==============================] - 5s 151us/step - loss: 2.8288e-05 - mean_squared_error: 2.6192e-05 - val_loss: 6.1275e-05 - val_mean_squared_error: 5.9181e-05\n",
      "Epoch 21/1000\n",
      "34452/34452 [==============================] - 4s 130us/step - loss: 2.8285e-05 - mean_squared_error: 2.6191e-05 - val_loss: 6.1316e-05 - val_mean_squared_error: 5.9224e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 22/1000\n",
      "34452/34452 [==============================] - 5s 139us/step - loss: 2.8276e-05 - mean_squared_error: 2.6184e-05 - val_loss: 6.1305e-05 - val_mean_squared_error: 5.9214e-05\n",
      "Epoch 23/1000\n",
      "34452/34452 [==============================] - 5s 132us/step - loss: 2.8275e-05 - mean_squared_error: 2.6183e-05 - val_loss: 6.1297e-05 - val_mean_squared_error: 5.9205e-05\n",
      "Epoch 24/1000\n",
      "34452/34452 [==============================] - 7s 211us/step - loss: 2.8274e-05 - mean_squared_error: 2.6183e-05 - val_loss: 6.1291e-05 - val_mean_squared_error: 5.9200e-05\n",
      "Epoch 25/1000\n",
      "34452/34452 [==============================] - 6s 163us/step - loss: 2.8274e-05 - mean_squared_error: 2.6183e-05 - val_loss: 6.1287e-05 - val_mean_squared_error: 5.9196e-05\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "Epoch 26/1000\n",
      "34452/34452 [==============================] - 4s 122us/step - loss: 2.8273e-05 - mean_squared_error: 2.6181e-05 - val_loss: 6.1287e-05 - val_mean_squared_error: 5.9196e-05\n",
      "Epoch 00026: early stopping\n",
      "Train on 34452 samples, validate on 8636 samples\n",
      "Epoch 1/1000\n",
      "34452/34452 [==============================] - 5s 142us/step - loss: 3.6298e-05 - mean_squared_error: 3.0516e-05 - val_loss: 6.7121e-05 - val_mean_squared_error: 6.2344e-05\n",
      "Epoch 2/1000\n",
      "34452/34452 [==============================] - 4s 125us/step - loss: 3.4388e-05 - mean_squared_error: 2.9693e-05 - val_loss: 6.4401e-05 - val_mean_squared_error: 6.0510e-05\n",
      "Epoch 3/1000\n",
      "34452/34452 [==============================] - 7s 195us/step - loss: 3.4195e-05 - mean_squared_error: 2.9669e-05 - val_loss: 6.5096e-05 - val_mean_squared_error: 6.0489e-05\n",
      "Epoch 4/1000\n",
      "34452/34452 [==============================] - 6s 180us/step - loss: 3.4207e-05 - mean_squared_error: 2.9668e-05 - val_loss: 6.4699e-05 - val_mean_squared_error: 6.0053e-05\n",
      "Epoch 5/1000\n",
      "34452/34452 [==============================] - 5s 132us/step - loss: 3.4319e-05 - mean_squared_error: 2.9603e-05 - val_loss: 7.0773e-05 - val_mean_squared_error: 6.6194e-05\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 6/1000\n",
      "34452/34452 [==============================] - 5s 139us/step - loss: 2.9301e-05 - mean_squared_error: 2.6812e-05 - val_loss: 6.1564e-05 - val_mean_squared_error: 5.9240e-05\n",
      "Epoch 7/1000\n",
      "34452/34452 [==============================] - 8s 219us/step - loss: 2.9136e-05 - mean_squared_error: 2.6734e-05 - val_loss: 6.1529e-05 - val_mean_squared_error: 5.9134e-05\n",
      "Epoch 8/1000\n",
      "34452/34452 [==============================] - 5s 157us/step - loss: 2.9051e-05 - mean_squared_error: 2.6692e-05 - val_loss: 6.2293e-05 - val_mean_squared_error: 5.9849e-05\n",
      "Epoch 9/1000\n",
      "34452/34452 [==============================] - 4s 124us/step - loss: 2.8983e-05 - mean_squared_error: 2.6681e-05 - val_loss: 6.0855e-05 - val_mean_squared_error: 5.8642e-05\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 10/1000\n",
      "34452/34452 [==============================] - 5s 141us/step - loss: 2.8390e-05 - mean_squared_error: 2.6284e-05 - val_loss: 6.1072e-05 - val_mean_squared_error: 5.8970e-05\n",
      "Epoch 11/1000\n",
      "34452/34452 [==============================] - 4s 130us/step - loss: 2.8327e-05 - mean_squared_error: 2.6233e-05 - val_loss: 6.1708e-05 - val_mean_squared_error: 5.9587e-05\n",
      "Epoch 12/1000\n",
      "34452/34452 [==============================] - 7s 204us/step - loss: 2.8321e-05 - mean_squared_error: 2.6223e-05 - val_loss: 6.1225e-05 - val_mean_squared_error: 5.9114e-05\n",
      "Epoch 13/1000\n",
      "34452/34452 [==============================] - 6s 174us/step - loss: 2.8298e-05 - mean_squared_error: 2.6207e-05 - val_loss: 6.1489e-05 - val_mean_squared_error: 5.9376e-05\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 14/1000\n",
      "34452/34452 [==============================] - 4s 128us/step - loss: 2.8239e-05 - mean_squared_error: 2.6141e-05 - val_loss: 6.1304e-05 - val_mean_squared_error: 5.9212e-05\n",
      "Epoch 15/1000\n",
      "34452/34452 [==============================] - 5s 152us/step - loss: 2.8224e-05 - mean_squared_error: 2.6132e-05 - val_loss: 6.1238e-05 - val_mean_squared_error: 5.9154e-05\n",
      "Epoch 16/1000\n",
      "34452/34452 [==============================] - 8s 220us/step - loss: 2.8219e-05 - mean_squared_error: 2.6138e-05 - val_loss: 6.1193e-05 - val_mean_squared_error: 5.9110e-05\n",
      "Epoch 17/1000\n",
      "34452/34452 [==============================] - 6s 168us/step - loss: 2.8216e-05 - mean_squared_error: 2.6135e-05 - val_loss: 6.1224e-05 - val_mean_squared_error: 5.9144e-05\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 18/1000\n",
      "34452/34452 [==============================] - 6s 167us/step - loss: 2.8207e-05 - mean_squared_error: 2.6127e-05 - val_loss: 6.1213e-05 - val_mean_squared_error: 5.9134e-05\n",
      "Epoch 19/1000\n",
      "34452/34452 [==============================] - 4s 123us/step - loss: 2.8206e-05 - mean_squared_error: 2.6127e-05 - val_loss: 6.1204e-05 - val_mean_squared_error: 5.9125e-05\n",
      "Epoch 20/1000\n",
      "34452/34452 [==============================] - 6s 171us/step - loss: 2.8205e-05 - mean_squared_error: 2.6127e-05 - val_loss: 6.1196e-05 - val_mean_squared_error: 5.9118e-05\n",
      "Epoch 21/1000\n",
      "34452/34452 [==============================] - 8s 246us/step - loss: 2.8205e-05 - mean_squared_error: 2.6127e-05 - val_loss: 6.1191e-05 - val_mean_squared_error: 5.9113e-05\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "Epoch 22/1000\n",
      "34452/34452 [==============================] - 7s 207us/step - loss: 2.8204e-05 - mean_squared_error: 2.6126e-05 - val_loss: 6.1191e-05 - val_mean_squared_error: 5.9113e-05\n",
      "Epoch 23/1000\n",
      "34452/34452 [==============================] - 7s 211us/step - loss: 2.8204e-05 - mean_squared_error: 2.6126e-05 - val_loss: 6.1190e-05 - val_mean_squared_error: 5.9112e-05\n",
      "Epoch 24/1000\n",
      "34452/34452 [==============================] - 8s 232us/step - loss: 2.8204e-05 - mean_squared_error: 2.6126e-05 - val_loss: 6.1190e-05 - val_mean_squared_error: 5.9112e-05\n",
      "Epoch 25/1000\n",
      "34452/34452 [==============================] - 10s 278us/step - loss: 2.8204e-05 - mean_squared_error: 2.6126e-05 - val_loss: 6.1189e-05 - val_mean_squared_error: 5.9111e-05\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "Epoch 26/1000\n",
      "34452/34452 [==============================] - 7s 195us/step - loss: 2.8204e-05 - mean_squared_error: 2.6126e-05 - val_loss: 6.1189e-05 - val_mean_squared_error: 5.9111e-05\n",
      "Epoch 27/1000\n",
      "34452/34452 [==============================] - 7s 199us/step - loss: 2.8204e-05 - mean_squared_error: 2.6126e-05 - val_loss: 6.1189e-05 - val_mean_squared_error: 5.9111e-05\n",
      "Epoch 28/1000\n",
      "34452/34452 [==============================] - 7s 201us/step - loss: 2.8204e-05 - mean_squared_error: 2.6126e-05 - val_loss: 6.1189e-05 - val_mean_squared_error: 5.9111e-05\n",
      "Epoch 29/1000\n",
      "34452/34452 [==============================] - 5s 149us/step - loss: 2.8204e-05 - mean_squared_error: 2.6126e-05 - val_loss: 6.1189e-05 - val_mean_squared_error: 5.9111e-05\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "Epoch 00029: early stopping\n",
      "Train on 34452 samples, validate on 8636 samples\n",
      "Epoch 1/1000\n",
      "34452/34452 [==============================] - 6s 162us/step - loss: 3.6127e-05 - mean_squared_error: 3.0385e-05 - val_loss: 7.0182e-05 - val_mean_squared_error: 6.4898e-05\n",
      "Epoch 2/1000\n",
      "34452/34452 [==============================] - 8s 227us/step - loss: 3.4229e-05 - mean_squared_error: 2.9716e-05 - val_loss: 6.5010e-05 - val_mean_squared_error: 6.0969e-05\n",
      "Epoch 3/1000\n",
      "34452/34452 [==============================] - 6s 177us/step - loss: 3.4322e-05 - mean_squared_error: 2.9714e-05 - val_loss: 6.5015e-05 - val_mean_squared_error: 5.9441e-05\n",
      "Epoch 4/1000\n",
      "34452/34452 [==============================] - 9s 254us/step - loss: 3.4516e-05 - mean_squared_error: 2.9744e-05 - val_loss: 6.7268e-05 - val_mean_squared_error: 6.3511e-05\n",
      "Epoch 5/1000\n",
      "34452/34452 [==============================] - 7s 194us/step - loss: 3.4215e-05 - mean_squared_error: 2.9574e-05 - val_loss: 6.9015e-05 - val_mean_squared_error: 6.4593e-05\n",
      "Epoch 6/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34452/34452 [==============================] - 6s 185us/step - loss: 3.4379e-05 - mean_squared_error: 2.9669e-05 - val_loss: 6.5663e-05 - val_mean_squared_error: 6.0236e-05\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 7/1000\n",
      "34452/34452 [==============================] - 6s 173us/step - loss: 2.9406e-05 - mean_squared_error: 2.6850e-05 - val_loss: 6.1779e-05 - val_mean_squared_error: 5.9299e-05\n",
      "Epoch 8/1000\n",
      "34452/34452 [==============================] - 6s 164us/step - loss: 2.9167e-05 - mean_squared_error: 2.6707e-05 - val_loss: 6.3968e-05 - val_mean_squared_error: 6.1359e-05\n",
      "Epoch 9/1000\n",
      "34452/34452 [==============================] - 6s 180us/step - loss: 2.9059e-05 - mean_squared_error: 2.6655e-05 - val_loss: 6.1457e-05 - val_mean_squared_error: 5.9187e-05\n",
      "Epoch 10/1000\n",
      "34452/34452 [==============================] - 6s 182us/step - loss: 2.8935e-05 - mean_squared_error: 2.6603e-05 - val_loss: 6.2240e-05 - val_mean_squared_error: 5.9845e-05\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 11/1000\n",
      "34452/34452 [==============================] - 6s 172us/step - loss: 2.8386e-05 - mean_squared_error: 2.6221e-05 - val_loss: 6.1570e-05 - val_mean_squared_error: 5.9449e-05\n",
      "Epoch 12/1000\n",
      "34452/34452 [==============================] - 6s 169us/step - loss: 2.8312e-05 - mean_squared_error: 2.6179e-05 - val_loss: 6.1078e-05 - val_mean_squared_error: 5.8970e-05\n",
      "Epoch 13/1000\n",
      "34452/34452 [==============================] - 6s 179us/step - loss: 2.8297e-05 - mean_squared_error: 2.6174e-05 - val_loss: 6.1433e-05 - val_mean_squared_error: 5.9313e-05\n",
      "Epoch 14/1000\n",
      "34452/34452 [==============================] - 5s 131us/step - loss: 2.8284e-05 - mean_squared_error: 2.6160e-05 - val_loss: 6.1166e-05 - val_mean_squared_error: 5.9062e-05\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 15/1000\n",
      "34452/34452 [==============================] - 5s 154us/step - loss: 2.8211e-05 - mean_squared_error: 2.6118e-05 - val_loss: 6.1220e-05 - val_mean_squared_error: 5.9125e-05\n",
      "Epoch 16/1000\n",
      "34452/34452 [==============================] - 8s 227us/step - loss: 2.8199e-05 - mean_squared_error: 2.6103e-05 - val_loss: 6.1259e-05 - val_mean_squared_error: 5.9162e-05\n",
      "Epoch 17/1000\n",
      "34452/34452 [==============================] - 6s 177us/step - loss: 2.8195e-05 - mean_squared_error: 2.6097e-05 - val_loss: 6.1265e-05 - val_mean_squared_error: 5.9168e-05\n",
      "Epoch 18/1000\n",
      "34452/34452 [==============================] - 6s 169us/step - loss: 2.8192e-05 - mean_squared_error: 2.6095e-05 - val_loss: 6.1289e-05 - val_mean_squared_error: 5.9194e-05\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 19/1000\n",
      "34452/34452 [==============================] - 6s 184us/step - loss: 2.8182e-05 - mean_squared_error: 2.6086e-05 - val_loss: 6.1293e-05 - val_mean_squared_error: 5.9198e-05\n",
      "Epoch 20/1000\n",
      "34452/34452 [==============================] - 6s 184us/step - loss: 2.8181e-05 - mean_squared_error: 2.6085e-05 - val_loss: 6.1295e-05 - val_mean_squared_error: 5.9199e-05\n",
      "Epoch 21/1000\n",
      "34452/34452 [==============================] - 6s 176us/step - loss: 2.8181e-05 - mean_squared_error: 2.6084e-05 - val_loss: 6.1298e-05 - val_mean_squared_error: 5.9202e-05\n",
      "Epoch 22/1000\n",
      "34452/34452 [==============================] - 6s 171us/step - loss: 2.8180e-05 - mean_squared_error: 2.6084e-05 - val_loss: 6.1299e-05 - val_mean_squared_error: 5.9203e-05\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "Epoch 23/1000\n",
      "34452/34452 [==============================] - 8s 236us/step - loss: 2.8179e-05 - mean_squared_error: 2.6083e-05 - val_loss: 6.1300e-05 - val_mean_squared_error: 5.9203e-05\n",
      "Epoch 24/1000\n",
      "34452/34452 [==============================] - 8s 223us/step - loss: 2.8179e-05 - mean_squared_error: 2.6083e-05 - val_loss: 6.1300e-05 - val_mean_squared_error: 5.9204e-05\n",
      "Epoch 25/1000\n",
      "34452/34452 [==============================] - 6s 174us/step - loss: 2.8179e-05 - mean_squared_error: 2.6083e-05 - val_loss: 6.1300e-05 - val_mean_squared_error: 5.9204e-05\n",
      "Epoch 26/1000\n",
      "34452/34452 [==============================] - 6s 173us/step - loss: 2.8179e-05 - mean_squared_error: 2.6083e-05 - val_loss: 6.1300e-05 - val_mean_squared_error: 5.9204e-05\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "Epoch 27/1000\n",
      "34452/34452 [==============================] - 6s 184us/step - loss: 2.8179e-05 - mean_squared_error: 2.6083e-05 - val_loss: 6.1300e-05 - val_mean_squared_error: 5.9204e-05\n",
      "Epoch 28/1000\n",
      "34452/34452 [==============================] - 5s 132us/step - loss: 2.8179e-05 - mean_squared_error: 2.6083e-05 - val_loss: 6.1300e-05 - val_mean_squared_error: 5.9204e-05\n",
      "Epoch 29/1000\n",
      "34452/34452 [==============================] - 6s 164us/step - loss: 2.8179e-05 - mean_squared_error: 2.6083e-05 - val_loss: 6.1300e-05 - val_mean_squared_error: 5.9204e-05\n",
      "Epoch 30/1000\n",
      "34452/34452 [==============================] - 9s 258us/step - loss: 2.8179e-05 - mean_squared_error: 2.6083e-05 - val_loss: 6.1300e-05 - val_mean_squared_error: 5.9204e-05\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "Epoch 31/1000\n",
      "34452/34452 [==============================] - 9s 251us/step - loss: 2.8179e-05 - mean_squared_error: 2.6083e-05 - val_loss: 6.1300e-05 - val_mean_squared_error: 5.9204e-05\n",
      "Epoch 32/1000\n",
      "34452/34452 [==============================] - 7s 208us/step - loss: 2.8179e-05 - mean_squared_error: 2.6083e-05 - val_loss: 6.1300e-05 - val_mean_squared_error: 5.9204e-05\n",
      "Epoch 00032: early stopping\n",
      "Train on 34452 samples, validate on 8636 samples\n",
      "Epoch 1/1000\n",
      "34452/34452 [==============================] - 8s 241us/step - loss: 3.6136e-05 - mean_squared_error: 3.0470e-05 - val_loss: 6.4968e-05 - val_mean_squared_error: 5.9563e-05\n",
      "Epoch 2/1000\n",
      "34452/34452 [==============================] - 7s 201us/step - loss: 3.4256e-05 - mean_squared_error: 2.9667e-05 - val_loss: 6.3424e-05 - val_mean_squared_error: 5.9463e-05\n",
      "Epoch 3/1000\n",
      "34452/34452 [==============================] - 7s 215us/step - loss: 3.4386e-05 - mean_squared_error: 2.9681e-05 - val_loss: 6.7235e-05 - val_mean_squared_error: 6.1991e-05\n",
      "Epoch 4/1000\n",
      "34452/34452 [==============================] - 9s 275us/step - loss: 3.4279e-05 - mean_squared_error: 2.9652e-05 - val_loss: 6.7121e-05 - val_mean_squared_error: 6.2553e-05\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 5/1000\n",
      "34452/34452 [==============================] - 10s 280us/step - loss: 2.9264e-05 - mean_squared_error: 2.6733e-05 - val_loss: 6.1936e-05 - val_mean_squared_error: 5.9473e-05\n",
      "Epoch 6/1000\n",
      "34452/34452 [==============================] - 8s 236us/step - loss: 2.9157e-05 - mean_squared_error: 2.6710e-05 - val_loss: 6.1740e-05 - val_mean_squared_error: 5.9347e-05\n",
      "Epoch 7/1000\n",
      "34452/34452 [==============================] - 8s 236us/step - loss: 2.9018e-05 - mean_squared_error: 2.6630e-05 - val_loss: 6.1863e-05 - val_mean_squared_error: 5.9484e-05\n",
      "Epoch 8/1000\n",
      "34452/34452 [==============================] - 7s 211us/step - loss: 2.8899e-05 - mean_squared_error: 2.6559e-05 - val_loss: 6.1374e-05 - val_mean_squared_error: 5.9172e-05\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 9/1000\n",
      "34452/34452 [==============================] - 9s 259us/step - loss: 2.8312e-05 - mean_squared_error: 2.6204e-05 - val_loss: 6.1430e-05 - val_mean_squared_error: 5.9298e-05\n",
      "Epoch 10/1000\n",
      "34452/34452 [==============================] - 9s 265us/step - loss: 2.8274e-05 - mean_squared_error: 2.6155e-05 - val_loss: 6.1487e-05 - val_mean_squared_error: 5.9345e-05\n",
      "Epoch 11/1000\n",
      "34452/34452 [==============================] - 7s 215us/step - loss: 2.8252e-05 - mean_squared_error: 2.6120e-05 - val_loss: 6.1345e-05 - val_mean_squared_error: 5.9241e-05\n",
      "Epoch 12/1000\n",
      "34452/34452 [==============================] - 7s 209us/step - loss: 2.8231e-05 - mean_squared_error: 2.6117e-05 - val_loss: 6.1669e-05 - val_mean_squared_error: 5.9530e-05\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 13/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34452/34452 [==============================] - 6s 165us/step - loss: 2.8171e-05 - mean_squared_error: 2.6051e-05 - val_loss: 6.1434e-05 - val_mean_squared_error: 5.9321e-05\n",
      "Epoch 14/1000\n",
      "34452/34452 [==============================] - 6s 172us/step - loss: 2.8154e-05 - mean_squared_error: 2.6043e-05 - val_loss: 6.1369e-05 - val_mean_squared_error: 5.9261e-05\n",
      "Epoch 15/1000\n",
      "34452/34452 [==============================] - 4s 126us/step - loss: 2.8149e-05 - mean_squared_error: 2.6044e-05 - val_loss: 6.1371e-05 - val_mean_squared_error: 5.9266e-05\n",
      "Epoch 16/1000\n",
      "34452/34452 [==============================] - 6s 167us/step - loss: 2.8146e-05 - mean_squared_error: 2.6043e-05 - val_loss: 6.1359e-05 - val_mean_squared_error: 5.9254e-05\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 17/1000\n",
      "34452/34452 [==============================] - 7s 212us/step - loss: 2.8135e-05 - mean_squared_error: 2.6032e-05 - val_loss: 6.1358e-05 - val_mean_squared_error: 5.9255e-05\n",
      "Epoch 18/1000\n",
      "34452/34452 [==============================] - 6s 172us/step - loss: 2.8135e-05 - mean_squared_error: 2.6032e-05 - val_loss: 6.1356e-05 - val_mean_squared_error: 5.9253e-05\n",
      "Epoch 19/1000\n",
      "34452/34452 [==============================] - 9s 249us/step - loss: 2.8134e-05 - mean_squared_error: 2.6032e-05 - val_loss: 6.1351e-05 - val_mean_squared_error: 5.9248e-05\n",
      "Epoch 20/1000\n",
      "34452/34452 [==============================] - 7s 195us/step - loss: 2.8134e-05 - mean_squared_error: 2.6031e-05 - val_loss: 6.1350e-05 - val_mean_squared_error: 5.9248e-05\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "Epoch 21/1000\n",
      "34452/34452 [==============================] - 6s 185us/step - loss: 2.8133e-05 - mean_squared_error: 2.6030e-05 - val_loss: 6.1350e-05 - val_mean_squared_error: 5.9248e-05\n",
      "Epoch 22/1000\n",
      "34452/34452 [==============================] - 6s 176us/step - loss: 2.8133e-05 - mean_squared_error: 2.6030e-05 - val_loss: 6.1350e-05 - val_mean_squared_error: 5.9247e-05\n",
      "Epoch 23/1000\n",
      "34452/34452 [==============================] - 6s 168us/step - loss: 2.8133e-05 - mean_squared_error: 2.6030e-05 - val_loss: 6.1350e-05 - val_mean_squared_error: 5.9247e-05\n",
      "Epoch 24/1000\n",
      "34452/34452 [==============================] - 6s 183us/step - loss: 2.8133e-05 - mean_squared_error: 2.6030e-05 - val_loss: 6.1349e-05 - val_mean_squared_error: 5.9247e-05\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "Epoch 25/1000\n",
      "34452/34452 [==============================] - 6s 184us/step - loss: 2.8132e-05 - mean_squared_error: 2.6030e-05 - val_loss: 6.1349e-05 - val_mean_squared_error: 5.9247e-05\n",
      "Epoch 26/1000\n",
      "34452/34452 [==============================] - 6s 175us/step - loss: 2.8132e-05 - mean_squared_error: 2.6030e-05 - val_loss: 6.1349e-05 - val_mean_squared_error: 5.9247e-05\n",
      "Epoch 27/1000\n",
      "34452/34452 [==============================] - 6s 169us/step - loss: 2.8132e-05 - mean_squared_error: 2.6030e-05 - val_loss: 6.1349e-05 - val_mean_squared_error: 5.9247e-05\n",
      "Epoch 28/1000\n",
      "34452/34452 [==============================] - 6s 183us/step - loss: 2.8132e-05 - mean_squared_error: 2.6030e-05 - val_loss: 6.1349e-05 - val_mean_squared_error: 5.9247e-05\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "Epoch 00028: early stopping\n",
      "Train on 34452 samples, validate on 8636 samples\n",
      "Epoch 1/1000\n",
      "34452/34452 [==============================] - 6s 184us/step - loss: 3.5911e-05 - mean_squared_error: 3.0292e-05 - val_loss: 6.4062e-05 - val_mean_squared_error: 6.0456e-05\n",
      "Epoch 2/1000\n",
      "34452/34452 [==============================] - 6s 179us/step - loss: 3.4407e-05 - mean_squared_error: 2.9750e-05 - val_loss: 6.7107e-05 - val_mean_squared_error: 6.2242e-05\n",
      "Epoch 3/1000\n",
      "34452/34452 [==============================] - 6s 167us/step - loss: 3.4268e-05 - mean_squared_error: 2.9647e-05 - val_loss: 6.6849e-05 - val_mean_squared_error: 6.3015e-05\n",
      "Epoch 4/1000\n",
      "34452/34452 [==============================] - 6s 178us/step - loss: 3.4214e-05 - mean_squared_error: 2.9548e-05 - val_loss: 6.3147e-05 - val_mean_squared_error: 5.8869e-05\n",
      "Epoch 5/1000\n",
      "34452/34452 [==============================] - 7s 215us/step - loss: 3.4227e-05 - mean_squared_error: 2.9602e-05 - val_loss: 7.1394e-05 - val_mean_squared_error: 6.3844e-05\n",
      "Epoch 6/1000\n",
      "34452/34452 [==============================] - 8s 237us/step - loss: 3.4394e-05 - mean_squared_error: 2.9718e-05 - val_loss: 6.4050e-05 - val_mean_squared_error: 5.9925e-05\n",
      "Epoch 7/1000\n",
      "34452/34452 [==============================] - 6s 177us/step - loss: 3.4218e-05 - mean_squared_error: 2.9590e-05 - val_loss: 6.5791e-05 - val_mean_squared_error: 6.0296e-05\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 8/1000\n",
      "34452/34452 [==============================] - 7s 190us/step - loss: 2.9330e-05 - mean_squared_error: 2.6825e-05 - val_loss: 6.1156e-05 - val_mean_squared_error: 5.8719e-05\n",
      "Epoch 9/1000\n",
      "34452/34452 [==============================] - 6s 186us/step - loss: 2.9105e-05 - mean_squared_error: 2.6675e-05 - val_loss: 6.2593e-05 - val_mean_squared_error: 5.9959e-05\n",
      "Epoch 10/1000\n",
      "34452/34452 [==============================] - 6s 188us/step - loss: 2.9017e-05 - mean_squared_error: 2.6642e-05 - val_loss: 6.1469e-05 - val_mean_squared_error: 5.9155e-05\n",
      "Epoch 11/1000\n",
      "34452/34452 [==============================] - 5s 154us/step - loss: 2.8916e-05 - mean_squared_error: 2.6609e-05 - val_loss: 6.2044e-05 - val_mean_squared_error: 5.9648e-05\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 12/1000\n",
      "34452/34452 [==============================] - 5s 141us/step - loss: 2.8324e-05 - mean_squared_error: 2.6182e-05 - val_loss: 6.1340e-05 - val_mean_squared_error: 5.9220e-05\n",
      "Epoch 13/1000\n",
      "34452/34452 [==============================] - 7s 217us/step - loss: 2.8278e-05 - mean_squared_error: 2.6176e-05 - val_loss: 6.1329e-05 - val_mean_squared_error: 5.9208e-05\n",
      "Epoch 14/1000\n",
      "34452/34452 [==============================] - 6s 187us/step - loss: 2.8259e-05 - mean_squared_error: 2.6159e-05 - val_loss: 6.1342e-05 - val_mean_squared_error: 5.9240e-05\n",
      "Epoch 15/1000\n",
      "34452/34452 [==============================] - 8s 236us/step - loss: 2.8248e-05 - mean_squared_error: 2.6155e-05 - val_loss: 6.1083e-05 - val_mean_squared_error: 5.8993e-05\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 16/1000\n",
      "34452/34452 [==============================] - 8s 227us/step - loss: 2.8181e-05 - mean_squared_error: 2.6098e-05 - val_loss: 6.1217e-05 - val_mean_squared_error: 5.9137e-05\n",
      "Epoch 17/1000\n",
      "34452/34452 [==============================] - 6s 180us/step - loss: 2.8166e-05 - mean_squared_error: 2.6085e-05 - val_loss: 6.1225e-05 - val_mean_squared_error: 5.9149e-05\n",
      "Epoch 18/1000\n",
      "34452/34452 [==============================] - 6s 187us/step - loss: 2.8161e-05 - mean_squared_error: 2.6085e-05 - val_loss: 6.1233e-05 - val_mean_squared_error: 5.9157e-05\n",
      "Epoch 19/1000\n",
      "34452/34452 [==============================] - 8s 239us/step - loss: 2.8158e-05 - mean_squared_error: 2.6083e-05 - val_loss: 6.1238e-05 - val_mean_squared_error: 5.9163e-05\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 20/1000\n",
      "34452/34452 [==============================] - 8s 223us/step - loss: 2.8148e-05 - mean_squared_error: 2.6074e-05 - val_loss: 6.1235e-05 - val_mean_squared_error: 5.9161e-05\n",
      "Epoch 21/1000\n",
      "34452/34452 [==============================] - 6s 177us/step - loss: 2.8147e-05 - mean_squared_error: 2.6073e-05 - val_loss: 6.1231e-05 - val_mean_squared_error: 5.9157e-05\n",
      "Epoch 22/1000\n",
      "34452/34452 [==============================] - 7s 192us/step - loss: 2.8147e-05 - mean_squared_error: 2.6073e-05 - val_loss: 6.1227e-05 - val_mean_squared_error: 5.9154e-05\n",
      "Epoch 23/1000\n",
      "34452/34452 [==============================] - 7s 200us/step - loss: 2.8147e-05 - mean_squared_error: 2.6073e-05 - val_loss: 6.1226e-05 - val_mean_squared_error: 5.9153e-05\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "Epoch 24/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34452/34452 [==============================] - 6s 177us/step - loss: 2.8145e-05 - mean_squared_error: 2.6072e-05 - val_loss: 6.1226e-05 - val_mean_squared_error: 5.9153e-05\n",
      "Epoch 25/1000\n",
      "34452/34452 [==============================] - 6s 184us/step - loss: 2.8145e-05 - mean_squared_error: 2.6072e-05 - val_loss: 6.1226e-05 - val_mean_squared_error: 5.9152e-05\n",
      "Epoch 26/1000\n",
      "34452/34452 [==============================] - 6s 175us/step - loss: 2.8145e-05 - mean_squared_error: 2.6072e-05 - val_loss: 6.1226e-05 - val_mean_squared_error: 5.9152e-05\n",
      "Epoch 27/1000\n",
      "34452/34452 [==============================] - 6s 165us/step - loss: 2.8145e-05 - mean_squared_error: 2.6072e-05 - val_loss: 6.1225e-05 - val_mean_squared_error: 5.9152e-05\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "Epoch 28/1000\n",
      "34452/34452 [==============================] - 6s 178us/step - loss: 2.8145e-05 - mean_squared_error: 2.6072e-05 - val_loss: 6.1225e-05 - val_mean_squared_error: 5.9152e-05\n",
      "Epoch 00028: early stopping\n",
      "Train on 34452 samples, validate on 8636 samples\n",
      "Epoch 1/1000\n",
      "34452/34452 [==============================] - 6s 182us/step - loss: 3.5967e-05 - mean_squared_error: 3.0391e-05 - val_loss: 6.5426e-05 - val_mean_squared_error: 6.0767e-05\n",
      "Epoch 2/1000\n",
      "34452/34452 [==============================] - 6s 177us/step - loss: 3.4317e-05 - mean_squared_error: 2.9644e-05 - val_loss: 6.7449e-05 - val_mean_squared_error: 6.2453e-05\n",
      "Epoch 3/1000\n",
      "34452/34452 [==============================] - 6s 171us/step - loss: 3.4053e-05 - mean_squared_error: 2.9469e-05 - val_loss: 6.5934e-05 - val_mean_squared_error: 6.0961e-05\n",
      "Epoch 4/1000\n",
      "34452/34452 [==============================] - 6s 180us/step - loss: 3.4282e-05 - mean_squared_error: 2.9619e-05 - val_loss: 6.6230e-05 - val_mean_squared_error: 6.0923e-05\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 5/1000\n",
      "34452/34452 [==============================] - 6s 183us/step - loss: 2.9300e-05 - mean_squared_error: 2.6797e-05 - val_loss: 6.3252e-05 - val_mean_squared_error: 6.0685e-05\n",
      "Epoch 6/1000\n",
      "34452/34452 [==============================] - 6s 182us/step - loss: 2.9126e-05 - mean_squared_error: 2.6698e-05 - val_loss: 6.2108e-05 - val_mean_squared_error: 5.9785e-05\n",
      "Epoch 7/1000\n",
      "34452/34452 [==============================] - 9s 256us/step - loss: 2.9004e-05 - mean_squared_error: 2.6632e-05 - val_loss: 6.1115e-05 - val_mean_squared_error: 5.8860e-05\n",
      "Epoch 8/1000\n",
      "34452/34452 [==============================] - 6s 178us/step - loss: 2.8877e-05 - mean_squared_error: 2.6576e-05 - val_loss: 6.2543e-05 - val_mean_squared_error: 6.0184e-05\n",
      "Epoch 9/1000\n",
      "34452/34452 [==============================] - 6s 185us/step - loss: 2.8787e-05 - mean_squared_error: 2.6528e-05 - val_loss: 6.2754e-05 - val_mean_squared_error: 6.0406e-05\n",
      "Epoch 10/1000\n",
      "34452/34452 [==============================] - 6s 178us/step - loss: 2.8718e-05 - mean_squared_error: 2.6489e-05 - val_loss: 6.1749e-05 - val_mean_squared_error: 5.9612e-05\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 11/1000\n",
      "34452/34452 [==============================] - 6s 169us/step - loss: 2.8065e-05 - mean_squared_error: 2.6026e-05 - val_loss: 6.1576e-05 - val_mean_squared_error: 5.9523e-05\n",
      "Epoch 12/1000\n",
      "34452/34452 [==============================] - 6s 179us/step - loss: 2.8026e-05 - mean_squared_error: 2.5989e-05 - val_loss: 6.1324e-05 - val_mean_squared_error: 5.9294e-05\n",
      "Epoch 13/1000\n",
      "34452/34452 [==============================] - 7s 215us/step - loss: 2.7995e-05 - mean_squared_error: 2.5968e-05 - val_loss: 6.1888e-05 - val_mean_squared_error: 5.9853e-05\n",
      "Epoch 14/1000\n",
      "34452/34452 [==============================] - 8s 239us/step - loss: 2.7995e-05 - mean_squared_error: 2.5959e-05 - val_loss: 6.1214e-05 - val_mean_squared_error: 5.9206e-05\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 15/1000\n",
      "34452/34452 [==============================] - 6s 161us/step - loss: 2.7913e-05 - mean_squared_error: 2.5909e-05 - val_loss: 6.1217e-05 - val_mean_squared_error: 5.9212e-05\n",
      "Epoch 16/1000\n",
      "34452/34452 [==============================] - 5s 131us/step - loss: 2.7902e-05 - mean_squared_error: 2.5894e-05 - val_loss: 6.1286e-05 - val_mean_squared_error: 5.9281e-05\n",
      "Epoch 17/1000\n",
      "34452/34452 [==============================] - 7s 207us/step - loss: 2.7898e-05 - mean_squared_error: 2.5891e-05 - val_loss: 6.1262e-05 - val_mean_squared_error: 5.9256e-05\n",
      "Epoch 18/1000\n",
      "34452/34452 [==============================] - 7s 193us/step - loss: 2.7895e-05 - mean_squared_error: 2.5888e-05 - val_loss: 6.1255e-05 - val_mean_squared_error: 5.9252e-05\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 19/1000\n",
      "34452/34452 [==============================] - 7s 204us/step - loss: 2.7885e-05 - mean_squared_error: 2.5882e-05 - val_loss: 6.1260e-05 - val_mean_squared_error: 5.9257e-05\n",
      "Epoch 20/1000\n",
      "34452/34452 [==============================] - 8s 247us/step - loss: 2.7884e-05 - mean_squared_error: 2.5880e-05 - val_loss: 6.1267e-05 - val_mean_squared_error: 5.9263e-05\n",
      "Epoch 21/1000\n",
      "34452/34452 [==============================] - 6s 178us/step - loss: 2.7884e-05 - mean_squared_error: 2.5879e-05 - val_loss: 6.1270e-05 - val_mean_squared_error: 5.9266e-05\n",
      "Epoch 22/1000\n",
      "34452/34452 [==============================] - 6s 182us/step - loss: 2.7883e-05 - mean_squared_error: 2.5879e-05 - val_loss: 6.1272e-05 - val_mean_squared_error: 5.9267e-05\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "Epoch 23/1000\n",
      "34452/34452 [==============================] - 7s 195us/step - loss: 2.7882e-05 - mean_squared_error: 2.5877e-05 - val_loss: 6.1272e-05 - val_mean_squared_error: 5.9267e-05\n",
      "Epoch 24/1000\n",
      "34452/34452 [==============================] - 6s 160us/step - loss: 2.7882e-05 - mean_squared_error: 2.5877e-05 - val_loss: 6.1273e-05 - val_mean_squared_error: 5.9268e-05\n",
      "Epoch 25/1000\n",
      "34452/34452 [==============================] - 5s 151us/step - loss: 2.7882e-05 - mean_squared_error: 2.5877e-05 - val_loss: 6.1273e-05 - val_mean_squared_error: 5.9268e-05\n",
      "Epoch 26/1000\n",
      "34452/34452 [==============================] - 8s 231us/step - loss: 2.7882e-05 - mean_squared_error: 2.5877e-05 - val_loss: 6.1273e-05 - val_mean_squared_error: 5.9268e-05\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "Epoch 27/1000\n",
      "34452/34452 [==============================] - 6s 186us/step - loss: 2.7882e-05 - mean_squared_error: 2.5877e-05 - val_loss: 6.1273e-05 - val_mean_squared_error: 5.9268e-05\n",
      "Epoch 00027: early stopping\n",
      "Train on 34452 samples, validate on 8636 samples\n",
      "Epoch 1/1000\n",
      "34452/34452 [==============================] - 6s 173us/step - loss: 3.6082e-05 - mean_squared_error: 3.0405e-05 - val_loss: 6.9857e-05 - val_mean_squared_error: 6.5209e-05\n",
      "Epoch 2/1000\n",
      "34452/34452 [==============================] - 7s 196us/step - loss: 3.4062e-05 - mean_squared_error: 2.9595e-05 - val_loss: 6.7178e-05 - val_mean_squared_error: 6.2751e-05\n",
      "Epoch 3/1000\n",
      "34452/34452 [==============================] - 7s 217us/step - loss: 3.4298e-05 - mean_squared_error: 2.9583e-05 - val_loss: 6.6345e-05 - val_mean_squared_error: 6.1790e-05\n",
      "Epoch 4/1000\n",
      "34452/34452 [==============================] - 8s 240us/step - loss: 3.4070e-05 - mean_squared_error: 2.9530e-05 - val_loss: 7.0978e-05 - val_mean_squared_error: 6.5693e-05\n",
      "Epoch 5/1000\n",
      "34452/34452 [==============================] - 6s 176us/step - loss: 3.4639e-05 - mean_squared_error: 2.9741e-05 - val_loss: 6.7399e-05 - val_mean_squared_error: 6.3271e-05\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 6/1000\n",
      "34452/34452 [==============================] - 7s 192us/step - loss: 2.9269e-05 - mean_squared_error: 2.6753e-05 - val_loss: 6.1456e-05 - val_mean_squared_error: 5.9061e-05\n",
      "Epoch 7/1000\n",
      "34452/34452 [==============================] - 7s 198us/step - loss: 2.9108e-05 - mean_squared_error: 2.6662e-05 - val_loss: 6.2397e-05 - val_mean_squared_error: 6.0080e-05\n",
      "Epoch 8/1000\n",
      "34452/34452 [==============================] - 7s 191us/step - loss: 2.8992e-05 - mean_squared_error: 2.6608e-05 - val_loss: 6.0806e-05 - val_mean_squared_error: 5.8484e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/1000\n",
      "34452/34452 [==============================] - 6s 179us/step - loss: 2.8898e-05 - mean_squared_error: 2.6571e-05 - val_loss: 6.1443e-05 - val_mean_squared_error: 5.9192e-05\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 10/1000\n",
      "34452/34452 [==============================] - 6s 167us/step - loss: 2.8314e-05 - mean_squared_error: 2.6199e-05 - val_loss: 6.1603e-05 - val_mean_squared_error: 5.9491e-05\n",
      "Epoch 11/1000\n",
      "34452/34452 [==============================] - 6s 176us/step - loss: 2.8261e-05 - mean_squared_error: 2.6139e-05 - val_loss: 6.1209e-05 - val_mean_squared_error: 5.9100e-05\n",
      "Epoch 12/1000\n",
      "34452/34452 [==============================] - 6s 182us/step - loss: 2.8243e-05 - mean_squared_error: 2.6126e-05 - val_loss: 6.1679e-05 - val_mean_squared_error: 5.9576e-05\n",
      "Epoch 13/1000\n",
      "34452/34452 [==============================] - 6s 180us/step - loss: 2.8223e-05 - mean_squared_error: 2.6117e-05 - val_loss: 6.1662e-05 - val_mean_squared_error: 5.9531e-05\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 14/1000\n",
      "34452/34452 [==============================] - 6s 167us/step - loss: 2.8161e-05 - mean_squared_error: 2.6050e-05 - val_loss: 6.1450e-05 - val_mean_squared_error: 5.9349e-05\n",
      "Epoch 15/1000\n",
      "34452/34452 [==============================] - 8s 236us/step - loss: 2.8146e-05 - mean_squared_error: 2.6046e-05 - val_loss: 6.1382e-05 - val_mean_squared_error: 5.9286e-05\n",
      "Epoch 16/1000\n",
      "34452/34452 [==============================] - 8s 218us/step - loss: 2.8142e-05 - mean_squared_error: 2.6045e-05 - val_loss: 6.1375e-05 - val_mean_squared_error: 5.9282e-05\n",
      "Epoch 17/1000\n",
      "34452/34452 [==============================] - 6s 177us/step - loss: 2.8140e-05 - mean_squared_error: 2.6045e-05 - val_loss: 6.1335e-05 - val_mean_squared_error: 5.9243e-05\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 18/1000\n",
      "34452/34452 [==============================] - 9s 252us/step - loss: 2.8130e-05 - mean_squared_error: 2.6038e-05 - val_loss: 6.1336e-05 - val_mean_squared_error: 5.9244e-05\n",
      "Epoch 19/1000\n",
      "34452/34452 [==============================] - 7s 189us/step - loss: 2.8129e-05 - mean_squared_error: 2.6038e-05 - val_loss: 6.1336e-05 - val_mean_squared_error: 5.9244e-05\n",
      "Epoch 20/1000\n",
      "34452/34452 [==============================] - 6s 182us/step - loss: 2.8129e-05 - mean_squared_error: 2.6036e-05 - val_loss: 6.1336e-05 - val_mean_squared_error: 5.9245e-05\n",
      "Epoch 21/1000\n",
      "34452/34452 [==============================] - 6s 170us/step - loss: 2.8128e-05 - mean_squared_error: 2.6037e-05 - val_loss: 6.1336e-05 - val_mean_squared_error: 5.9244e-05\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "Epoch 22/1000\n",
      "34452/34452 [==============================] - 6s 169us/step - loss: 2.8127e-05 - mean_squared_error: 2.6035e-05 - val_loss: 6.1336e-05 - val_mean_squared_error: 5.9244e-05\n",
      "Epoch 23/1000\n",
      "34452/34452 [==============================] - 6s 185us/step - loss: 2.8127e-05 - mean_squared_error: 2.6035e-05 - val_loss: 6.1336e-05 - val_mean_squared_error: 5.9244e-05\n",
      "Epoch 24/1000\n",
      "34452/34452 [==============================] - 7s 203us/step - loss: 2.8127e-05 - mean_squared_error: 2.6035e-05 - val_loss: 6.1336e-05 - val_mean_squared_error: 5.9244e-05\n",
      "Epoch 25/1000\n",
      "34452/34452 [==============================] - 9s 247us/step - loss: 2.8127e-05 - mean_squared_error: 2.6035e-05 - val_loss: 6.1336e-05 - val_mean_squared_error: 5.9244e-05\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "Epoch 26/1000\n",
      "34452/34452 [==============================] - 8s 229us/step - loss: 2.8127e-05 - mean_squared_error: 2.6035e-05 - val_loss: 6.1336e-05 - val_mean_squared_error: 5.9244e-05\n",
      "Epoch 27/1000\n",
      "34452/34452 [==============================] - 6s 172us/step - loss: 2.8127e-05 - mean_squared_error: 2.6035e-05 - val_loss: 6.1336e-05 - val_mean_squared_error: 5.9244e-05\n",
      "Epoch 28/1000\n",
      "34452/34452 [==============================] - 8s 227us/step - loss: 2.8127e-05 - mean_squared_error: 2.6035e-05 - val_loss: 6.1336e-05 - val_mean_squared_error: 5.9244e-05\n",
      "Epoch 00028: early stopping\n",
      "Train on 34452 samples, validate on 8636 samples\n",
      "Epoch 1/1000\n",
      "34452/34452 [==============================] - 8s 232us/step - loss: 3.5890e-05 - mean_squared_error: 3.0315e-05 - val_loss: 6.5425e-05 - val_mean_squared_error: 6.1479e-05\n",
      "Epoch 2/1000\n",
      "34452/34452 [==============================] - 8s 233us/step - loss: 3.4375e-05 - mean_squared_error: 2.9761e-05 - val_loss: 6.6094e-05 - val_mean_squared_error: 6.1607e-05\n",
      "Epoch 3/1000\n",
      "34452/34452 [==============================] - 6s 177us/step - loss: 3.4090e-05 - mean_squared_error: 2.9492e-05 - val_loss: 6.6734e-05 - val_mean_squared_error: 6.0515e-05\n",
      "Epoch 4/1000\n",
      "34452/34452 [==============================] - 6s 175us/step - loss: 3.4014e-05 - mean_squared_error: 2.9551e-05 - val_loss: 6.9776e-05 - val_mean_squared_error: 6.5021e-05\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 5/1000\n",
      "34452/34452 [==============================] - 8s 225us/step - loss: 2.9231e-05 - mean_squared_error: 2.6725e-05 - val_loss: 6.2122e-05 - val_mean_squared_error: 5.9621e-05\n",
      "Epoch 6/1000\n",
      "34452/34452 [==============================] - 8s 241us/step - loss: 2.9082e-05 - mean_squared_error: 2.6655e-05 - val_loss: 6.1997e-05 - val_mean_squared_error: 5.9570e-05\n",
      "Epoch 7/1000\n",
      "34452/34452 [==============================] - 6s 171us/step - loss: 2.8950e-05 - mean_squared_error: 2.6572e-05 - val_loss: 6.2154e-05 - val_mean_squared_error: 5.9783e-05\n",
      "Epoch 8/1000\n",
      "34452/34452 [==============================] - 6s 175us/step - loss: 2.8850e-05 - mean_squared_error: 2.6543e-05 - val_loss: 6.2386e-05 - val_mean_squared_error: 5.9923e-05\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 9/1000\n",
      "34452/34452 [==============================] - 7s 189us/step - loss: 2.8277e-05 - mean_squared_error: 2.6104e-05 - val_loss: 6.1326e-05 - val_mean_squared_error: 5.9200e-05\n",
      "Epoch 10/1000\n",
      "34452/34452 [==============================] - 6s 185us/step - loss: 2.8227e-05 - mean_squared_error: 2.6102e-05 - val_loss: 6.1333e-05 - val_mean_squared_error: 5.9223e-05\n",
      "Epoch 11/1000\n",
      "34452/34452 [==============================] - 6s 174us/step - loss: 2.8210e-05 - mean_squared_error: 2.6090e-05 - val_loss: 6.1867e-05 - val_mean_squared_error: 5.9778e-05\n",
      "Epoch 12/1000\n",
      "34452/34452 [==============================] - 6s 168us/step - loss: 2.8194e-05 - mean_squared_error: 2.6091e-05 - val_loss: 6.1592e-05 - val_mean_squared_error: 5.9479e-05\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 13/1000\n",
      "34452/34452 [==============================] - 7s 189us/step - loss: 2.8132e-05 - mean_squared_error: 2.6029e-05 - val_loss: 6.1434e-05 - val_mean_squared_error: 5.9336e-05\n",
      "Epoch 14/1000\n",
      "34452/34452 [==============================] - 7s 199us/step - loss: 2.8112e-05 - mean_squared_error: 2.6011e-05 - val_loss: 6.1396e-05 - val_mean_squared_error: 5.9300e-05\n",
      "Epoch 15/1000\n",
      "34452/34452 [==============================] - 7s 203us/step - loss: 2.8106e-05 - mean_squared_error: 2.6011e-05 - val_loss: 6.1380e-05 - val_mean_squared_error: 5.9283e-05\n",
      "Epoch 16/1000\n",
      "34452/34452 [==============================] - 7s 206us/step - loss: 2.8104e-05 - mean_squared_error: 2.6009e-05 - val_loss: 6.1384e-05 - val_mean_squared_error: 5.9291e-05\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 17/1000\n",
      "34452/34452 [==============================] - 7s 204us/step - loss: 2.8093e-05 - mean_squared_error: 2.6001e-05 - val_loss: 6.1380e-05 - val_mean_squared_error: 5.9287e-05\n",
      "Epoch 18/1000\n",
      "34452/34452 [==============================] - 6s 173us/step - loss: 2.8093e-05 - mean_squared_error: 2.6000e-05 - val_loss: 6.1376e-05 - val_mean_squared_error: 5.9283e-05\n",
      "Epoch 19/1000\n",
      "34452/34452 [==============================] - 6s 181us/step - loss: 2.8092e-05 - mean_squared_error: 2.5999e-05 - val_loss: 6.1374e-05 - val_mean_squared_error: 5.9281e-05\n",
      "Epoch 20/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34452/34452 [==============================] - 6s 182us/step - loss: 2.8092e-05 - mean_squared_error: 2.5999e-05 - val_loss: 6.1373e-05 - val_mean_squared_error: 5.9279e-05\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "Epoch 21/1000\n",
      "34452/34452 [==============================] - 6s 179us/step - loss: 2.8091e-05 - mean_squared_error: 2.5998e-05 - val_loss: 6.1372e-05 - val_mean_squared_error: 5.9279e-05\n",
      "Epoch 22/1000\n",
      "34452/34452 [==============================] - 9s 253us/step - loss: 2.8091e-05 - mean_squared_error: 2.5998e-05 - val_loss: 6.1372e-05 - val_mean_squared_error: 5.9279e-05\n",
      "Epoch 23/1000\n",
      "34452/34452 [==============================] - 6s 182us/step - loss: 2.8091e-05 - mean_squared_error: 2.5998e-05 - val_loss: 6.1372e-05 - val_mean_squared_error: 5.9279e-05\n",
      "Epoch 24/1000\n",
      "34452/34452 [==============================] - 6s 183us/step - loss: 2.8091e-05 - mean_squared_error: 2.5998e-05 - val_loss: 6.1372e-05 - val_mean_squared_error: 5.9279e-05\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "Epoch 25/1000\n",
      "34452/34452 [==============================] - 6s 175us/step - loss: 2.8091e-05 - mean_squared_error: 2.5998e-05 - val_loss: 6.1372e-05 - val_mean_squared_error: 5.9279e-05\n",
      "Epoch 26/1000\n",
      "34452/34452 [==============================] - 6s 164us/step - loss: 2.8091e-05 - mean_squared_error: 2.5998e-05 - val_loss: 6.1372e-05 - val_mean_squared_error: 5.9279e-05\n",
      "Epoch 27/1000\n",
      "34452/34452 [==============================] - 6s 185us/step - loss: 2.8091e-05 - mean_squared_error: 2.5998e-05 - val_loss: 6.1372e-05 - val_mean_squared_error: 5.9279e-05\n",
      "Epoch 28/1000\n",
      "34452/34452 [==============================] - 6s 183us/step - loss: 2.8091e-05 - mean_squared_error: 2.5998e-05 - val_loss: 6.1372e-05 - val_mean_squared_error: 5.9279e-05\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "Epoch 29/1000\n",
      "34452/34452 [==============================] - 6s 180us/step - loss: 2.8091e-05 - mean_squared_error: 2.5998e-05 - val_loss: 6.1372e-05 - val_mean_squared_error: 5.9279e-05\n",
      "Epoch 00029: early stopping\n",
      "Train on 34452 samples, validate on 8636 samples\n",
      "Epoch 1/1000\n",
      "34452/34452 [==============================] - 6s 171us/step - loss: 3.6204e-05 - mean_squared_error: 3.0448e-05 - val_loss: 6.7011e-05 - val_mean_squared_error: 6.2980e-05\n",
      "Epoch 2/1000\n",
      "34452/34452 [==============================] - 8s 239us/step - loss: 3.3970e-05 - mean_squared_error: 2.9499e-05 - val_loss: 6.9284e-05 - val_mean_squared_error: 6.4625e-05\n",
      "Epoch 3/1000\n",
      "34452/34452 [==============================] - 7s 215us/step - loss: 3.3898e-05 - mean_squared_error: 2.9420e-05 - val_loss: 6.3329e-05 - val_mean_squared_error: 5.9473e-05\n",
      "Epoch 4/1000\n",
      "34452/34452 [==============================] - 6s 176us/step - loss: 3.4534e-05 - mean_squared_error: 2.9674e-05 - val_loss: 6.4989e-05 - val_mean_squared_error: 6.0794e-05\n",
      "Epoch 5/1000\n",
      "34452/34452 [==============================] - 9s 255us/step - loss: 3.3976e-05 - mean_squared_error: 2.9482e-05 - val_loss: 6.7738e-05 - val_mean_squared_error: 6.3014e-05\n",
      "Epoch 6/1000\n",
      "34452/34452 [==============================] - 8s 231us/step - loss: 3.4054e-05 - mean_squared_error: 2.9543e-05 - val_loss: 6.3702e-05 - val_mean_squared_error: 6.0102e-05\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 7/1000\n",
      "34452/34452 [==============================] - 6s 188us/step - loss: 2.9168e-05 - mean_squared_error: 2.6694e-05 - val_loss: 6.2185e-05 - val_mean_squared_error: 5.9641e-05\n",
      "Epoch 8/1000\n",
      "34452/34452 [==============================] - 7s 196us/step - loss: 2.9037e-05 - mean_squared_error: 2.6615e-05 - val_loss: 6.2313e-05 - val_mean_squared_error: 5.9850e-05\n",
      "Epoch 9/1000\n",
      "34452/34452 [==============================] - 9s 250us/step - loss: 2.8917e-05 - mean_squared_error: 2.6552e-05 - val_loss: 6.1058e-05 - val_mean_squared_error: 5.8740e-05\n",
      "Epoch 10/1000\n",
      "34452/34452 [==============================] - 8s 235us/step - loss: 2.8864e-05 - mean_squared_error: 2.6555e-05 - val_loss: 6.2392e-05 - val_mean_squared_error: 6.0036e-05\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 11/1000\n",
      "34452/34452 [==============================] - 6s 177us/step - loss: 2.8277e-05 - mean_squared_error: 2.6149e-05 - val_loss: 6.1128e-05 - val_mean_squared_error: 5.9013e-05\n",
      "Epoch 12/1000\n",
      "34452/34452 [==============================] - 6s 186us/step - loss: 2.8203e-05 - mean_squared_error: 2.6095e-05 - val_loss: 6.1287e-05 - val_mean_squared_error: 5.9210e-05\n",
      "Epoch 13/1000\n",
      "34452/34452 [==============================] - 7s 197us/step - loss: 2.8189e-05 - mean_squared_error: 2.6091e-05 - val_loss: 6.1251e-05 - val_mean_squared_error: 5.9170e-05\n",
      "Epoch 14/1000\n",
      "34452/34452 [==============================] - 9s 251us/step - loss: 2.8166e-05 - mean_squared_error: 2.6073e-05 - val_loss: 6.1373e-05 - val_mean_squared_error: 5.9288e-05\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 15/1000\n",
      "34452/34452 [==============================] - 6s 173us/step - loss: 2.8105e-05 - mean_squared_error: 2.6027e-05 - val_loss: 6.1208e-05 - val_mean_squared_error: 5.9133e-05\n",
      "Epoch 16/1000\n",
      "34452/34452 [==============================] - 7s 196us/step - loss: 2.8091e-05 - mean_squared_error: 2.6014e-05 - val_loss: 6.1188e-05 - val_mean_squared_error: 5.9113e-05\n",
      "Epoch 17/1000\n",
      "34452/34452 [==============================] - 7s 200us/step - loss: 2.8086e-05 - mean_squared_error: 2.6011e-05 - val_loss: 6.1214e-05 - val_mean_squared_error: 5.9140e-05\n",
      "Epoch 18/1000\n",
      "34452/34452 [==============================] - 9s 249us/step - loss: 2.8083e-05 - mean_squared_error: 2.6007e-05 - val_loss: 6.1219e-05 - val_mean_squared_error: 5.9147e-05\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 19/1000\n",
      "34452/34452 [==============================] - 8s 231us/step - loss: 2.8073e-05 - mean_squared_error: 2.6001e-05 - val_loss: 6.1216e-05 - val_mean_squared_error: 5.9144e-05\n",
      "Epoch 20/1000\n",
      "34452/34452 [==============================] - 6s 177us/step - loss: 2.8073e-05 - mean_squared_error: 2.6000e-05 - val_loss: 6.1216e-05 - val_mean_squared_error: 5.9143e-05\n",
      "Epoch 21/1000\n",
      "34452/34452 [==============================] - 7s 203us/step - loss: 2.8072e-05 - mean_squared_error: 2.6000e-05 - val_loss: 6.1214e-05 - val_mean_squared_error: 5.9141e-05\n",
      "Epoch 22/1000\n",
      "34452/34452 [==============================] - 7s 196us/step - loss: 2.8072e-05 - mean_squared_error: 2.5999e-05 - val_loss: 6.1212e-05 - val_mean_squared_error: 5.9139e-05\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "Epoch 23/1000\n",
      "34452/34452 [==============================] - 7s 190us/step - loss: 2.8071e-05 - mean_squared_error: 2.5998e-05 - val_loss: 6.1212e-05 - val_mean_squared_error: 5.9139e-05\n",
      "Epoch 24/1000\n",
      "34452/34452 [==============================] - 9s 256us/step - loss: 2.8071e-05 - mean_squared_error: 2.5998e-05 - val_loss: 6.1211e-05 - val_mean_squared_error: 5.9138e-05\n",
      "Epoch 25/1000\n",
      "34452/34452 [==============================] - 6s 180us/step - loss: 2.8071e-05 - mean_squared_error: 2.5998e-05 - val_loss: 6.1211e-05 - val_mean_squared_error: 5.9138e-05\n",
      "Epoch 26/1000\n",
      "34452/34452 [==============================] - 6s 186us/step - loss: 2.8071e-05 - mean_squared_error: 2.5998e-05 - val_loss: 6.1211e-05 - val_mean_squared_error: 5.9138e-05\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "Epoch 27/1000\n",
      "34452/34452 [==============================] - 6s 183us/step - loss: 2.8070e-05 - mean_squared_error: 2.5997e-05 - val_loss: 6.1211e-05 - val_mean_squared_error: 5.9138e-05\n",
      "Epoch 28/1000\n",
      "34452/34452 [==============================] - 9s 259us/step - loss: 2.8070e-05 - mean_squared_error: 2.5997e-05 - val_loss: 6.1211e-05 - val_mean_squared_error: 5.9138e-05\n",
      "Epoch 29/1000\n",
      "34452/34452 [==============================] - 8s 237us/step - loss: 2.8070e-05 - mean_squared_error: 2.5997e-05 - val_loss: 6.1211e-05 - val_mean_squared_error: 5.9138e-05\n",
      "Epoch 00029: early stopping\n",
      "Train on 34452 samples, validate on 8636 samples\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34452/34452 [==============================] - 6s 175us/step - loss: 3.6233e-05 - mean_squared_error: 3.0393e-05 - val_loss: 6.7138e-05 - val_mean_squared_error: 6.1688e-05\n",
      "Epoch 2/1000\n",
      "34452/34452 [==============================] - 6s 182us/step - loss: 3.4199e-05 - mean_squared_error: 2.9666e-05 - val_loss: 6.6155e-05 - val_mean_squared_error: 6.2350e-05\n",
      "Epoch 3/1000\n",
      "34452/34452 [==============================] - 6s 180us/step - loss: 3.4048e-05 - mean_squared_error: 2.9518e-05 - val_loss: 7.0880e-05 - val_mean_squared_error: 6.5759e-05\n",
      "Epoch 4/1000\n",
      "34452/34452 [==============================] - 6s 166us/step - loss: 3.4352e-05 - mean_squared_error: 2.9624e-05 - val_loss: 6.5005e-05 - val_mean_squared_error: 5.9722e-05\n",
      "Epoch 5/1000\n",
      "34452/34452 [==============================] - 6s 172us/step - loss: 3.4245e-05 - mean_squared_error: 2.9554e-05 - val_loss: 6.3654e-05 - val_mean_squared_error: 5.9977e-05\n",
      "Epoch 6/1000\n",
      "34452/34452 [==============================] - 7s 214us/step - loss: 3.3999e-05 - mean_squared_error: 2.9411e-05 - val_loss: 6.3687e-05 - val_mean_squared_error: 5.8946e-05\n",
      "Epoch 7/1000\n",
      "34452/34452 [==============================] - 8s 237us/step - loss: 3.4025e-05 - mean_squared_error: 2.9508e-05 - val_loss: 6.3818e-05 - val_mean_squared_error: 5.9278e-05\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 8/1000\n",
      "34452/34452 [==============================] - 6s 167us/step - loss: 2.9183e-05 - mean_squared_error: 2.6685e-05 - val_loss: 6.1815e-05 - val_mean_squared_error: 5.9318e-05\n",
      "Epoch 9/1000\n",
      "34452/34452 [==============================] - 8s 232us/step - loss: 2.9017e-05 - mean_squared_error: 2.6594e-05 - val_loss: 6.1635e-05 - val_mean_squared_error: 5.9309e-05\n",
      "Epoch 10/1000\n",
      "34452/34452 [==============================] - 8s 228us/step - loss: 2.8933e-05 - mean_squared_error: 2.6562e-05 - val_loss: 6.0841e-05 - val_mean_squared_error: 5.8539e-05\n",
      "Epoch 11/1000\n",
      "34452/34452 [==============================] - 6s 175us/step - loss: 2.8811e-05 - mean_squared_error: 2.6509e-05 - val_loss: 6.2080e-05 - val_mean_squared_error: 5.9788e-05\n",
      "Epoch 12/1000\n",
      "34452/34452 [==============================] - 6s 170us/step - loss: 2.8790e-05 - mean_squared_error: 2.6538e-05 - val_loss: 6.1977e-05 - val_mean_squared_error: 5.9773e-05\n",
      "Epoch 13/1000\n",
      "34452/34452 [==============================] - 6s 181us/step - loss: 2.8654e-05 - mean_squared_error: 2.6442e-05 - val_loss: 6.1749e-05 - val_mean_squared_error: 5.9502e-05\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 14/1000\n",
      "34452/34452 [==============================] - 6s 187us/step - loss: 2.8030e-05 - mean_squared_error: 2.5976e-05 - val_loss: 6.1147e-05 - val_mean_squared_error: 5.9128e-05\n",
      "Epoch 15/1000\n",
      "34452/34452 [==============================] - 6s 177us/step - loss: 2.7975e-05 - mean_squared_error: 2.5953e-05 - val_loss: 6.0939e-05 - val_mean_squared_error: 5.8910e-05\n",
      "Epoch 16/1000\n",
      "34452/34452 [==============================] - 6s 172us/step - loss: 2.7950e-05 - mean_squared_error: 2.5927e-05 - val_loss: 6.1186e-05 - val_mean_squared_error: 5.9174e-05\n",
      "Epoch 17/1000\n",
      "34452/34452 [==============================] - 8s 237us/step - loss: 2.7927e-05 - mean_squared_error: 2.5909e-05 - val_loss: 6.0895e-05 - val_mean_squared_error: 5.8875e-05\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 18/1000\n",
      "34452/34452 [==============================] - 8s 221us/step - loss: 2.7858e-05 - mean_squared_error: 2.5852e-05 - val_loss: 6.1015e-05 - val_mean_squared_error: 5.9013e-05\n",
      "Epoch 19/1000\n",
      "34452/34452 [==============================] - 6s 178us/step - loss: 2.7843e-05 - mean_squared_error: 2.5842e-05 - val_loss: 6.1048e-05 - val_mean_squared_error: 5.9046e-05\n",
      "Epoch 20/1000\n",
      "34452/34452 [==============================] - 9s 255us/step - loss: 2.7839e-05 - mean_squared_error: 2.5838e-05 - val_loss: 6.1005e-05 - val_mean_squared_error: 5.9003e-05\n",
      "Epoch 21/1000\n",
      "34452/34452 [==============================] - 8s 229us/step - loss: 2.7836e-05 - mean_squared_error: 2.5836e-05 - val_loss: 6.1035e-05 - val_mean_squared_error: 5.9030e-05\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 22/1000\n",
      "34452/34452 [==============================] - 7s 191us/step - loss: 2.7826e-05 - mean_squared_error: 2.5822e-05 - val_loss: 6.1031e-05 - val_mean_squared_error: 5.9029e-05\n",
      "Epoch 23/1000\n",
      "34452/34452 [==============================] - 7s 193us/step - loss: 2.7825e-05 - mean_squared_error: 2.5823e-05 - val_loss: 6.1031e-05 - val_mean_squared_error: 5.9030e-05\n",
      "Epoch 24/1000\n",
      "34452/34452 [==============================] - 9s 253us/step - loss: 2.7825e-05 - mean_squared_error: 2.5824e-05 - val_loss: 6.1030e-05 - val_mean_squared_error: 5.9029e-05\n",
      "Epoch 25/1000\n",
      "34452/34452 [==============================] - 8s 231us/step - loss: 2.7824e-05 - mean_squared_error: 2.5823e-05 - val_loss: 6.1030e-05 - val_mean_squared_error: 5.9029e-05\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "Epoch 26/1000\n",
      "34452/34452 [==============================] - 6s 176us/step - loss: 2.7823e-05 - mean_squared_error: 2.5822e-05 - val_loss: 6.1030e-05 - val_mean_squared_error: 5.9029e-05\n",
      "Epoch 27/1000\n",
      "34452/34452 [==============================] - 6s 185us/step - loss: 2.7823e-05 - mean_squared_error: 2.5822e-05 - val_loss: 6.1030e-05 - val_mean_squared_error: 5.9029e-05\n",
      "Epoch 28/1000\n",
      "34452/34452 [==============================] - 6s 187us/step - loss: 2.7823e-05 - mean_squared_error: 2.5822e-05 - val_loss: 6.1029e-05 - val_mean_squared_error: 5.9029e-05\n",
      "Epoch 29/1000\n",
      "34452/34452 [==============================] - 6s 182us/step - loss: 2.7823e-05 - mean_squared_error: 2.5822e-05 - val_loss: 6.1029e-05 - val_mean_squared_error: 5.9029e-05\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "Epoch 30/1000\n",
      "34452/34452 [==============================] - 9s 251us/step - loss: 2.7822e-05 - mean_squared_error: 2.5822e-05 - val_loss: 6.1029e-05 - val_mean_squared_error: 5.9029e-05\n",
      "Epoch 00030: early stopping\n",
      "Train on 34452 samples, validate on 8636 samples\n",
      "Epoch 1/1000\n",
      "34452/34452 [==============================] - 7s 208us/step - loss: 3.5839e-05 - mean_squared_error: 3.0229e-05 - val_loss: 6.5435e-05 - val_mean_squared_error: 6.1320e-05\n",
      "Epoch 2/1000\n",
      "34452/34452 [==============================] - 7s 200us/step - loss: 3.4272e-05 - mean_squared_error: 2.9681e-05 - val_loss: 6.5127e-05 - val_mean_squared_error: 6.1150e-05\n",
      "Epoch 3/1000\n",
      "34452/34452 [==============================] - 9s 250us/step - loss: 3.4093e-05 - mean_squared_error: 2.9513e-05 - val_loss: 7.0450e-05 - val_mean_squared_error: 6.5450e-05\n",
      "Epoch 4/1000\n",
      "34452/34452 [==============================] - 8s 237us/step - loss: 3.4073e-05 - mean_squared_error: 2.9463e-05 - val_loss: 7.0771e-05 - val_mean_squared_error: 6.5898e-05\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 5/1000\n",
      "34452/34452 [==============================] - 7s 207us/step - loss: 2.9202e-05 - mean_squared_error: 2.6669e-05 - val_loss: 6.0570e-05 - val_mean_squared_error: 5.8118e-05\n",
      "Epoch 6/1000\n",
      "34452/34452 [==============================] - 5s 141us/step - loss: 2.8987e-05 - mean_squared_error: 2.6545e-05 - val_loss: 6.1348e-05 - val_mean_squared_error: 5.9005e-05\n",
      "Epoch 7/1000\n",
      "34452/34452 [==============================] - 7s 213us/step - loss: 2.8889e-05 - mean_squared_error: 2.6527e-05 - val_loss: 6.1694e-05 - val_mean_squared_error: 5.9388e-05\n",
      "Epoch 8/1000\n",
      "34452/34452 [==============================] - 6s 179us/step - loss: 2.8797e-05 - mean_squared_error: 2.6501e-05 - val_loss: 6.0994e-05 - val_mean_squared_error: 5.8735e-05\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 9/1000\n",
      "34452/34452 [==============================] - 8s 223us/step - loss: 2.8217e-05 - mean_squared_error: 2.6100e-05 - val_loss: 6.0904e-05 - val_mean_squared_error: 5.8788e-05\n",
      "Epoch 10/1000\n",
      "34452/34452 [==============================] - 8s 239us/step - loss: 2.8171e-05 - mean_squared_error: 2.6058e-05 - val_loss: 6.0880e-05 - val_mean_squared_error: 5.8802e-05\n",
      "Epoch 11/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34452/34452 [==============================] - 8s 228us/step - loss: 2.8151e-05 - mean_squared_error: 2.6063e-05 - val_loss: 6.0975e-05 - val_mean_squared_error: 5.8871e-05\n",
      "Epoch 12/1000\n",
      "34452/34452 [==============================] - 8s 228us/step - loss: 2.8129e-05 - mean_squared_error: 2.6028e-05 - val_loss: 6.0744e-05 - val_mean_squared_error: 5.8649e-05\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 13/1000\n",
      "34452/34452 [==============================] - 8s 229us/step - loss: 2.8065e-05 - mean_squared_error: 2.5986e-05 - val_loss: 6.0860e-05 - val_mean_squared_error: 5.8780e-05\n",
      "Epoch 14/1000\n",
      "34452/34452 [==============================] - 6s 170us/step - loss: 2.8051e-05 - mean_squared_error: 2.5973e-05 - val_loss: 6.0910e-05 - val_mean_squared_error: 5.8833e-05\n",
      "Epoch 15/1000\n",
      "34452/34452 [==============================] - 6s 176us/step - loss: 2.8046e-05 - mean_squared_error: 2.5971e-05 - val_loss: 6.0905e-05 - val_mean_squared_error: 5.8828e-05\n",
      "Epoch 16/1000\n",
      "34452/34452 [==============================] - 6s 183us/step - loss: 2.8044e-05 - mean_squared_error: 2.5970e-05 - val_loss: 6.0890e-05 - val_mean_squared_error: 5.8812e-05\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 17/1000\n",
      "34452/34452 [==============================] - 6s 178us/step - loss: 2.8035e-05 - mean_squared_error: 2.5957e-05 - val_loss: 6.0895e-05 - val_mean_squared_error: 5.8818e-05\n",
      "Epoch 18/1000\n",
      "34452/34452 [==============================] - 6s 172us/step - loss: 2.8034e-05 - mean_squared_error: 2.5957e-05 - val_loss: 6.0901e-05 - val_mean_squared_error: 5.8825e-05\n",
      "Epoch 19/1000\n",
      "34452/34452 [==============================] - 8s 239us/step - loss: 2.8033e-05 - mean_squared_error: 2.5957e-05 - val_loss: 6.0904e-05 - val_mean_squared_error: 5.8828e-05\n",
      "Epoch 20/1000\n",
      "34452/34452 [==============================] - 7s 213us/step - loss: 2.8033e-05 - mean_squared_error: 2.5957e-05 - val_loss: 6.0907e-05 - val_mean_squared_error: 5.8831e-05\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "Epoch 21/1000\n",
      "34452/34452 [==============================] - 6s 175us/step - loss: 2.8032e-05 - mean_squared_error: 2.5956e-05 - val_loss: 6.0907e-05 - val_mean_squared_error: 5.8832e-05\n",
      "Epoch 22/1000\n",
      "34452/34452 [==============================] - 6s 170us/step - loss: 2.8032e-05 - mean_squared_error: 2.5956e-05 - val_loss: 6.0908e-05 - val_mean_squared_error: 5.8832e-05\n",
      "Epoch 23/1000\n",
      "34452/34452 [==============================] - 6s 178us/step - loss: 2.8032e-05 - mean_squared_error: 2.5956e-05 - val_loss: 6.0908e-05 - val_mean_squared_error: 5.8832e-05\n",
      "Epoch 24/1000\n",
      "34452/34452 [==============================] - 6s 185us/step - loss: 2.8032e-05 - mean_squared_error: 2.5956e-05 - val_loss: 6.0908e-05 - val_mean_squared_error: 5.8832e-05\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "Epoch 25/1000\n",
      "34452/34452 [==============================] - 6s 181us/step - loss: 2.8031e-05 - mean_squared_error: 2.5956e-05 - val_loss: 6.0908e-05 - val_mean_squared_error: 5.8832e-05\n",
      "Epoch 00025: early stopping\n",
      "Train on 34452 samples, validate on 8636 samples\n",
      "Epoch 1/1000\n",
      "34452/34452 [==============================] - 6s 175us/step - loss: 3.5976e-05 - mean_squared_error: 3.0291e-05 - val_loss: 7.1731e-05 - val_mean_squared_error: 6.6983e-05\n",
      "Epoch 2/1000\n",
      "34452/34452 [==============================] - 8s 243us/step - loss: 3.4117e-05 - mean_squared_error: 2.9586e-05 - val_loss: 6.5777e-05 - val_mean_squared_error: 6.1400e-05\n",
      "Epoch 3/1000\n",
      "34452/34452 [==============================] - 7s 216us/step - loss: 3.3906e-05 - mean_squared_error: 2.9374e-05 - val_loss: 6.8422e-05 - val_mean_squared_error: 6.3264e-05\n",
      "Epoch 4/1000\n",
      "34452/34452 [==============================] - 6s 182us/step - loss: 3.4414e-05 - mean_squared_error: 2.9710e-05 - val_loss: 6.5461e-05 - val_mean_squared_error: 6.1370e-05\n",
      "Epoch 5/1000\n",
      "34452/34452 [==============================] - 9s 259us/step - loss: 3.3733e-05 - mean_squared_error: 2.9320e-05 - val_loss: 6.7486e-05 - val_mean_squared_error: 6.3411e-05\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 6/1000\n",
      "34452/34452 [==============================] - 6s 181us/step - loss: 2.9155e-05 - mean_squared_error: 2.6689e-05 - val_loss: 6.0779e-05 - val_mean_squared_error: 5.8407e-05\n",
      "Epoch 7/1000\n",
      "34452/34452 [==============================] - 7s 206us/step - loss: 2.8947e-05 - mean_squared_error: 2.6540e-05 - val_loss: 6.1591e-05 - val_mean_squared_error: 5.8987e-05\n",
      "Epoch 8/1000\n",
      "34452/34452 [==============================] - 8s 244us/step - loss: 2.8930e-05 - mean_squared_error: 2.6568e-05 - val_loss: 6.0666e-05 - val_mean_squared_error: 5.8449e-05\n",
      "Epoch 9/1000\n",
      "34452/34452 [==============================] - 6s 179us/step - loss: 2.8798e-05 - mean_squared_error: 2.6503e-05 - val_loss: 6.1125e-05 - val_mean_squared_error: 5.8871e-05\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 10/1000\n",
      "34452/34452 [==============================] - 7s 194us/step - loss: 2.8212e-05 - mean_squared_error: 2.6128e-05 - val_loss: 6.0852e-05 - val_mean_squared_error: 5.8759e-05\n",
      "Epoch 11/1000\n",
      "34452/34452 [==============================] - 7s 216us/step - loss: 2.8141e-05 - mean_squared_error: 2.6061e-05 - val_loss: 6.0986e-05 - val_mean_squared_error: 5.8887e-05\n",
      "Epoch 12/1000\n",
      "34452/34452 [==============================] - 8s 244us/step - loss: 2.8121e-05 - mean_squared_error: 2.6038e-05 - val_loss: 6.0863e-05 - val_mean_squared_error: 5.8785e-05\n",
      "Epoch 13/1000\n",
      "34452/34452 [==============================] - 6s 170us/step - loss: 2.8115e-05 - mean_squared_error: 2.6039e-05 - val_loss: 6.0911e-05 - val_mean_squared_error: 5.8833e-05\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 14/1000\n",
      "34452/34452 [==============================] - 6s 187us/step - loss: 2.8043e-05 - mean_squared_error: 2.5977e-05 - val_loss: 6.0869e-05 - val_mean_squared_error: 5.8807e-05\n",
      "Epoch 15/1000\n",
      "34452/34452 [==============================] - 8s 218us/step - loss: 2.8029e-05 - mean_squared_error: 2.5967e-05 - val_loss: 6.0807e-05 - val_mean_squared_error: 5.8750e-05\n",
      "Epoch 16/1000\n",
      "34452/34452 [==============================] - 8s 237us/step - loss: 2.8024e-05 - mean_squared_error: 2.5966e-05 - val_loss: 6.0823e-05 - val_mean_squared_error: 5.8767e-05\n",
      "Epoch 17/1000\n",
      "34452/34452 [==============================] - 8s 232us/step - loss: 2.8023e-05 - mean_squared_error: 2.5967e-05 - val_loss: 6.0822e-05 - val_mean_squared_error: 5.8767e-05\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 18/1000\n",
      "34452/34452 [==============================] - 8s 233us/step - loss: 2.8012e-05 - mean_squared_error: 2.5959e-05 - val_loss: 6.0822e-05 - val_mean_squared_error: 5.8768e-05\n",
      "Epoch 19/1000\n",
      "34452/34452 [==============================] - 8s 233us/step - loss: 2.8012e-05 - mean_squared_error: 2.5958e-05 - val_loss: 6.0823e-05 - val_mean_squared_error: 5.8769e-05\n",
      "Epoch 20/1000\n",
      "34452/34452 [==============================] - 7s 200us/step - loss: 2.8011e-05 - mean_squared_error: 2.5958e-05 - val_loss: 6.0821e-05 - val_mean_squared_error: 5.8767e-05\n",
      "Epoch 21/1000\n",
      "34452/34452 [==============================] - 5s 143us/step - loss: 2.8011e-05 - mean_squared_error: 2.5958e-05 - val_loss: 6.0822e-05 - val_mean_squared_error: 5.8769e-05\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "Epoch 22/1000\n",
      "34452/34452 [==============================] - 8s 238us/step - loss: 2.8010e-05 - mean_squared_error: 2.5956e-05 - val_loss: 6.0822e-05 - val_mean_squared_error: 5.8769e-05\n",
      "Epoch 23/1000\n",
      "34452/34452 [==============================] - 9s 261us/step - loss: 2.8010e-05 - mean_squared_error: 2.5956e-05 - val_loss: 6.0822e-05 - val_mean_squared_error: 5.8769e-05\n",
      "Epoch 24/1000\n",
      "34452/34452 [==============================] - 7s 195us/step - loss: 2.8010e-05 - mean_squared_error: 2.5956e-05 - val_loss: 6.0822e-05 - val_mean_squared_error: 5.8768e-05\n",
      "Epoch 25/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34452/34452 [==============================] - 6s 184us/step - loss: 2.8010e-05 - mean_squared_error: 2.5956e-05 - val_loss: 6.0822e-05 - val_mean_squared_error: 5.8769e-05\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "Epoch 26/1000\n",
      "34452/34452 [==============================] - 6s 173us/step - loss: 2.8009e-05 - mean_squared_error: 2.5956e-05 - val_loss: 6.0822e-05 - val_mean_squared_error: 5.8769e-05\n",
      "Epoch 00026: early stopping\n",
      "Train on 34452 samples, validate on 8636 samples\n",
      "Epoch 1/1000\n",
      "34452/34452 [==============================] - 6s 167us/step - loss: 3.5874e-05 - mean_squared_error: 3.0310e-05 - val_loss: 6.5620e-05 - val_mean_squared_error: 6.1656e-05\n",
      "Epoch 2/1000\n",
      "34452/34452 [==============================] - 6s 180us/step - loss: 3.4392e-05 - mean_squared_error: 2.9624e-05 - val_loss: 6.7128e-05 - val_mean_squared_error: 6.3282e-05\n",
      "Epoch 3/1000\n",
      "34452/34452 [==============================] - 6s 181us/step - loss: 3.3757e-05 - mean_squared_error: 2.9336e-05 - val_loss: 6.7649e-05 - val_mean_squared_error: 6.2638e-05\n",
      "Epoch 4/1000\n",
      "34452/34452 [==============================] - 6s 178us/step - loss: 3.3833e-05 - mean_squared_error: 2.9334e-05 - val_loss: 6.6447e-05 - val_mean_squared_error: 6.1602e-05\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 5/1000\n",
      "34452/34452 [==============================] - 6s 167us/step - loss: 2.9088e-05 - mean_squared_error: 2.6632e-05 - val_loss: 6.2541e-05 - val_mean_squared_error: 5.9980e-05\n",
      "Epoch 6/1000\n",
      "34452/34452 [==============================] - 8s 243us/step - loss: 2.8921e-05 - mean_squared_error: 2.6524e-05 - val_loss: 6.1348e-05 - val_mean_squared_error: 5.9084e-05\n",
      "Epoch 7/1000\n",
      "34452/34452 [==============================] - 7s 216us/step - loss: 2.8843e-05 - mean_squared_error: 2.6522e-05 - val_loss: 5.9979e-05 - val_mean_squared_error: 5.7795e-05\n",
      "Epoch 8/1000\n",
      "34452/34452 [==============================] - 6s 176us/step - loss: 2.8800e-05 - mean_squared_error: 2.6539e-05 - val_loss: 6.1031e-05 - val_mean_squared_error: 5.8762e-05\n",
      "Epoch 9/1000\n",
      "34452/34452 [==============================] - 9s 253us/step - loss: 2.8674e-05 - mean_squared_error: 2.6465e-05 - val_loss: 6.1128e-05 - val_mean_squared_error: 5.8972e-05\n",
      "Epoch 10/1000\n",
      "34452/34452 [==============================] - 7s 189us/step - loss: 2.8598e-05 - mean_squared_error: 2.6426e-05 - val_loss: 6.1699e-05 - val_mean_squared_error: 5.9425e-05\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 11/1000\n",
      "34452/34452 [==============================] - 7s 192us/step - loss: 2.7965e-05 - mean_squared_error: 2.5947e-05 - val_loss: 6.0798e-05 - val_mean_squared_error: 5.8769e-05\n",
      "Epoch 12/1000\n",
      "34452/34452 [==============================] - 9s 250us/step - loss: 2.7909e-05 - mean_squared_error: 2.5918e-05 - val_loss: 6.0809e-05 - val_mean_squared_error: 5.8815e-05\n",
      "Epoch 13/1000\n",
      "34452/34452 [==============================] - 8s 231us/step - loss: 2.7886e-05 - mean_squared_error: 2.5899e-05 - val_loss: 6.0691e-05 - val_mean_squared_error: 5.8711e-05\n",
      "Epoch 14/1000\n",
      "34452/34452 [==============================] - 6s 177us/step - loss: 2.7881e-05 - mean_squared_error: 2.5900e-05 - val_loss: 6.0516e-05 - val_mean_squared_error: 5.8554e-05\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 15/1000\n",
      "34452/34452 [==============================] - 7s 217us/step - loss: 2.7801e-05 - mean_squared_error: 2.5844e-05 - val_loss: 6.0513e-05 - val_mean_squared_error: 5.8556e-05\n",
      "Epoch 16/1000\n",
      "34452/34452 [==============================] - 8s 238us/step - loss: 2.7790e-05 - mean_squared_error: 2.5836e-05 - val_loss: 6.0545e-05 - val_mean_squared_error: 5.8587e-05\n",
      "Epoch 17/1000\n",
      "34452/34452 [==============================] - 6s 173us/step - loss: 2.7786e-05 - mean_squared_error: 2.5826e-05 - val_loss: 6.0587e-05 - val_mean_squared_error: 5.8627e-05\n",
      "Epoch 18/1000\n",
      "34452/34452 [==============================] - 6s 179us/step - loss: 2.7783e-05 - mean_squared_error: 2.5822e-05 - val_loss: 6.0558e-05 - val_mean_squared_error: 5.8597e-05\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 19/1000\n",
      "34452/34452 [==============================] - 7s 215us/step - loss: 2.7772e-05 - mean_squared_error: 2.5813e-05 - val_loss: 6.0563e-05 - val_mean_squared_error: 5.8604e-05\n",
      "Epoch 20/1000\n",
      "34452/34452 [==============================] - 8s 241us/step - loss: 2.7772e-05 - mean_squared_error: 2.5813e-05 - val_loss: 6.0568e-05 - val_mean_squared_error: 5.8609e-05\n",
      "Epoch 21/1000\n",
      "34452/34452 [==============================] - 6s 169us/step - loss: 2.7771e-05 - mean_squared_error: 2.5812e-05 - val_loss: 6.0572e-05 - val_mean_squared_error: 5.8613e-05\n",
      "Epoch 22/1000\n",
      "34452/34452 [==============================] - 8s 242us/step - loss: 2.7771e-05 - mean_squared_error: 2.5813e-05 - val_loss: 6.0576e-05 - val_mean_squared_error: 5.8618e-05\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "Epoch 23/1000\n",
      "34452/34452 [==============================] - 8s 229us/step - loss: 2.7770e-05 - mean_squared_error: 2.5811e-05 - val_loss: 6.0576e-05 - val_mean_squared_error: 5.8618e-05\n",
      "Epoch 24/1000\n",
      "34452/34452 [==============================] - 8s 227us/step - loss: 2.7770e-05 - mean_squared_error: 2.5811e-05 - val_loss: 6.0577e-05 - val_mean_squared_error: 5.8618e-05\n",
      "Epoch 25/1000\n",
      "34452/34452 [==============================] - 6s 180us/step - loss: 2.7769e-05 - mean_squared_error: 2.5811e-05 - val_loss: 6.0577e-05 - val_mean_squared_error: 5.8618e-05\n",
      "Epoch 26/1000\n",
      "34452/34452 [==============================] - 6s 182us/step - loss: 2.7769e-05 - mean_squared_error: 2.5811e-05 - val_loss: 6.0577e-05 - val_mean_squared_error: 5.8618e-05\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "Epoch 27/1000\n",
      "34452/34452 [==============================] - 8s 241us/step - loss: 2.7769e-05 - mean_squared_error: 2.5811e-05 - val_loss: 6.0577e-05 - val_mean_squared_error: 5.8618e-05\n",
      "Epoch 00027: early stopping\n",
      "Train on 34452 samples, validate on 8636 samples\n",
      "Epoch 1/1000\n",
      "34452/34452 [==============================] - 8s 221us/step - loss: 3.5864e-05 - mean_squared_error: 3.0297e-05 - val_loss: 6.5621e-05 - val_mean_squared_error: 6.1116e-05\n",
      "Epoch 2/1000\n",
      "34452/34452 [==============================] - 7s 199us/step - loss: 3.3643e-05 - mean_squared_error: 2.9262e-05 - val_loss: 7.0328e-05 - val_mean_squared_error: 6.5680e-05\n",
      "Epoch 3/1000\n",
      "34452/34452 [==============================] - 6s 175us/step - loss: 3.3802e-05 - mean_squared_error: 2.9370e-05 - val_loss: 6.3691e-05 - val_mean_squared_error: 5.8703e-05\n",
      "Epoch 4/1000\n",
      "34452/34452 [==============================] - 6s 174us/step - loss: 3.4106e-05 - mean_squared_error: 2.9407e-05 - val_loss: 6.5387e-05 - val_mean_squared_error: 6.1171e-05\n",
      "Epoch 5/1000\n",
      "34452/34452 [==============================] - 8s 231us/step - loss: 3.3873e-05 - mean_squared_error: 2.9382e-05 - val_loss: 6.3099e-05 - val_mean_squared_error: 5.9917e-05\n",
      "Epoch 6/1000\n",
      "34452/34452 [==============================] - 8s 235us/step - loss: 3.4169e-05 - mean_squared_error: 2.9480e-05 - val_loss: 6.6112e-05 - val_mean_squared_error: 6.1100e-05\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 7/1000\n",
      "34452/34452 [==============================] - 6s 174us/step - loss: 2.9087e-05 - mean_squared_error: 2.6570e-05 - val_loss: 6.0605e-05 - val_mean_squared_error: 5.8277e-05\n",
      "Epoch 8/1000\n",
      "34452/34452 [==============================] - 6s 178us/step - loss: 2.8924e-05 - mean_squared_error: 2.6494e-05 - val_loss: 6.1653e-05 - val_mean_squared_error: 5.9309e-05\n",
      "Epoch 9/1000\n",
      "34452/34452 [==============================] - 7s 195us/step - loss: 2.8864e-05 - mean_squared_error: 2.6487e-05 - val_loss: 6.0933e-05 - val_mean_squared_error: 5.8734e-05\n",
      "Epoch 10/1000\n",
      "34452/34452 [==============================] - 7s 213us/step - loss: 2.8758e-05 - mean_squared_error: 2.6464e-05 - val_loss: 6.0998e-05 - val_mean_squared_error: 5.8739e-05\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 11/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34452/34452 [==============================] - 8s 238us/step - loss: 2.8171e-05 - mean_squared_error: 2.6069e-05 - val_loss: 6.0748e-05 - val_mean_squared_error: 5.8660e-05\n",
      "Epoch 12/1000\n",
      "34452/34452 [==============================] - 6s 169us/step - loss: 2.8109e-05 - mean_squared_error: 2.6014e-05 - val_loss: 6.0572e-05 - val_mean_squared_error: 5.8492e-05\n",
      "Epoch 13/1000\n",
      "34452/34452 [==============================] - 6s 180us/step - loss: 2.8093e-05 - mean_squared_error: 2.6015e-05 - val_loss: 6.0746e-05 - val_mean_squared_error: 5.8665e-05\n",
      "Epoch 14/1000\n",
      "34452/34452 [==============================] - 6s 181us/step - loss: 2.8076e-05 - mean_squared_error: 2.6004e-05 - val_loss: 6.0686e-05 - val_mean_squared_error: 5.8587e-05\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 15/1000\n",
      "34452/34452 [==============================] - 6s 172us/step - loss: 2.8011e-05 - mean_squared_error: 2.5930e-05 - val_loss: 6.0676e-05 - val_mean_squared_error: 5.8601e-05\n",
      "Epoch 16/1000\n",
      "34452/34452 [==============================] - 6s 166us/step - loss: 2.7998e-05 - mean_squared_error: 2.5927e-05 - val_loss: 6.0701e-05 - val_mean_squared_error: 5.8634e-05\n",
      "Epoch 17/1000\n",
      "34452/34452 [==============================] - 8s 230us/step - loss: 2.7994e-05 - mean_squared_error: 2.5927e-05 - val_loss: 6.0658e-05 - val_mean_squared_error: 5.8593e-05\n",
      "Epoch 18/1000\n",
      "34452/34452 [==============================] - 8s 227us/step - loss: 2.7992e-05 - mean_squared_error: 2.5928e-05 - val_loss: 6.0675e-05 - val_mean_squared_error: 5.8615e-05\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 19/1000\n",
      "34452/34452 [==============================] - 6s 168us/step - loss: 2.7982e-05 - mean_squared_error: 2.5921e-05 - val_loss: 6.0675e-05 - val_mean_squared_error: 5.8615e-05\n",
      "Epoch 20/1000\n",
      "34452/34452 [==============================] - 6s 171us/step - loss: 2.7981e-05 - mean_squared_error: 2.5921e-05 - val_loss: 6.0673e-05 - val_mean_squared_error: 5.8612e-05\n",
      "Epoch 21/1000\n",
      "34452/34452 [==============================] - 6s 185us/step - loss: 2.7981e-05 - mean_squared_error: 2.5920e-05 - val_loss: 6.0672e-05 - val_mean_squared_error: 5.8612e-05\n",
      "Epoch 22/1000\n",
      "34452/34452 [==============================] - 7s 189us/step - loss: 2.7980e-05 - mean_squared_error: 2.5920e-05 - val_loss: 6.0673e-05 - val_mean_squared_error: 5.8613e-05\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "Epoch 23/1000\n",
      "34452/34452 [==============================] - 9s 251us/step - loss: 2.7979e-05 - mean_squared_error: 2.5919e-05 - val_loss: 6.0672e-05 - val_mean_squared_error: 5.8612e-05\n",
      "Epoch 24/1000\n",
      "34452/34452 [==============================] - 8s 231us/step - loss: 2.7979e-05 - mean_squared_error: 2.5919e-05 - val_loss: 6.0672e-05 - val_mean_squared_error: 5.8612e-05\n",
      "Epoch 25/1000\n",
      "34452/34452 [==============================] - 6s 174us/step - loss: 2.7979e-05 - mean_squared_error: 2.5919e-05 - val_loss: 6.0672e-05 - val_mean_squared_error: 5.8612e-05\n",
      "Epoch 26/1000\n",
      "34452/34452 [==============================] - 7s 216us/step - loss: 2.7979e-05 - mean_squared_error: 2.5919e-05 - val_loss: 6.0672e-05 - val_mean_squared_error: 5.8612e-05\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "Epoch 27/1000\n",
      "34452/34452 [==============================] - 8s 243us/step - loss: 2.7979e-05 - mean_squared_error: 2.5919e-05 - val_loss: 6.0672e-05 - val_mean_squared_error: 5.8612e-05\n",
      "Epoch 00027: early stopping\n",
      "Train on 34452 samples, validate on 8636 samples\n",
      "Epoch 1/1000\n",
      "34452/34452 [==============================] - 8s 230us/step - loss: 3.5870e-05 - mean_squared_error: 3.0349e-05 - val_loss: 6.6395e-05 - val_mean_squared_error: 6.1593e-05\n",
      "Epoch 2/1000\n",
      "34452/34452 [==============================] - 6s 171us/step - loss: 3.4232e-05 - mean_squared_error: 2.9499e-05 - val_loss: 6.4857e-05 - val_mean_squared_error: 6.0495e-05\n",
      "Epoch 3/1000\n",
      "34452/34452 [==============================] - 8s 238us/step - loss: 3.3891e-05 - mean_squared_error: 2.9335e-05 - val_loss: 6.4378e-05 - val_mean_squared_error: 6.0020e-05\n",
      "Epoch 4/1000\n",
      "34452/34452 [==============================] - 8s 220us/step - loss: 3.4290e-05 - mean_squared_error: 2.9559e-05 - val_loss: 6.7696e-05 - val_mean_squared_error: 6.3789e-05\n",
      "Epoch 5/1000\n",
      "34452/34452 [==============================] - 6s 178us/step - loss: 3.4125e-05 - mean_squared_error: 2.9437e-05 - val_loss: 6.6333e-05 - val_mean_squared_error: 6.2715e-05\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 6/1000\n",
      "34452/34452 [==============================] - 6s 173us/step - loss: 2.9150e-05 - mean_squared_error: 2.6654e-05 - val_loss: 6.0905e-05 - val_mean_squared_error: 5.8391e-05\n",
      "Epoch 7/1000\n",
      "34452/34452 [==============================] - 6s 185us/step - loss: 2.8908e-05 - mean_squared_error: 2.6479e-05 - val_loss: 6.1492e-05 - val_mean_squared_error: 5.9032e-05\n",
      "Epoch 8/1000\n",
      "34452/34452 [==============================] - 7s 213us/step - loss: 2.8843e-05 - mean_squared_error: 2.6475e-05 - val_loss: 6.2158e-05 - val_mean_squared_error: 5.9706e-05\n",
      "Epoch 9/1000\n",
      "34452/34452 [==============================] - 8s 242us/step - loss: 2.8737e-05 - mean_squared_error: 2.6434e-05 - val_loss: 6.1907e-05 - val_mean_squared_error: 5.9491e-05\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 10/1000\n",
      "34452/34452 [==============================] - 6s 168us/step - loss: 2.8159e-05 - mean_squared_error: 2.6021e-05 - val_loss: 6.0824e-05 - val_mean_squared_error: 5.8716e-05\n",
      "Epoch 11/1000\n",
      "34452/34452 [==============================] - 6s 184us/step - loss: 2.8106e-05 - mean_squared_error: 2.6003e-05 - val_loss: 6.0740e-05 - val_mean_squared_error: 5.8649e-05\n",
      "Epoch 12/1000\n",
      "34452/34452 [==============================] - 7s 189us/step - loss: 2.8076e-05 - mean_squared_error: 2.5993e-05 - val_loss: 6.0737e-05 - val_mean_squared_error: 5.8625e-05\n",
      "Epoch 13/1000\n",
      "34452/34452 [==============================] - 6s 184us/step - loss: 2.8069e-05 - mean_squared_error: 2.5971e-05 - val_loss: 6.0836e-05 - val_mean_squared_error: 5.8762e-05\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 14/1000\n",
      "34452/34452 [==============================] - 9s 256us/step - loss: 2.8006e-05 - mean_squared_error: 2.5940e-05 - val_loss: 6.0658e-05 - val_mean_squared_error: 5.8597e-05\n",
      "Epoch 15/1000\n",
      "34452/34452 [==============================] - 7s 207us/step - loss: 2.7987e-05 - mean_squared_error: 2.5922e-05 - val_loss: 6.0633e-05 - val_mean_squared_error: 5.8570e-05\n",
      "Epoch 16/1000\n",
      "34452/34452 [==============================] - 8s 228us/step - loss: 2.7982e-05 - mean_squared_error: 2.5921e-05 - val_loss: 6.0651e-05 - val_mean_squared_error: 5.8584e-05\n",
      "Epoch 17/1000\n",
      "34452/34452 [==============================] - 9s 264us/step - loss: 2.7981e-05 - mean_squared_error: 2.5917e-05 - val_loss: 6.0655e-05 - val_mean_squared_error: 5.8586e-05\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 18/1000\n",
      "34452/34452 [==============================] - 8s 224us/step - loss: 2.7970e-05 - mean_squared_error: 2.5903e-05 - val_loss: 6.0651e-05 - val_mean_squared_error: 5.8584e-05\n",
      "Epoch 19/1000\n",
      "34452/34452 [==============================] - 6s 173us/step - loss: 2.7969e-05 - mean_squared_error: 2.5903e-05 - val_loss: 6.0648e-05 - val_mean_squared_error: 5.8582e-05\n",
      "Epoch 20/1000\n",
      "34452/34452 [==============================] - 9s 249us/step - loss: 2.7969e-05 - mean_squared_error: 2.5903e-05 - val_loss: 6.0644e-05 - val_mean_squared_error: 5.8579e-05\n",
      "Epoch 21/1000\n",
      "34452/34452 [==============================] - 7s 214us/step - loss: 2.7969e-05 - mean_squared_error: 2.5903e-05 - val_loss: 6.0642e-05 - val_mean_squared_error: 5.8577e-05\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "Epoch 22/1000\n",
      "34452/34452 [==============================] - 7s 191us/step - loss: 2.7967e-05 - mean_squared_error: 2.5902e-05 - val_loss: 6.0642e-05 - val_mean_squared_error: 5.8577e-05\n",
      "Epoch 23/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34452/34452 [==============================] - 6s 177us/step - loss: 2.7967e-05 - mean_squared_error: 2.5902e-05 - val_loss: 6.0642e-05 - val_mean_squared_error: 5.8577e-05\n",
      "Epoch 24/1000\n",
      "34452/34452 [==============================] - 9s 247us/step - loss: 2.7967e-05 - mean_squared_error: 2.5902e-05 - val_loss: 6.0642e-05 - val_mean_squared_error: 5.8577e-05\n",
      "Epoch 25/1000\n",
      "34452/34452 [==============================] - 7s 189us/step - loss: 2.7967e-05 - mean_squared_error: 2.5902e-05 - val_loss: 6.0642e-05 - val_mean_squared_error: 5.8577e-05\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "Epoch 26/1000\n",
      "34452/34452 [==============================] - 6s 185us/step - loss: 2.7967e-05 - mean_squared_error: 2.5902e-05 - val_loss: 6.0642e-05 - val_mean_squared_error: 5.8577e-05\n",
      "Epoch 00026: early stopping\n",
      "Train on 34452 samples, validate on 8636 samples\n",
      "Epoch 1/1000\n",
      "34452/34452 [==============================] - 6s 170us/step - loss: 3.5749e-05 - mean_squared_error: 3.0123e-05 - val_loss: 6.7399e-05 - val_mean_squared_error: 6.3445e-05\n",
      "Epoch 2/1000\n",
      "34452/34452 [==============================] - 6s 166us/step - loss: 3.3639e-05 - mean_squared_error: 2.9212e-05 - val_loss: 6.7127e-05 - val_mean_squared_error: 6.2855e-05\n",
      "Epoch 3/1000\n",
      "34452/34452 [==============================] - 6s 183us/step - loss: 3.4402e-05 - mean_squared_error: 2.9502e-05 - val_loss: 6.4704e-05 - val_mean_squared_error: 6.0231e-05\n",
      "Epoch 4/1000\n",
      "34452/34452 [==============================] - 7s 193us/step - loss: 3.3801e-05 - mean_squared_error: 2.9369e-05 - val_loss: 6.7098e-05 - val_mean_squared_error: 6.2750e-05\n",
      "Epoch 5/1000\n",
      "34452/34452 [==============================] - 9s 252us/step - loss: 3.4148e-05 - mean_squared_error: 2.9444e-05 - val_loss: 6.4874e-05 - val_mean_squared_error: 5.9643e-05\n",
      "Epoch 6/1000\n",
      "34452/34452 [==============================] - 6s 173us/step - loss: 3.4015e-05 - mean_squared_error: 2.9430e-05 - val_loss: 6.7863e-05 - val_mean_squared_error: 6.2953e-05\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 7/1000\n",
      "34452/34452 [==============================] - 8s 223us/step - loss: 2.9123e-05 - mean_squared_error: 2.6597e-05 - val_loss: 6.0753e-05 - val_mean_squared_error: 5.8295e-05\n",
      "Epoch 8/1000\n",
      "34452/34452 [==============================] - 8s 236us/step - loss: 2.8916e-05 - mean_squared_error: 2.6477e-05 - val_loss: 6.1241e-05 - val_mean_squared_error: 5.8819e-05\n",
      "Epoch 9/1000\n",
      "34452/34452 [==============================] - 8s 229us/step - loss: 2.8799e-05 - mean_squared_error: 2.6426e-05 - val_loss: 6.1627e-05 - val_mean_squared_error: 5.9218e-05\n",
      "Epoch 10/1000\n",
      "34452/34452 [==============================] - 6s 170us/step - loss: 2.8708e-05 - mean_squared_error: 2.6393e-05 - val_loss: 6.1994e-05 - val_mean_squared_error: 5.9753e-05\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 11/1000\n",
      "34452/34452 [==============================] - 8s 236us/step - loss: 2.8132e-05 - mean_squared_error: 2.6030e-05 - val_loss: 6.0380e-05 - val_mean_squared_error: 5.8276e-05\n",
      "Epoch 12/1000\n",
      "34452/34452 [==============================] - 8s 218us/step - loss: 2.8074e-05 - mean_squared_error: 2.5985e-05 - val_loss: 6.0878e-05 - val_mean_squared_error: 5.8762e-05\n",
      "Epoch 13/1000\n",
      "34452/34452 [==============================] - 6s 174us/step - loss: 2.8066e-05 - mean_squared_error: 2.5971e-05 - val_loss: 6.0377e-05 - val_mean_squared_error: 5.8301e-05\n",
      "Epoch 14/1000\n",
      "34452/34452 [==============================] - 9s 249us/step - loss: 2.8043e-05 - mean_squared_error: 2.5961e-05 - val_loss: 6.0478e-05 - val_mean_squared_error: 5.8400e-05\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 15/1000\n",
      "34452/34452 [==============================] - 7s 198us/step - loss: 2.7978e-05 - mean_squared_error: 2.5907e-05 - val_loss: 6.0411e-05 - val_mean_squared_error: 5.8343e-05\n",
      "Epoch 16/1000\n",
      "34452/34452 [==============================] - 6s 185us/step - loss: 2.7965e-05 - mean_squared_error: 2.5896e-05 - val_loss: 6.0474e-05 - val_mean_squared_error: 5.8406e-05\n",
      "Epoch 17/1000\n",
      "34452/34452 [==============================] - 6s 171us/step - loss: 2.7962e-05 - mean_squared_error: 2.5898e-05 - val_loss: 6.0457e-05 - val_mean_squared_error: 5.8393e-05\n",
      "Epoch 18/1000\n",
      "34452/34452 [==============================] - 8s 247us/step - loss: 2.7958e-05 - mean_squared_error: 2.5895e-05 - val_loss: 6.0463e-05 - val_mean_squared_error: 5.8394e-05\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 19/1000\n",
      "34452/34452 [==============================] - 8s 231us/step - loss: 2.7948e-05 - mean_squared_error: 2.5882e-05 - val_loss: 6.0457e-05 - val_mean_squared_error: 5.8391e-05\n",
      "Epoch 20/1000\n",
      "34452/34452 [==============================] - 8s 234us/step - loss: 2.7948e-05 - mean_squared_error: 2.5881e-05 - val_loss: 6.0453e-05 - val_mean_squared_error: 5.8388e-05\n",
      "Epoch 21/1000\n",
      "34452/34452 [==============================] - 7s 212us/step - loss: 2.7947e-05 - mean_squared_error: 2.5882e-05 - val_loss: 6.0449e-05 - val_mean_squared_error: 5.8385e-05\n",
      "Epoch 22/1000\n",
      "34452/34452 [==============================] - 7s 194us/step - loss: 2.7947e-05 - mean_squared_error: 2.5882e-05 - val_loss: 6.0448e-05 - val_mean_squared_error: 5.8384e-05\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "Epoch 23/1000\n",
      "34452/34452 [==============================] - 6s 180us/step - loss: 2.7946e-05 - mean_squared_error: 2.5882e-05 - val_loss: 6.0447e-05 - val_mean_squared_error: 5.8383e-05\n",
      "Epoch 24/1000\n",
      "34452/34452 [==============================] - 9s 258us/step - loss: 2.7946e-05 - mean_squared_error: 2.5882e-05 - val_loss: 6.0447e-05 - val_mean_squared_error: 5.8383e-05\n",
      "Epoch 25/1000\n",
      "34452/34452 [==============================] - 8s 231us/step - loss: 2.7946e-05 - mean_squared_error: 2.5882e-05 - val_loss: 6.0447e-05 - val_mean_squared_error: 5.8383e-05\n",
      "Epoch 26/1000\n",
      "34452/34452 [==============================] - 8s 232us/step - loss: 2.7946e-05 - mean_squared_error: 2.5882e-05 - val_loss: 6.0446e-05 - val_mean_squared_error: 5.8382e-05\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "Epoch 27/1000\n",
      "34452/34452 [==============================] - 7s 205us/step - loss: 2.7945e-05 - mean_squared_error: 2.5882e-05 - val_loss: 6.0446e-05 - val_mean_squared_error: 5.8382e-05\n",
      "Epoch 28/1000\n",
      "34452/34452 [==============================] - 7s 210us/step - loss: 2.7945e-05 - mean_squared_error: 2.5882e-05 - val_loss: 6.0446e-05 - val_mean_squared_error: 5.8382e-05\n",
      "Epoch 29/1000\n",
      "34452/34452 [==============================] - 8s 242us/step - loss: 2.7945e-05 - mean_squared_error: 2.5882e-05 - val_loss: 6.0446e-05 - val_mean_squared_error: 5.8382e-05\n",
      "Epoch 30/1000\n",
      "34452/34452 [==============================] - 7s 195us/step - loss: 2.7945e-05 - mean_squared_error: 2.5882e-05 - val_loss: 6.0446e-05 - val_mean_squared_error: 5.8382e-05\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "Epoch 31/1000\n",
      "34452/34452 [==============================] - 8s 239us/step - loss: 2.7945e-05 - mean_squared_error: 2.5882e-05 - val_loss: 6.0446e-05 - val_mean_squared_error: 5.8382e-05\n",
      "Epoch 00031: early stopping\n",
      "Train on 34452 samples, validate on 8636 samples\n",
      "Epoch 1/1000\n",
      "34452/34452 [==============================] - 8s 220us/step - loss: 3.6035e-05 - mean_squared_error: 3.0295e-05 - val_loss: 6.3173e-05 - val_mean_squared_error: 5.9446e-05\n",
      "Epoch 2/1000\n",
      "34452/34452 [==============================] - 6s 179us/step - loss: 3.3871e-05 - mean_squared_error: 2.9417e-05 - val_loss: 6.6043e-05 - val_mean_squared_error: 6.1783e-05\n",
      "Epoch 3/1000\n",
      "34452/34452 [==============================] - 6s 185us/step - loss: 3.3682e-05 - mean_squared_error: 2.9173e-05 - val_loss: 6.1748e-05 - val_mean_squared_error: 5.7703e-05\n",
      "Epoch 4/1000\n",
      "34452/34452 [==============================] - 8s 246us/step - loss: 3.4040e-05 - mean_squared_error: 2.9423e-05 - val_loss: 7.0026e-05 - val_mean_squared_error: 6.5447e-05\n",
      "Epoch 5/1000\n",
      "34452/34452 [==============================] - 8s 233us/step - loss: 3.3910e-05 - mean_squared_error: 2.9324e-05 - val_loss: 6.8857e-05 - val_mean_squared_error: 6.3781e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/1000\n",
      "34452/34452 [==============================] - 8s 227us/step - loss: 3.3882e-05 - mean_squared_error: 2.9284e-05 - val_loss: 6.7337e-05 - val_mean_squared_error: 6.1840e-05\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 7/1000\n",
      "34452/34452 [==============================] - 7s 206us/step - loss: 2.9073e-05 - mean_squared_error: 2.6584e-05 - val_loss: 6.1012e-05 - val_mean_squared_error: 5.8687e-05\n",
      "Epoch 8/1000\n",
      "34452/34452 [==============================] - 5s 142us/step - loss: 2.8839e-05 - mean_squared_error: 2.6445e-05 - val_loss: 6.0266e-05 - val_mean_squared_error: 5.8001e-05\n",
      "Epoch 9/1000\n",
      "34452/34452 [==============================] - 5s 138us/step - loss: 2.8749e-05 - mean_squared_error: 2.6417e-05 - val_loss: 6.0987e-05 - val_mean_squared_error: 5.8665e-05\n",
      "Epoch 10/1000\n",
      "34452/34452 [==============================] - 7s 217us/step - loss: 2.8653e-05 - mean_squared_error: 2.6382e-05 - val_loss: 6.1465e-05 - val_mean_squared_error: 5.9256e-05\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 11/1000\n",
      "34452/34452 [==============================] - 6s 167us/step - loss: 2.8077e-05 - mean_squared_error: 2.5989e-05 - val_loss: 6.0587e-05 - val_mean_squared_error: 5.8515e-05\n",
      "Epoch 12/1000\n",
      "34452/34452 [==============================] - 8s 228us/step - loss: 2.8032e-05 - mean_squared_error: 2.5968e-05 - val_loss: 6.0463e-05 - val_mean_squared_error: 5.8403e-05\n",
      "Epoch 13/1000\n",
      "34452/34452 [==============================] - 8s 232us/step - loss: 2.8014e-05 - mean_squared_error: 2.5955e-05 - val_loss: 6.0317e-05 - val_mean_squared_error: 5.8256e-05\n",
      "Epoch 14/1000\n",
      "34452/34452 [==============================] - 6s 167us/step - loss: 2.7995e-05 - mean_squared_error: 2.5943e-05 - val_loss: 6.0223e-05 - val_mean_squared_error: 5.8187e-05\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 15/1000\n",
      "34452/34452 [==============================] - 6s 174us/step - loss: 2.7930e-05 - mean_squared_error: 2.5896e-05 - val_loss: 6.0264e-05 - val_mean_squared_error: 5.8236e-05\n",
      "Epoch 16/1000\n",
      "34452/34452 [==============================] - 6s 183us/step - loss: 2.7919e-05 - mean_squared_error: 2.5891e-05 - val_loss: 6.0267e-05 - val_mean_squared_error: 5.8238e-05\n",
      "Epoch 17/1000\n",
      "34452/34452 [==============================] - 6s 184us/step - loss: 2.7915e-05 - mean_squared_error: 2.5885e-05 - val_loss: 6.0257e-05 - val_mean_squared_error: 5.8226e-05\n",
      "Epoch 18/1000\n",
      "34452/34452 [==============================] - 9s 256us/step - loss: 2.7913e-05 - mean_squared_error: 2.5885e-05 - val_loss: 6.0298e-05 - val_mean_squared_error: 5.8270e-05\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 19/1000\n",
      "34452/34452 [==============================] - 6s 179us/step - loss: 2.7903e-05 - mean_squared_error: 2.5874e-05 - val_loss: 6.0298e-05 - val_mean_squared_error: 5.8269e-05\n",
      "Epoch 20/1000\n",
      "34452/34452 [==============================] - 7s 212us/step - loss: 2.7902e-05 - mean_squared_error: 2.5874e-05 - val_loss: 6.0296e-05 - val_mean_squared_error: 5.8267e-05\n",
      "Epoch 21/1000\n",
      "34452/34452 [==============================] - 8s 240us/step - loss: 2.7902e-05 - mean_squared_error: 2.5873e-05 - val_loss: 6.0296e-05 - val_mean_squared_error: 5.8267e-05\n",
      "Epoch 22/1000\n",
      "34452/34452 [==============================] - 8s 235us/step - loss: 2.7902e-05 - mean_squared_error: 2.5873e-05 - val_loss: 6.0296e-05 - val_mean_squared_error: 5.8267e-05\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "Epoch 23/1000\n",
      "34452/34452 [==============================] - 8s 233us/step - loss: 2.7900e-05 - mean_squared_error: 2.5871e-05 - val_loss: 6.0296e-05 - val_mean_squared_error: 5.8267e-05\n",
      "Epoch 00023: early stopping\n",
      "Train on 34452 samples, validate on 8636 samples\n",
      "Epoch 1/1000\n",
      "34452/34452 [==============================] - 6s 173us/step - loss: 3.5562e-05 - mean_squared_error: 3.0102e-05 - val_loss: 6.5547e-05 - val_mean_squared_error: 6.0867e-05\n",
      "Epoch 2/1000\n",
      "34452/34452 [==============================] - 8s 237us/step - loss: 3.3782e-05 - mean_squared_error: 2.9299e-05 - val_loss: 6.3801e-05 - val_mean_squared_error: 5.9828e-05\n",
      "Epoch 3/1000\n",
      "34452/34452 [==============================] - 8s 226us/step - loss: 3.3740e-05 - mean_squared_error: 2.9252e-05 - val_loss: 6.9351e-05 - val_mean_squared_error: 6.4573e-05\n",
      "Epoch 4/1000\n",
      "34452/34452 [==============================] - 6s 184us/step - loss: 3.3921e-05 - mean_squared_error: 2.9274e-05 - val_loss: 6.5553e-05 - val_mean_squared_error: 6.0878e-05\n",
      "Epoch 5/1000\n",
      "34452/34452 [==============================] - 6s 187us/step - loss: 3.3815e-05 - mean_squared_error: 2.9270e-05 - val_loss: 6.3107e-05 - val_mean_squared_error: 5.9303e-05\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 6/1000\n",
      "34452/34452 [==============================] - 6s 179us/step - loss: 2.8975e-05 - mean_squared_error: 2.6527e-05 - val_loss: 6.0576e-05 - val_mean_squared_error: 5.8229e-05\n",
      "Epoch 7/1000\n",
      "34452/34452 [==============================] - 8s 227us/step - loss: 2.8814e-05 - mean_squared_error: 2.6434e-05 - val_loss: 6.0782e-05 - val_mean_squared_error: 5.8343e-05\n",
      "Epoch 8/1000\n",
      "34452/34452 [==============================] - 8s 236us/step - loss: 2.8758e-05 - mean_squared_error: 2.6426e-05 - val_loss: 6.0909e-05 - val_mean_squared_error: 5.8590e-05\n",
      "Epoch 9/1000\n",
      "34452/34452 [==============================] - 6s 176us/step - loss: 2.8620e-05 - mean_squared_error: 2.6354e-05 - val_loss: 6.0962e-05 - val_mean_squared_error: 5.8743e-05\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 10/1000\n",
      "34452/34452 [==============================] - 9s 249us/step - loss: 2.8048e-05 - mean_squared_error: 2.5977e-05 - val_loss: 6.0125e-05 - val_mean_squared_error: 5.8054e-05\n",
      "Epoch 11/1000\n",
      "34452/34452 [==============================] - 9s 265us/step - loss: 2.8005e-05 - mean_squared_error: 2.5945e-05 - val_loss: 6.0189e-05 - val_mean_squared_error: 5.8144e-05\n",
      "Epoch 12/1000\n",
      "34452/34452 [==============================] - 8s 232us/step - loss: 2.7992e-05 - mean_squared_error: 2.5940e-05 - val_loss: 6.0160e-05 - val_mean_squared_error: 5.8122e-05\n",
      "Epoch 13/1000\n",
      "34452/34452 [==============================] - 7s 206us/step - loss: 2.7969e-05 - mean_squared_error: 2.5927e-05 - val_loss: 6.0259e-05 - val_mean_squared_error: 5.8209e-05\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 14/1000\n",
      "34452/34452 [==============================] - 7s 201us/step - loss: 2.7904e-05 - mean_squared_error: 2.5866e-05 - val_loss: 6.0154e-05 - val_mean_squared_error: 5.8124e-05\n",
      "Epoch 15/1000\n",
      "34452/34452 [==============================] - 9s 248us/step - loss: 2.7893e-05 - mean_squared_error: 2.5862e-05 - val_loss: 6.0142e-05 - val_mean_squared_error: 5.8115e-05\n",
      "Epoch 16/1000\n",
      "34452/34452 [==============================] - 8s 232us/step - loss: 2.7889e-05 - mean_squared_error: 2.5861e-05 - val_loss: 6.0097e-05 - val_mean_squared_error: 5.8069e-05\n",
      "Epoch 17/1000\n",
      "34452/34452 [==============================] - 8s 232us/step - loss: 2.7887e-05 - mean_squared_error: 2.5861e-05 - val_loss: 6.0100e-05 - val_mean_squared_error: 5.8075e-05\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 18/1000\n",
      "34452/34452 [==============================] - 6s 173us/step - loss: 2.7876e-05 - mean_squared_error: 2.5852e-05 - val_loss: 6.0100e-05 - val_mean_squared_error: 5.8076e-05\n",
      "Epoch 19/1000\n",
      "34452/34452 [==============================] - 6s 186us/step - loss: 2.7876e-05 - mean_squared_error: 2.5851e-05 - val_loss: 6.0101e-05 - val_mean_squared_error: 5.8077e-05\n",
      "Epoch 20/1000\n",
      "34452/34452 [==============================] - 7s 200us/step - loss: 2.7876e-05 - mean_squared_error: 2.5851e-05 - val_loss: 6.0101e-05 - val_mean_squared_error: 5.8076e-05\n",
      "Epoch 21/1000\n",
      "34452/34452 [==============================] - 9s 251us/step - loss: 2.7875e-05 - mean_squared_error: 2.5851e-05 - val_loss: 6.0100e-05 - val_mean_squared_error: 5.8076e-05\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "Epoch 22/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34452/34452 [==============================] - 8s 234us/step - loss: 2.7874e-05 - mean_squared_error: 2.5850e-05 - val_loss: 6.0100e-05 - val_mean_squared_error: 5.8076e-05\n",
      "Epoch 23/1000\n",
      "34452/34452 [==============================] - 8s 228us/step - loss: 2.7874e-05 - mean_squared_error: 2.5850e-05 - val_loss: 6.0100e-05 - val_mean_squared_error: 5.8076e-05\n",
      "Epoch 24/1000\n",
      "34452/34452 [==============================] - 8s 231us/step - loss: 2.7874e-05 - mean_squared_error: 2.5850e-05 - val_loss: 6.0100e-05 - val_mean_squared_error: 5.8076e-05\n",
      "Epoch 25/1000\n",
      "34452/34452 [==============================] - 6s 171us/step - loss: 2.7874e-05 - mean_squared_error: 2.5850e-05 - val_loss: 6.0100e-05 - val_mean_squared_error: 5.8076e-05\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "Epoch 26/1000\n",
      "34452/34452 [==============================] - 8s 222us/step - loss: 2.7874e-05 - mean_squared_error: 2.5850e-05 - val_loss: 6.0100e-05 - val_mean_squared_error: 5.8076e-05\n",
      "Epoch 27/1000\n",
      "34452/34452 [==============================] - 8s 233us/step - loss: 2.7874e-05 - mean_squared_error: 2.5850e-05 - val_loss: 6.0100e-05 - val_mean_squared_error: 5.8076e-05\n",
      "Epoch 28/1000\n",
      "34452/34452 [==============================] - 6s 167us/step - loss: 2.7874e-05 - mean_squared_error: 2.5850e-05 - val_loss: 6.0100e-05 - val_mean_squared_error: 5.8076e-05\n",
      "Epoch 29/1000\n",
      "34452/34452 [==============================] - 6s 178us/step - loss: 2.7874e-05 - mean_squared_error: 2.5850e-05 - val_loss: 6.0100e-05 - val_mean_squared_error: 5.8076e-05\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "Epoch 30/1000\n",
      "34452/34452 [==============================] - 6s 187us/step - loss: 2.7874e-05 - mean_squared_error: 2.5850e-05 - val_loss: 6.0100e-05 - val_mean_squared_error: 5.8076e-05\n",
      "Epoch 00030: early stopping\n",
      "Train on 34452 samples, validate on 8636 samples\n",
      "Epoch 1/1000\n",
      "34452/34452 [==============================] - 6s 181us/step - loss: 3.5659e-05 - mean_squared_error: 3.0112e-05 - val_loss: 6.5162e-05 - val_mean_squared_error: 6.0930e-05\n",
      "Epoch 2/1000\n",
      "34452/34452 [==============================] - 9s 255us/step - loss: 3.3688e-05 - mean_squared_error: 2.9269e-05 - val_loss: 6.2940e-05 - val_mean_squared_error: 5.9508e-05\n",
      "Epoch 3/1000\n",
      "34452/34452 [==============================] - 6s 182us/step - loss: 3.3486e-05 - mean_squared_error: 2.9176e-05 - val_loss: 6.7293e-05 - val_mean_squared_error: 6.2324e-05\n",
      "Epoch 4/1000\n",
      "34452/34452 [==============================] - 6s 185us/step - loss: 3.4071e-05 - mean_squared_error: 2.9367e-05 - val_loss: 6.6953e-05 - val_mean_squared_error: 6.2586e-05\n",
      "Epoch 5/1000\n",
      "34452/34452 [==============================] - 6s 178us/step - loss: 3.3923e-05 - mean_squared_error: 2.9207e-05 - val_loss: 6.7534e-05 - val_mean_squared_error: 6.1716e-05\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 6/1000\n",
      "34452/34452 [==============================] - 6s 172us/step - loss: 2.9001e-05 - mean_squared_error: 2.6503e-05 - val_loss: 6.1255e-05 - val_mean_squared_error: 5.8566e-05\n",
      "Epoch 7/1000\n",
      "34452/34452 [==============================] - 6s 176us/step - loss: 2.8861e-05 - mean_squared_error: 2.6439e-05 - val_loss: 6.0186e-05 - val_mean_squared_error: 5.7897e-05\n",
      "Epoch 8/1000\n",
      "34452/34452 [==============================] - 7s 216us/step - loss: 2.8726e-05 - mean_squared_error: 2.6372e-05 - val_loss: 6.0437e-05 - val_mean_squared_error: 5.8146e-05\n",
      "Epoch 9/1000\n",
      "34452/34452 [==============================] - 8s 239us/step - loss: 2.8640e-05 - mean_squared_error: 2.6354e-05 - val_loss: 6.0429e-05 - val_mean_squared_error: 5.8191e-05\n",
      "Epoch 10/1000\n",
      "34452/34452 [==============================] - 6s 182us/step - loss: 2.8549e-05 - mean_squared_error: 2.6321e-05 - val_loss: 6.1161e-05 - val_mean_squared_error: 5.8964e-05\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 11/1000\n",
      "34452/34452 [==============================] - 6s 176us/step - loss: 2.7940e-05 - mean_squared_error: 2.5920e-05 - val_loss: 6.0303e-05 - val_mean_squared_error: 5.8257e-05\n",
      "Epoch 12/1000\n",
      "34452/34452 [==============================] - 7s 189us/step - loss: 2.7893e-05 - mean_squared_error: 2.5870e-05 - val_loss: 6.0055e-05 - val_mean_squared_error: 5.8032e-05\n",
      "Epoch 13/1000\n",
      "34452/34452 [==============================] - 6s 185us/step - loss: 2.7875e-05 - mean_squared_error: 2.5859e-05 - val_loss: 6.0172e-05 - val_mean_squared_error: 5.8154e-05\n",
      "Epoch 14/1000\n",
      "34452/34452 [==============================] - 9s 255us/step - loss: 2.7857e-05 - mean_squared_error: 2.5840e-05 - val_loss: 6.0037e-05 - val_mean_squared_error: 5.8017e-05\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 15/1000\n",
      "34452/34452 [==============================] - 6s 180us/step - loss: 2.7788e-05 - mean_squared_error: 2.5787e-05 - val_loss: 6.0049e-05 - val_mean_squared_error: 5.8053e-05\n",
      "Epoch 16/1000\n",
      "34452/34452 [==============================] - 6s 187us/step - loss: 2.7775e-05 - mean_squared_error: 2.5779e-05 - val_loss: 6.0089e-05 - val_mean_squared_error: 5.8095e-05\n",
      "Epoch 17/1000\n",
      "34452/34452 [==============================] - 6s 183us/step - loss: 2.7771e-05 - mean_squared_error: 2.5778e-05 - val_loss: 6.0076e-05 - val_mean_squared_error: 5.8082e-05\n",
      "Epoch 18/1000\n",
      "34452/34452 [==============================] - 9s 257us/step - loss: 2.7767e-05 - mean_squared_error: 2.5772e-05 - val_loss: 6.0127e-05 - val_mean_squared_error: 5.8137e-05\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 19/1000\n",
      "34452/34452 [==============================] - 8s 232us/step - loss: 2.7759e-05 - mean_squared_error: 2.5769e-05 - val_loss: 6.0115e-05 - val_mean_squared_error: 5.8125e-05\n",
      "Epoch 20/1000\n",
      "34452/34452 [==============================] - 8s 232us/step - loss: 2.7758e-05 - mean_squared_error: 2.5767e-05 - val_loss: 6.0107e-05 - val_mean_squared_error: 5.8116e-05\n",
      "Epoch 21/1000\n",
      "34452/34452 [==============================] - 7s 209us/step - loss: 2.7757e-05 - mean_squared_error: 2.5767e-05 - val_loss: 6.0101e-05 - val_mean_squared_error: 5.8110e-05\n",
      "Epoch 22/1000\n",
      "34452/34452 [==============================] - 8s 230us/step - loss: 2.7757e-05 - mean_squared_error: 2.5766e-05 - val_loss: 6.0096e-05 - val_mean_squared_error: 5.8105e-05\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "Epoch 23/1000\n",
      "34452/34452 [==============================] - 8s 235us/step - loss: 2.7755e-05 - mean_squared_error: 2.5764e-05 - val_loss: 6.0096e-05 - val_mean_squared_error: 5.8105e-05\n",
      "Epoch 24/1000\n",
      "34452/34452 [==============================] - 7s 194us/step - loss: 2.7755e-05 - mean_squared_error: 2.5764e-05 - val_loss: 6.0095e-05 - val_mean_squared_error: 5.8104e-05\n",
      "Epoch 25/1000\n",
      "34452/34452 [==============================] - 7s 194us/step - loss: 2.7755e-05 - mean_squared_error: 2.5764e-05 - val_loss: 6.0095e-05 - val_mean_squared_error: 5.8104e-05\n",
      "Epoch 26/1000\n",
      "34452/34452 [==============================] - 5s 137us/step - loss: 2.7755e-05 - mean_squared_error: 2.5764e-05 - val_loss: 6.0094e-05 - val_mean_squared_error: 5.8104e-05\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "Epoch 27/1000\n",
      "34452/34452 [==============================] - 7s 212us/step - loss: 2.7755e-05 - mean_squared_error: 2.5764e-05 - val_loss: 6.0094e-05 - val_mean_squared_error: 5.8104e-05\n",
      "Epoch 00027: early stopping\n",
      "Train on 34452 samples, validate on 8636 samples\n",
      "Epoch 1/1000\n",
      "34452/34452 [==============================] - 8s 234us/step - loss: 3.5882e-05 - mean_squared_error: 3.0292e-05 - val_loss: 6.8740e-05 - val_mean_squared_error: 6.1516e-05\n",
      "Epoch 2/1000\n",
      "34452/34452 [==============================] - 8s 232us/step - loss: 3.3691e-05 - mean_squared_error: 2.9246e-05 - val_loss: 6.7927e-05 - val_mean_squared_error: 6.2623e-05\n",
      "Epoch 3/1000\n",
      "34452/34452 [==============================] - 8s 230us/step - loss: 3.3657e-05 - mean_squared_error: 2.9131e-05 - val_loss: 6.4565e-05 - val_mean_squared_error: 6.0042e-05\n",
      "Epoch 4/1000\n",
      "34452/34452 [==============================] - 8s 232us/step - loss: 3.3904e-05 - mean_squared_error: 2.9310e-05 - val_loss: 6.4368e-05 - val_mean_squared_error: 5.9648e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/1000\n",
      "34452/34452 [==============================] - 8s 229us/step - loss: 3.3884e-05 - mean_squared_error: 2.9335e-05 - val_loss: 6.6497e-05 - val_mean_squared_error: 6.1493e-05\n",
      "Epoch 6/1000\n",
      "34452/34452 [==============================] - 6s 174us/step - loss: 3.3681e-05 - mean_squared_error: 2.9139e-05 - val_loss: 6.7179e-05 - val_mean_squared_error: 6.1721e-05\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 7/1000\n",
      "34452/34452 [==============================] - 6s 183us/step - loss: 2.8903e-05 - mean_squared_error: 2.6446e-05 - val_loss: 6.0889e-05 - val_mean_squared_error: 5.8464e-05\n",
      "Epoch 8/1000\n",
      "34452/34452 [==============================] - 6s 178us/step - loss: 2.8748e-05 - mean_squared_error: 2.6376e-05 - val_loss: 6.0253e-05 - val_mean_squared_error: 5.7967e-05\n",
      "Epoch 9/1000\n",
      "34452/34452 [==============================] - 6s 166us/step - loss: 2.8655e-05 - mean_squared_error: 2.6338e-05 - val_loss: 6.0552e-05 - val_mean_squared_error: 5.8325e-05\n",
      "Epoch 10/1000\n",
      "34452/34452 [==============================] - 8s 241us/step - loss: 2.8583e-05 - mean_squared_error: 2.6320e-05 - val_loss: 5.9883e-05 - val_mean_squared_error: 5.7784e-05\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 11/1000\n",
      "34452/34452 [==============================] - 8s 229us/step - loss: 2.7981e-05 - mean_squared_error: 2.5933e-05 - val_loss: 6.0067e-05 - val_mean_squared_error: 5.8045e-05\n",
      "Epoch 12/1000\n",
      "34452/34452 [==============================] - 8s 231us/step - loss: 2.7928e-05 - mean_squared_error: 2.5883e-05 - val_loss: 5.9972e-05 - val_mean_squared_error: 5.7951e-05\n",
      "Epoch 13/1000\n",
      "34452/34452 [==============================] - 7s 214us/step - loss: 2.7913e-05 - mean_squared_error: 2.5875e-05 - val_loss: 5.9902e-05 - val_mean_squared_error: 5.7865e-05\n",
      "Epoch 14/1000\n",
      "34452/34452 [==============================] - 6s 174us/step - loss: 2.7897e-05 - mean_squared_error: 2.5866e-05 - val_loss: 6.0039e-05 - val_mean_squared_error: 5.7990e-05\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 15/1000\n",
      "34452/34452 [==============================] - 6s 170us/step - loss: 2.7834e-05 - mean_squared_error: 2.5800e-05 - val_loss: 6.0053e-05 - val_mean_squared_error: 5.8023e-05\n",
      "Epoch 16/1000\n",
      "34452/34452 [==============================] - 8s 238us/step - loss: 2.7821e-05 - mean_squared_error: 2.5795e-05 - val_loss: 6.0053e-05 - val_mean_squared_error: 5.8027e-05\n",
      "Epoch 17/1000\n",
      "34452/34452 [==============================] - 8s 220us/step - loss: 2.7818e-05 - mean_squared_error: 2.5791e-05 - val_loss: 6.0039e-05 - val_mean_squared_error: 5.8017e-05\n",
      "Epoch 18/1000\n",
      "34452/34452 [==============================] - 6s 171us/step - loss: 2.7815e-05 - mean_squared_error: 2.5793e-05 - val_loss: 6.0033e-05 - val_mean_squared_error: 5.8014e-05\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 19/1000\n",
      "34452/34452 [==============================] - 6s 167us/step - loss: 2.7806e-05 - mean_squared_error: 2.5787e-05 - val_loss: 6.0026e-05 - val_mean_squared_error: 5.8007e-05\n",
      "Epoch 20/1000\n",
      "34452/34452 [==============================] - 8s 229us/step - loss: 2.7805e-05 - mean_squared_error: 2.5786e-05 - val_loss: 6.0021e-05 - val_mean_squared_error: 5.8003e-05\n",
      "Epoch 21/1000\n",
      "34452/34452 [==============================] - 8s 234us/step - loss: 2.7804e-05 - mean_squared_error: 2.5785e-05 - val_loss: 6.0018e-05 - val_mean_squared_error: 5.7999e-05\n",
      "Epoch 22/1000\n",
      "34452/34452 [==============================] - 6s 168us/step - loss: 2.7804e-05 - mean_squared_error: 2.5785e-05 - val_loss: 6.0014e-05 - val_mean_squared_error: 5.7995e-05\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "Epoch 23/1000\n",
      "34452/34452 [==============================] - 8s 242us/step - loss: 2.7803e-05 - mean_squared_error: 2.5784e-05 - val_loss: 6.0013e-05 - val_mean_squared_error: 5.7995e-05\n",
      "Epoch 24/1000\n",
      "34452/34452 [==============================] - 8s 227us/step - loss: 2.7803e-05 - mean_squared_error: 2.5784e-05 - val_loss: 6.0013e-05 - val_mean_squared_error: 5.7995e-05\n",
      "Epoch 25/1000\n",
      "34452/34452 [==============================] - 8s 229us/step - loss: 2.7803e-05 - mean_squared_error: 2.5784e-05 - val_loss: 6.0013e-05 - val_mean_squared_error: 5.7995e-05\n",
      "Epoch 26/1000\n",
      "34452/34452 [==============================] - 8s 230us/step - loss: 2.7803e-05 - mean_squared_error: 2.5784e-05 - val_loss: 6.0013e-05 - val_mean_squared_error: 5.7995e-05\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "Epoch 27/1000\n",
      "34452/34452 [==============================] - 7s 214us/step - loss: 2.7802e-05 - mean_squared_error: 2.5784e-05 - val_loss: 6.0013e-05 - val_mean_squared_error: 5.7995e-05\n",
      "Epoch 28/1000\n",
      "34452/34452 [==============================] - 6s 181us/step - loss: 2.7802e-05 - mean_squared_error: 2.5784e-05 - val_loss: 6.0013e-05 - val_mean_squared_error: 5.7995e-05\n",
      "Epoch 29/1000\n",
      "34452/34452 [==============================] - 9s 254us/step - loss: 2.7802e-05 - mean_squared_error: 2.5784e-05 - val_loss: 6.0013e-05 - val_mean_squared_error: 5.7994e-05\n",
      "Epoch 30/1000\n",
      "34452/34452 [==============================] - 8s 231us/step - loss: 2.7802e-05 - mean_squared_error: 2.5784e-05 - val_loss: 6.0013e-05 - val_mean_squared_error: 5.7994e-05\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "Epoch 00030: early stopping\n",
      "Train on 34452 samples, validate on 8636 samples\n",
      "Epoch 1/1000\n",
      "34452/34452 [==============================] - 6s 184us/step - loss: 3.5493e-05 - mean_squared_error: 2.9945e-05 - val_loss: 6.5675e-05 - val_mean_squared_error: 6.0670e-05\n",
      "Epoch 2/1000\n",
      "34452/34452 [==============================] - 7s 204us/step - loss: 3.3746e-05 - mean_squared_error: 2.9200e-05 - val_loss: 6.4884e-05 - val_mean_squared_error: 6.0857e-05\n",
      "Epoch 3/1000\n",
      "34452/34452 [==============================] - 9s 249us/step - loss: 3.3795e-05 - mean_squared_error: 2.9233e-05 - val_loss: 6.4586e-05 - val_mean_squared_error: 5.9331e-05\n",
      "Epoch 4/1000\n",
      "34452/34452 [==============================] - 8s 234us/step - loss: 3.3634e-05 - mean_squared_error: 2.9168e-05 - val_loss: 6.3859e-05 - val_mean_squared_error: 5.9968e-05\n",
      "Epoch 5/1000\n",
      "34452/34452 [==============================] - 8s 234us/step - loss: 3.3839e-05 - mean_squared_error: 2.9263e-05 - val_loss: 6.1403e-05 - val_mean_squared_error: 5.7043e-05\n",
      "Epoch 6/1000\n",
      "34452/34452 [==============================] - 6s 184us/step - loss: 3.3783e-05 - mean_squared_error: 2.9210e-05 - val_loss: 6.7555e-05 - val_mean_squared_error: 6.0901e-05\n",
      "Epoch 7/1000\n",
      "34452/34452 [==============================] - 8s 235us/step - loss: 3.3437e-05 - mean_squared_error: 2.9074e-05 - val_loss: 6.5072e-05 - val_mean_squared_error: 6.1197e-05\n",
      "Epoch 8/1000\n",
      "34452/34452 [==============================] - 8s 227us/step - loss: 3.3626e-05 - mean_squared_error: 2.9198e-05 - val_loss: 6.5485e-05 - val_mean_squared_error: 6.0445e-05\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 9/1000\n",
      "34452/34452 [==============================] - 7s 190us/step - loss: 2.8854e-05 - mean_squared_error: 2.6432e-05 - val_loss: 6.1278e-05 - val_mean_squared_error: 5.8838e-05\n",
      "Epoch 10/1000\n",
      "34452/34452 [==============================] - 9s 254us/step - loss: 2.8705e-05 - mean_squared_error: 2.6345e-05 - val_loss: 6.1429e-05 - val_mean_squared_error: 5.8952e-05\n",
      "Epoch 11/1000\n",
      "34452/34452 [==============================] - 6s 188us/step - loss: 2.8616e-05 - mean_squared_error: 2.6301e-05 - val_loss: 6.0619e-05 - val_mean_squared_error: 5.8344e-05\n",
      "Epoch 12/1000\n",
      "34452/34452 [==============================] - 7s 194us/step - loss: 2.8524e-05 - mean_squared_error: 2.6286e-05 - val_loss: 6.0606e-05 - val_mean_squared_error: 5.8388e-05\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 13/1000\n",
      "34452/34452 [==============================] - 7s 205us/step - loss: 2.7942e-05 - mean_squared_error: 2.5893e-05 - val_loss: 5.9761e-05 - val_mean_squared_error: 5.7731e-05\n",
      "Epoch 14/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34452/34452 [==============================] - 9s 253us/step - loss: 2.7897e-05 - mean_squared_error: 2.5865e-05 - val_loss: 6.0031e-05 - val_mean_squared_error: 5.7978e-05\n",
      "Epoch 15/1000\n",
      "34452/34452 [==============================] - 6s 175us/step - loss: 2.7881e-05 - mean_squared_error: 2.5846e-05 - val_loss: 5.9843e-05 - val_mean_squared_error: 5.7803e-05\n",
      "Epoch 16/1000\n",
      "34452/34452 [==============================] - 7s 199us/step - loss: 2.7869e-05 - mean_squared_error: 2.5831e-05 - val_loss: 5.9785e-05 - val_mean_squared_error: 5.7780e-05\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 17/1000\n",
      "34452/34452 [==============================] - 8s 245us/step - loss: 2.7799e-05 - mean_squared_error: 2.5796e-05 - val_loss: 5.9750e-05 - val_mean_squared_error: 5.7750e-05\n",
      "Epoch 18/1000\n",
      "34452/34452 [==============================] - 6s 169us/step - loss: 2.7786e-05 - mean_squared_error: 2.5784e-05 - val_loss: 5.9738e-05 - val_mean_squared_error: 5.7734e-05\n",
      "Epoch 19/1000\n",
      "34452/34452 [==============================] - 8s 226us/step - loss: 2.7781e-05 - mean_squared_error: 2.5773e-05 - val_loss: 5.9750e-05 - val_mean_squared_error: 5.7748e-05\n",
      "Epoch 20/1000\n",
      "34452/34452 [==============================] - 8s 232us/step - loss: 2.7778e-05 - mean_squared_error: 2.5773e-05 - val_loss: 5.9714e-05 - val_mean_squared_error: 5.7711e-05\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 21/1000\n",
      "34452/34452 [==============================] - 6s 170us/step - loss: 2.7769e-05 - mean_squared_error: 2.5766e-05 - val_loss: 5.9721e-05 - val_mean_squared_error: 5.7717e-05\n",
      "Epoch 22/1000\n",
      "34452/34452 [==============================] - 8s 239us/step - loss: 2.7768e-05 - mean_squared_error: 2.5764e-05 - val_loss: 5.9726e-05 - val_mean_squared_error: 5.7722e-05\n",
      "Epoch 23/1000\n",
      "34452/34452 [==============================] - 8s 234us/step - loss: 2.7768e-05 - mean_squared_error: 2.5764e-05 - val_loss: 5.9729e-05 - val_mean_squared_error: 5.7725e-05\n",
      "Epoch 24/1000\n",
      "34452/34452 [==============================] - 8s 233us/step - loss: 2.7767e-05 - mean_squared_error: 2.5764e-05 - val_loss: 5.9734e-05 - val_mean_squared_error: 5.7730e-05\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "Epoch 25/1000\n",
      "34452/34452 [==============================] - 8s 231us/step - loss: 2.7766e-05 - mean_squared_error: 2.5762e-05 - val_loss: 5.9734e-05 - val_mean_squared_error: 5.7730e-05\n",
      "Epoch 00025: early stopping\n",
      "Train on 34452 samples, validate on 8636 samples\n",
      "Epoch 1/1000\n",
      "34452/34452 [==============================] - 8s 230us/step - loss: 3.5802e-05 - mean_squared_error: 3.0104e-05 - val_loss: 6.5940e-05 - val_mean_squared_error: 6.1924e-05\n",
      "Epoch 2/1000\n",
      "34452/34452 [==============================] - 7s 212us/step - loss: 3.3389e-05 - mean_squared_error: 2.9099e-05 - val_loss: 6.1901e-05 - val_mean_squared_error: 5.7716e-05\n",
      "Epoch 3/1000\n",
      "34452/34452 [==============================] - 6s 172us/step - loss: 3.3909e-05 - mean_squared_error: 2.9248e-05 - val_loss: 6.4818e-05 - val_mean_squared_error: 6.0384e-05\n",
      "Epoch 4/1000\n",
      "34452/34452 [==============================] - 6s 171us/step - loss: 3.3651e-05 - mean_squared_error: 2.9066e-05 - val_loss: 6.3362e-05 - val_mean_squared_error: 5.8878e-05\n",
      "Epoch 5/1000\n",
      "34452/34452 [==============================] - 8s 236us/step - loss: 3.3540e-05 - mean_squared_error: 2.9070e-05 - val_loss: 6.3762e-05 - val_mean_squared_error: 5.9827e-05\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 6/1000\n",
      "34452/34452 [==============================] - 8s 220us/step - loss: 2.8838e-05 - mean_squared_error: 2.6429e-05 - val_loss: 5.9976e-05 - val_mean_squared_error: 5.7555e-05\n",
      "Epoch 7/1000\n",
      "34452/34452 [==============================] - 6s 174us/step - loss: 2.8666e-05 - mean_squared_error: 2.6312e-05 - val_loss: 6.0216e-05 - val_mean_squared_error: 5.7867e-05\n",
      "Epoch 8/1000\n",
      "34452/34452 [==============================] - 9s 251us/step - loss: 2.8568e-05 - mean_squared_error: 2.6268e-05 - val_loss: 6.0572e-05 - val_mean_squared_error: 5.8331e-05\n",
      "Epoch 9/1000\n",
      "34452/34452 [==============================] - 7s 197us/step - loss: 2.8486e-05 - mean_squared_error: 2.6246e-05 - val_loss: 6.0216e-05 - val_mean_squared_error: 5.8016e-05\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 10/1000\n",
      "34452/34452 [==============================] - 6s 187us/step - loss: 2.7910e-05 - mean_squared_error: 2.5863e-05 - val_loss: 5.9696e-05 - val_mean_squared_error: 5.7664e-05\n",
      "Epoch 11/1000\n",
      "34452/34452 [==============================] - 6s 178us/step - loss: 2.7858e-05 - mean_squared_error: 2.5821e-05 - val_loss: 5.9613e-05 - val_mean_squared_error: 5.7570e-05\n",
      "Epoch 12/1000\n",
      "34452/34452 [==============================] - 6s 170us/step - loss: 2.7842e-05 - mean_squared_error: 2.5807e-05 - val_loss: 5.9538e-05 - val_mean_squared_error: 5.7529e-05\n",
      "Epoch 13/1000\n",
      "34452/34452 [==============================] - 8s 238us/step - loss: 2.7827e-05 - mean_squared_error: 2.5806e-05 - val_loss: 5.9642e-05 - val_mean_squared_error: 5.7627e-05\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 14/1000\n",
      "34452/34452 [==============================] - 8s 232us/step - loss: 2.7767e-05 - mean_squared_error: 2.5757e-05 - val_loss: 5.9536e-05 - val_mean_squared_error: 5.7530e-05\n",
      "Epoch 15/1000\n",
      "34452/34452 [==============================] - 6s 172us/step - loss: 2.7753e-05 - mean_squared_error: 2.5744e-05 - val_loss: 5.9526e-05 - val_mean_squared_error: 5.7523e-05\n",
      "Epoch 16/1000\n",
      "34452/34452 [==============================] - 9s 262us/step - loss: 2.7748e-05 - mean_squared_error: 2.5742e-05 - val_loss: 5.9520e-05 - val_mean_squared_error: 5.7517e-05\n",
      "Epoch 17/1000\n",
      "34452/34452 [==============================] - 9s 256us/step - loss: 2.7745e-05 - mean_squared_error: 2.5741e-05 - val_loss: 5.9520e-05 - val_mean_squared_error: 5.7512e-05\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 18/1000\n",
      "34452/34452 [==============================] - 6s 177us/step - loss: 2.7736e-05 - mean_squared_error: 2.5729e-05 - val_loss: 5.9521e-05 - val_mean_squared_error: 5.7515e-05\n",
      "Epoch 19/1000\n",
      "34452/34452 [==============================] - 6s 184us/step - loss: 2.7735e-05 - mean_squared_error: 2.5729e-05 - val_loss: 5.9525e-05 - val_mean_squared_error: 5.7520e-05\n",
      "Epoch 20/1000\n",
      "34452/34452 [==============================] - 6s 173us/step - loss: 2.7735e-05 - mean_squared_error: 2.5729e-05 - val_loss: 5.9525e-05 - val_mean_squared_error: 5.7520e-05\n",
      "Epoch 21/1000\n",
      "34452/34452 [==============================] - 6s 167us/step - loss: 2.7734e-05 - mean_squared_error: 2.5729e-05 - val_loss: 5.9527e-05 - val_mean_squared_error: 5.7523e-05\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "Epoch 22/1000\n",
      "34452/34452 [==============================] - 6s 187us/step - loss: 2.7733e-05 - mean_squared_error: 2.5728e-05 - val_loss: 5.9527e-05 - val_mean_squared_error: 5.7523e-05\n",
      "Epoch 23/1000\n",
      "34452/34452 [==============================] - 6s 180us/step - loss: 2.7733e-05 - mean_squared_error: 2.5728e-05 - val_loss: 5.9527e-05 - val_mean_squared_error: 5.7523e-05\n",
      "Epoch 24/1000\n",
      "34452/34452 [==============================] - 6s 174us/step - loss: 2.7733e-05 - mean_squared_error: 2.5728e-05 - val_loss: 5.9527e-05 - val_mean_squared_error: 5.7523e-05\n",
      "Epoch 25/1000\n",
      "34452/34452 [==============================] - 6s 167us/step - loss: 2.7733e-05 - mean_squared_error: 2.5728e-05 - val_loss: 5.9527e-05 - val_mean_squared_error: 5.7523e-05\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "Epoch 26/1000\n",
      "34452/34452 [==============================] - 8s 233us/step - loss: 2.7733e-05 - mean_squared_error: 2.5728e-05 - val_loss: 5.9527e-05 - val_mean_squared_error: 5.7523e-05\n",
      "Epoch 27/1000\n",
      "34452/34452 [==============================] - 8s 222us/step - loss: 2.7733e-05 - mean_squared_error: 2.5728e-05 - val_loss: 5.9527e-05 - val_mean_squared_error: 5.7523e-05\n",
      "Epoch 28/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34452/34452 [==============================] - 6s 168us/step - loss: 2.7733e-05 - mean_squared_error: 2.5728e-05 - val_loss: 5.9527e-05 - val_mean_squared_error: 5.7523e-05\n",
      "Epoch 29/1000\n",
      "34452/34452 [==============================] - 5s 159us/step - loss: 2.7733e-05 - mean_squared_error: 2.5728e-05 - val_loss: 5.9527e-05 - val_mean_squared_error: 5.7523e-05\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "Epoch 30/1000\n",
      "34452/34452 [==============================] - 6s 176us/step - loss: 2.7733e-05 - mean_squared_error: 2.5728e-05 - val_loss: 5.9527e-05 - val_mean_squared_error: 5.7523e-05\n",
      "Epoch 31/1000\n",
      "34452/34452 [==============================] - 6s 179us/step - loss: 2.7733e-05 - mean_squared_error: 2.5728e-05 - val_loss: 5.9527e-05 - val_mean_squared_error: 5.7523e-05\n",
      "Epoch 32/1000\n",
      "34452/34452 [==============================] - 5s 159us/step - loss: 2.7733e-05 - mean_squared_error: 2.5728e-05 - val_loss: 5.9527e-05 - val_mean_squared_error: 5.7523e-05\n",
      "Epoch 33/1000\n",
      "34452/34452 [==============================] - 6s 169us/step - loss: 2.7733e-05 - mean_squared_error: 2.5728e-05 - val_loss: 5.9527e-05 - val_mean_squared_error: 5.7523e-05\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
      "Epoch 34/1000\n",
      "34452/34452 [==============================] - 6s 177us/step - loss: 2.7733e-05 - mean_squared_error: 2.5728e-05 - val_loss: 5.9527e-05 - val_mean_squared_error: 5.7523e-05\n",
      "Epoch 35/1000\n",
      "34452/34452 [==============================] - 6s 175us/step - loss: 2.7733e-05 - mean_squared_error: 2.5728e-05 - val_loss: 5.9527e-05 - val_mean_squared_error: 5.7523e-05\n",
      "Epoch 36/1000\n",
      "34452/34452 [==============================] - 6s 162us/step - loss: 2.7733e-05 - mean_squared_error: 2.5728e-05 - val_loss: 5.9527e-05 - val_mean_squared_error: 5.7523e-05\n",
      "Epoch 00036: early stopping\n",
      "Train on 34452 samples, validate on 8636 samples\n",
      "Epoch 1/1000\n",
      "34452/34452 [==============================] - 6s 172us/step - loss: 3.5629e-05 - mean_squared_error: 3.0091e-05 - val_loss: 6.5441e-05 - val_mean_squared_error: 6.0652e-05\n",
      "Epoch 2/1000\n",
      "34452/34452 [==============================] - 6s 178us/step - loss: 3.3832e-05 - mean_squared_error: 2.9216e-05 - val_loss: 6.0896e-05 - val_mean_squared_error: 5.6810e-05\n",
      "Epoch 3/1000\n",
      "34452/34452 [==============================] - 6s 171us/step - loss: 3.3663e-05 - mean_squared_error: 2.9140e-05 - val_loss: 6.4214e-05 - val_mean_squared_error: 6.0404e-05\n",
      "Epoch 4/1000\n",
      "34452/34452 [==============================] - 6s 161us/step - loss: 3.3761e-05 - mean_squared_error: 2.9168e-05 - val_loss: 7.0579e-05 - val_mean_squared_error: 6.3832e-05\n",
      "Epoch 5/1000\n",
      "34452/34452 [==============================] - 6s 177us/step - loss: 3.3520e-05 - mean_squared_error: 2.9057e-05 - val_loss: 6.6655e-05 - val_mean_squared_error: 6.2245e-05\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 6/1000\n",
      "34452/34452 [==============================] - 6s 180us/step - loss: 2.8814e-05 - mean_squared_error: 2.6389e-05 - val_loss: 6.0622e-05 - val_mean_squared_error: 5.8283e-05\n",
      "Epoch 7/1000\n",
      "34452/34452 [==============================] - 6s 169us/step - loss: 2.8678e-05 - mean_squared_error: 2.6319e-05 - val_loss: 6.0825e-05 - val_mean_squared_error: 5.8518e-05\n",
      "Epoch 8/1000\n",
      "34452/34452 [==============================] - 6s 165us/step - loss: 2.8563e-05 - mean_squared_error: 2.6265e-05 - val_loss: 6.1251e-05 - val_mean_squared_error: 5.8907e-05\n",
      "Epoch 9/1000\n",
      "34452/34452 [==============================] - 6s 178us/step - loss: 2.8470e-05 - mean_squared_error: 2.6219e-05 - val_loss: 6.0076e-05 - val_mean_squared_error: 5.7938e-05\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 10/1000\n",
      "34452/34452 [==============================] - 6s 180us/step - loss: 2.7889e-05 - mean_squared_error: 2.5858e-05 - val_loss: 5.9681e-05 - val_mean_squared_error: 5.7623e-05\n",
      "Epoch 11/1000\n",
      "34452/34452 [==============================] - 6s 168us/step - loss: 2.7850e-05 - mean_squared_error: 2.5813e-05 - val_loss: 5.9544e-05 - val_mean_squared_error: 5.7530e-05\n",
      "Epoch 12/1000\n",
      "34452/34452 [==============================] - 8s 241us/step - loss: 2.7836e-05 - mean_squared_error: 2.5820e-05 - val_loss: 5.9878e-05 - val_mean_squared_error: 5.7838e-05\n",
      "Epoch 13/1000\n",
      "34452/34452 [==============================] - 7s 194us/step - loss: 2.7815e-05 - mean_squared_error: 2.5796e-05 - val_loss: 5.9592e-05 - val_mean_squared_error: 5.7568e-05\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 14/1000\n",
      "34452/34452 [==============================] - 6s 174us/step - loss: 2.7761e-05 - mean_squared_error: 2.5753e-05 - val_loss: 5.9726e-05 - val_mean_squared_error: 5.7721e-05\n",
      "Epoch 15/1000\n",
      "34452/34452 [==============================] - 6s 160us/step - loss: 2.7744e-05 - mean_squared_error: 2.5741e-05 - val_loss: 5.9748e-05 - val_mean_squared_error: 5.7749e-05\n",
      "Epoch 16/1000\n",
      "34452/34452 [==============================] - 6s 175us/step - loss: 2.7739e-05 - mean_squared_error: 2.5739e-05 - val_loss: 5.9751e-05 - val_mean_squared_error: 5.7755e-05\n",
      "Epoch 17/1000\n",
      "34452/34452 [==============================] - 6s 181us/step - loss: 2.7736e-05 - mean_squared_error: 2.5737e-05 - val_loss: 5.9766e-05 - val_mean_squared_error: 5.7769e-05\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 18/1000\n",
      "34452/34452 [==============================] - 6s 174us/step - loss: 2.7726e-05 - mean_squared_error: 2.5729e-05 - val_loss: 5.9765e-05 - val_mean_squared_error: 5.7769e-05\n",
      "Epoch 19/1000\n",
      "34452/34452 [==============================] - 6s 168us/step - loss: 2.7725e-05 - mean_squared_error: 2.5729e-05 - val_loss: 5.9765e-05 - val_mean_squared_error: 5.7768e-05\n",
      "Epoch 20/1000\n",
      "34452/34452 [==============================] - 8s 233us/step - loss: 2.7725e-05 - mean_squared_error: 2.5728e-05 - val_loss: 5.9764e-05 - val_mean_squared_error: 5.7767e-05\n",
      "Epoch 21/1000\n",
      "34452/34452 [==============================] - 8s 225us/step - loss: 2.7724e-05 - mean_squared_error: 2.5728e-05 - val_loss: 5.9763e-05 - val_mean_squared_error: 5.7766e-05\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "Epoch 22/1000\n",
      "34452/34452 [==============================] - 8s 220us/step - loss: 2.7723e-05 - mean_squared_error: 2.5726e-05 - val_loss: 5.9763e-05 - val_mean_squared_error: 5.7766e-05\n",
      "Epoch 00022: early stopping\n",
      "Train on 34452 samples, validate on 8636 samples\n",
      "Epoch 1/1000\n",
      "34452/34452 [==============================] - 6s 172us/step - loss: 3.5265e-05 - mean_squared_error: 2.9777e-05 - val_loss: 6.3709e-05 - val_mean_squared_error: 5.9990e-05\n",
      "Epoch 2/1000\n",
      "34452/34452 [==============================] - 6s 166us/step - loss: 3.3396e-05 - mean_squared_error: 2.9013e-05 - val_loss: 6.3795e-05 - val_mean_squared_error: 5.9821e-05\n",
      "Epoch 3/1000\n",
      "34452/34452 [==============================] - 6s 182us/step - loss: 3.3487e-05 - mean_squared_error: 2.9001e-05 - val_loss: 6.2718e-05 - val_mean_squared_error: 5.8740e-05\n",
      "Epoch 4/1000\n",
      "34452/34452 [==============================] - 6s 187us/step - loss: 3.3890e-05 - mean_squared_error: 2.9294e-05 - val_loss: 6.3393e-05 - val_mean_squared_error: 5.9597e-05\n",
      "Epoch 5/1000\n",
      "34452/34452 [==============================] - 9s 249us/step - loss: 3.3494e-05 - mean_squared_error: 2.9050e-05 - val_loss: 6.4407e-05 - val_mean_squared_error: 5.9129e-05\n",
      "Epoch 6/1000\n",
      "34452/34452 [==============================] - 6s 176us/step - loss: 3.3800e-05 - mean_squared_error: 2.9212e-05 - val_loss: 6.1449e-05 - val_mean_squared_error: 5.7930e-05\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 7/1000\n",
      "34452/34452 [==============================] - 6s 183us/step - loss: 2.8767e-05 - mean_squared_error: 2.6359e-05 - val_loss: 6.0285e-05 - val_mean_squared_error: 5.7870e-05\n",
      "Epoch 8/1000\n",
      "34452/34452 [==============================] - 6s 182us/step - loss: 2.8584e-05 - mean_squared_error: 2.6243e-05 - val_loss: 6.0703e-05 - val_mean_squared_error: 5.8351e-05\n",
      "Epoch 9/1000\n",
      "34452/34452 [==============================] - 6s 171us/step - loss: 2.8533e-05 - mean_squared_error: 2.6237e-05 - val_loss: 6.0364e-05 - val_mean_squared_error: 5.7938e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/1000\n",
      "34452/34452 [==============================] - 6s 164us/step - loss: 2.8459e-05 - mean_squared_error: 2.6207e-05 - val_loss: 5.9788e-05 - val_mean_squared_error: 5.7584e-05\n",
      "Epoch 11/1000\n",
      "34452/34452 [==============================] - 6s 178us/step - loss: 2.8369e-05 - mean_squared_error: 2.6179e-05 - val_loss: 5.8907e-05 - val_mean_squared_error: 5.6753e-05\n",
      "Epoch 12/1000\n",
      "34452/34452 [==============================] - 6s 174us/step - loss: 2.8275e-05 - mean_squared_error: 2.6126e-05 - val_loss: 5.9322e-05 - val_mean_squared_error: 5.7273e-05\n",
      "Epoch 13/1000\n",
      "34452/34452 [==============================] - 5s 150us/step - loss: 2.8129e-05 - mean_squared_error: 2.6030e-05 - val_loss: 6.0780e-05 - val_mean_squared_error: 5.8631e-05\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 14/1000\n",
      "34452/34452 [==============================] - 4s 123us/step - loss: 2.7517e-05 - mean_squared_error: 2.5556e-05 - val_loss: 5.9418e-05 - val_mean_squared_error: 5.7475e-05\n",
      "Epoch 15/1000\n",
      "34452/34452 [==============================] - 6s 188us/step - loss: 2.7468e-05 - mean_squared_error: 2.5537e-05 - val_loss: 5.9122e-05 - val_mean_squared_error: 5.7176e-05\n",
      "Epoch 16/1000\n",
      "34452/34452 [==============================] - 6s 187us/step - loss: 2.7449e-05 - mean_squared_error: 2.5521e-05 - val_loss: 5.9148e-05 - val_mean_squared_error: 5.7215e-05\n",
      "Epoch 17/1000\n",
      "34452/34452 [==============================] - 5s 134us/step - loss: 2.7427e-05 - mean_squared_error: 2.5504e-05 - val_loss: 5.9138e-05 - val_mean_squared_error: 5.7227e-05\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 18/1000\n",
      "34452/34452 [==============================] - 5s 136us/step - loss: 2.7366e-05 - mean_squared_error: 2.5464e-05 - val_loss: 5.9290e-05 - val_mean_squared_error: 5.7385e-05\n",
      "Epoch 19/1000\n",
      "34452/34452 [==============================] - 4s 125us/step - loss: 2.7346e-05 - mean_squared_error: 2.5442e-05 - val_loss: 5.9269e-05 - val_mean_squared_error: 5.7366e-05\n",
      "Epoch 20/1000\n",
      "34452/34452 [==============================] - 5s 151us/step - loss: 2.7343e-05 - mean_squared_error: 2.5442e-05 - val_loss: 5.9287e-05 - val_mean_squared_error: 5.7384e-05\n",
      "Epoch 21/1000\n",
      "34452/34452 [==============================] - 8s 220us/step - loss: 2.7342e-05 - mean_squared_error: 2.5441e-05 - val_loss: 5.9255e-05 - val_mean_squared_error: 5.7352e-05\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 22/1000\n",
      "34452/34452 [==============================] - 6s 164us/step - loss: 2.7331e-05 - mean_squared_error: 2.5429e-05 - val_loss: 5.9261e-05 - val_mean_squared_error: 5.7360e-05\n",
      "Epoch 23/1000\n",
      "34452/34452 [==============================] - 6s 168us/step - loss: 2.7330e-05 - mean_squared_error: 2.5428e-05 - val_loss: 5.9267e-05 - val_mean_squared_error: 5.7366e-05\n",
      "Epoch 24/1000\n",
      "34452/34452 [==============================] - 6s 177us/step - loss: 2.7329e-05 - mean_squared_error: 2.5429e-05 - val_loss: 5.9271e-05 - val_mean_squared_error: 5.7370e-05\n",
      "Epoch 25/1000\n",
      "34452/34452 [==============================] - 6s 178us/step - loss: 2.7329e-05 - mean_squared_error: 2.5429e-05 - val_loss: 5.9274e-05 - val_mean_squared_error: 5.7373e-05\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "Epoch 26/1000\n",
      "34452/34452 [==============================] - 6s 162us/step - loss: 2.7328e-05 - mean_squared_error: 2.5427e-05 - val_loss: 5.9274e-05 - val_mean_squared_error: 5.7373e-05\n",
      "Epoch 27/1000\n",
      "34452/34452 [==============================] - 6s 171us/step - loss: 2.7328e-05 - mean_squared_error: 2.5427e-05 - val_loss: 5.9274e-05 - val_mean_squared_error: 5.7373e-05\n",
      "Epoch 28/1000\n",
      "34452/34452 [==============================] - 6s 179us/step - loss: 2.7328e-05 - mean_squared_error: 2.5427e-05 - val_loss: 5.9274e-05 - val_mean_squared_error: 5.7373e-05\n",
      "Epoch 29/1000\n",
      "34452/34452 [==============================] - 6s 175us/step - loss: 2.7328e-05 - mean_squared_error: 2.5427e-05 - val_loss: 5.9274e-05 - val_mean_squared_error: 5.7373e-05\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "Epoch 30/1000\n",
      "34452/34452 [==============================] - 6s 164us/step - loss: 2.7328e-05 - mean_squared_error: 2.5427e-05 - val_loss: 5.9274e-05 - val_mean_squared_error: 5.7373e-05\n",
      "Epoch 31/1000\n",
      "34452/34452 [==============================] - 6s 171us/step - loss: 2.7328e-05 - mean_squared_error: 2.5427e-05 - val_loss: 5.9274e-05 - val_mean_squared_error: 5.7373e-05\n",
      "Epoch 00031: early stopping\n",
      "Train on 34452 samples, validate on 8636 samples\n",
      "Epoch 1/1000\n",
      "34452/34452 [==============================] - 6s 180us/step - loss: 3.5203e-05 - mean_squared_error: 2.9743e-05 - val_loss: 7.0643e-05 - val_mean_squared_error: 6.4890e-05\n",
      "Epoch 2/1000\n",
      "34452/34452 [==============================] - 6s 174us/step - loss: 3.3549e-05 - mean_squared_error: 2.9214e-05 - val_loss: 6.2918e-05 - val_mean_squared_error: 5.8695e-05\n",
      "Epoch 3/1000\n",
      "34452/34452 [==============================] - 6s 164us/step - loss: 3.3385e-05 - mean_squared_error: 2.8992e-05 - val_loss: 6.7695e-05 - val_mean_squared_error: 6.2587e-05\n",
      "Epoch 4/1000\n",
      "34452/34452 [==============================] - 6s 173us/step - loss: 3.3966e-05 - mean_squared_error: 2.9279e-05 - val_loss: 6.7521e-05 - val_mean_squared_error: 6.1836e-05\n",
      "Epoch 5/1000\n",
      "34452/34452 [==============================] - 7s 201us/step - loss: 3.3776e-05 - mean_squared_error: 2.9177e-05 - val_loss: 6.3086e-05 - val_mean_squared_error: 5.8543e-05\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 6/1000\n",
      "34452/34452 [==============================] - 9s 253us/step - loss: 2.8771e-05 - mean_squared_error: 2.6337e-05 - val_loss: 5.9660e-05 - val_mean_squared_error: 5.7276e-05\n",
      "Epoch 7/1000\n",
      "34452/34452 [==============================] - 8s 240us/step - loss: 2.8562e-05 - mean_squared_error: 2.6198e-05 - val_loss: 6.0232e-05 - val_mean_squared_error: 5.7819e-05\n",
      "Epoch 8/1000\n",
      "34452/34452 [==============================] - 6s 162us/step - loss: 2.8512e-05 - mean_squared_error: 2.6186e-05 - val_loss: 5.9559e-05 - val_mean_squared_error: 5.7307e-05\n",
      "Epoch 9/1000\n",
      "34452/34452 [==============================] - 6s 177us/step - loss: 2.8383e-05 - mean_squared_error: 2.6120e-05 - val_loss: 6.0219e-05 - val_mean_squared_error: 5.8058e-05\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 10/1000\n",
      "34452/34452 [==============================] - 6s 182us/step - loss: 2.7815e-05 - mean_squared_error: 2.5754e-05 - val_loss: 5.9480e-05 - val_mean_squared_error: 5.7427e-05\n",
      "Epoch 11/1000\n",
      "34452/34452 [==============================] - 5s 140us/step - loss: 2.7765e-05 - mean_squared_error: 2.5708e-05 - val_loss: 5.9409e-05 - val_mean_squared_error: 5.7359e-05\n",
      "Epoch 12/1000\n",
      "34452/34452 [==============================] - 5s 133us/step - loss: 2.7753e-05 - mean_squared_error: 2.5700e-05 - val_loss: 5.9492e-05 - val_mean_squared_error: 5.7455e-05\n",
      "Epoch 13/1000\n",
      "34452/34452 [==============================] - 7s 208us/step - loss: 2.7730e-05 - mean_squared_error: 2.5684e-05 - val_loss: 5.9716e-05 - val_mean_squared_error: 5.7654e-05\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 14/1000\n",
      "34452/34452 [==============================] - 6s 174us/step - loss: 2.7677e-05 - mean_squared_error: 2.5638e-05 - val_loss: 5.9417e-05 - val_mean_squared_error: 5.7384e-05\n",
      "Epoch 15/1000\n",
      "34452/34452 [==============================] - 6s 183us/step - loss: 2.7654e-05 - mean_squared_error: 2.5623e-05 - val_loss: 5.9375e-05 - val_mean_squared_error: 5.7346e-05\n",
      "Epoch 16/1000\n",
      "34452/34452 [==============================] - 6s 176us/step - loss: 2.7650e-05 - mean_squared_error: 2.5623e-05 - val_loss: 5.9399e-05 - val_mean_squared_error: 5.7370e-05\n",
      "Epoch 17/1000\n",
      "34452/34452 [==============================] - 6s 169us/step - loss: 2.7646e-05 - mean_squared_error: 2.5617e-05 - val_loss: 5.9384e-05 - val_mean_squared_error: 5.7357e-05\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 18/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34452/34452 [==============================] - 6s 167us/step - loss: 2.7637e-05 - mean_squared_error: 2.5611e-05 - val_loss: 5.9379e-05 - val_mean_squared_error: 5.7353e-05\n",
      "Epoch 19/1000\n",
      "34452/34452 [==============================] - 6s 176us/step - loss: 2.7636e-05 - mean_squared_error: 2.5610e-05 - val_loss: 5.9376e-05 - val_mean_squared_error: 5.7349e-05\n",
      "Epoch 20/1000\n",
      "34452/34452 [==============================] - 6s 172us/step - loss: 2.7636e-05 - mean_squared_error: 2.5610e-05 - val_loss: 5.9374e-05 - val_mean_squared_error: 5.7348e-05\n",
      "Epoch 21/1000\n",
      "34452/34452 [==============================] - 5s 159us/step - loss: 2.7636e-05 - mean_squared_error: 2.5609e-05 - val_loss: 5.9372e-05 - val_mean_squared_error: 5.7346e-05\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "Epoch 22/1000\n",
      "34452/34452 [==============================] - 6s 174us/step - loss: 2.7634e-05 - mean_squared_error: 2.5608e-05 - val_loss: 5.9372e-05 - val_mean_squared_error: 5.7346e-05\n",
      "Epoch 23/1000\n",
      "34452/34452 [==============================] - 6s 177us/step - loss: 2.7634e-05 - mean_squared_error: 2.5608e-05 - val_loss: 5.9372e-05 - val_mean_squared_error: 5.7345e-05\n",
      "Epoch 24/1000\n",
      "34452/34452 [==============================] - 6s 166us/step - loss: 2.7634e-05 - mean_squared_error: 2.5608e-05 - val_loss: 5.9371e-05 - val_mean_squared_error: 5.7345e-05\n",
      "Epoch 25/1000\n",
      "34452/34452 [==============================] - 6s 160us/step - loss: 2.7634e-05 - mean_squared_error: 2.5608e-05 - val_loss: 5.9371e-05 - val_mean_squared_error: 5.7345e-05\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "Epoch 26/1000\n",
      "34452/34452 [==============================] - 6s 180us/step - loss: 2.7634e-05 - mean_squared_error: 2.5608e-05 - val_loss: 5.9371e-05 - val_mean_squared_error: 5.7345e-05\n",
      "Epoch 00026: early stopping\n",
      "Train on 34452 samples, validate on 8636 samples\n",
      "Epoch 1/1000\n",
      "34452/34452 [==============================] - 6s 179us/step - loss: 3.5295e-05 - mean_squared_error: 2.9720e-05 - val_loss: 6.4456e-05 - val_mean_squared_error: 6.0657e-05\n",
      "Epoch 2/1000\n",
      "34452/34452 [==============================] - 6s 164us/step - loss: 3.3639e-05 - mean_squared_error: 2.9090e-05 - val_loss: 6.5783e-05 - val_mean_squared_error: 6.1561e-05\n",
      "Epoch 3/1000\n",
      "34452/34452 [==============================] - 6s 165us/step - loss: 3.3488e-05 - mean_squared_error: 2.8887e-05 - val_loss: 6.1395e-05 - val_mean_squared_error: 5.7194e-05\n",
      "Epoch 4/1000\n",
      "34452/34452 [==============================] - 6s 178us/step - loss: 3.3569e-05 - mean_squared_error: 2.8914e-05 - val_loss: 6.2485e-05 - val_mean_squared_error: 5.7781e-05\n",
      "Epoch 5/1000\n",
      "34452/34452 [==============================] - 6s 183us/step - loss: 3.3450e-05 - mean_squared_error: 2.8931e-05 - val_loss: 6.2073e-05 - val_mean_squared_error: 5.7602e-05\n",
      "Epoch 6/1000\n",
      "34452/34452 [==============================] - 6s 166us/step - loss: 3.3370e-05 - mean_squared_error: 2.8782e-05 - val_loss: 6.6734e-05 - val_mean_squared_error: 6.2875e-05\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 7/1000\n",
      "34452/34452 [==============================] - 6s 168us/step - loss: 2.8507e-05 - mean_squared_error: 2.6070e-05 - val_loss: 5.9874e-05 - val_mean_squared_error: 5.7443e-05\n",
      "Epoch 8/1000\n",
      "34452/34452 [==============================] - 6s 178us/step - loss: 2.8360e-05 - mean_squared_error: 2.5957e-05 - val_loss: 5.9759e-05 - val_mean_squared_error: 5.7410e-05\n",
      "Epoch 9/1000\n",
      "34452/34452 [==============================] - 6s 178us/step - loss: 2.8259e-05 - mean_squared_error: 2.5908e-05 - val_loss: 5.9929e-05 - val_mean_squared_error: 5.7708e-05\n",
      "Epoch 10/1000\n",
      "34452/34452 [==============================] - 6s 164us/step - loss: 2.8163e-05 - mean_squared_error: 2.5877e-05 - val_loss: 5.9564e-05 - val_mean_squared_error: 5.7303e-05\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 11/1000\n",
      "34452/34452 [==============================] - 6s 170us/step - loss: 2.7544e-05 - mean_squared_error: 2.5452e-05 - val_loss: 5.9066e-05 - val_mean_squared_error: 5.6976e-05\n",
      "Epoch 12/1000\n",
      "34452/34452 [==============================] - 6s 180us/step - loss: 2.7498e-05 - mean_squared_error: 2.5420e-05 - val_loss: 5.9124e-05 - val_mean_squared_error: 5.7049e-05\n",
      "Epoch 13/1000\n",
      "34452/34452 [==============================] - 6s 174us/step - loss: 2.7485e-05 - mean_squared_error: 2.5415e-05 - val_loss: 5.9229e-05 - val_mean_squared_error: 5.7155e-05\n",
      "Epoch 14/1000\n",
      "34452/34452 [==============================] - 6s 165us/step - loss: 2.7471e-05 - mean_squared_error: 2.5401e-05 - val_loss: 5.9161e-05 - val_mean_squared_error: 5.7108e-05\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 15/1000\n",
      "34452/34452 [==============================] - 6s 172us/step - loss: 2.7405e-05 - mean_squared_error: 2.5362e-05 - val_loss: 5.9002e-05 - val_mean_squared_error: 5.6959e-05\n",
      "Epoch 16/1000\n",
      "34452/34452 [==============================] - 6s 182us/step - loss: 2.7391e-05 - mean_squared_error: 2.5352e-05 - val_loss: 5.8983e-05 - val_mean_squared_error: 5.6939e-05\n",
      "Epoch 17/1000\n",
      "34452/34452 [==============================] - 6s 175us/step - loss: 2.7387e-05 - mean_squared_error: 2.5343e-05 - val_loss: 5.9009e-05 - val_mean_squared_error: 5.6966e-05\n",
      "Epoch 18/1000\n",
      "34452/34452 [==============================] - 6s 163us/step - loss: 2.7384e-05 - mean_squared_error: 2.5341e-05 - val_loss: 5.8981e-05 - val_mean_squared_error: 5.6939e-05\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 19/1000\n",
      "34452/34452 [==============================] - 6s 176us/step - loss: 2.7374e-05 - mean_squared_error: 2.5332e-05 - val_loss: 5.8982e-05 - val_mean_squared_error: 5.6940e-05\n",
      "Epoch 20/1000\n",
      "34452/34452 [==============================] - 6s 183us/step - loss: 2.7373e-05 - mean_squared_error: 2.5331e-05 - val_loss: 5.8984e-05 - val_mean_squared_error: 5.6943e-05\n",
      "Epoch 21/1000\n",
      "34452/34452 [==============================] - 6s 177us/step - loss: 2.7373e-05 - mean_squared_error: 2.5331e-05 - val_loss: 5.8986e-05 - val_mean_squared_error: 5.6944e-05\n",
      "Epoch 22/1000\n",
      "34452/34452 [==============================] - 9s 249us/step - loss: 2.7372e-05 - mean_squared_error: 2.5331e-05 - val_loss: 5.8987e-05 - val_mean_squared_error: 5.6946e-05\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "Epoch 23/1000\n",
      "34452/34452 [==============================] - 6s 181us/step - loss: 2.7371e-05 - mean_squared_error: 2.5330e-05 - val_loss: 5.8987e-05 - val_mean_squared_error: 5.6946e-05\n",
      "Epoch 24/1000\n",
      "34452/34452 [==============================] - 7s 191us/step - loss: 2.7371e-05 - mean_squared_error: 2.5330e-05 - val_loss: 5.8987e-05 - val_mean_squared_error: 5.6946e-05\n",
      "Epoch 25/1000\n",
      "34452/34452 [==============================] - 8s 245us/step - loss: 2.7371e-05 - mean_squared_error: 2.5330e-05 - val_loss: 5.8988e-05 - val_mean_squared_error: 5.6946e-05\n",
      "Epoch 26/1000\n",
      "34452/34452 [==============================] - 6s 170us/step - loss: 2.7371e-05 - mean_squared_error: 2.5330e-05 - val_loss: 5.8988e-05 - val_mean_squared_error: 5.6946e-05\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "Epoch 27/1000\n",
      "34452/34452 [==============================] - 7s 206us/step - loss: 2.7371e-05 - mean_squared_error: 2.5330e-05 - val_loss: 5.8987e-05 - val_mean_squared_error: 5.6946e-05\n",
      "Epoch 28/1000\n",
      "34452/34452 [==============================] - 8s 238us/step - loss: 2.7371e-05 - mean_squared_error: 2.5330e-05 - val_loss: 5.8987e-05 - val_mean_squared_error: 5.6946e-05\n",
      "Epoch 29/1000\n",
      "34452/34452 [==============================] - 6s 173us/step - loss: 2.7371e-05 - mean_squared_error: 2.5330e-05 - val_loss: 5.8987e-05 - val_mean_squared_error: 5.6946e-05\n",
      "Epoch 30/1000\n",
      "34452/34452 [==============================] - 6s 180us/step - loss: 2.7371e-05 - mean_squared_error: 2.5330e-05 - val_loss: 5.8987e-05 - val_mean_squared_error: 5.6946e-05\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "Epoch 31/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34452/34452 [==============================] - 6s 176us/step - loss: 2.7371e-05 - mean_squared_error: 2.5329e-05 - val_loss: 5.8987e-05 - val_mean_squared_error: 5.6946e-05\n",
      "Epoch 32/1000\n",
      "34452/34452 [==============================] - 6s 167us/step - loss: 2.7371e-05 - mean_squared_error: 2.5329e-05 - val_loss: 5.8987e-05 - val_mean_squared_error: 5.6946e-05\n",
      "Epoch 33/1000\n",
      "34452/34452 [==============================] - 5s 159us/step - loss: 2.7371e-05 - mean_squared_error: 2.5330e-05 - val_loss: 5.8987e-05 - val_mean_squared_error: 5.6946e-05\n",
      "Epoch 34/1000\n",
      "34452/34452 [==============================] - 6s 177us/step - loss: 2.7371e-05 - mean_squared_error: 2.5329e-05 - val_loss: 5.8987e-05 - val_mean_squared_error: 5.6946e-05\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
      "Epoch 35/1000\n",
      "34452/34452 [==============================] - 6s 178us/step - loss: 2.7371e-05 - mean_squared_error: 2.5329e-05 - val_loss: 5.8987e-05 - val_mean_squared_error: 5.6946e-05\n",
      "Epoch 36/1000\n",
      "34452/34452 [==============================] - 6s 166us/step - loss: 2.7371e-05 - mean_squared_error: 2.5329e-05 - val_loss: 5.8987e-05 - val_mean_squared_error: 5.6946e-05\n",
      "Epoch 00036: early stopping\n",
      "Train on 34452 samples, validate on 8636 samples\n",
      "Epoch 1/1000\n",
      "34452/34452 [==============================] - 6s 165us/step - loss: 3.5211e-05 - mean_squared_error: 2.9631e-05 - val_loss: 6.2181e-05 - val_mean_squared_error: 5.8239e-05\n",
      "Epoch 2/1000\n",
      "34452/34452 [==============================] - 6s 178us/step - loss: 3.3464e-05 - mean_squared_error: 2.8755e-05 - val_loss: 6.4022e-05 - val_mean_squared_error: 5.9482e-05\n",
      "Epoch 3/1000\n",
      "34452/34452 [==============================] - 5s 131us/step - loss: 3.3375e-05 - mean_squared_error: 2.8744e-05 - val_loss: 6.4105e-05 - val_mean_squared_error: 5.8812e-05\n",
      "Epoch 4/1000\n",
      "34452/34452 [==============================] - 5s 136us/step - loss: 3.3371e-05 - mean_squared_error: 2.8740e-05 - val_loss: 6.4918e-05 - val_mean_squared_error: 5.9596e-05\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 5/1000\n",
      "34452/34452 [==============================] - 7s 212us/step - loss: 2.8428e-05 - mean_squared_error: 2.5926e-05 - val_loss: 5.9067e-05 - val_mean_squared_error: 5.6640e-05\n",
      "Epoch 6/1000\n",
      "34452/34452 [==============================] - 6s 165us/step - loss: 2.8229e-05 - mean_squared_error: 2.5807e-05 - val_loss: 5.9695e-05 - val_mean_squared_error: 5.7350e-05\n",
      "Epoch 7/1000\n",
      "34452/34452 [==============================] - 6s 181us/step - loss: 2.8163e-05 - mean_squared_error: 2.5810e-05 - val_loss: 5.9118e-05 - val_mean_squared_error: 5.6740e-05\n",
      "Epoch 8/1000\n",
      "34452/34452 [==============================] - 6s 180us/step - loss: 2.8040e-05 - mean_squared_error: 2.5753e-05 - val_loss: 5.9503e-05 - val_mean_squared_error: 5.7097e-05\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 9/1000\n",
      "34452/34452 [==============================] - 6s 161us/step - loss: 2.7479e-05 - mean_squared_error: 2.5335e-05 - val_loss: 5.8865e-05 - val_mean_squared_error: 5.6794e-05\n",
      "Epoch 10/1000\n",
      "34452/34452 [==============================] - 6s 164us/step - loss: 2.7407e-05 - mean_squared_error: 2.5333e-05 - val_loss: 5.9117e-05 - val_mean_squared_error: 5.7023e-05\n",
      "Epoch 11/1000\n",
      "34452/34452 [==============================] - 6s 180us/step - loss: 2.7392e-05 - mean_squared_error: 2.5318e-05 - val_loss: 5.9065e-05 - val_mean_squared_error: 5.6994e-05\n",
      "Epoch 12/1000\n",
      "34452/34452 [==============================] - 6s 181us/step - loss: 2.7375e-05 - mean_squared_error: 2.5310e-05 - val_loss: 5.8921e-05 - val_mean_squared_error: 5.6843e-05\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 13/1000\n",
      "34452/34452 [==============================] - 9s 250us/step - loss: 2.7315e-05 - mean_squared_error: 2.5252e-05 - val_loss: 5.9002e-05 - val_mean_squared_error: 5.6946e-05\n",
      "Epoch 14/1000\n",
      "34452/34452 [==============================] - 6s 178us/step - loss: 2.7301e-05 - mean_squared_error: 2.5246e-05 - val_loss: 5.9019e-05 - val_mean_squared_error: 5.6967e-05\n",
      "Epoch 15/1000\n",
      "34452/34452 [==============================] - 6s 179us/step - loss: 2.7297e-05 - mean_squared_error: 2.5247e-05 - val_loss: 5.8972e-05 - val_mean_squared_error: 5.6922e-05\n",
      "Epoch 16/1000\n",
      "34452/34452 [==============================] - 5s 140us/step - loss: 2.7293e-05 - mean_squared_error: 2.5241e-05 - val_loss: 5.8999e-05 - val_mean_squared_error: 5.6952e-05\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 17/1000\n",
      "34452/34452 [==============================] - 5s 134us/step - loss: 2.7285e-05 - mean_squared_error: 2.5238e-05 - val_loss: 5.8990e-05 - val_mean_squared_error: 5.6942e-05\n",
      "Epoch 18/1000\n",
      "34452/34452 [==============================] - 7s 207us/step - loss: 2.7284e-05 - mean_squared_error: 2.5237e-05 - val_loss: 5.8983e-05 - val_mean_squared_error: 5.6936e-05\n",
      "Epoch 19/1000\n",
      "34452/34452 [==============================] - 6s 168us/step - loss: 2.7283e-05 - mean_squared_error: 2.5236e-05 - val_loss: 5.8979e-05 - val_mean_squared_error: 5.6932e-05\n",
      "Epoch 20/1000\n",
      "34452/34452 [==============================] - 6s 180us/step - loss: 2.7283e-05 - mean_squared_error: 2.5236e-05 - val_loss: 5.8975e-05 - val_mean_squared_error: 5.6928e-05\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "Epoch 21/1000\n",
      "34452/34452 [==============================] - 6s 178us/step - loss: 2.7282e-05 - mean_squared_error: 2.5235e-05 - val_loss: 5.8975e-05 - val_mean_squared_error: 5.6928e-05\n",
      "Epoch 22/1000\n",
      "34452/34452 [==============================] - 6s 170us/step - loss: 2.7282e-05 - mean_squared_error: 2.5235e-05 - val_loss: 5.8975e-05 - val_mean_squared_error: 5.6928e-05\n",
      "Epoch 23/1000\n",
      "34452/34452 [==============================] - 6s 170us/step - loss: 2.7282e-05 - mean_squared_error: 2.5235e-05 - val_loss: 5.8975e-05 - val_mean_squared_error: 5.6928e-05\n",
      "Epoch 24/1000\n",
      "34452/34452 [==============================] - 7s 211us/step - loss: 2.7282e-05 - mean_squared_error: 2.5235e-05 - val_loss: 5.8974e-05 - val_mean_squared_error: 5.6927e-05\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "Epoch 25/1000\n",
      "34452/34452 [==============================] - 8s 235us/step - loss: 2.7282e-05 - mean_squared_error: 2.5235e-05 - val_loss: 5.8974e-05 - val_mean_squared_error: 5.6927e-05\n",
      "Epoch 00025: early stopping\n",
      "Train on 34452 samples, validate on 8636 samples\n",
      "Epoch 1/1000\n",
      "34452/34452 [==============================] - 8s 225us/step - loss: 3.4730e-05 - mean_squared_error: 2.9245e-05 - val_loss: 6.2668e-05 - val_mean_squared_error: 5.8743e-05\n",
      "Epoch 2/1000\n",
      "34452/34452 [==============================] - 6s 171us/step - loss: 3.3557e-05 - mean_squared_error: 2.8818e-05 - val_loss: 6.2374e-05 - val_mean_squared_error: 5.9047e-05\n",
      "Epoch 3/1000\n",
      "34452/34452 [==============================] - 6s 185us/step - loss: 3.3112e-05 - mean_squared_error: 2.8570e-05 - val_loss: 6.5233e-05 - val_mean_squared_error: 5.9869e-05\n",
      "Epoch 4/1000\n",
      "34452/34452 [==============================] - 6s 188us/step - loss: 3.2959e-05 - mean_squared_error: 2.8429e-05 - val_loss: 6.2853e-05 - val_mean_squared_error: 5.9086e-05\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 5/1000\n",
      "34452/34452 [==============================] - 6s 175us/step - loss: 2.8242e-05 - mean_squared_error: 2.5839e-05 - val_loss: 5.9818e-05 - val_mean_squared_error: 5.7299e-05\n",
      "Epoch 6/1000\n",
      "34452/34452 [==============================] - 6s 167us/step - loss: 2.8063e-05 - mean_squared_error: 2.5706e-05 - val_loss: 5.8755e-05 - val_mean_squared_error: 5.6543e-05\n",
      "Epoch 7/1000\n",
      "34452/34452 [==============================] - 6s 179us/step - loss: 2.8010e-05 - mean_squared_error: 2.5720e-05 - val_loss: 5.9440e-05 - val_mean_squared_error: 5.7164e-05\n",
      "Epoch 8/1000\n",
      "34452/34452 [==============================] - 6s 184us/step - loss: 2.7911e-05 - mean_squared_error: 2.5669e-05 - val_loss: 5.8613e-05 - val_mean_squared_error: 5.6408e-05\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 9/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34452/34452 [==============================] - 6s 172us/step - loss: 2.7323e-05 - mean_squared_error: 2.5255e-05 - val_loss: 5.8879e-05 - val_mean_squared_error: 5.6849e-05\n",
      "Epoch 10/1000\n",
      "34452/34452 [==============================] - 5s 158us/step - loss: 2.7270e-05 - mean_squared_error: 2.5226e-05 - val_loss: 5.8999e-05 - val_mean_squared_error: 5.6958e-05\n",
      "Epoch 11/1000\n",
      "34452/34452 [==============================] - 6s 174us/step - loss: 2.7248e-05 - mean_squared_error: 2.5213e-05 - val_loss: 5.8815e-05 - val_mean_squared_error: 5.6756e-05\n",
      "Epoch 12/1000\n",
      "34452/34452 [==============================] - 4s 127us/step - loss: 2.7230e-05 - mean_squared_error: 2.5191e-05 - val_loss: 5.9125e-05 - val_mean_squared_error: 5.7086e-05\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 13/1000\n",
      "34452/34452 [==============================] - 5s 142us/step - loss: 2.7168e-05 - mean_squared_error: 2.5144e-05 - val_loss: 5.8935e-05 - val_mean_squared_error: 5.6911e-05\n",
      "Epoch 14/1000\n",
      "34452/34452 [==============================] - 8s 224us/step - loss: 2.7155e-05 - mean_squared_error: 2.5134e-05 - val_loss: 5.8925e-05 - val_mean_squared_error: 5.6905e-05\n",
      "Epoch 15/1000\n",
      "34452/34452 [==============================] - 6s 161us/step - loss: 2.7151e-05 - mean_squared_error: 2.5130e-05 - val_loss: 5.8888e-05 - val_mean_squared_error: 5.6866e-05\n",
      "Epoch 16/1000\n",
      "34452/34452 [==============================] - 6s 170us/step - loss: 2.7148e-05 - mean_squared_error: 2.5127e-05 - val_loss: 5.8922e-05 - val_mean_squared_error: 5.6902e-05\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 17/1000\n",
      "34452/34452 [==============================] - 6s 178us/step - loss: 2.7139e-05 - mean_squared_error: 2.5120e-05 - val_loss: 5.8913e-05 - val_mean_squared_error: 5.6894e-05\n",
      "Epoch 18/1000\n",
      "34452/34452 [==============================] - 5s 136us/step - loss: 2.7138e-05 - mean_squared_error: 2.5119e-05 - val_loss: 5.8907e-05 - val_mean_squared_error: 5.6888e-05\n",
      "Epoch 19/1000\n",
      "34452/34452 [==============================] - 5s 133us/step - loss: 2.7138e-05 - mean_squared_error: 2.5118e-05 - val_loss: 5.8903e-05 - val_mean_squared_error: 5.6884e-05\n",
      "Epoch 20/1000\n",
      "34452/34452 [==============================] - 4s 130us/step - loss: 2.7137e-05 - mean_squared_error: 2.5118e-05 - val_loss: 5.8898e-05 - val_mean_squared_error: 5.6879e-05\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "Epoch 21/1000\n",
      "34452/34452 [==============================] - 5s 142us/step - loss: 2.7136e-05 - mean_squared_error: 2.5117e-05 - val_loss: 5.8898e-05 - val_mean_squared_error: 5.6879e-05\n",
      "Epoch 22/1000\n",
      "34452/34452 [==============================] - 8s 224us/step - loss: 2.7136e-05 - mean_squared_error: 2.5117e-05 - val_loss: 5.8898e-05 - val_mean_squared_error: 5.6879e-05\n",
      "Epoch 23/1000\n",
      "34452/34452 [==============================] - 6s 162us/step - loss: 2.7136e-05 - mean_squared_error: 2.5117e-05 - val_loss: 5.8898e-05 - val_mean_squared_error: 5.6879e-05\n",
      "Epoch 24/1000\n",
      "34452/34452 [==============================] - 6s 171us/step - loss: 2.7136e-05 - mean_squared_error: 2.5117e-05 - val_loss: 5.8897e-05 - val_mean_squared_error: 5.6878e-05\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "Epoch 25/1000\n",
      "34452/34452 [==============================] - 4s 126us/step - loss: 2.7136e-05 - mean_squared_error: 2.5117e-05 - val_loss: 5.8897e-05 - val_mean_squared_error: 5.6878e-05\n",
      "Epoch 26/1000\n",
      "34452/34452 [==============================] - 5s 155us/step - loss: 2.7136e-05 - mean_squared_error: 2.5117e-05 - val_loss: 5.8897e-05 - val_mean_squared_error: 5.6878e-05\n",
      "Epoch 27/1000\n",
      "34452/34452 [==============================] - 8s 218us/step - loss: 2.7136e-05 - mean_squared_error: 2.5117e-05 - val_loss: 5.8897e-05 - val_mean_squared_error: 5.6878e-05\n",
      "Epoch 28/1000\n",
      "34452/34452 [==============================] - 6s 165us/step - loss: 2.7136e-05 - mean_squared_error: 2.5117e-05 - val_loss: 5.8897e-05 - val_mean_squared_error: 5.6878e-05\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "Epoch 00028: early stopping\n",
      "Train on 34452 samples, validate on 8636 samples\n",
      "Epoch 1/1000\n",
      "34452/34452 [==============================] - 6s 165us/step - loss: 3.5354e-05 - mean_squared_error: 2.9866e-05 - val_loss: 6.5738e-05 - val_mean_squared_error: 6.1741e-05\n",
      "Epoch 2/1000\n",
      "34452/34452 [==============================] - 6s 181us/step - loss: 3.3233e-05 - mean_squared_error: 2.8689e-05 - val_loss: 6.5838e-05 - val_mean_squared_error: 6.0305e-05\n",
      "Epoch 3/1000\n",
      "34452/34452 [==============================] - 6s 181us/step - loss: 3.2728e-05 - mean_squared_error: 2.8375e-05 - val_loss: 6.5563e-05 - val_mean_squared_error: 6.0797e-05\n",
      "Epoch 4/1000\n",
      "34452/34452 [==============================] - 6s 166us/step - loss: 3.3316e-05 - mean_squared_error: 2.8634e-05 - val_loss: 6.8605e-05 - val_mean_squared_error: 6.3057e-05\n",
      "Epoch 5/1000\n",
      "34452/34452 [==============================] - 6s 169us/step - loss: 3.2790e-05 - mean_squared_error: 2.8318e-05 - val_loss: 6.6613e-05 - val_mean_squared_error: 6.2497e-05\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 6/1000\n",
      "34452/34452 [==============================] - 8s 220us/step - loss: 2.8197e-05 - mean_squared_error: 2.5769e-05 - val_loss: 5.9029e-05 - val_mean_squared_error: 5.6660e-05\n",
      "Epoch 7/1000\n",
      "34452/34452 [==============================] - 8s 232us/step - loss: 2.8064e-05 - mean_squared_error: 2.5697e-05 - val_loss: 5.9647e-05 - val_mean_squared_error: 5.7335e-05\n",
      "Epoch 8/1000\n",
      "34452/34452 [==============================] - 5s 160us/step - loss: 2.7948e-05 - mean_squared_error: 2.5657e-05 - val_loss: 5.9554e-05 - val_mean_squared_error: 5.7188e-05\n",
      "Epoch 9/1000\n",
      "34452/34452 [==============================] - 4s 127us/step - loss: 2.7866e-05 - mean_squared_error: 2.5623e-05 - val_loss: 5.9471e-05 - val_mean_squared_error: 5.7260e-05\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 10/1000\n",
      "34452/34452 [==============================] - 7s 200us/step - loss: 2.7272e-05 - mean_squared_error: 2.5213e-05 - val_loss: 5.9163e-05 - val_mean_squared_error: 5.7148e-05\n",
      "Epoch 11/1000\n",
      "34452/34452 [==============================] - 6s 183us/step - loss: 2.7229e-05 - mean_squared_error: 2.5188e-05 - val_loss: 5.9008e-05 - val_mean_squared_error: 5.6980e-05\n",
      "Epoch 12/1000\n",
      "34452/34452 [==============================] - 6s 184us/step - loss: 2.7210e-05 - mean_squared_error: 2.5173e-05 - val_loss: 5.9268e-05 - val_mean_squared_error: 5.7248e-05\n",
      "Epoch 13/1000\n",
      "34452/34452 [==============================] - 6s 170us/step - loss: 2.7196e-05 - mean_squared_error: 2.5157e-05 - val_loss: 5.9091e-05 - val_mean_squared_error: 5.7105e-05\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 14/1000\n",
      "34452/34452 [==============================] - 6s 172us/step - loss: 2.7140e-05 - mean_squared_error: 2.5155e-05 - val_loss: 5.8996e-05 - val_mean_squared_error: 5.7004e-05\n",
      "Epoch 15/1000\n",
      "34452/34452 [==============================] - 6s 181us/step - loss: 2.7123e-05 - mean_squared_error: 2.5126e-05 - val_loss: 5.8988e-05 - val_mean_squared_error: 5.6991e-05\n",
      "Epoch 16/1000\n",
      "34452/34452 [==============================] - 6s 183us/step - loss: 2.7118e-05 - mean_squared_error: 2.5117e-05 - val_loss: 5.8993e-05 - val_mean_squared_error: 5.6991e-05\n",
      "Epoch 17/1000\n",
      "34452/34452 [==============================] - 6s 173us/step - loss: 2.7115e-05 - mean_squared_error: 2.5113e-05 - val_loss: 5.9028e-05 - val_mean_squared_error: 5.7026e-05\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 18/1000\n",
      "34452/34452 [==============================] - 6s 161us/step - loss: 2.7107e-05 - mean_squared_error: 2.5106e-05 - val_loss: 5.9020e-05 - val_mean_squared_error: 5.7018e-05\n",
      "Epoch 19/1000\n",
      "34452/34452 [==============================] - 4s 126us/step - loss: 2.7106e-05 - mean_squared_error: 2.5104e-05 - val_loss: 5.9012e-05 - val_mean_squared_error: 5.7010e-05\n",
      "Epoch 20/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34452/34452 [==============================] - 6s 188us/step - loss: 2.7105e-05 - mean_squared_error: 2.5103e-05 - val_loss: 5.9010e-05 - val_mean_squared_error: 5.7007e-05\n",
      "Epoch 21/1000\n",
      "34452/34452 [==============================] - 6s 187us/step - loss: 2.7105e-05 - mean_squared_error: 2.5102e-05 - val_loss: 5.9008e-05 - val_mean_squared_error: 5.7005e-05\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "Epoch 22/1000\n",
      "34452/34452 [==============================] - 6s 178us/step - loss: 2.7103e-05 - mean_squared_error: 2.5100e-05 - val_loss: 5.9008e-05 - val_mean_squared_error: 5.7005e-05\n",
      "Epoch 23/1000\n",
      "34452/34452 [==============================] - 9s 247us/step - loss: 2.7103e-05 - mean_squared_error: 2.5100e-05 - val_loss: 5.9008e-05 - val_mean_squared_error: 5.7005e-05\n",
      "Epoch 24/1000\n",
      "34452/34452 [==============================] - 6s 177us/step - loss: 2.7103e-05 - mean_squared_error: 2.5100e-05 - val_loss: 5.9008e-05 - val_mean_squared_error: 5.7005e-05\n",
      "Epoch 25/1000\n",
      "34452/34452 [==============================] - 6s 180us/step - loss: 2.7103e-05 - mean_squared_error: 2.5100e-05 - val_loss: 5.9008e-05 - val_mean_squared_error: 5.7005e-05\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "Epoch 26/1000\n",
      "34452/34452 [==============================] - 6s 165us/step - loss: 2.7103e-05 - mean_squared_error: 2.5100e-05 - val_loss: 5.9008e-05 - val_mean_squared_error: 5.7005e-05\n",
      "Epoch 00026: early stopping\n",
      "Train on 34452 samples, validate on 8636 samples\n",
      "Epoch 1/1000\n",
      "34452/34452 [==============================] - 6s 162us/step - loss: 3.4795e-05 - mean_squared_error: 2.9367e-05 - val_loss: 6.4120e-05 - val_mean_squared_error: 5.9473e-05\n",
      "Epoch 2/1000\n",
      "34452/34452 [==============================] - 6s 180us/step - loss: 3.3074e-05 - mean_squared_error: 2.8513e-05 - val_loss: 6.4826e-05 - val_mean_squared_error: 5.9310e-05\n",
      "Epoch 3/1000\n",
      "34452/34452 [==============================] - 6s 177us/step - loss: 3.3290e-05 - mean_squared_error: 2.8532e-05 - val_loss: 6.6226e-05 - val_mean_squared_error: 5.9932e-05\n",
      "Epoch 4/1000\n",
      "34452/34452 [==============================] - 6s 165us/step - loss: 3.2826e-05 - mean_squared_error: 2.8457e-05 - val_loss: 7.0782e-05 - val_mean_squared_error: 6.3104e-05\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 5/1000\n",
      "34452/34452 [==============================] - 6s 167us/step - loss: 2.8269e-05 - mean_squared_error: 2.5759e-05 - val_loss: 5.9379e-05 - val_mean_squared_error: 5.7045e-05\n",
      "Epoch 6/1000\n",
      "34452/34452 [==============================] - 6s 178us/step - loss: 2.8011e-05 - mean_squared_error: 2.5647e-05 - val_loss: 5.9674e-05 - val_mean_squared_error: 5.7259e-05\n",
      "Epoch 7/1000\n",
      "34452/34452 [==============================] - 5s 133us/step - loss: 2.7934e-05 - mean_squared_error: 2.5598e-05 - val_loss: 5.9804e-05 - val_mean_squared_error: 5.7494e-05\n",
      "Epoch 8/1000\n",
      "34452/34452 [==============================] - 5s 138us/step - loss: 2.7847e-05 - mean_squared_error: 2.5590e-05 - val_loss: 6.0403e-05 - val_mean_squared_error: 5.8032e-05\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 9/1000\n",
      "34452/34452 [==============================] - 7s 214us/step - loss: 2.7252e-05 - mean_squared_error: 2.5147e-05 - val_loss: 5.9110e-05 - val_mean_squared_error: 5.7074e-05\n",
      "Epoch 10/1000\n",
      "34452/34452 [==============================] - 6s 165us/step - loss: 2.7192e-05 - mean_squared_error: 2.5158e-05 - val_loss: 5.9318e-05 - val_mean_squared_error: 5.7262e-05\n",
      "Epoch 11/1000\n",
      "34452/34452 [==============================] - 6s 178us/step - loss: 2.7174e-05 - mean_squared_error: 2.5133e-05 - val_loss: 5.9341e-05 - val_mean_squared_error: 5.7314e-05\n",
      "Epoch 12/1000\n",
      "34452/34452 [==============================] - 6s 181us/step - loss: 2.7157e-05 - mean_squared_error: 2.5132e-05 - val_loss: 5.9178e-05 - val_mean_squared_error: 5.7130e-05\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 13/1000\n",
      "34452/34452 [==============================] - 5s 140us/step - loss: 2.7099e-05 - mean_squared_error: 2.5072e-05 - val_loss: 5.9224e-05 - val_mean_squared_error: 5.7204e-05\n",
      "Epoch 14/1000\n",
      "34452/34452 [==============================] - 5s 133us/step - loss: 2.7081e-05 - mean_squared_error: 2.5065e-05 - val_loss: 5.9186e-05 - val_mean_squared_error: 5.7173e-05\n",
      "Epoch 15/1000\n",
      "34452/34452 [==============================] - 7s 208us/step - loss: 2.7077e-05 - mean_squared_error: 2.5066e-05 - val_loss: 5.9180e-05 - val_mean_squared_error: 5.7171e-05\n",
      "Epoch 16/1000\n",
      "34452/34452 [==============================] - 6s 170us/step - loss: 2.7075e-05 - mean_squared_error: 2.5065e-05 - val_loss: 5.9131e-05 - val_mean_squared_error: 5.7122e-05\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 17/1000\n",
      "34452/34452 [==============================] - 7s 202us/step - loss: 2.7064e-05 - mean_squared_error: 2.5057e-05 - val_loss: 5.9134e-05 - val_mean_squared_error: 5.7126e-05\n",
      "Epoch 18/1000\n",
      "34452/34452 [==============================] - 8s 239us/step - loss: 2.7064e-05 - mean_squared_error: 2.5056e-05 - val_loss: 5.9136e-05 - val_mean_squared_error: 5.7129e-05\n",
      "Epoch 19/1000\n",
      "34452/34452 [==============================] - 6s 167us/step - loss: 2.7063e-05 - mean_squared_error: 2.5056e-05 - val_loss: 5.9138e-05 - val_mean_squared_error: 5.7131e-05\n",
      "Epoch 20/1000\n",
      "34452/34452 [==============================] - 6s 184us/step - loss: 2.7063e-05 - mean_squared_error: 2.5056e-05 - val_loss: 5.9140e-05 - val_mean_squared_error: 5.7133e-05\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "Epoch 21/1000\n",
      "34452/34452 [==============================] - 6s 181us/step - loss: 2.7062e-05 - mean_squared_error: 2.5055e-05 - val_loss: 5.9140e-05 - val_mean_squared_error: 5.7133e-05\n",
      "Epoch 22/1000\n",
      "34452/34452 [==============================] - 6s 167us/step - loss: 2.7062e-05 - mean_squared_error: 2.5055e-05 - val_loss: 5.9140e-05 - val_mean_squared_error: 5.7133e-05\n",
      "Epoch 23/1000\n",
      "34452/34452 [==============================] - 6s 167us/step - loss: 2.7062e-05 - mean_squared_error: 2.5055e-05 - val_loss: 5.9140e-05 - val_mean_squared_error: 5.7133e-05\n",
      "Epoch 24/1000\n",
      "34452/34452 [==============================] - 6s 180us/step - loss: 2.7062e-05 - mean_squared_error: 2.5055e-05 - val_loss: 5.9140e-05 - val_mean_squared_error: 5.7133e-05\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "Epoch 25/1000\n",
      "34452/34452 [==============================] - 6s 183us/step - loss: 2.7062e-05 - mean_squared_error: 2.5055e-05 - val_loss: 5.9140e-05 - val_mean_squared_error: 5.7133e-05\n",
      "Epoch 00025: early stopping\n",
      "Train on 34452 samples, validate on 8636 samples\n",
      "Epoch 1/1000\n",
      "34452/34452 [==============================] - 6s 170us/step - loss: 3.4792e-05 - mean_squared_error: 2.9322e-05 - val_loss: 6.2027e-05 - val_mean_squared_error: 5.7440e-05\n",
      "Epoch 2/1000\n",
      "34452/34452 [==============================] - 6s 163us/step - loss: 3.3100e-05 - mean_squared_error: 2.8536e-05 - val_loss: 6.4405e-05 - val_mean_squared_error: 5.9693e-05\n",
      "Epoch 3/1000\n",
      "34452/34452 [==============================] - 7s 189us/step - loss: 3.2944e-05 - mean_squared_error: 2.8423e-05 - val_loss: 6.3894e-05 - val_mean_squared_error: 5.9521e-05\n",
      "Epoch 4/1000\n",
      "34452/34452 [==============================] - 6s 183us/step - loss: 3.3403e-05 - mean_squared_error: 2.8536e-05 - val_loss: 6.3213e-05 - val_mean_squared_error: 5.9246e-05\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 5/1000\n",
      "34452/34452 [==============================] - 6s 170us/step - loss: 2.8148e-05 - mean_squared_error: 2.5695e-05 - val_loss: 5.9448e-05 - val_mean_squared_error: 5.7047e-05\n",
      "Epoch 6/1000\n",
      "34452/34452 [==============================] - 6s 164us/step - loss: 2.7972e-05 - mean_squared_error: 2.5588e-05 - val_loss: 5.9197e-05 - val_mean_squared_error: 5.6883e-05\n",
      "Epoch 7/1000\n",
      "34452/34452 [==============================] - 6s 181us/step - loss: 2.7868e-05 - mean_squared_error: 2.5562e-05 - val_loss: 6.0137e-05 - val_mean_squared_error: 5.7798e-05\n",
      "Epoch 8/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34452/34452 [==============================] - 6s 179us/step - loss: 2.7805e-05 - mean_squared_error: 2.5550e-05 - val_loss: 6.0114e-05 - val_mean_squared_error: 5.7787e-05\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 9/1000\n",
      "34452/34452 [==============================] - 6s 166us/step - loss: 2.7205e-05 - mean_squared_error: 2.5099e-05 - val_loss: 5.9073e-05 - val_mean_squared_error: 5.7015e-05\n",
      "Epoch 10/1000\n",
      "34452/34452 [==============================] - 6s 160us/step - loss: 2.7157e-05 - mean_squared_error: 2.5102e-05 - val_loss: 5.8984e-05 - val_mean_squared_error: 5.6941e-05\n",
      "Epoch 11/1000\n",
      "34452/34452 [==============================] - 6s 178us/step - loss: 2.7139e-05 - mean_squared_error: 2.5086e-05 - val_loss: 5.9094e-05 - val_mean_squared_error: 5.7067e-05\n",
      "Epoch 12/1000\n",
      "34452/34452 [==============================] - 6s 179us/step - loss: 2.7120e-05 - mean_squared_error: 2.5070e-05 - val_loss: 5.9188e-05 - val_mean_squared_error: 5.7163e-05\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 13/1000\n",
      "34452/34452 [==============================] - 6s 162us/step - loss: 2.7067e-05 - mean_squared_error: 2.5052e-05 - val_loss: 5.9032e-05 - val_mean_squared_error: 5.7020e-05\n",
      "Epoch 14/1000\n",
      "34452/34452 [==============================] - 6s 165us/step - loss: 2.7048e-05 - mean_squared_error: 2.5035e-05 - val_loss: 5.9039e-05 - val_mean_squared_error: 5.7023e-05\n",
      "Epoch 15/1000\n",
      "34452/34452 [==============================] - 4s 122us/step - loss: 2.7042e-05 - mean_squared_error: 2.5026e-05 - val_loss: 5.9026e-05 - val_mean_squared_error: 5.7009e-05\n",
      "Epoch 16/1000\n",
      "34452/34452 [==============================] - 6s 164us/step - loss: 2.7040e-05 - mean_squared_error: 2.5023e-05 - val_loss: 5.9064e-05 - val_mean_squared_error: 5.7045e-05\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 17/1000\n",
      "34452/34452 [==============================] - 7s 210us/step - loss: 2.7029e-05 - mean_squared_error: 2.5010e-05 - val_loss: 5.9062e-05 - val_mean_squared_error: 5.7042e-05\n",
      "Epoch 18/1000\n",
      "34452/34452 [==============================] - 6s 165us/step - loss: 2.7029e-05 - mean_squared_error: 2.5010e-05 - val_loss: 5.9059e-05 - val_mean_squared_error: 5.7040e-05\n",
      "Epoch 19/1000\n",
      "34452/34452 [==============================] - 6s 165us/step - loss: 2.7028e-05 - mean_squared_error: 2.5009e-05 - val_loss: 5.9060e-05 - val_mean_squared_error: 5.7041e-05\n",
      "Epoch 20/1000\n",
      "34452/34452 [==============================] - 6s 178us/step - loss: 2.7028e-05 - mean_squared_error: 2.5008e-05 - val_loss: 5.9058e-05 - val_mean_squared_error: 5.7039e-05\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "Epoch 21/1000\n",
      "34452/34452 [==============================] - 6s 178us/step - loss: 2.7027e-05 - mean_squared_error: 2.5007e-05 - val_loss: 5.9058e-05 - val_mean_squared_error: 5.7039e-05\n",
      "Epoch 22/1000\n",
      "34452/34452 [==============================] - 5s 142us/step - loss: 2.7027e-05 - mean_squared_error: 2.5007e-05 - val_loss: 5.9058e-05 - val_mean_squared_error: 5.7039e-05\n",
      "Epoch 23/1000\n",
      "34452/34452 [==============================] - 4s 130us/step - loss: 2.7027e-05 - mean_squared_error: 2.5007e-05 - val_loss: 5.9058e-05 - val_mean_squared_error: 5.7038e-05\n",
      "Epoch 24/1000\n",
      "34452/34452 [==============================] - 7s 202us/step - loss: 2.7027e-05 - mean_squared_error: 2.5007e-05 - val_loss: 5.9058e-05 - val_mean_squared_error: 5.7038e-05\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "Epoch 25/1000\n",
      "34452/34452 [==============================] - 6s 176us/step - loss: 2.7027e-05 - mean_squared_error: 2.5007e-05 - val_loss: 5.9058e-05 - val_mean_squared_error: 5.7038e-05\n",
      "Epoch 26/1000\n",
      "34452/34452 [==============================] - 6s 182us/step - loss: 2.7027e-05 - mean_squared_error: 2.5007e-05 - val_loss: 5.9058e-05 - val_mean_squared_error: 5.7038e-05\n",
      "Epoch 00026: early stopping\n",
      "Train on 34452 samples, validate on 8636 samples\n",
      "Epoch 1/1000\n",
      "34452/34452 [==============================] - 6s 171us/step - loss: 3.4978e-05 - mean_squared_error: 2.9418e-05 - val_loss: 6.4591e-05 - val_mean_squared_error: 6.0827e-05\n",
      "Epoch 2/1000\n",
      "34452/34452 [==============================] - 6s 163us/step - loss: 3.3059e-05 - mean_squared_error: 2.8468e-05 - val_loss: 6.1962e-05 - val_mean_squared_error: 5.7612e-05\n",
      "Epoch 3/1000\n",
      "34452/34452 [==============================] - 6s 175us/step - loss: 3.2819e-05 - mean_squared_error: 2.8389e-05 - val_loss: 6.4948e-05 - val_mean_squared_error: 6.1286e-05\n",
      "Epoch 4/1000\n",
      "34452/34452 [==============================] - 6s 180us/step - loss: 3.2717e-05 - mean_squared_error: 2.8286e-05 - val_loss: 6.3291e-05 - val_mean_squared_error: 5.9430e-05\n",
      "Epoch 5/1000\n",
      "34452/34452 [==============================] - 6s 170us/step - loss: 3.2755e-05 - mean_squared_error: 2.8305e-05 - val_loss: 6.7436e-05 - val_mean_squared_error: 6.2626e-05\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 6/1000\n",
      "34452/34452 [==============================] - 6s 166us/step - loss: 2.8086e-05 - mean_squared_error: 2.5643e-05 - val_loss: 5.9294e-05 - val_mean_squared_error: 5.6996e-05\n",
      "Epoch 7/1000\n",
      "34452/34452 [==============================] - 8s 224us/step - loss: 2.7907e-05 - mean_squared_error: 2.5572e-05 - val_loss: 5.9728e-05 - val_mean_squared_error: 5.7446e-05\n",
      "Epoch 8/1000\n",
      "34452/34452 [==============================] - 8s 229us/step - loss: 2.7813e-05 - mean_squared_error: 2.5531e-05 - val_loss: 5.9399e-05 - val_mean_squared_error: 5.7166e-05\n",
      "Epoch 9/1000\n",
      "34452/34452 [==============================] - 5s 150us/step - loss: 2.7710e-05 - mean_squared_error: 2.5497e-05 - val_loss: 5.9916e-05 - val_mean_squared_error: 5.7696e-05\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 10/1000\n",
      "34452/34452 [==============================] - 4s 129us/step - loss: 2.7140e-05 - mean_squared_error: 2.5092e-05 - val_loss: 5.8911e-05 - val_mean_squared_error: 5.6877e-05\n",
      "Epoch 11/1000\n",
      "34452/34452 [==============================] - 7s 202us/step - loss: 2.7103e-05 - mean_squared_error: 2.5071e-05 - val_loss: 5.9226e-05 - val_mean_squared_error: 5.7191e-05\n",
      "Epoch 12/1000\n",
      "34452/34452 [==============================] - 6s 177us/step - loss: 2.7086e-05 - mean_squared_error: 2.5057e-05 - val_loss: 5.9026e-05 - val_mean_squared_error: 5.7025e-05\n",
      "Epoch 13/1000\n",
      "34452/34452 [==============================] - 6s 179us/step - loss: 2.7070e-05 - mean_squared_error: 2.5058e-05 - val_loss: 5.9202e-05 - val_mean_squared_error: 5.7164e-05\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 14/1000\n",
      "34452/34452 [==============================] - 6s 168us/step - loss: 2.7002e-05 - mean_squared_error: 2.4980e-05 - val_loss: 5.9098e-05 - val_mean_squared_error: 5.7085e-05\n",
      "Epoch 15/1000\n",
      "34452/34452 [==============================] - 6s 169us/step - loss: 2.6994e-05 - mean_squared_error: 2.4982e-05 - val_loss: 5.9089e-05 - val_mean_squared_error: 5.7080e-05\n",
      "Epoch 16/1000\n",
      "34452/34452 [==============================] - 6s 182us/step - loss: 2.6990e-05 - mean_squared_error: 2.4980e-05 - val_loss: 5.9047e-05 - val_mean_squared_error: 5.7041e-05\n",
      "Epoch 17/1000\n",
      "34452/34452 [==============================] - 6s 184us/step - loss: 2.6987e-05 - mean_squared_error: 2.4983e-05 - val_loss: 5.9074e-05 - val_mean_squared_error: 5.7071e-05\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 18/1000\n",
      "34452/34452 [==============================] - 6s 171us/step - loss: 2.6978e-05 - mean_squared_error: 2.4974e-05 - val_loss: 5.9066e-05 - val_mean_squared_error: 5.7063e-05\n",
      "Epoch 19/1000\n",
      "34452/34452 [==============================] - 6s 163us/step - loss: 2.6977e-05 - mean_squared_error: 2.4974e-05 - val_loss: 5.9060e-05 - val_mean_squared_error: 5.7058e-05\n",
      "Epoch 20/1000\n",
      "34452/34452 [==============================] - 4s 125us/step - loss: 2.6977e-05 - mean_squared_error: 2.4974e-05 - val_loss: 5.9055e-05 - val_mean_squared_error: 5.7053e-05\n",
      "Epoch 21/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34452/34452 [==============================] - 6s 180us/step - loss: 2.6976e-05 - mean_squared_error: 2.4974e-05 - val_loss: 5.9051e-05 - val_mean_squared_error: 5.7049e-05\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "Epoch 22/1000\n",
      "34452/34452 [==============================] - 7s 192us/step - loss: 2.6975e-05 - mean_squared_error: 2.4973e-05 - val_loss: 5.9051e-05 - val_mean_squared_error: 5.7049e-05\n",
      "Epoch 23/1000\n",
      "34452/34452 [==============================] - 6s 173us/step - loss: 2.6975e-05 - mean_squared_error: 2.4973e-05 - val_loss: 5.9050e-05 - val_mean_squared_error: 5.7048e-05\n",
      "Epoch 24/1000\n",
      "34452/34452 [==============================] - 6s 160us/step - loss: 2.6975e-05 - mean_squared_error: 2.4973e-05 - val_loss: 5.9050e-05 - val_mean_squared_error: 5.7048e-05\n",
      "Epoch 25/1000\n",
      "34452/34452 [==============================] - 6s 172us/step - loss: 2.6975e-05 - mean_squared_error: 2.4973e-05 - val_loss: 5.9050e-05 - val_mean_squared_error: 5.7048e-05\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "Epoch 26/1000\n",
      "34452/34452 [==============================] - 6s 178us/step - loss: 2.6975e-05 - mean_squared_error: 2.4973e-05 - val_loss: 5.9050e-05 - val_mean_squared_error: 5.7048e-05\n",
      "Epoch 27/1000\n",
      "34452/34452 [==============================] - 6s 170us/step - loss: 2.6975e-05 - mean_squared_error: 2.4973e-05 - val_loss: 5.9050e-05 - val_mean_squared_error: 5.7048e-05\n",
      "Epoch 28/1000\n",
      "34452/34452 [==============================] - 6s 160us/step - loss: 2.6975e-05 - mean_squared_error: 2.4973e-05 - val_loss: 5.9050e-05 - val_mean_squared_error: 5.7048e-05\n",
      "Epoch 29/1000\n",
      "34452/34452 [==============================] - 8s 223us/step - loss: 2.6975e-05 - mean_squared_error: 2.4973e-05 - val_loss: 5.9050e-05 - val_mean_squared_error: 5.7048e-05\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "Epoch 30/1000\n",
      "34452/34452 [==============================] - 8s 222us/step - loss: 2.6975e-05 - mean_squared_error: 2.4973e-05 - val_loss: 5.9050e-05 - val_mean_squared_error: 5.7048e-05\n",
      "Epoch 00030: early stopping\n",
      "Train on 34452 samples, validate on 8636 samples\n",
      "Epoch 1/1000\n",
      "34452/34452 [==============================] - 5s 150us/step - loss: 3.5270e-05 - mean_squared_error: 2.9502e-05 - val_loss: 6.3269e-05 - val_mean_squared_error: 5.9161e-05\n",
      "Epoch 2/1000\n",
      "34452/34452 [==============================] - 4s 125us/step - loss: 3.2948e-05 - mean_squared_error: 2.8491e-05 - val_loss: 6.3143e-05 - val_mean_squared_error: 5.8758e-05\n",
      "Epoch 3/1000\n",
      "34452/34452 [==============================] - 7s 195us/step - loss: 3.2985e-05 - mean_squared_error: 2.8365e-05 - val_loss: 6.2596e-05 - val_mean_squared_error: 5.8740e-05\n",
      "Epoch 4/1000\n",
      "34452/34452 [==============================] - 8s 221us/step - loss: 3.2838e-05 - mean_squared_error: 2.8296e-05 - val_loss: 6.3174e-05 - val_mean_squared_error: 5.9059e-05\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 5/1000\n",
      "34452/34452 [==============================] - 6s 186us/step - loss: 2.8027e-05 - mean_squared_error: 2.5614e-05 - val_loss: 5.9361e-05 - val_mean_squared_error: 5.6942e-05\n",
      "Epoch 6/1000\n",
      "34452/34452 [==============================] - 6s 178us/step - loss: 2.7875e-05 - mean_squared_error: 2.5531e-05 - val_loss: 5.9762e-05 - val_mean_squared_error: 5.7488e-05\n",
      "Epoch 7/1000\n",
      "34452/34452 [==============================] - 6s 170us/step - loss: 2.7807e-05 - mean_squared_error: 2.5508e-05 - val_loss: 5.8801e-05 - val_mean_squared_error: 5.6730e-05\n",
      "Epoch 8/1000\n",
      "34452/34452 [==============================] - 6s 167us/step - loss: 2.7695e-05 - mean_squared_error: 2.5466e-05 - val_loss: 6.0230e-05 - val_mean_squared_error: 5.7967e-05\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 9/1000\n",
      "34452/34452 [==============================] - 6s 179us/step - loss: 2.7128e-05 - mean_squared_error: 2.5056e-05 - val_loss: 5.9483e-05 - val_mean_squared_error: 5.7444e-05\n",
      "Epoch 10/1000\n",
      "34452/34452 [==============================] - 5s 133us/step - loss: 2.7077e-05 - mean_squared_error: 2.5035e-05 - val_loss: 5.9157e-05 - val_mean_squared_error: 5.7136e-05\n",
      "Epoch 11/1000\n",
      "34452/34452 [==============================] - 5s 137us/step - loss: 2.7054e-05 - mean_squared_error: 2.5023e-05 - val_loss: 5.9376e-05 - val_mean_squared_error: 5.7362e-05\n",
      "Epoch 12/1000\n",
      "34452/34452 [==============================] - 7s 217us/step - loss: 2.7039e-05 - mean_squared_error: 2.5011e-05 - val_loss: 5.9068e-05 - val_mean_squared_error: 5.7043e-05\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 13/1000\n",
      "34452/34452 [==============================] - 6s 162us/step - loss: 2.6981e-05 - mean_squared_error: 2.4967e-05 - val_loss: 5.9173e-05 - val_mean_squared_error: 5.7162e-05\n",
      "Epoch 14/1000\n",
      "34452/34452 [==============================] - 6s 182us/step - loss: 2.6962e-05 - mean_squared_error: 2.4954e-05 - val_loss: 5.9211e-05 - val_mean_squared_error: 5.7199e-05\n",
      "Epoch 15/1000\n",
      "34452/34452 [==============================] - 5s 131us/step - loss: 2.6959e-05 - mean_squared_error: 2.4947e-05 - val_loss: 5.9228e-05 - val_mean_squared_error: 5.7219e-05\n",
      "Epoch 16/1000\n",
      "34452/34452 [==============================] - 5s 143us/step - loss: 2.6956e-05 - mean_squared_error: 2.4947e-05 - val_loss: 5.9219e-05 - val_mean_squared_error: 5.7211e-05\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 17/1000\n",
      "34452/34452 [==============================] - 8s 223us/step - loss: 2.6946e-05 - mean_squared_error: 2.4939e-05 - val_loss: 5.9222e-05 - val_mean_squared_error: 5.7215e-05\n",
      "Epoch 18/1000\n",
      "34452/34452 [==============================] - 5s 155us/step - loss: 2.6945e-05 - mean_squared_error: 2.4939e-05 - val_loss: 5.9224e-05 - val_mean_squared_error: 5.7217e-05\n",
      "Epoch 19/1000\n",
      "34452/34452 [==============================] - 4s 131us/step - loss: 2.6945e-05 - mean_squared_error: 2.4938e-05 - val_loss: 5.9224e-05 - val_mean_squared_error: 5.7218e-05\n",
      "Epoch 20/1000\n",
      "34452/34452 [==============================] - 7s 198us/step - loss: 2.6945e-05 - mean_squared_error: 2.4938e-05 - val_loss: 5.9224e-05 - val_mean_squared_error: 5.7218e-05\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "Epoch 21/1000\n",
      "34452/34452 [==============================] - 8s 226us/step - loss: 2.6943e-05 - mean_squared_error: 2.4937e-05 - val_loss: 5.9225e-05 - val_mean_squared_error: 5.7218e-05\n",
      "Epoch 22/1000\n",
      "34452/34452 [==============================] - 6s 182us/step - loss: 2.6943e-05 - mean_squared_error: 2.4937e-05 - val_loss: 5.9225e-05 - val_mean_squared_error: 5.7218e-05\n",
      "Epoch 23/1000\n",
      "34452/34452 [==============================] - 6s 179us/step - loss: 2.6943e-05 - mean_squared_error: 2.4937e-05 - val_loss: 5.9225e-05 - val_mean_squared_error: 5.7218e-05\n",
      "Epoch 24/1000\n",
      "34452/34452 [==============================] - 6s 168us/step - loss: 2.6943e-05 - mean_squared_error: 2.4937e-05 - val_loss: 5.9225e-05 - val_mean_squared_error: 5.7218e-05\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "Epoch 25/1000\n",
      "34452/34452 [==============================] - 6s 167us/step - loss: 2.6943e-05 - mean_squared_error: 2.4937e-05 - val_loss: 5.9225e-05 - val_mean_squared_error: 5.7218e-05\n",
      "Epoch 26/1000\n",
      "34452/34452 [==============================] - 6s 181us/step - loss: 2.6943e-05 - mean_squared_error: 2.4937e-05 - val_loss: 5.9225e-05 - val_mean_squared_error: 5.7218e-05\n",
      "Epoch 27/1000\n",
      "34452/34452 [==============================] - 6s 183us/step - loss: 2.6943e-05 - mean_squared_error: 2.4937e-05 - val_loss: 5.9225e-05 - val_mean_squared_error: 5.7218e-05\n",
      "Epoch 00027: early stopping\n",
      "Train on 34452 samples, validate on 8636 samples\n",
      "Epoch 1/1000\n",
      "34452/34452 [==============================] - 6s 175us/step - loss: 3.4815e-05 - mean_squared_error: 2.9223e-05 - val_loss: 6.4678e-05 - val_mean_squared_error: 6.0364e-05\n",
      "Epoch 2/1000\n",
      "34452/34452 [==============================] - 6s 173us/step - loss: 3.2952e-05 - mean_squared_error: 2.8352e-05 - val_loss: 6.3045e-05 - val_mean_squared_error: 5.8147e-05\n",
      "Epoch 3/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34452/34452 [==============================] - 6s 174us/step - loss: 3.2640e-05 - mean_squared_error: 2.8214e-05 - val_loss: 6.2522e-05 - val_mean_squared_error: 5.8592e-05\n",
      "Epoch 4/1000\n",
      "34452/34452 [==============================] - 6s 177us/step - loss: 3.2700e-05 - mean_squared_error: 2.8247e-05 - val_loss: 6.3058e-05 - val_mean_squared_error: 5.9274e-05\n",
      "Epoch 5/1000\n",
      "34452/34452 [==============================] - 6s 164us/step - loss: 3.3063e-05 - mean_squared_error: 2.8401e-05 - val_loss: 6.6592e-05 - val_mean_squared_error: 6.2245e-05\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 6/1000\n",
      "34452/34452 [==============================] - 6s 163us/step - loss: 2.8026e-05 - mean_squared_error: 2.5559e-05 - val_loss: 6.0210e-05 - val_mean_squared_error: 5.7810e-05\n",
      "Epoch 7/1000\n",
      "34452/34452 [==============================] - 6s 178us/step - loss: 2.7875e-05 - mean_squared_error: 2.5505e-05 - val_loss: 5.9344e-05 - val_mean_squared_error: 5.7074e-05\n",
      "Epoch 8/1000\n",
      "34452/34452 [==============================] - 6s 177us/step - loss: 2.7799e-05 - mean_squared_error: 2.5476e-05 - val_loss: 5.9271e-05 - val_mean_squared_error: 5.7039e-05\n",
      "Epoch 9/1000\n",
      "34452/34452 [==============================] - 6s 163us/step - loss: 2.7647e-05 - mean_squared_error: 2.5385e-05 - val_loss: 5.9620e-05 - val_mean_squared_error: 5.7342e-05\n",
      "Epoch 10/1000\n",
      "34452/34452 [==============================] - 8s 234us/step - loss: 2.7576e-05 - mean_squared_error: 2.5359e-05 - val_loss: 5.9758e-05 - val_mean_squared_error: 5.7599e-05\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 11/1000\n",
      "34452/34452 [==============================] - 7s 207us/step - loss: 2.6963e-05 - mean_squared_error: 2.4934e-05 - val_loss: 5.9173e-05 - val_mean_squared_error: 5.7162e-05\n",
      "Epoch 12/1000\n",
      "34452/34452 [==============================] - 7s 198us/step - loss: 2.6905e-05 - mean_squared_error: 2.4897e-05 - val_loss: 5.9475e-05 - val_mean_squared_error: 5.7418e-05\n",
      "Epoch 13/1000\n",
      "34452/34452 [==============================] - 7s 201us/step - loss: 2.6885e-05 - mean_squared_error: 2.4864e-05 - val_loss: 5.9326e-05 - val_mean_squared_error: 5.7309e-05\n",
      "Epoch 14/1000\n",
      "30784/34452 [=========================>....] - ETA: 1s - loss: 2.6839e-05 - mean_squared_error: 2.4825e-05"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-f9526a0e83e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#model_path + name_folder,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;31m#log_dir=None#\"./logs/H/\" + name + \"_\" + \"x\".join(list(map(str, structure))) + \"_\" + str(i)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m )\n",
      "\u001b[0;32m<ipython-input-30-1a05f5499106>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, dataset, filepath, learning_rate, log_dir)\u001b[0m\n\u001b[1;32m     59\u001b[0m             callbacks=[\n\u001b[1;32m     60\u001b[0m                 \u001b[0mearly_stopping\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                 \u001b[0mreduce_lr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m                 \u001b[0;31m#checkpoint,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m                 \u001b[0;31m#tensorboard\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1361\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1362\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1363\u001b[0;31m           validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1365\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    262\u001b[0m           \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m           \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2912\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_arrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_symbols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2914\u001b[0;31m     \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2915\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2916\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5763763278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#i+=1\n",
    "train_model(\n",
    "    model, \n",
    "    dataset, \n",
    "    #model_path + name_folder,\n",
    "    learning_rate=1e-3,\n",
    "    #log_dir=None#\"./logs/H/\" + name + \"_\" + \"x\".join(list(map(str, structure))) + \"_\" + str(i)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
